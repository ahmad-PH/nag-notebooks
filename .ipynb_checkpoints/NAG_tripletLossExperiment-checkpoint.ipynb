{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ahmad-PH/nag-notebooks/blob/master/NAG_tripletLossExperiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cqeZpz16do4y"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "def run_shell_command(cmd):\n",
    "  p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)\n",
    "  print(str(p.communicate()[0], 'utf-8'))\n",
    "\n",
    "\n",
    "def detect_env():\n",
    "    import os\n",
    "    if 'content' in os.listdir('/'):\n",
    "      return \"colab\"\n",
    "    else:\n",
    "      return \"IBM\"\n",
    "  \n",
    "def create_env():\n",
    "  if detect_env() == \"IBM\":\n",
    "    return IBMEnv()\n",
    "  elif detect_env() == \"colab\":\n",
    "    return ColabEnv()\n",
    "\n",
    "\n",
    "class Env:\n",
    "  def get_nag_util_files(self):\n",
    "      import os\n",
    "      \n",
    "      print(\"\\ngetting git files ...\")\n",
    "      if os.path.isdir(self.python_files_path):\n",
    "        os.chdir(self.python_files_path)\n",
    "        run_shell_command('git pull')\n",
    "        os.chdir(self.root_folder)\n",
    "      else:\n",
    "        run_shell_command('git clone https://github.com/ahmad-PH/nag-public.git')\n",
    "      print(\"done.\")\n",
    "  \n",
    "\n",
    "class IBMEnv(Env):\n",
    "    def __init__(self):\n",
    "      self.root_folder = \"/root/Derakhshani/adversarial\"\n",
    "      self.temp_csv_path = self.root_folder + \"/temp\"\n",
    "      self.python_files_path = self.root_folder + \"/nag-public\"\n",
    "      self.python_files_dir = \"NAG-11May-beforeDenoiser\"\n",
    "      \n",
    "      import sys\n",
    "      sys.path.append('./nag/nag_util')\n",
    "      \n",
    "    def get_csv_path(self):\n",
    "      return self.root_folder + \"/textual_notes/CSVs/\" + self.save_filename\n",
    "    \n",
    "    def get_models_path(self):\n",
    "      return self.root_folder + \"/models/\" + self.save_filename\n",
    "      \n",
    "    def setup(self):\n",
    "      self.get_nag_util_files()\n",
    "      \n",
    "      import os; import torch;\n",
    "      os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "      cuda_index = 0\n",
    "      os.environ['CUDA_VISIBLE_DEVICES']=str(cuda_index)\n",
    "#       defaults.device = torch.device('cuda:' + str(cuda_index))\n",
    "#       print('cuda:' + str(cuda_index))\n",
    "#       torch.cuda.set_device('cuda:1')\n",
    "      \n",
    "    def load_dataset(self, compressed_name, unpacked_name):\n",
    "      pass\n",
    "\n",
    "    def load_test_dataset(self, root_folder):\n",
    "      pass\n",
    "    \n",
    "    def set_data_path(self, path):\n",
    "      self.data_path = Path(self.root_folder + '/datasets/' + path)\n",
    "    \n",
    "        \n",
    "class ColabEnv(Env):\n",
    "    def __init__(self):\n",
    "      self.root_folder = '/content'\n",
    "      self.temp_csv_path = self.root_folder\n",
    "      self.python_files_path = self.root_folder + '/nag-public'\n",
    "      self.python_files_dir = \"NAG-11May-beforeDenoiser\"\n",
    "      self.torchvision_upgraded = False\n",
    "      \n",
    "    def get_csv_path(self):\n",
    "      return self.root_folder + '/gdrive/My Drive/DL/textual_notes/CSVs/' + self.save_filename\n",
    "    \n",
    "    def get_models_path(self):\n",
    "      return self.root_folder + \"/gdrive/My Drive/DL/models/\" + self.save_filename\n",
    "        \n",
    "    def setup(self):\n",
    "        # ######################################################\n",
    "        # # TODO remove this once torchvision 0.3 is present by\n",
    "        # # default in Colab\n",
    "        # ######################################################\n",
    "        global torchvision_upgraded\n",
    "        try:\n",
    "            torchvision_upgraded\n",
    "        except NameError:\n",
    "          !pip uninstall -y torchvision\n",
    "          !pip install https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl\n",
    "          torchvision_upgraded = True\n",
    "        else:\n",
    "          print(\"torchvision already upgraded\")\n",
    "          \n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/gdrive')\n",
    "        \n",
    "        self.get_nag_util_files()\n",
    "        \n",
    "    def load_dataset(self, compressed_name, unpacked_name):\n",
    "      if compressed_name not in os.listdir('.'):\n",
    "        print(compressed_name + ' not found, getting it from drive')\n",
    "        shutil.copyfile(\"/content/gdrive/My Drive/DL/{}.tar.gz\".format(compressed_name), \"./{}.tar.gz\".format(compressed_name))\n",
    "\n",
    "        gunzip_arg = \"./{}.tar.gz\".format(compressed_name)\n",
    "        !gunzip -f $gunzip_arg\n",
    "\n",
    "        tar_arg = \"./{}.tar\".format(compressed_name)\n",
    "        !tar -xvf $tar_arg > /dev/null\n",
    "\n",
    "        os.rename(unpacked_name, compressed_name)\n",
    "\n",
    "    #     ls_arg = \"./{}/train/n01440764\".format(compressed_name)\n",
    "    #     !ls $ls_arg\n",
    "\n",
    "        !rm $tar_arg\n",
    "\n",
    "        print(\"done\") \n",
    "      else:\n",
    "        print(compressed_name + \" found\")\n",
    "        \n",
    "    def load_test_dataset(self, root_folder):\n",
    "      test_folder = root_folder + '/test/'\n",
    "      if 'test' not in os.listdir(root_folder):\n",
    "        print('getting test dataset from drive')\n",
    "        os.mkdir(test_folder)\n",
    "        for i in range(1,11):\n",
    "          shutil.copy(\"/content/gdrive/My Drive/DL/full_test_folder/{}.zip\".format(i), test_folder)\n",
    "          shutil.unpack_archive(test_folder + \"/{}.zip\".format(i), test_folder)\n",
    "          os.remove(test_folder + \"/{}.zip\".format(i))\n",
    "          print(\"done with the {}th fragment\".format(i))\n",
    "      else:\n",
    "        print('test dataset found.')\n",
    "        \n",
    "    def set_data_path(self, path):\n",
    "      self.data_path = Path('./' + path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "id": "YyZUYSjBi9K9",
    "outputId": "5ef25a03-c55f-43de-8460-a1afde369fd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "getting git files ...\n",
      "Already up-to-date.\n",
      "\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "env = create_env()\n",
    "env.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Ev7jcRKoARg"
   },
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.imports import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.utils.mem import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import sys; import os; import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3_1aE41PZAMw"
   },
   "outputs": [],
   "source": [
    "sys.path.append(env.python_files_path + '/' + env.python_files_dir)\n",
    "\n",
    "from nag_util import *\n",
    "import nag_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tltucTv2ep9-"
   },
   "outputs": [],
   "source": [
    "# mode = \"sanity_check\"\n",
    "mode = \"normal\"\n",
    "# mode = \"div_metric_calc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "SO1h55obXzOv",
    "outputId": "54414cc5-84d5-4f45-ecab-87374a58dd33"
   },
   "outputs": [],
   "source": [
    "if mode == \"normal\":\n",
    "  env.load_dataset('dataset','data')\n",
    "  env.set_data_path('dataset')\n",
    "elif mode == \"sanity_check\":\n",
    "  env.load_dataset('dataset_sanity_check_small', 'dataset_sanity_check_small')  \n",
    "  env.set_data_path('dataset_sanity_check_small')\n",
    "elif mode == \"div_metric_calc\":\n",
    "  env.load_dataset('dataset','data')\n",
    "  env.set_data_path('dataset')\n",
    "  env.load_test_dataset(str(env.data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "koaQZmjMom7w"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "gpu_flag = True\n",
    "nag_util.batch_size = batch_size; nag_util.gpu_flag = gpu_flag;\n",
    "# nag_util.set_globals(gpu_flag, batch_size)\n",
    "tfms = get_transforms(do_flip=False, max_rotate=0)\n",
    "data = (ImageList.from_folder(env.data_path)\n",
    "        .split_by_folder(valid=('test' if mode == 'div_metric_calc' else 'valid'))\n",
    "        .label_from_folder()\n",
    "        .transform(tfms, size=224)\n",
    "        .databunch(bs=batch_size, num_workers=1)\n",
    "        .normalize(imagenet_stats))\n",
    "\n",
    "# data.show_batch(rows=2, figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kDBkRV8yovwV"
   },
   "outputs": [],
   "source": [
    "model = models.resnet50\n",
    "# model = models.resnet152\n",
    "# model = models.vgg16_bn\n",
    "# model = torchvision.models.googlenet\n",
    "model_name = model.__name__\n",
    "z_dim = 1000\n",
    " \n",
    "arch = SoftmaxWrapper(model(pretrained=True).cuda().eval())\n",
    "nag_util.arch = arch\n",
    "requires_grad(arch, False)\n",
    "\n",
    "# vgg:\n",
    "# layers = []\n",
    "# blocks = [i-1 for i,o in enumerate(children(arch.features)) if isinstance(o, nn.MaxPool2d)]\n",
    "# layers = [arch.features[i] for i in blocks]\n",
    "# layer_weights = [1] * len(layers)\n",
    "\n",
    "layers = [\n",
    "    arch.softmax\n",
    "]\n",
    "\n",
    "layer_weights = [1.] * len(layers)\n",
    "\n",
    "# inception:\n",
    "# layers = [\n",
    "#     arch.Conv2d_1a_3x3,\n",
    "#     arch.Mixed_6e,\n",
    "#     arch.Mixed_7a,\n",
    "#     arch.fc    \n",
    "# ]\n",
    "# layer_weights = [1.0/4.0] * len(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gen(nn.Module):\n",
    "  def __init__(self, z_dim, gf_dim=64, y_dim = None, df_dim = 64, image_shape = [3,128,128]):\n",
    "    super(Gen, self).__init__()\n",
    "\n",
    "    self.bs = None\n",
    "    self.z_dim = z_dim\n",
    "    self.gf_dim = gf_dim\n",
    "    self.y_dim = y_dim\n",
    "    self.df_dim = df_dim\n",
    "    self.image_shape = image_shape\n",
    "\n",
    "    self.z_ = nn.Linear(self.z_dim, self.gf_dim * 7 * 4 * 4, bias=True)\n",
    "    self.z_.bias.data.fill_(0)\n",
    "    self.BN_ = nn.BatchNorm2d(self.gf_dim * 7)\n",
    "\n",
    "    self.CT2d_1 = deconv_layer(self.gf_dim * 8, self.gf_dim * 4, k_size = (5,5), pad = (2,2))\n",
    "    \n",
    "    self.CT2d_2 = deconv_layer(self.gf_dim * 5, self.gf_dim * 2)\n",
    "\n",
    "    self.half = max(self.gf_dim // 2, 1) \n",
    "    self.CT2d_3 = deconv_layer(self.gf_dim * 2 + self.half, self.gf_dim * 1)\n",
    "\n",
    "    self.quarter = max(self.gf_dim // 4, 1)\n",
    "    self.CT2d_4 = deconv_layer(self.gf_dim * 1 + self.quarter, self.gf_dim * 1)\n",
    "\n",
    "    self.eighth = max(self.gf_dim // 8, 1)\n",
    "    self.CT2d_5 = deconv_layer(self.gf_dim * 1 + self.eighth, self.gf_dim * 1)\n",
    "\n",
    "    # sixteenth = max(self.gf_dim // 16, 1)\n",
    "    self.CT2d_6 = deconv_layer(self.gf_dim * 1 + self.eighth, self.gf_dim * 1)\n",
    "\n",
    "    # sixteenth = max(self.gf_dim // 16, 1)\n",
    "    self.CT2d_7 = deconv_layer(self.gf_dim * 1 + self.eighth, 3, k_size = (5,5), s = (1,1), pad = (2,2), activation = False)\n",
    "\n",
    "  def randomized_deconv_layer(self, h_input, z_size_0, z_size_1, deconv_layer, expected_output_size):\n",
    "    h_input_z = self.make_z([self.bs, z_size_0, z_size_1, z_size_1])\n",
    "    h_input = torch.cat([h_input, h_input_z], dim = 1)\n",
    "    output = deconv_layer(h_input)\n",
    "    assert output.shape[2:] == (expected_output_size, expected_output_size), \\\n",
    "            \"Unexpected output shape at randomized_deconv_layer. expected\" + \\\n",
    "            \"({0},{0}), got {1}\".format(expected_output_size, output.shape[2:])\n",
    "    return output\n",
    "  \n",
    "  def forward_z(self, z):\n",
    "    self.bs = z.shape[0]\n",
    "    \n",
    "    h0 = F.relu(self.BN_(self.z_(z).contiguous().view(self.bs, -1, 4, 4)))\n",
    "    assert h0.shape[2:] == (4, 4), \"Non-expected shape, it shoud be (4,4)\"\n",
    "\n",
    "    h1 = self.randomized_deconv_layer(h0, self.gf_dim, 4, self.CT2d_1, 7)\n",
    "    h2 = self.randomized_deconv_layer(h1, self.gf_dim, 7, self.CT2d_2, 14)\n",
    "    h3 = self.randomized_deconv_layer(h2, self.half, 14, self.CT2d_3, 28)\n",
    "    h4 = self.randomized_deconv_layer(h3, self.quarter, 28, self.CT2d_4, 56)\n",
    "    h5 = self.randomized_deconv_layer(h4, self.eighth, 56, self.CT2d_5, 112)\n",
    "    h6 = self.randomized_deconv_layer(h5, self.eighth, 112, self.CT2d_6, 224)\n",
    "    h7 = self.randomized_deconv_layer(h6, self.eighth, 224, self.CT2d_7, 224)\n",
    "\n",
    "    ksi = 10.0\n",
    "    output_coeff = ksi / (255.0 * np.mean(imagenet_stats[1])) \n",
    "    # this coeff scales the output to be appropriate for images that are \n",
    "    # normalized using imagenet_stats (and are hence in the approximate [-2.5, 2.5]\n",
    "    # interval)\n",
    "    return output_coeff * torch.tanh(h7)\n",
    "\n",
    "  def forward(self, inputs):\n",
    "    self.bs = inputs.shape[0]\n",
    "\n",
    "    benign_preds_onehot = arch(inputs)\n",
    "    benign_preds = torch.argmax(benign_preds_onehot, dim = 1)\n",
    "    \n",
    "    z = torch.zeros([self.bs, 1000]).cuda()\n",
    "    for i in range(self.bs):\n",
    "      random_label = self.randint(0,1000, exclude = benign_preds[i].item())\n",
    "      z[i][random_label] = 1.\n",
    "    \n",
    "    z_out = self.forward_z(z)\n",
    "    \n",
    "    return z_out, None, None, inputs, benign_preds_onehot, z\n",
    "  \n",
    "  @staticmethod\n",
    "  def randint(low, high, exclude):\n",
    "    temp = np.random.randint(low, high - 1)\n",
    "    if temp == exclude:\n",
    "      temp = temp + 1\n",
    "    return temp\n",
    "  \n",
    "  def forward_single_z(self, z):\n",
    "    return self.forward_z(z[None]).squeeze()\n",
    "           \n",
    "  \n",
    "  def make_triplet_samples(self, z, margin, r2, r3):\n",
    "    positive_sample = z + self.random_vector_volume(z.shape, 0, margin).cuda() \n",
    "    negative_sample = z + self.random_vector_volume(z.shape, r2, r3).cuda()\n",
    "    return positive_sample, negative_sample\n",
    "\n",
    "  def random_vector_surface(self, shape, r = 1.):\n",
    "    mat = torch.randn(size=shape).cuda()\n",
    "    norm = torch.norm(mat, p=2, dim=1, keepdim = True).cuda()\n",
    "    return (mat/norm) * r\n",
    "\n",
    "  \n",
    "  def random_vector_volume(self, shape, inner_r, outer_r):\n",
    "    fraction = torch.empty(shape[0]).uniform_(inner_r, outer_r).cuda()\n",
    "    fraction = ((fraction / outer_r) ** (1 / shape[1])) * outer_r # volume-normalize the fraction\n",
    "    fraction.unsqueeze_(-1)\n",
    "    return self.random_vector_surface(shape, 1) * fraction\n",
    "\n",
    "  def make_z(self, in_shape):\n",
    "    return torch.empty(in_shape).cuda().uniform_(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NkfbLWEQqRA_"
   },
   "outputs": [],
   "source": [
    "def js_distance(x1, x2):\n",
    "  m = 0.5 * (x1 + x2)\n",
    "  return 0.5 * (F.kl_div(x1, m) + F.kl_div(x2, m))\n",
    "\n",
    "def kl_distance(x1, x2):\n",
    "  inp = torch.log(x1)\n",
    "  target = x2\n",
    "  return F.kl_div(inp, target, reduction='batchmean')\n",
    "\n",
    "def distrib_distance(x1, x2):\n",
    "  x1 = tensorify(x1)\n",
    "  x2 = tensorify(x2)\n",
    "  x1 = x1 / torch.sum(x1)\n",
    "  x2 = x2 / torch.sum(x2)\n",
    "  return kl_distance(x1[None], x2[None])\n",
    "\n",
    "def distrib_distance(x1, x2):\n",
    "  if not isinstance(x1, torch.Tensor): x1 = torch.tensor(x1)\n",
    "  if not isinstance(x2, torch.Tensor): x2 = torch.tensor(x2)\n",
    "  x1 = x1 * 100. / torch.sum(x1)\n",
    "  x2 = x2 * 100. / torch.sum(x2)\n",
    "  return torch.norm(x1 - x2, 2)\n",
    "\n",
    "def distance_from_uniform(x):\n",
    "  return distrib_distance(x, [1.] * len(x))\n",
    "\n",
    "def wasserstein_distance(x1, x2):\n",
    "  return torch.mean(x1 - x2)\n",
    "\n",
    "def l1_distance(x1, x2):\n",
    "  return F.l1_loss(x1, x2)\n",
    "\n",
    "def l2_distance(x1, x2):\n",
    "  return F.mse_loss(x1 * 10, x2 * 10)\n",
    "\n",
    "def mse_loss(x1, x2):\n",
    "  return F.mse_loss(x1, x2)\n",
    "\n",
    "def cos_distance(x1, x2, dim = 1):\n",
    "  return -1 * torch.mean(F.cosine_similarity(x1, x2, dim=dim))\n",
    "\n",
    "triplet_call_cnt = 0\n",
    "\n",
    "def triplet_loss(anchor, positive, negative, distance_func, margin):\n",
    "  # max distance when using l1_distance is 2\n",
    "  # max distacne when using l2-distance is sqrt(2)\n",
    "#   print(\"anchor: \", anchor.min(), anchor.max())\n",
    "  ap_dist = distance_func(anchor, positive)\n",
    "  an_dist = distance_func(anchor, negative)\n",
    "\n",
    "  global triplet_call_cnt\n",
    "  triplet_call_cnt += 1\n",
    "  if triplet_call_cnt % 10 in [0,1] : #and anchor.shape[1] == 1000:\n",
    "#     print(\"a: \", end=\"\"); print_big_vector(anchor[0])\n",
    "#     print(\"p: \", end=\"\"); print_big_vector(positive[0])\n",
    "#     print(\"n: \", end=\"\"); print_big_vector(negative[0])\n",
    "#     print(\"ap_dist: {}, an_dist: {}\".format(ap_dist, an_dist))\n",
    "    print(\"func:{}, ap_dist: {}, an_dist: {}\".format(distance_func.__name__, ap_dist, an_dist))\n",
    "    \n",
    "  return torch.mean(F.relu(ap_dist - an_dist + margin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hsFgfiN8EV7z"
   },
   "outputs": [],
   "source": [
    "def diversity_loss(input, target):\n",
    "#   return -1 * torch.mean(torch.pow(f_x_a-f_x_s,2))\n",
    "  if input.shape[0] != batch_size:\n",
    "    print(\"input shape: \", input.shape)\n",
    "    print(\"target shape: \", target.shape, \"\\n\\n\")\n",
    "  return torch.mean(F.cosine_similarity(\n",
    "    input.view([batch_size, -1]),\n",
    "    target.view([batch_size, -1]), \n",
    "  ))\n",
    "\n",
    "# def fool_loss(input, target):\n",
    "#     true_class = torch.argmax(target, dim=1).view(-1,1).long()\n",
    "#     return -1 * torch.log(torch.mean(1 - input.gather(1, true_class)))\n",
    "\n",
    "def fool_loss_old(input, target, trash):\n",
    "  print(\"fool_loss:\")\n",
    "  true_class = torch.argmax(target, dim=1).view(-1,1).long()\n",
    "  print(true_class)\n",
    "  print(\"input: \", input.shape)\n",
    "  a = input.gather(1, true_class)\n",
    "  print(a)\n",
    "  print(1 - a)\n",
    "  print(torch.mean(1 - a))\n",
    "  print(torch.log(torch.mean(1-a)))\n",
    "  print(\"\\n\\n\")\n",
    "  # this is wrong! first log should be taken, THEN mean.\n",
    "  return -1 * torch.log(torch.mean(1 - input.gather(1, true_class)))\n",
    "\n",
    "fool_loss_count = 0\n",
    "\n",
    "def fool_loss(model_output, target_labels):\n",
    "  target_labels = target_labels.view(-1, 1).long().cuda()\n",
    "  target_probabilities = model_output.gather(1, target_labels)\n",
    "  epsilon = 1e-10\n",
    "  # highest possible fool_loss is - log(1e-10) == 23\n",
    "  result = torch.mean(-1 * torch.log(target_probabilities + epsilon))\n",
    "  \n",
    "  global fool_loss_count\n",
    "  fool_loss_count += 1\n",
    "  if fool_loss_count % 20 == 0:\n",
    "    print(\"target probs {}, loss: {}: \".format(target_probabilities, result))\n",
    "  \n",
    "  return result\n",
    "\n",
    "def validation(gen_output, target):\n",
    "  perturbations, _, _, clean_images, _, _ = gen_output\n",
    "  perturbed_images = clean_images + perturbations\n",
    "  benign_preds = torch.argmax(arch(clean_images), 1)\n",
    "  adversary_preds = torch.argmax(arch(perturbed_images), 1)\n",
    "  return (benign_preds != adversary_preds).float().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureLoss(nn.Module):\n",
    "    def __name__(self):\n",
    "      return \"feature_loss\"\n",
    "  \n",
    "    def __init__(self, dis, layers, layer_weights):\n",
    "        super().__init__()\n",
    "        \n",
    "        # define generator here \n",
    "        self.dis = dis\n",
    "        self.diversity_layers = layers\n",
    "        self.hooks = hook_outputs(self.diversity_layers, detach=False)\n",
    "        self.weights = layer_weights\n",
    "        self.metric_names = [\"fool_loss\"] #+ [f\"div_loss_{i}\" for i in range(len(layers))] #maybe Gram\n",
    "#         self.triplet_hooks = hook_outputs([arch.m.features[4]], detach=False)\n",
    "    \n",
    "    def make_features(self, x, clone=False):\n",
    "        y = self.dis(x)\n",
    "        return y, [(o.clone() if clone else o) for o in self.hooks.stored]\n",
    "  \n",
    "    def forward(self, inp, target):\n",
    "      sigma_B, _, _, X_B, B_Y, z = inp\n",
    "\n",
    "      X_A = X_B + sigma_B\n",
    "#       X_S = self.add_perturbation_shuffled(X_B, sigma_B) # Shuffled Addversarial Examples\n",
    "\n",
    "      A_Y, A_feat = self.make_features(X_A)\n",
    "#       _, S_feat = self.make_features(X_S)\n",
    "\n",
    "      chosen_labels = z.argmax(dim=1)\n",
    "      fooling_loss =  fool_loss(A_Y, chosen_labels)\n",
    "\n",
    "#       raw_diversity_losses = [diversity_loss(a_f, s_f) for a_f, s_f in zip(A_feat, S_feat)]\n",
    "#       weighted_diversity_losses = [diversity_loss(a_f, s_f) * weight for a_f, s_f, weight in zip(A_feat, S_feat, self.weights)]\n",
    "\n",
    "#       self.losses = [fooling_loss] + weighted_diversity_losses\n",
    "#       self.metrics = dict(zip(self.metric_names, [fooling_loss] + raw_diversity_losses))\n",
    "\n",
    "      self.losses = [fooling_loss]\n",
    "      self.metrics = dict(zip(self.metric_names, [fooling_loss]))\n",
    "\n",
    "      return sum(self.losses)\n",
    "  \n",
    "    def add_perturbation_shuffled(self, inp, perturbation):\n",
    "#         j = torch.randperm(inp.shape[0])\n",
    "        j = derangement(inp.shape[0])\n",
    "        return inp.add(perturbation[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qd9gXUy_ovww"
   },
   "outputs": [],
   "source": [
    "feat_loss = FeatureLoss(arch, layers, layer_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IfZKdYD2MSdi"
   },
   "outputs": [],
   "source": [
    "env.save_filename = 'resnet50_x'\n",
    "\n",
    "if Path(env.get_csv_path() + '.csv').exists(): raise FileExistsError(\"csv_path already exists\")\n",
    "if Path(env.get_models_path()).exists(): raise FileExistsError(\"models_path already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b9J20CBLS8S9"
   },
   "outputs": [],
   "source": [
    "learn = None; gc.collect()\n",
    "csv_logger = partial(ImmediateCSVLogger, filename= env.temp_csv_path + '/' + env.save_filename)\n",
    "# learn = Learner(data, Gen(z_dim=10), loss_func = feat_loss, metrics=[validation], callback_fns=LossMetrics, opt_func = optim.SGD)\n",
    "# learn = Learner(data, Gen(z_dim=z_dim), loss_func = feat_loss, metrics=[validation], callback_fns=[LossMetrics, DiversityWeightsScheduler])\n",
    "learn = Learner(data, Gen(z_dim=z_dim), loss_func = feat_loss, metrics=[validation], callback_fns=[LossMetrics, csv_logger])\n",
    "# load_starting_point(learn, model_name, z_dim)\n",
    "# random_seed(42, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wk9E0AUm9rmn"
   },
   "outputs": [],
   "source": [
    "# learn.lr_find(1e-6, 1000)\n",
    "# learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0wOZYzOHDEdB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/mmderakhshani/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type FeatureLoss. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/root/anaconda3/envs/mmderakhshani/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type SoftmaxWrapper. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/root/anaconda3/envs/mmderakhshani/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Gen. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (9000 items)\n",
       "x: ImageList\n",
       "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
       "y: CategoryList\n",
       "n02454379,n02454379,n02454379,n02454379,n02454379\n",
       "Path: /root/Derakhshani/adversarial/datasets/dataset;\n",
       "\n",
       "Valid: LabelList (1000 items)\n",
       "x: ImageList\n",
       "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
       "y: CategoryList\n",
       "n02454379,n02397096,n02090379,n01729977,n02268853\n",
       "Path: /root/Derakhshani/adversarial/datasets/dataset;\n",
       "\n",
       "Test: None, model=Gen(\n",
       "  (z_): Linear(in_features=1000, out_features=7168, bias=True)\n",
       "  (BN_): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (CT2d_1): deconv_layer(\n",
       "    (CT2d): ConvTranspose2d(512, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (BN2d): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (CT2d_2): deconv_layer(\n",
       "    (CT2d): ConvTranspose2d(320, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (BN2d): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (CT2d_3): deconv_layer(\n",
       "    (CT2d): ConvTranspose2d(160, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (BN2d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (CT2d_4): deconv_layer(\n",
       "    (CT2d): ConvTranspose2d(80, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (BN2d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (CT2d_5): deconv_layer(\n",
       "    (CT2d): ConvTranspose2d(72, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (BN2d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (CT2d_6): deconv_layer(\n",
       "    (CT2d): ConvTranspose2d(72, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (BN2d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (CT2d_7): deconv_layer(\n",
       "    (CT2d): ConvTranspose2d(72, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (BN2d): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FeatureLoss(\n",
       "  (dis): SoftmaxWrapper(\n",
       "    (m): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "    )\n",
       "    (softmax): Softmax()\n",
       "  )\n",
       "), metrics=[<function validation at 0x7f228ae9dae8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/root/Derakhshani/adversarial/datasets/dataset'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.callbacks.loss_metrics.LossMetrics'>, functools.partial(<class 'nag_util.ImmediateCSVLogger'>, filename='/root/Derakhshani/adversarial/temp/resnet50_x')], callbacks=[], layer_groups=[Sequential(\n",
       "  (0): Linear(in_features=1000, out_features=7168, bias=True)\n",
       "  (1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ConvTranspose2d(512, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "  (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): ConvTranspose2d(320, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): ConvTranspose2d(160, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): ConvTranspose2d(80, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (10): ConvTranspose2d(72, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (12): ConvTranspose2d(72, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (14): ConvTranspose2d(72, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (15): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")], add_time=True, silent=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !cp \"/content/gdrive/My Drive/DL/models/vgg16_12-last.pth\"  \"/content/\"\n",
    "# learn.load('/content/vgg16_12-last')\n",
    "\n",
    "learn.load('/root/Derakhshani/adversarial/models/vgg16_28/vgg16_28_89')\n",
    "# learn.load('/root/Derakhshani/adversarial/models/vgg16_12-last')\n",
    "# learn.load('/root/Derakhshani/adversarial/models/resnet50-11_39')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 783
    },
    "colab_type": "code",
    "id": "LA1ffVbbEwQS",
    "outputId": "cb14c6fd-158b-4deb-c931-792b0fd7b3a2"
   },
   "outputs": [],
   "source": [
    "if mode == \"sanity_check\":\n",
    "  print(\"\\n\\n\\nWARNING: you are training on a sanity_check dataset.\\n\\n\\n\\n\")\n",
    "if len(learn.callback_fns) == 1:\n",
    "  print(\"\\n\\n\\nWARNING: you are not using the DiversityWeightsScheduler callback.\\n\\n\\n\")\n",
    "\n",
    "saver_best = SaveModelCallback(learn, every='improvement', monitor='validation', name=env.save_filename + \"-best\")\n",
    "saver_every_epoch = SaveModelCallback(learn, every='epoch', name=env.save_filename)\n",
    "\n",
    "learn.fit(70, lr=5e-03, wd = 0., callbacks=[saver_best, saver_every_epoch])\n",
    "\n",
    "# learn.fit_one_cycle(8, max_lr=5e-01) #mohammad's setting that got 77 validation start on resnet with diversity loss on AdaptiveAvgPool2d\n",
    "# learn.fit_one_cycle(5, max_lr=2e-2) #used for vgg-19-bn\n",
    "# learn.fit_one_cycle(5, max_lr=3e-3) # used for resnet50\n",
    "\n",
    "shutil.copyfile(env.temp_csv_path + '/' + env.save_filename + \".csv\", env.get_csv_path() + '.csv')\n",
    "shutil.copytree(env.data_path/\"models\", env.get_models_path())\n",
    "shutil.rmtree(env.data_path/\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MO2fZ-hSSUzJ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# z1 = torch.empty(10).uniform_(-1,1).cuda()\n",
    "# z2 = torch.empty(10).uniform_(-1,1).cuda()\n",
    "z1 = torch.tensor([0.8, -0.5] * 5).cuda()\n",
    "z2 = torch.tensor([-1.] * 10).cuda()\n",
    "print(\"z1: \", z1)\n",
    "print(\"z2: \", z2)\n",
    "print(\"distance: \", torch.norm(z1-z2,p=2))\n",
    "model = learn.model.eval()\n",
    "\n",
    "z_s = interpolate(z1, z2, 0.1)\n",
    "print(len(z_s))\n",
    "\n",
    "for i,z in enumerate(z_s):\n",
    "  img = noise_to_image(model.forward_single_z(z))\n",
    "  img.show()\n",
    "  #img.save('./pics/' + str(i) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DGuGN7B7V0Xt"
   },
   "outputs": [],
   "source": [
    "def generate_perturbations(learn, n_perturbations):\n",
    "  initial_training_mode = learn.model.training\n",
    "  \n",
    "  model = learn.model.eval()\n",
    "  input_img = (learn.data.valid_ds[0][0].data)[None].cuda()\n",
    "  perturbations = []\n",
    "  for i in range(n_perturbations):\n",
    "    perturbation = model(input_img)[0].squeeze()\n",
    "    perturbations.append(perturbation)\n",
    "    \n",
    "  learn.model.train(initial_training_mode)  \n",
    "  return perturbations\n",
    "\n",
    "def compute_prediction_histogram(learn, perturbation, verbose=False):\n",
    "  pred_hist = [0] * 1000\n",
    "  batch_no = -1\n",
    "  for batch, _ in learn.data.valid_dl:\n",
    "    batch_no += 1\n",
    "    if batch_no % 100 == 0 and verbose: print (\"at batch no {}\".format(batch_no))\n",
    "    perturbed_batch = batch + perturbation[None]\n",
    "    preds = arch(perturbed_batch).argmax(1)\n",
    "    for pred in preds:\n",
    "      pred_hist[pred] += 1\n",
    "  return pred_hist\n",
    "\n",
    "\n",
    "def compute_mean_prediction_histogram(learn, perturbations):\n",
    "  pred_histogram = torch.tensor([0] * 1000).detach_()\n",
    "  for j, perturbation in enumerate(perturbations):\n",
    "    pred_histogram_j = torch.tensor(compute_prediction_histogram(learn, perturbation, True)).detach_()\n",
    "    pred_histogram += pred_histogram_j\n",
    "    print(\"finished creating histogram for the {}th perturbation\".format(j))\n",
    "  \n",
    "  pred_histogram = pred_histogram.float() / len(perturbations)\n",
    "  return pred_histogram.tolist()\n",
    "\n",
    "\n",
    "def diversity(learn, n_perturbations, percentage):\n",
    "  pred_histogram = compute_mean_prediction_histogram(\n",
    "      learn, generate_perturbations(learn, n_perturbations)\n",
    "  )\n",
    "  print(\"finished creating the prediction histogram\")\n",
    "  pred_histogram_sum = np.sum(pred_histogram)\n",
    "\n",
    "  indexed_pred_histogram = [(i, hist_element) for i,hist_element in  \n",
    "                            enumerate(pred_histogram)]\n",
    "\n",
    "  indexed_pred_histogram.sort(key=lambda x: x[1], reverse = True)\n",
    "\n",
    "  cumulative_percent = 0\n",
    "  n_used_classes = 0\n",
    "  top_classes = []\n",
    "  while cumulative_percent < percentage:\n",
    "    hist_elem = indexed_pred_histogram[n_used_classes]\n",
    "    cumulative_percent += (hist_elem[1] / pred_histogram_sum) * 100.\n",
    "    top_classes.append(hist_elem[0])\n",
    "    n_used_classes += 1\n",
    "\n",
    "  return n_used_classes, indexed_pred_histogram, top_classes\n",
    "\n",
    "# idea : have 1k noises (1 for each class), then start iterating the dataset, and for each image, randomly apply one noise and record the result\n",
    "def targeted_diversity(learn, percentage):\n",
    "  model = learn.model.eval()\n",
    "\n",
    "  one_hot_conditions = [torch.empty(z_dim).uniform_(0,1).cuda().detach() for _ in range(200)]\n",
    "#   for i in range(z_dim):\n",
    "#     one_hot_conditions[i][i] = 1.\n",
    "\n",
    "  perturbations = [model.forward_single_z(z) for z in one_hot_conditions]\n",
    "\n",
    "  hist = [0.] * z_dim\n",
    "  batch_no = -1\n",
    "  for batch, _ in learn.data.valid_dl:\n",
    "    batch_no += 1\n",
    "    if batch_no % 100 == 0 : print(\"at batch_no {}\".format(batch_no))\n",
    "    perturbed_batch = batch + perturbations[np.random.randint(0,len(perturbations))][None]\n",
    "    preds = arch(perturbed_batch).argmax(1)\n",
    "    for pred in preds:\n",
    "      hist[pred] += 1\n",
    "\n",
    "  pred_histogram_sum = np.sum(hist)\n",
    "  indexed_pred_histogram = [(i, hist_element) for i,hist_element in  \n",
    "                            enumerate(hist)]\n",
    "\n",
    "  indexed_pred_histogram.sort(key=lambda x: x[1], reverse = True)\n",
    "\n",
    "  cumulative_percent = 0\n",
    "  n_used_classes = 0\n",
    "  while cumulative_percent < percentage:\n",
    "    hist_elem = indexed_pred_histogram[n_used_classes]\n",
    "    cumulative_percent += (hist_elem[1] / pred_histogram_sum) * 100.\n",
    "    n_used_classes += 1\n",
    "\n",
    "  return n_used_classes, indexed_pred_histogram\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at batch_no 0\n",
      "at batch_no 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(626,\n",
       " [(815, 16.00),\n",
       "  (794, 13.00),\n",
       "  (489, 10.00),\n",
       "  (828, 9.00),\n",
       "  (904, 9.00),\n",
       "  (669, 7.00),\n",
       "  (55, 6.00),\n",
       "  (84, 6.00),\n",
       "  (490, 5.00),\n",
       "  (632, 5.00),\n",
       "  (770, 5.00),\n",
       "  (854, 5.00),\n",
       "  (69, 4.00),\n",
       "  (87, 4.00),\n",
       "  (94, 4.00),\n",
       "  (182, 4.00),\n",
       "  (401, 4.00),\n",
       "  (457, 4.00),\n",
       "  (523, 4.00),\n",
       "  (562, 4.00),\n",
       "  (579, 4.00),\n",
       "  (735, 4.00),\n",
       "  (753, 4.00),\n",
       "  (791, 4.00),\n",
       "  (905, 4.00),\n",
       "  (46, 3.00),\n",
       "  (61, 3.00),\n",
       "  (68, 3.00),\n",
       "  (109, 3.00),\n",
       "  (128, 3.00),\n",
       "  (186, 3.00),\n",
       "  (189, 3.00),\n",
       "  (238, 3.00),\n",
       "  (264, 3.00),\n",
       "  (318, 3.00),\n",
       "  (399, 3.00),\n",
       "  (411, 3.00),\n",
       "  (414, 3.00),\n",
       "  (472, 3.00),\n",
       "  (474, 3.00),\n",
       "  (511, 3.00),\n",
       "  (515, 3.00),\n",
       "  (545, 3.00),\n",
       "  (556, 3.00),\n",
       "  (572, 3.00),\n",
       "  (597, 3.00),\n",
       "  (611, 3.00),\n",
       "  (641, 3.00),\n",
       "  (700, 3.00),\n",
       "  (709, 3.00),\n",
       "  (772, 3.00),\n",
       "  (801, 3.00),\n",
       "  (808, 3.00),\n",
       "  (826, 3.00),\n",
       "  (839, 3.00),\n",
       "  (893, 3.00),\n",
       "  (898, 3.00),\n",
       "  (981, 3.00),\n",
       "  (1, 2.00),\n",
       "  (2, 2.00),\n",
       "  (12, 2.00),\n",
       "  (19, 2.00),\n",
       "  (21, 2.00),\n",
       "  (34, 2.00),\n",
       "  (42, 2.00),\n",
       "  (47, 2.00),\n",
       "  (48, 2.00),\n",
       "  (50, 2.00),\n",
       "  (57, 2.00),\n",
       "  (58, 2.00),\n",
       "  (62, 2.00),\n",
       "  (65, 2.00),\n",
       "  (75, 2.00),\n",
       "  (76, 2.00),\n",
       "  (91, 2.00),\n",
       "  (99, 2.00),\n",
       "  (107, 2.00),\n",
       "  (108, 2.00),\n",
       "  (113, 2.00),\n",
       "  (116, 2.00),\n",
       "  (124, 2.00),\n",
       "  (131, 2.00),\n",
       "  (151, 2.00),\n",
       "  (195, 2.00),\n",
       "  (197, 2.00),\n",
       "  (198, 2.00),\n",
       "  (200, 2.00),\n",
       "  (203, 2.00),\n",
       "  (204, 2.00),\n",
       "  (207, 2.00),\n",
       "  (216, 2.00),\n",
       "  (222, 2.00),\n",
       "  (227, 2.00),\n",
       "  (229, 2.00),\n",
       "  (231, 2.00),\n",
       "  (247, 2.00),\n",
       "  (256, 2.00),\n",
       "  (263, 2.00),\n",
       "  (273, 2.00),\n",
       "  (282, 2.00),\n",
       "  (286, 2.00),\n",
       "  (289, 2.00),\n",
       "  (292, 2.00),\n",
       "  (296, 2.00),\n",
       "  (300, 2.00),\n",
       "  (305, 2.00),\n",
       "  (307, 2.00),\n",
       "  (313, 2.00),\n",
       "  (334, 2.00),\n",
       "  (336, 2.00),\n",
       "  (342, 2.00),\n",
       "  (343, 2.00),\n",
       "  (348, 2.00),\n",
       "  (361, 2.00),\n",
       "  (363, 2.00),\n",
       "  (365, 2.00),\n",
       "  (374, 2.00),\n",
       "  (375, 2.00),\n",
       "  (377, 2.00),\n",
       "  (386, 2.00),\n",
       "  (406, 2.00),\n",
       "  (408, 2.00),\n",
       "  (412, 2.00),\n",
       "  (415, 2.00),\n",
       "  (431, 2.00),\n",
       "  (434, 2.00),\n",
       "  (440, 2.00),\n",
       "  (441, 2.00),\n",
       "  (454, 2.00),\n",
       "  (455, 2.00),\n",
       "  (461, 2.00),\n",
       "  (463, 2.00),\n",
       "  (464, 2.00),\n",
       "  (473, 2.00),\n",
       "  (480, 2.00),\n",
       "  (485, 2.00),\n",
       "  (487, 2.00),\n",
       "  (497, 2.00),\n",
       "  (501, 2.00),\n",
       "  (508, 2.00),\n",
       "  (518, 2.00),\n",
       "  (520, 2.00),\n",
       "  (526, 2.00),\n",
       "  (532, 2.00),\n",
       "  (536, 2.00),\n",
       "  (538, 2.00),\n",
       "  (558, 2.00),\n",
       "  (565, 2.00),\n",
       "  (570, 2.00),\n",
       "  (589, 2.00),\n",
       "  (593, 2.00),\n",
       "  (604, 2.00),\n",
       "  (608, 2.00),\n",
       "  (616, 2.00),\n",
       "  (618, 2.00),\n",
       "  (626, 2.00),\n",
       "  (633, 2.00),\n",
       "  (636, 2.00),\n",
       "  (646, 2.00),\n",
       "  (650, 2.00),\n",
       "  (698, 2.00),\n",
       "  (725, 2.00),\n",
       "  (732, 2.00),\n",
       "  (743, 2.00),\n",
       "  (745, 2.00),\n",
       "  (759, 2.00),\n",
       "  (763, 2.00),\n",
       "  (777, 2.00),\n",
       "  (778, 2.00),\n",
       "  (779, 2.00),\n",
       "  (788, 2.00),\n",
       "  (804, 2.00),\n",
       "  (806, 2.00),\n",
       "  (830, 2.00),\n",
       "  (834, 2.00),\n",
       "  (840, 2.00),\n",
       "  (842, 2.00),\n",
       "  (843, 2.00),\n",
       "  (846, 2.00),\n",
       "  (850, 2.00),\n",
       "  (864, 2.00),\n",
       "  (866, 2.00),\n",
       "  (867, 2.00),\n",
       "  (868, 2.00),\n",
       "  (871, 2.00),\n",
       "  (872, 2.00),\n",
       "  (877, 2.00),\n",
       "  (879, 2.00),\n",
       "  (882, 2.00),\n",
       "  (907, 2.00),\n",
       "  (947, 2.00),\n",
       "  (973, 2.00),\n",
       "  (982, 2.00),\n",
       "  (996, 2.00),\n",
       "  (0, 1.00),\n",
       "  (7, 1.00),\n",
       "  (8, 1.00),\n",
       "  (9, 1.00),\n",
       "  (10, 1.00),\n",
       "  (14, 1.00),\n",
       "  (15, 1.00),\n",
       "  (17, 1.00),\n",
       "  (18, 1.00),\n",
       "  (20, 1.00),\n",
       "  (22, 1.00),\n",
       "  (23, 1.00),\n",
       "  (24, 1.00),\n",
       "  (25, 1.00),\n",
       "  (28, 1.00),\n",
       "  (32, 1.00),\n",
       "  (33, 1.00),\n",
       "  (37, 1.00),\n",
       "  (45, 1.00),\n",
       "  (52, 1.00),\n",
       "  (53, 1.00),\n",
       "  (60, 1.00),\n",
       "  (63, 1.00),\n",
       "  (67, 1.00),\n",
       "  (70, 1.00),\n",
       "  (72, 1.00),\n",
       "  (73, 1.00),\n",
       "  (74, 1.00),\n",
       "  (77, 1.00),\n",
       "  (79, 1.00),\n",
       "  (81, 1.00),\n",
       "  (82, 1.00),\n",
       "  (83, 1.00),\n",
       "  (86, 1.00),\n",
       "  (88, 1.00),\n",
       "  (89, 1.00),\n",
       "  (90, 1.00),\n",
       "  (92, 1.00),\n",
       "  (93, 1.00),\n",
       "  (95, 1.00),\n",
       "  (96, 1.00),\n",
       "  (97, 1.00),\n",
       "  (98, 1.00),\n",
       "  (100, 1.00),\n",
       "  (102, 1.00),\n",
       "  (105, 1.00),\n",
       "  (110, 1.00),\n",
       "  (114, 1.00),\n",
       "  (115, 1.00),\n",
       "  (117, 1.00),\n",
       "  (118, 1.00),\n",
       "  (119, 1.00),\n",
       "  (120, 1.00),\n",
       "  (122, 1.00),\n",
       "  (123, 1.00),\n",
       "  (125, 1.00),\n",
       "  (126, 1.00),\n",
       "  (130, 1.00),\n",
       "  (134, 1.00),\n",
       "  (135, 1.00),\n",
       "  (136, 1.00),\n",
       "  (137, 1.00),\n",
       "  (139, 1.00),\n",
       "  (140, 1.00),\n",
       "  (141, 1.00),\n",
       "  (142, 1.00),\n",
       "  (144, 1.00),\n",
       "  (145, 1.00),\n",
       "  (146, 1.00),\n",
       "  (148, 1.00),\n",
       "  (150, 1.00),\n",
       "  (154, 1.00),\n",
       "  (155, 1.00),\n",
       "  (157, 1.00),\n",
       "  (158, 1.00),\n",
       "  (160, 1.00),\n",
       "  (161, 1.00),\n",
       "  (162, 1.00),\n",
       "  (163, 1.00),\n",
       "  (164, 1.00),\n",
       "  (166, 1.00),\n",
       "  (169, 1.00),\n",
       "  (171, 1.00),\n",
       "  (173, 1.00),\n",
       "  (176, 1.00),\n",
       "  (177, 1.00),\n",
       "  (180, 1.00),\n",
       "  (183, 1.00),\n",
       "  (185, 1.00),\n",
       "  (187, 1.00),\n",
       "  (188, 1.00),\n",
       "  (190, 1.00),\n",
       "  (192, 1.00),\n",
       "  (193, 1.00),\n",
       "  (194, 1.00),\n",
       "  (196, 1.00),\n",
       "  (199, 1.00),\n",
       "  (201, 1.00),\n",
       "  (202, 1.00),\n",
       "  (205, 1.00),\n",
       "  (206, 1.00),\n",
       "  (208, 1.00),\n",
       "  (209, 1.00),\n",
       "  (213, 1.00),\n",
       "  (217, 1.00),\n",
       "  (218, 1.00),\n",
       "  (219, 1.00),\n",
       "  (224, 1.00),\n",
       "  (228, 1.00),\n",
       "  (230, 1.00),\n",
       "  (232, 1.00),\n",
       "  (233, 1.00),\n",
       "  (234, 1.00),\n",
       "  (235, 1.00),\n",
       "  (236, 1.00),\n",
       "  (242, 1.00),\n",
       "  (243, 1.00),\n",
       "  (245, 1.00),\n",
       "  (248, 1.00),\n",
       "  (249, 1.00),\n",
       "  (250, 1.00),\n",
       "  (252, 1.00),\n",
       "  (258, 1.00),\n",
       "  (260, 1.00),\n",
       "  (261, 1.00),\n",
       "  (266, 1.00),\n",
       "  (270, 1.00),\n",
       "  (271, 1.00),\n",
       "  (274, 1.00),\n",
       "  (275, 1.00),\n",
       "  (276, 1.00),\n",
       "  (280, 1.00),\n",
       "  (281, 1.00),\n",
       "  (283, 1.00),\n",
       "  (284, 1.00),\n",
       "  (285, 1.00),\n",
       "  (290, 1.00),\n",
       "  (291, 1.00),\n",
       "  (293, 1.00),\n",
       "  (294, 1.00),\n",
       "  (295, 1.00),\n",
       "  (297, 1.00),\n",
       "  (301, 1.00),\n",
       "  (302, 1.00),\n",
       "  (304, 1.00),\n",
       "  (306, 1.00),\n",
       "  (308, 1.00),\n",
       "  (310, 1.00),\n",
       "  (314, 1.00),\n",
       "  (315, 1.00),\n",
       "  (316, 1.00),\n",
       "  (317, 1.00),\n",
       "  (319, 1.00),\n",
       "  (320, 1.00),\n",
       "  (321, 1.00),\n",
       "  (323, 1.00),\n",
       "  (327, 1.00),\n",
       "  (328, 1.00),\n",
       "  (330, 1.00),\n",
       "  (331, 1.00),\n",
       "  (332, 1.00),\n",
       "  (335, 1.00),\n",
       "  (337, 1.00),\n",
       "  (338, 1.00),\n",
       "  (339, 1.00),\n",
       "  (344, 1.00),\n",
       "  (345, 1.00),\n",
       "  (347, 1.00),\n",
       "  (350, 1.00),\n",
       "  (352, 1.00),\n",
       "  (353, 1.00),\n",
       "  (354, 1.00),\n",
       "  (355, 1.00),\n",
       "  (357, 1.00),\n",
       "  (360, 1.00),\n",
       "  (362, 1.00),\n",
       "  (364, 1.00),\n",
       "  (366, 1.00),\n",
       "  (369, 1.00),\n",
       "  (372, 1.00),\n",
       "  (376, 1.00),\n",
       "  (378, 1.00),\n",
       "  (379, 1.00),\n",
       "  (381, 1.00),\n",
       "  (382, 1.00),\n",
       "  (384, 1.00),\n",
       "  (385, 1.00),\n",
       "  (387, 1.00),\n",
       "  (388, 1.00),\n",
       "  (389, 1.00),\n",
       "  (391, 1.00),\n",
       "  (392, 1.00),\n",
       "  (393, 1.00),\n",
       "  (394, 1.00),\n",
       "  (395, 1.00),\n",
       "  (396, 1.00),\n",
       "  (397, 1.00),\n",
       "  (398, 1.00),\n",
       "  (400, 1.00),\n",
       "  (402, 1.00),\n",
       "  (405, 1.00),\n",
       "  (407, 1.00),\n",
       "  (409, 1.00),\n",
       "  (410, 1.00),\n",
       "  (413, 1.00),\n",
       "  (417, 1.00),\n",
       "  (419, 1.00),\n",
       "  (420, 1.00),\n",
       "  (422, 1.00),\n",
       "  (423, 1.00),\n",
       "  (424, 1.00),\n",
       "  (425, 1.00),\n",
       "  (428, 1.00),\n",
       "  (429, 1.00),\n",
       "  (432, 1.00),\n",
       "  (433, 1.00),\n",
       "  (436, 1.00),\n",
       "  (438, 1.00),\n",
       "  (439, 1.00),\n",
       "  (442, 1.00),\n",
       "  (443, 1.00),\n",
       "  (444, 1.00),\n",
       "  (445, 1.00),\n",
       "  (447, 1.00),\n",
       "  (450, 1.00),\n",
       "  (451, 1.00),\n",
       "  (456, 1.00),\n",
       "  (458, 1.00),\n",
       "  (459, 1.00),\n",
       "  (467, 1.00),\n",
       "  (468, 1.00),\n",
       "  (470, 1.00),\n",
       "  (471, 1.00),\n",
       "  (475, 1.00),\n",
       "  (476, 1.00),\n",
       "  (477, 1.00),\n",
       "  (478, 1.00),\n",
       "  (483, 1.00),\n",
       "  (486, 1.00),\n",
       "  (488, 1.00),\n",
       "  (491, 1.00),\n",
       "  (492, 1.00),\n",
       "  (495, 1.00),\n",
       "  (496, 1.00),\n",
       "  (498, 1.00),\n",
       "  (502, 1.00),\n",
       "  (503, 1.00),\n",
       "  (504, 1.00),\n",
       "  (505, 1.00),\n",
       "  (506, 1.00),\n",
       "  (507, 1.00),\n",
       "  (509, 1.00),\n",
       "  (512, 1.00),\n",
       "  (513, 1.00),\n",
       "  (514, 1.00),\n",
       "  (522, 1.00),\n",
       "  (527, 1.00),\n",
       "  (528, 1.00),\n",
       "  (530, 1.00),\n",
       "  (531, 1.00),\n",
       "  (533, 1.00),\n",
       "  (535, 1.00),\n",
       "  (537, 1.00),\n",
       "  (539, 1.00),\n",
       "  (540, 1.00),\n",
       "  (543, 1.00),\n",
       "  (544, 1.00),\n",
       "  (546, 1.00),\n",
       "  (547, 1.00),\n",
       "  (550, 1.00),\n",
       "  (552, 1.00),\n",
       "  (554, 1.00),\n",
       "  (555, 1.00),\n",
       "  (560, 1.00),\n",
       "  (561, 1.00),\n",
       "  (563, 1.00),\n",
       "  (564, 1.00),\n",
       "  (566, 1.00),\n",
       "  (567, 1.00),\n",
       "  (573, 1.00),\n",
       "  (574, 1.00),\n",
       "  (575, 1.00),\n",
       "  (576, 1.00),\n",
       "  (577, 1.00),\n",
       "  (580, 1.00),\n",
       "  (581, 1.00),\n",
       "  (582, 1.00),\n",
       "  (584, 1.00),\n",
       "  (585, 1.00),\n",
       "  (586, 1.00),\n",
       "  (587, 1.00),\n",
       "  (588, 1.00),\n",
       "  (591, 1.00),\n",
       "  (592, 1.00),\n",
       "  (595, 1.00),\n",
       "  (599, 1.00),\n",
       "  (600, 1.00),\n",
       "  (602, 1.00),\n",
       "  (606, 1.00),\n",
       "  (607, 1.00),\n",
       "  (609, 1.00),\n",
       "  (612, 1.00),\n",
       "  (619, 1.00),\n",
       "  (621, 1.00),\n",
       "  (624, 1.00),\n",
       "  (625, 1.00),\n",
       "  (628, 1.00),\n",
       "  (629, 1.00),\n",
       "  (630, 1.00),\n",
       "  (635, 1.00),\n",
       "  (637, 1.00),\n",
       "  (638, 1.00),\n",
       "  (640, 1.00),\n",
       "  (642, 1.00),\n",
       "  (644, 1.00),\n",
       "  (645, 1.00),\n",
       "  (647, 1.00),\n",
       "  (651, 1.00),\n",
       "  (654, 1.00),\n",
       "  (656, 1.00),\n",
       "  (661, 1.00),\n",
       "  (662, 1.00),\n",
       "  (664, 1.00),\n",
       "  (665, 1.00),\n",
       "  (667, 1.00),\n",
       "  (670, 1.00),\n",
       "  (672, 1.00),\n",
       "  (674, 1.00),\n",
       "  (679, 1.00),\n",
       "  (681, 1.00),\n",
       "  (683, 1.00),\n",
       "  (684, 1.00),\n",
       "  (687, 1.00),\n",
       "  (688, 1.00),\n",
       "  (689, 1.00),\n",
       "  (694, 1.00),\n",
       "  (695, 1.00),\n",
       "  (696, 1.00),\n",
       "  (699, 1.00),\n",
       "  (701, 1.00),\n",
       "  (702, 1.00),\n",
       "  (703, 1.00),\n",
       "  (706, 1.00),\n",
       "  (707, 1.00),\n",
       "  (711, 1.00),\n",
       "  (712, 1.00),\n",
       "  (715, 1.00),\n",
       "  (716, 1.00),\n",
       "  (717, 1.00),\n",
       "  (720, 1.00),\n",
       "  (721, 1.00),\n",
       "  (722, 1.00),\n",
       "  (723, 1.00),\n",
       "  (724, 1.00),\n",
       "  (727, 1.00),\n",
       "  (729, 1.00),\n",
       "  (734, 1.00),\n",
       "  (738, 1.00),\n",
       "  (739, 1.00),\n",
       "  (741, 1.00),\n",
       "  (746, 1.00),\n",
       "  (747, 1.00),\n",
       "  (750, 1.00),\n",
       "  (751, 1.00),\n",
       "  (752, 1.00),\n",
       "  (754, 1.00),\n",
       "  (755, 1.00),\n",
       "  (757, 1.00),\n",
       "  (758, 1.00),\n",
       "  (760, 1.00),\n",
       "  (761, 1.00),\n",
       "  (762, 1.00),\n",
       "  (765, 1.00),\n",
       "  (766, 1.00),\n",
       "  (768, 1.00),\n",
       "  (775, 1.00),\n",
       "  (776, 1.00),\n",
       "  (780, 1.00),\n",
       "  (781, 1.00),\n",
       "  (783, 1.00),\n",
       "  (784, 1.00),\n",
       "  (786, 1.00),\n",
       "  (787, 1.00),\n",
       "  (793, 1.00),\n",
       "  (796, 1.00),\n",
       "  (797, 1.00),\n",
       "  (799, 1.00),\n",
       "  (800, 1.00),\n",
       "  (802, 1.00),\n",
       "  (803, 1.00),\n",
       "  (809, 1.00),\n",
       "  (814, 1.00),\n",
       "  (816, 1.00),\n",
       "  (817, 1.00),\n",
       "  (819, 1.00),\n",
       "  (820, 1.00),\n",
       "  (821, 1.00),\n",
       "  (822, 1.00),\n",
       "  (823, 1.00),\n",
       "  (825, 1.00),\n",
       "  (827, 1.00),\n",
       "  (829, 1.00),\n",
       "  (831, 1.00),\n",
       "  (833, 1.00),\n",
       "  (837, 1.00),\n",
       "  (844, 1.00),\n",
       "  (847, 1.00),\n",
       "  (848, 1.00),\n",
       "  (852, 1.00),\n",
       "  (853, 1.00),\n",
       "  (855, 1.00),\n",
       "  (857, 1.00),\n",
       "  (858, 1.00),\n",
       "  (859, 1.00),\n",
       "  (865, 1.00),\n",
       "  (870, 1.00),\n",
       "  (873, 1.00),\n",
       "  (874, 1.00),\n",
       "  (875, 1.00),\n",
       "  (880, 1.00),\n",
       "  (881, 1.00),\n",
       "  (883, 1.00),\n",
       "  (884, 1.00),\n",
       "  (885, 1.00),\n",
       "  (886, 1.00),\n",
       "  (887, 1.00),\n",
       "  (888, 1.00),\n",
       "  (889, 1.00),\n",
       "  (890, 1.00),\n",
       "  (892, 1.00),\n",
       "  (894, 1.00),\n",
       "  (897, 1.00),\n",
       "  (900, 1.00),\n",
       "  (901, 1.00),\n",
       "  (902, 1.00),\n",
       "  (903, 1.00),\n",
       "  (906, 1.00),\n",
       "  (910, 1.00),\n",
       "  (911, 1.00),\n",
       "  (912, 1.00),\n",
       "  (913, 1.00),\n",
       "  (915, 1.00),\n",
       "  (918, 1.00),\n",
       "  (919, 1.00),\n",
       "  (920, 1.00),\n",
       "  (923, 1.00),\n",
       "  (924, 1.00),\n",
       "  (925, 1.00),\n",
       "  (926, 1.00),\n",
       "  (927, 1.00),\n",
       "  (932, 1.00),\n",
       "  (933, 1.00),\n",
       "  (934, 1.00),\n",
       "  (937, 1.00),\n",
       "  (939, 1.00),\n",
       "  (944, 1.00),\n",
       "  (946, 1.00),\n",
       "  (948, 1.00),\n",
       "  (949, 1.00),\n",
       "  (951, 1.00),\n",
       "  (952, 1.00),\n",
       "  (953, 1.00),\n",
       "  (955, 1.00),\n",
       "  (956, 1.00),\n",
       "  (957, 1.00),\n",
       "  (959, 1.00),\n",
       "  (962, 1.00),\n",
       "  (963, 1.00),\n",
       "  (971, 1.00),\n",
       "  (972, 1.00),\n",
       "  (978, 1.00),\n",
       "  (984, 1.00),\n",
       "  (985, 1.00),\n",
       "  (987, 1.00),\n",
       "  (988, 1.00),\n",
       "  (989, 1.00),\n",
       "  (990, 1.00),\n",
       "  (991, 1.00),\n",
       "  (992, 1.00),\n",
       "  (998, 1.00),\n",
       "  (999, 1.00),\n",
       "  (3, 0.00),\n",
       "  (4, 0.00),\n",
       "  (5, 0.00),\n",
       "  (6, 0.00),\n",
       "  (11, 0.00),\n",
       "  (13, 0.00),\n",
       "  (16, 0.00),\n",
       "  (26, 0.00),\n",
       "  (27, 0.00),\n",
       "  (29, 0.00),\n",
       "  (30, 0.00),\n",
       "  (31, 0.00),\n",
       "  (35, 0.00),\n",
       "  (36, 0.00),\n",
       "  (38, 0.00),\n",
       "  (39, 0.00),\n",
       "  (40, 0.00),\n",
       "  (41, 0.00),\n",
       "  (43, 0.00),\n",
       "  (44, 0.00),\n",
       "  (49, 0.00),\n",
       "  (51, 0.00),\n",
       "  (54, 0.00),\n",
       "  (56, 0.00),\n",
       "  (59, 0.00),\n",
       "  (64, 0.00),\n",
       "  (66, 0.00),\n",
       "  (71, 0.00),\n",
       "  (78, 0.00),\n",
       "  (80, 0.00),\n",
       "  (85, 0.00),\n",
       "  (101, 0.00),\n",
       "  (103, 0.00),\n",
       "  (104, 0.00),\n",
       "  (106, 0.00),\n",
       "  (111, 0.00),\n",
       "  (112, 0.00),\n",
       "  (121, 0.00),\n",
       "  (127, 0.00),\n",
       "  (129, 0.00),\n",
       "  (132, 0.00),\n",
       "  (133, 0.00),\n",
       "  (138, 0.00),\n",
       "  (143, 0.00),\n",
       "  (147, 0.00),\n",
       "  (149, 0.00),\n",
       "  (152, 0.00),\n",
       "  (153, 0.00),\n",
       "  (156, 0.00),\n",
       "  (159, 0.00),\n",
       "  (165, 0.00),\n",
       "  (167, 0.00),\n",
       "  (168, 0.00),\n",
       "  (170, 0.00),\n",
       "  (172, 0.00),\n",
       "  (174, 0.00),\n",
       "  (175, 0.00),\n",
       "  (178, 0.00),\n",
       "  (179, 0.00),\n",
       "  (181, 0.00),\n",
       "  (184, 0.00),\n",
       "  (191, 0.00),\n",
       "  (210, 0.00),\n",
       "  (211, 0.00),\n",
       "  (212, 0.00),\n",
       "  (214, 0.00),\n",
       "  (215, 0.00),\n",
       "  (220, 0.00),\n",
       "  (221, 0.00),\n",
       "  (223, 0.00),\n",
       "  (225, 0.00),\n",
       "  (226, 0.00),\n",
       "  (237, 0.00),\n",
       "  (239, 0.00),\n",
       "  (240, 0.00),\n",
       "  (241, 0.00),\n",
       "  (244, 0.00),\n",
       "  (246, 0.00),\n",
       "  (251, 0.00),\n",
       "  (253, 0.00),\n",
       "  (254, 0.00),\n",
       "  (255, 0.00),\n",
       "  (257, 0.00),\n",
       "  (259, 0.00),\n",
       "  (262, 0.00),\n",
       "  (265, 0.00),\n",
       "  (267, 0.00),\n",
       "  (268, 0.00),\n",
       "  (269, 0.00),\n",
       "  (272, 0.00),\n",
       "  (277, 0.00),\n",
       "  (278, 0.00),\n",
       "  (279, 0.00),\n",
       "  (287, 0.00),\n",
       "  (288, 0.00),\n",
       "  (298, 0.00),\n",
       "  (299, 0.00),\n",
       "  (303, 0.00),\n",
       "  (309, 0.00),\n",
       "  (311, 0.00),\n",
       "  (312, 0.00),\n",
       "  (322, 0.00),\n",
       "  (324, 0.00),\n",
       "  (325, 0.00),\n",
       "  (326, 0.00),\n",
       "  (329, 0.00),\n",
       "  (333, 0.00),\n",
       "  (340, 0.00),\n",
       "  (341, 0.00),\n",
       "  (346, 0.00),\n",
       "  (349, 0.00),\n",
       "  (351, 0.00),\n",
       "  (356, 0.00),\n",
       "  (358, 0.00),\n",
       "  (359, 0.00),\n",
       "  (367, 0.00),\n",
       "  (368, 0.00),\n",
       "  (370, 0.00),\n",
       "  (371, 0.00),\n",
       "  (373, 0.00),\n",
       "  (380, 0.00),\n",
       "  (383, 0.00),\n",
       "  (390, 0.00),\n",
       "  (403, 0.00),\n",
       "  (404, 0.00),\n",
       "  (416, 0.00),\n",
       "  (418, 0.00),\n",
       "  (421, 0.00),\n",
       "  (426, 0.00),\n",
       "  (427, 0.00),\n",
       "  (430, 0.00),\n",
       "  (435, 0.00),\n",
       "  (437, 0.00),\n",
       "  (446, 0.00),\n",
       "  (448, 0.00),\n",
       "  (449, 0.00),\n",
       "  (452, 0.00),\n",
       "  (453, 0.00),\n",
       "  (460, 0.00),\n",
       "  (462, 0.00),\n",
       "  (465, 0.00),\n",
       "  (466, 0.00),\n",
       "  (469, 0.00),\n",
       "  (479, 0.00),\n",
       "  (481, 0.00),\n",
       "  (482, 0.00),\n",
       "  (484, 0.00),\n",
       "  (493, 0.00),\n",
       "  (494, 0.00),\n",
       "  (499, 0.00),\n",
       "  (500, 0.00),\n",
       "  (510, 0.00),\n",
       "  (516, 0.00),\n",
       "  (517, 0.00),\n",
       "  (519, 0.00),\n",
       "  (521, 0.00),\n",
       "  (524, 0.00),\n",
       "  (525, 0.00),\n",
       "  (529, 0.00),\n",
       "  (534, 0.00),\n",
       "  (541, 0.00),\n",
       "  (542, 0.00),\n",
       "  (548, 0.00),\n",
       "  (549, 0.00),\n",
       "  (551, 0.00),\n",
       "  (553, 0.00),\n",
       "  (557, 0.00),\n",
       "  (559, 0.00),\n",
       "  (568, 0.00),\n",
       "  (569, 0.00),\n",
       "  (571, 0.00),\n",
       "  (578, 0.00),\n",
       "  (583, 0.00),\n",
       "  (590, 0.00),\n",
       "  (594, 0.00),\n",
       "  (596, 0.00),\n",
       "  (598, 0.00),\n",
       "  (601, 0.00),\n",
       "  (603, 0.00),\n",
       "  (605, 0.00),\n",
       "  (610, 0.00),\n",
       "  (613, 0.00),\n",
       "  (614, 0.00),\n",
       "  (615, 0.00),\n",
       "  (617, 0.00),\n",
       "  (620, 0.00),\n",
       "  (622, 0.00),\n",
       "  (623, 0.00),\n",
       "  (627, 0.00),\n",
       "  (631, 0.00),\n",
       "  (634, 0.00),\n",
       "  (639, 0.00),\n",
       "  (643, 0.00),\n",
       "  (648, 0.00),\n",
       "  (649, 0.00),\n",
       "  (652, 0.00),\n",
       "  (653, 0.00),\n",
       "  (655, 0.00),\n",
       "  (657, 0.00),\n",
       "  (658, 0.00),\n",
       "  (659, 0.00),\n",
       "  (660, 0.00),\n",
       "  (663, 0.00),\n",
       "  (666, 0.00),\n",
       "  (668, 0.00),\n",
       "  (671, 0.00),\n",
       "  (673, 0.00),\n",
       "  (675, 0.00),\n",
       "  (676, 0.00),\n",
       "  (677, 0.00),\n",
       "  (678, 0.00),\n",
       "  (680, 0.00),\n",
       "  (682, 0.00),\n",
       "  (685, 0.00),\n",
       "  (686, 0.00),\n",
       "  (690, 0.00),\n",
       "  (691, 0.00),\n",
       "  (692, 0.00),\n",
       "  (693, 0.00),\n",
       "  (697, 0.00),\n",
       "  (704, 0.00),\n",
       "  (705, 0.00),\n",
       "  (708, 0.00),\n",
       "  (710, 0.00),\n",
       "  (713, 0.00),\n",
       "  (714, 0.00),\n",
       "  (718, 0.00),\n",
       "  (719, 0.00),\n",
       "  (726, 0.00),\n",
       "  (728, 0.00),\n",
       "  (730, 0.00),\n",
       "  (731, 0.00),\n",
       "  (733, 0.00),\n",
       "  (736, 0.00),\n",
       "  (737, 0.00),\n",
       "  (740, 0.00),\n",
       "  (742, 0.00),\n",
       "  (744, 0.00),\n",
       "  (748, 0.00),\n",
       "  (749, 0.00),\n",
       "  (756, 0.00),\n",
       "  (764, 0.00),\n",
       "  (767, 0.00),\n",
       "  (769, 0.00),\n",
       "  (771, 0.00),\n",
       "  (773, 0.00),\n",
       "  (774, 0.00),\n",
       "  (782, 0.00),\n",
       "  (785, 0.00),\n",
       "  (789, 0.00),\n",
       "  (790, 0.00),\n",
       "  (792, 0.00),\n",
       "  (795, 0.00),\n",
       "  (798, 0.00),\n",
       "  (805, 0.00),\n",
       "  (807, 0.00),\n",
       "  (810, 0.00),\n",
       "  (811, 0.00),\n",
       "  (812, 0.00),\n",
       "  (813, 0.00),\n",
       "  (818, 0.00),\n",
       "  (824, 0.00),\n",
       "  (832, 0.00),\n",
       "  (835, 0.00),\n",
       "  (836, 0.00),\n",
       "  (838, 0.00),\n",
       "  (841, 0.00),\n",
       "  (845, 0.00),\n",
       "  (849, 0.00),\n",
       "  (851, 0.00),\n",
       "  (856, 0.00),\n",
       "  (860, 0.00),\n",
       "  (861, 0.00),\n",
       "  (862, 0.00),\n",
       "  (863, 0.00),\n",
       "  (869, 0.00),\n",
       "  (876, 0.00),\n",
       "  (878, 0.00),\n",
       "  (891, 0.00),\n",
       "  (895, 0.00),\n",
       "  (896, 0.00),\n",
       "  (899, 0.00),\n",
       "  (908, 0.00),\n",
       "  (909, 0.00),\n",
       "  (914, 0.00),\n",
       "  (916, 0.00),\n",
       "  (917, 0.00),\n",
       "  (921, 0.00),\n",
       "  (922, 0.00),\n",
       "  (928, 0.00),\n",
       "  (929, 0.00),\n",
       "  (930, 0.00),\n",
       "  (931, 0.00),\n",
       "  (935, 0.00),\n",
       "  (936, 0.00),\n",
       "  (938, 0.00),\n",
       "  (940, 0.00),\n",
       "  (941, 0.00),\n",
       "  (942, 0.00),\n",
       "  (943, 0.00),\n",
       "  (945, 0.00),\n",
       "  (950, 0.00),\n",
       "  (954, 0.00),\n",
       "  (958, 0.00),\n",
       "  (960, 0.00),\n",
       "  (961, 0.00),\n",
       "  (964, 0.00),\n",
       "  (965, 0.00),\n",
       "  (966, 0.00),\n",
       "  (967, 0.00),\n",
       "  (968, 0.00),\n",
       "  (969, 0.00),\n",
       "  (970, 0.00),\n",
       "  (974, 0.00),\n",
       "  (975, 0.00),\n",
       "  (976, 0.00),\n",
       "  (977, 0.00),\n",
       "  (979, 0.00),\n",
       "  (980, 0.00),\n",
       "  (983, 0.00),\n",
       "  (986, 0.00),\n",
       "  (993, 0.00),\n",
       "  (994, 0.00),\n",
       "  (995, 0.00),\n",
       "  (997, 0.00)])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#on validation\n",
    "%precision 2\n",
    "n, hist = targeted_diversity(learn, 95)\n",
    "n, hist\n",
    "# n, hist, tk = diversity(learn, 10, 95)\n",
    "# n, hist, tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f228b1a9c88>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_hist = sorted(hist, key=lambda x: x[0], reverse = False)\n",
    "values = [elem[1] for elem in sorted_hist]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.1334)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7921)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_from_uniform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1fCvFG0VMKts"
   },
   "outputs": [],
   "source": [
    "def make_triplet_samples(z, margin, r2, r3):\n",
    "  positive_sample = z + random_vector_volume(z.shape, 0, margin).cuda() \n",
    "  negative_sample = z + random_vector_volume(z.shape, r2, r3).cuda()\n",
    "  return positive_sample, negative_sample\n",
    "\n",
    "def random_vector_surface(shape, r = 1.):\n",
    "  mat = torch.randn(size=shape).cuda()\n",
    "  norm = torch.norm(mat, p=2, dim=1, keepdim = True).cuda()\n",
    "  return (mat/norm) * r\n",
    "\n",
    "def random_vector_volume(shape, inner_r, outer_r):\n",
    "  fraction = torch.empty(shape[0]).uniform_(inner_r, outer_r).cuda()\n",
    "  fraction = ((fraction / outer_r) ** (1 / shape[1])) * outer_r # volume-normalize the fraction\n",
    "  fraction.unsqueeze_(-1)\n",
    "  return random_vector_surface(shape, 1) * fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PizmBkGqMKtu"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def most_frequent(x):\n",
    "  return Counter(x).most_common(1)[0]\n",
    "\n",
    "def preds_around(center, radius, n_preds, model, dummy_img):\n",
    "  z_s = random_vector_volume([n_preds, 10], radius, radius + 0.01) + center[None]\n",
    "  noises = model.forward_z(z_s)\n",
    "  perturbed_imgs = noises + dummy_img \n",
    "  return torch.argmax(arch(perturbed_imgs), 1)\n",
    "  \n",
    "def most_freq_pred_around(center, radius, n_preds, model, dummy_img):\n",
    "  preds = preds_around(center, radius, n_preds, model, dummy_img)\n",
    "  most_freq = most_frequent(preds.tolist())\n",
    "  return (class_index_to_label(most_freq[0]), most_freq[1]/n_preds)\n",
    "\n",
    "def investigate_neighborhood(z, step, model, dummy_img):\n",
    "  with torch.no_grad():\n",
    "    result = []\n",
    "    for radius in np.arange(0.1, 6., step):\n",
    "#       print(\"creating {} more preds\".format(int(10 + 5 * (radius ** 2))))\n",
    "      most_freq_pred = most_freq_pred_around(z, radius, int(10 + 5 * (radius ** 2)), model, dummy_img)\n",
    "      result.append((radius, most_freq_pred))\n",
    "    return result\n",
    "  \n",
    "def big_vector_to_str(x, thresh = 0.01):\n",
    "  torch.set_printoptions(precision=2, sci_mode=False, threshold=5000)  \n",
    "  result = \"[\"\n",
    "  for i, x_i in enumerate(x.data):\n",
    "    if abs(x_i) > thresh:\n",
    "      result += \"{}: {:.2f}\".format(i, x_i.item()) \n",
    "      result += \", \" if (i < x.shape[0]-1) else \"\"\n",
    "  result += \"]\"\n",
    "  return result\n",
    "\n",
    "def print_big_vector(x, thresh = 0.01):\n",
    "  print(big_vector_to_str(x, thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d-btRW4qMKtw",
    "outputId": "90e81f6a-1b9e-45a4-ae82-bda370319bd9"
   },
   "outputs": [],
   "source": [
    "#experiment 1\n",
    "\n",
    "z = torch.tensor([0.5] * 10).cuda()\n",
    "# z = torch.empty(10).uniform_(-1, 1).cuda()\n",
    "# z_s = z[None]\n",
    "\n",
    "model = learn.model.eval()\n",
    "x_img = normalize(learn.data.train_ds[50][0].data.cuda())\n",
    "  \n",
    "for i in range(6):\n",
    "  z = torch.empty(10).uniform_(-1, 1).cuda()\n",
    "  print(\"investigation for: \", z)\n",
    "  for elem in investigate_neighborhood(z, 0.5, model, x_img):\n",
    "    print(elem)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment 1-1: modified investigate_z\n",
    "z_investigate_path = '/root/Derakhshani/adversarial/textual_notes/investigate_z_{}.txt'.format(env.save_filename)\n",
    "if Path(z_investigate_path).exists(): raise FileExistsError(\"file already exists\")\n",
    "file = open(str(z_investigate_path), 'w')\n",
    "        \n",
    "for i, (z, noise) in enumerate(zip(pruned_z_s, pruned_noises)):\n",
    "  hist = compute_prediction_histogram(learn, noise)\n",
    "  indexed_hist = [(i, val) for i, val in enumerate(hist)]\n",
    "  sorted_hist = sorted(indexed_hist, key=lambda x: x[1], reverse=True)\n",
    "  labeled_hist = [(class_index_to_label(i), count) for i, count in sorted_hist]\n",
    "  print(\"result {}:\".format(i))\n",
    "  print(big_vector_to_str(z))\n",
    "  print(labeled_hist[:6])\n",
    "  print(\"\\n\\n\")\n",
    "  \n",
    "  file.write(\"result {}:\\n\".format(i))\n",
    "  file.write(big_vector_to_str(z) + \"\\n\")\n",
    "  file.write(str(labeled_hist[:6]))\n",
    "  file.write(\"\\n\\n\\n\")\n",
    "  file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bp6YOnipMKtz"
   },
   "outputs": [],
   "source": [
    "#experiment 2\n",
    "import itertools\n",
    "z_s = [torch.tensor(t).cuda() for t in itertools.product( *([[-0.33, 0.33]] * 10) )]\n",
    "model = learn.model.eval()\n",
    "noises = []\n",
    "with torch.no_grad():\n",
    "  for z in z_s:\n",
    "    noises.append(model.forward_single_z(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "55lErWDyMKt1",
    "outputId": "93d8fb71-3fd5-44a5-d3ec-8013e13f17ba"
   },
   "outputs": [],
   "source": [
    "x_img = normalize(learn.data.train_ds[50][0].data.cuda())\n",
    "\n",
    "preds = []\n",
    "for noise in noises:\n",
    "  perturbed_img = x_img + noise\n",
    "  preds.append(torch.argmax(arch(perturbed_img[None]), 1)[0].item())\n",
    "\n",
    "from collections import Counter\n",
    "result = [(class_index_to_label(index), count) for index, count in Counter(preds).most_common(5)]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4WSg-wBFMKt5"
   },
   "outputs": [],
   "source": [
    "#experiment 3\n",
    "import itertools\n",
    "dimension_values = [[-0.9, 0.9]] * z_dim\n",
    "for i in range(z_dim):\n",
    "  if i % 100 != 0:\n",
    "    dimension_values[i] = [0.]\n",
    "# dimension_values[0] = [0.]\n",
    "# dimension_values[3] = [0.]\n",
    "# dimension_values[6] = [0.]\n",
    "# dimension_values[9] = [0.]\n",
    "pruned_z_s = [torch.tensor(t).cuda() for t in itertools.product(*dimension_values)]\n",
    "model = learn.model.eval()\n",
    "with torch.no_grad():\n",
    "  pruned_noises = [model.forward_single_z(z) for z in pruned_z_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment 3: for the targeted-attack case\n",
    "pruned_z_s = []\n",
    "for i in range(z_dim):\n",
    "  new_z = torch.zeros(z_dim).cuda()\n",
    "  new_z[i] = 1.\n",
    "  pruned_z_s.append(new_z)\n",
    "  \n",
    "model = learn.model.eval()\n",
    "with torch.no_grad():\n",
    "  pruned_noises = [model.forward_single_z(z) for z in pruned_z_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment 3-1: noises for \n",
    "pruned_z_s = []\n",
    "# for i in range(z_dim):\n",
    "#   new_z = torch.empty(z_dim).uniform_(0,1).cuda().detach()\n",
    "#   pruned_z_s.append(new_z)\n",
    "\n",
    "for i in range(z_dim):\n",
    "  new_z = torch.zeros(z_dim).cuda().detach()\n",
    "  new_z[i] = 1.\n",
    "  pruned_z_s.append(new_z)\n",
    "  \n",
    "model = learn.model.eval()\n",
    "with torch.no_grad():\n",
    "  pruned_noises = [model.forward_single_z(z) for z in pruned_z_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "for noise in pruned_noises[0:200]:\n",
    "  img = noise_to_image(noise)\n",
    "  img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spider web\n",
    "z_values = [\n",
    "  [ 0.33, -0.33,  0.33,  0.33, -0.33,  0.33, -0.33, -0.33, -0.33, -0.33],\n",
    "  [ 0.33,  0.33, -0.33, -0.33, -0.33,  0.33, -0.33,  0.33, -0.33, -0.33],\n",
    "  [ 0.33,  0.33, -0.33,  0.33,  0.33, -0.33, -0.33, -0.33,  0.33, -0.33],\n",
    "  [-0.33, -0.33, -0.33, -0.33, -0.33, -0.33, -0.33, -0.33, -0.33, -0.33],\n",
    "  [-0.33, -0.33, -0.33, -0.33, -0.33,  0.33,  0.33, -0.33,  0.33,  0.33],\n",
    "  [-0.33, -0.33, -0.33,  0.33,  0.33, -0.33, -0.33, -0.33, -0.33, -0.33],\n",
    "  [-0.33, -0.33,  0.33,  0.33, -0.33, -0.33,  0.33, -0.33,  0.33, -0.33],\n",
    "  [-0.33,  0.33, -0.33,  0.33,  0.33, -0.33,  0.33,  0.33,  0.33,  0.33],\n",
    "  [-0.33,  0.33,  0.33,  0.33, -0.33, -0.33,  0.33,  0.33, -0.33, -0.33],\n",
    "  [ 0.33, -0.33, -0.33, -0.33,  0.33,  0.33, -0.33, -0.33, -0.33, -0.33],\n",
    "  [ 0.33, -0.33,  0.33,  0.33, -0.33, -0.33,  0.33,  0.33, -0.33,  0.33],\n",
    "  [ 0.33,  0.33, -0.33,  0.33, -0.33, -0.33,  0.33,  0.33, -0.33,  0.33],\n",
    "  [ 0.33,  0.33,  0.33, -0.33, -0.33, -0.33, -0.33,  0.33, -0.33, -0.33],\n",
    "  [ 0.33,  0.33,  0.33,  0.33, -0.33, -0.33, -0.33,  0.33, -0.33, -0.33],\n",
    "  [ 0.33,  0.33,  0.33,  0.33,  0.33,  0.33,  0.33,  0.33,  0.33, -0.33],\n",
    "  [ 0.33,  0.33,  0.33, -0.33, -0.33, -0.33, -0.33,  0.33,  0.33, -0.33],\n",
    "]\n",
    "\n",
    "if any(z_values.count(x) > 1 for x in z_values):\n",
    "  raise Exception(\"duplicate\")\n",
    "  \n",
    "z_s = [torch.tensor(z).cuda() for z in z_values]\n",
    "model = learn.model.eval()\n",
    "\n",
    "for z in z_s:\n",
    "  img = noise_to_image(model.forward_single_z(z))\n",
    "  img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_values = [\n",
    "  # window screen\n",
    "  [-0.33,  0.33,  0.33, -0.33, -0.33,  0.33, -0.33, -0.33, -0.33, -0.33],\n",
    "  [-0.33,  0.33,  0.33, -0.33, -0.33, -0.33, -0.33, -0.33,  0.33,  0.33],\n",
    "]\n",
    "\n",
    "if any(z_values.count(x) > 1 for x in z_values):\n",
    "  raise Exception(\"duplicate\")\n",
    "  \n",
    "z_s = [torch.tensor(z).cuda() for z in z_values]\n",
    "model = learn.model.eval()\n",
    "\n",
    "for z in z_s:\n",
    "  img = noise_to_image(model.forward_single_z(z))\n",
    "  img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KuAVZzmKMKt9",
    "outputId": "7e6643e0-ce55-438b-e0ae-79bde3ee4cef"
   },
   "outputs": [],
   "source": [
    "#vgg-16_12 most repeated labels:\n",
    "l = [(611, 215.0),\n",
    "  (474, 194.1),\n",
    "  (398, 120.3),\n",
    "  (721, 79.6),\n",
    "  (741, 73.5),\n",
    "  (510, 62.5)]\n",
    "\n",
    "[(class_index_to_label(index), count) for index, count in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FAgk-YyWc3rG"
   },
   "outputs": [],
   "source": [
    "# learn.recorder.plot_losses()\n",
    "# learn.recorder.plot_lr()\n",
    "# learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YTHG4Bt7VDYp"
   },
   "outputs": [],
   "source": [
    "fooling_rates = []\n",
    "model = learn.model.eval()\n",
    "learn.metrics = [validation_single_perturbation]\n",
    "for i in range(10):\n",
    "  global_perturbations = model(torch.rand(1, 3, 224, 244).cuda())[0]\n",
    "  nag_util.global_perturbations = global_perturbations\n",
    "  fooling_rates.append(learn.validate()[1].cpu().item())\n",
    "  print(\"%d : %f\"%(i, fooling_rates[-1]))\n",
    "\n",
    "mean = np.mean(fooling_rates)\n",
    "stddev = np.std(fooling_rates)\n",
    "print(mean, stddev); print(fooling_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "colab_type": "code",
    "id": "OFCjzI7UaY3C",
    "outputId": "740185b4-dd54-46f4-b0af-79ee452568e1"
   },
   "outputs": [],
   "source": [
    "#the Image works good for floats in range [0..1]\n",
    "model = learn.model.eval()\n",
    "\n",
    "x_img = learn.data.train_ds[200][0]\n",
    "x = normalize(x_img.data.cuda())\n",
    "z = torch.tensor([-0.33,  0.33, -0.33, -0.33, -0.33,  0.33,  0.33, -0.33, -0.33, -0.33], dtype=torch.float32).cuda()\n",
    "# z = torch.empty(z_dim).uniform_(-1,1).cuda()\n",
    "p = model.forward_single_z(z).detach()\n",
    "\n",
    "p_x = x + p\n",
    "# print(\"img range, noise range\")\n",
    "# print_range(x); print_range(p)\n",
    "adv_label = class_index_to_label(arch(p_x[None]).argmax(1).item())\n",
    "print_big_vector(arch(p_x[None])[0])\n",
    "p_x = denormalize(p_x)\n",
    "p_x.clamp_(0,1)\n",
    "\n",
    "\n",
    "#prepare images\n",
    "p_x_img = Image(p_x)\n",
    "p = scale_to_range(p, [0., 1.])\n",
    "p_img = Image(p)\n",
    "x_img.show()\n",
    "p_img.show()\n",
    "p_x_img.show()\n",
    "\n",
    "\n",
    "# print_range(p)\n",
    "# print_range(denormalize(x))\n",
    "# print_range(p_x)\n",
    "\n",
    "benign_label = class_index_to_label(arch(x[None]).argmax(1).item())\n",
    "\n",
    "print_big_vector(arch(x[None])[0])\n",
    "print(benign_label, adv_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mzwsI2P1ZANz"
   },
   "outputs": [],
   "source": [
    "z1 = torch.tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1], dtype=torch.float32).cuda()\n",
    "p1 = model.forward_single_z(z1)\n",
    "\n",
    "z2 = torch.tensor([1, -1, -1, -1, -1, -1, -1, -1, -1, -1], dtype=torch.float32).cuda()\n",
    "p2 = model.forward_single_z(z2)\n",
    "\n",
    "z3 = torch.tensor([1, 1, -1, -1, -1, -1, -1, -1, -1, -1], dtype=torch.float32).cuda()\n",
    "p3 = model.forward_single_z(z3)\n",
    "\n",
    "l2_distance(p1, p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eroI82OKSnAL"
   },
   "outputs": [],
   "source": [
    "#the Image works good for floats in range [0..1]\n",
    "model = learn.model.eval()\n",
    "\n",
    "x_img = learn.data.train_ds[4][0]\n",
    "x = x_img.data[None].cuda()\n",
    "p = model(x)[0].squeeze().detach() \n",
    "x = x.squeeze()\n",
    "x = normalize(x)\n",
    "\n",
    "p_x = x + p\n",
    "p_x = denormalize(p_x)\n",
    "p_x.clamp_(0,1)\n",
    "\n",
    "\n",
    "#prepare images\n",
    "p_x_img = Image(p_x)\n",
    "p = scale_to_range(p, [0.,1.])\n",
    "p_img = Image(p)\n",
    "# x_img.show()\n",
    "p_img.show()\n",
    "# p_x_img.show()\n",
    "\n",
    "print_range(p)\n",
    "print_range(x)\n",
    "print_range(p_x)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "NAG-tripletLossExperiment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
