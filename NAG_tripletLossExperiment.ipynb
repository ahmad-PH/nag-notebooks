{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NAG-tripletLossExperiment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cqeZpz16do4y",
        "colab": {}
      },
      "source": [
        "import subprocess\n",
        "def run_shell_command(cmd):\n",
        "  p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)\n",
        "  print(str(p.communicate()[0], 'utf-8'))\n",
        "  \n",
        "def detect_env():\n",
        "    import os\n",
        "    if 'content' in os.listdir('/'):\n",
        "      return \"colab\"\n",
        "    else:\n",
        "      return \"IBM\"\n",
        "    \n",
        "def create_env():\n",
        "  if detect_env() == \"IBM\":\n",
        "    return IBMEnv()\n",
        "  elif detect_env() == \"colab\":\n",
        "    return ColabEnv()\n",
        "\n",
        "\n",
        "class Env:\n",
        "  def get_nag_util_files(self):\n",
        "      import os\n",
        "      \n",
        "      print(\"\\ngetting git files ...\")\n",
        "      if os.path.isdir(self.python_files_path):\n",
        "        os.chdir(self.python_files_path)\n",
        "        run_shell_command('git pull')\n",
        "        os.chdir(self.root_folder)\n",
        "      else:\n",
        "        run_shell_command('git clone https://github.com/ahmad-PH/nag-public.git')\n",
        "      print(\"done.\")\n",
        "  \n",
        "\n",
        "class IBMEnv(Env):\n",
        "    def __init__(self):\n",
        "      self.root_folder = \"/root/Derakhshani/adversarial\"\n",
        "      self.temp_csv_path = self.root_folder + \"/temp\"\n",
        "      self.python_files_path = self.root_folder + \"/nag-public\"\n",
        "      self.python_files_dir = \"NAG-11May-beforeDenoiser\"\n",
        "      \n",
        "      import sys\n",
        "      sys.path.append('./nag/nag_util')\n",
        "      \n",
        "    def get_csv_path(self):\n",
        "      return self.root_folder + \"/textual_notes/CSVs/\" + self.save_filename\n",
        "    \n",
        "    def get_models_path(self):\n",
        "      return self.root_folder + \"/models/\" + self.save_filename\n",
        "      \n",
        "    def setup(self):\n",
        "      self.get_nag_util_files()\n",
        "#       defaults.device = torch.device('cuda:0')\n",
        "      import os;\n",
        "      os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
        "      os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
        "      \n",
        "    def load_dataset(self, compressed_name, unpacked_name):\n",
        "      pass\n",
        "\n",
        "    def load_test_dataset(root_folder):\n",
        "        raise NotImplementedError(\"test dataset on IBM needs work...\")\n",
        "    \n",
        "    def set_data_path(self, path):\n",
        "      self.data_path = Path(self.root_folder + '/datasets/' + path)\n",
        "    \n",
        "        \n",
        "class ColabEnv(Env):\n",
        "    def __init__(self):\n",
        "      self.root_folder = '/content'\n",
        "      self.temp_csv_path = self.root_folder\n",
        "      self.python_files_path = self.root_folder + '/nag-public'\n",
        "      self.python_files_dir = \"NAG-11May-beforeDenoiser\"\n",
        "      self.torchvision_upgraded = False\n",
        "      \n",
        "    def get_csv_path(self):\n",
        "      return self.root_folder + '/gdrive/My Drive/DL/textual_notes/CSVs/' + self.save_filename\n",
        "    \n",
        "    def get_models_path(self):\n",
        "      return self.root_folder + \"/gdrive/My Drive/DL/models/\" + self.save_filename\n",
        "        \n",
        "    def setup(self):\n",
        "        # ######################################################\n",
        "        # # TODO remove this once torchvision 0.3 is present by\n",
        "        # # default in Colab\n",
        "        # ######################################################\n",
        "        global torchvision_upgraded\n",
        "        try:\n",
        "            torchvision_upgraded\n",
        "        except NameError:\n",
        "          !pip uninstall -y torchvision\n",
        "          !pip install https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl\n",
        "          torchvision_upgraded = True\n",
        "        else:\n",
        "          print(\"torchvision already upgraded\")\n",
        "          \n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/gdrive')\n",
        "        \n",
        "        self.get_nag_util_files()\n",
        "        \n",
        "    def load_dataset(self, compressed_name, unpacked_name):\n",
        "      if compressed_name not in os.listdir('.'):\n",
        "        print(compressed_name + ' not found, getting it from drive')\n",
        "        shutil.copyfile(\"/content/gdrive/My Drive/DL/{}.tar.gz\".format(compressed_name), \"./{}.tar.gz\".format(compressed_name))\n",
        "\n",
        "        gunzip_arg = \"./{}.tar.gz\".format(compressed_name)\n",
        "        !gunzip -f $gunzip_arg\n",
        "\n",
        "        tar_arg = \"./{}.tar\".format(compressed_name)\n",
        "        !tar -xvf $tar_arg > /dev/null\n",
        "\n",
        "        os.rename(unpacked_name, compressed_name)\n",
        "\n",
        "    #     ls_arg = \"./{}/train/n01440764\".format(compressed_name)\n",
        "    #     !ls $ls_arg\n",
        "\n",
        "        !rm $tar_arg\n",
        "\n",
        "        print(\"done\") \n",
        "      else:\n",
        "        print(compressed_name + \" found\")\n",
        "        \n",
        "    def load_test_dataset(self, root_folder):\n",
        "      test_folder = root_folder + '/test/'\n",
        "      if 'test' not in os.listdir(root_folder):\n",
        "        print('getting test dataset from drive')\n",
        "        os.mkdir(test_folder)\n",
        "        for i in range(1,11):\n",
        "          shutil.copy(\"/content/gdrive/My Drive/DL/full_test_folder/{}.zip\".format(i), test_folder)\n",
        "          shutil.unpack_archive(test_folder + \"/{}.zip\".format(i), test_folder)\n",
        "          os.remove(test_folder + \"/{}.zip\".format(i))\n",
        "          print(\"done with the {}th fragment\".format(i))\n",
        "      else:\n",
        "        print('test dataset found.')\n",
        "        \n",
        "    def set_data_path(self, path):\n",
        "      self.data_path = Path('./' + path)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyZUYSjBi9K9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "a88472cd-6bbe-474d-c505-1c5791d6de13"
      },
      "source": [
        "env = create_env()\n",
        "env.setup()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torchvision already upgraded\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "\n",
            "getting git files ...\n",
            "Already up to date.\n",
            "\n",
            "done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3Ev7jcRKoARg",
        "colab": {}
      },
      "source": [
        "from fastai.vision import *\n",
        "from fastai.imports import *\n",
        "from fastai.callbacks import *\n",
        "from fastai.utils.mem import *\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import sys; import os; import shutil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_1aE41PZAMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sys.path.append(env.python_files_path + '/' + env.python_files_dir)\n",
        "\n",
        "from nag_util import *\n",
        "import nag_util"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tltucTv2ep9-",
        "colab": {}
      },
      "source": [
        "# mode = \"sanity_check\"\n",
        "# mode = \"normal\"\n",
        "mode = \"div_metric_calc\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SO1h55obXzOv",
        "outputId": "32b4001a-9389-4ae2-bd0c-c09953991995",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "if mode == \"normal\":\n",
        "  env.load_dataset('dataset','data')\n",
        "  env.set_data_path('dataset')\n",
        "elif mode == \"sanity_check\":\n",
        "  env.load_dataset('dataset_sanity_check_small', 'dataset_sanity_check_small')  \n",
        "  env.set_data_path('dataset_sanity_check_small')\n",
        "elif mode == \"div_metric_calc\":\n",
        "  env.load_dataset('dataset','data')\n",
        "  env.set_data_path('dataset')\n",
        "  env.load_test_dataset(str(env.data_path))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset found\n",
            "done with the 1th fragment\n",
            "done with the 2th fragment\n",
            "done with the 3th fragment\n",
            "done with the 4th fragment\n",
            "done with the 5th fragment\n",
            "done with the 6th fragment\n",
            "done with the 7th fragment\n",
            "done with the 8th fragment\n",
            "done with the 9th fragment\n",
            "done with the 10th fragment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "koaQZmjMom7w",
        "colab": {}
      },
      "source": [
        "batch_size = 8\n",
        "gpu_flag = True\n",
        "nag_util.batch_size = batch_size; nag_util.gpu_flag = gpu_flag;\n",
        "# nag_util.set_globals(gpu_flag, batch_size)\n",
        "tfms = get_transforms(do_flip=False, max_rotate=0)\n",
        "data = (ImageList.from_folder(env.data_path)\n",
        "        .split_by_folder(valid=('test' if mode == 'div_metric_calc' else 'valid'))\n",
        "        .label_from_folder()\n",
        "        .transform(tfms, size=224)\n",
        "        .databunch(bs=batch_size, num_workers=1)\n",
        "        .normalize(imagenet_stats))\n",
        "\n",
        "# data.show_batch(rows=2, figsize=(5,5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kDBkRV8yovwV",
        "colab": {}
      },
      "source": [
        "# model = models.resnet50\n",
        "model = models.vgg16_bn\n",
        "# model = torchvision.models.googlenet\n",
        "model_name = model.__name__\n",
        "z_dim = 10\n",
        "\n",
        "class SoftmaxWrapper(nn.Module):\n",
        "  def __init__(self, m):\n",
        "    super().__init__()\n",
        "    self.m = m\n",
        "    self.softmax = nn.Softmax(dim=-1)\n",
        "    \n",
        "  def forward(self, inp):\n",
        "    out = self.m(inp)\n",
        "    return self.softmax(out)\n",
        "  \n",
        "arch = SoftmaxWrapper(model(pretrained=True).cuda().eval())\n",
        "nag_util.arch = arch\n",
        "requires_grad(arch, False)\n",
        "\n",
        "# vgg:\n",
        "# layers = []\n",
        "# blocks = [i-1 for i,o in enumerate(children(arch.features)) if isinstance(o, nn.MaxPool2d)]\n",
        "# layers = [arch.features[i] for i in blocks]\n",
        "# layer_weights = [1] * len(layers)\n",
        "\n",
        "# resnet:\n",
        "# layers = [\n",
        "#   arch.layer2[0].downsample,\n",
        "#   arch.layer3[0].downsample,\n",
        "#   arch.layer4[0].downsample\n",
        "# ]\n",
        "layers = [\n",
        "    arch.softmax\n",
        "]\n",
        "\n",
        "layer_weights = [1.] * len(layers)\n",
        "\n",
        "# layers = []\n",
        "# last_layer = None\n",
        "# for o in children(arch):\n",
        "#   if isinstance(o, nn.AdaptiveAvgPool2d):\n",
        "#     layers.append(last_layer)\n",
        "#   last_layer = o\n",
        "    \n",
        "# # layers = [arch.fc]\n",
        "\n",
        "# layer_weights = [1] * len(layers)\n",
        "\n",
        "# inception:\n",
        "# layers = [\n",
        "#     arch.Conv2d_1a_3x3,\n",
        "#     arch.Mixed_6e,\n",
        "#     arch.Mixed_7a,\n",
        "#     arch.fc    \n",
        "# ]\n",
        "# layer_weights = [1.0/4.0] * len(layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QdqhsfBNWx66",
        "colab": {}
      },
      "source": [
        "class Gen(nn.Module):\n",
        "  def __init__(self, z_dim, gf_dim=64, y_dim = None, df_dim = 64, image_shape = [3,128,128]):\n",
        "    super(Gen, self).__init__()\n",
        "\n",
        "    self.bs = None\n",
        "    self.z_dim = z_dim\n",
        "    self.gf_dim = gf_dim\n",
        "    self.y_dim = y_dim\n",
        "    self.df_dim = df_dim\n",
        "    self.image_shape = image_shape\n",
        "\n",
        "    self.z_ = nn.Linear(self.z_dim, self.gf_dim * 7 * 4 * 4, bias=True)\n",
        "    self.z_.bias.data.fill_(0)\n",
        "    self.BN_ = nn.BatchNorm2d(self.gf_dim * 7)\n",
        "\n",
        "    self.CT2d_1 = deconv_layer(self.gf_dim * 8, \n",
        "                             self.gf_dim * 4,\n",
        "                              k_size = (5,5), s = (2,2), pad = (2,2))\n",
        "    self.CT2d_2 = deconv_layer(self.gf_dim * 5, self.gf_dim * 2)\n",
        "\n",
        "    self.half = self.gf_dim // 2\n",
        "    if self.half == 0:\n",
        "      self.half == 1\n",
        "    self.CT2d_3 = deconv_layer(self.gf_dim * 2 + self.half, self.gf_dim * 1)\n",
        "\n",
        "    self.quarter = self.gf_dim // 4\n",
        "    if self.quarter == 0:\n",
        "      self.quarter == 1\n",
        "    self.CT2d_4 = deconv_layer(self.gf_dim * 1 + self.quarter, self.gf_dim * 1)\n",
        "\n",
        "    self.eighth = self.gf_dim // 8\n",
        "    if self.eighth == 0:\n",
        "      self.eighth == 1\n",
        "    self.CT2d_5 = deconv_layer(self.gf_dim * 1 + self.eighth, self.gf_dim * 1)\n",
        "\n",
        "    # sixteenth = self.gf_dim // 16\n",
        "    # if half == 0:\n",
        "      # half == 1\n",
        "    self.CT2d_6 = deconv_layer(self.gf_dim * 1 + self.eighth, self.gf_dim * 1)\n",
        "\n",
        "    # sixteenth = self.gf_dim // 16\n",
        "    # if half == 0:\n",
        "      # half == 1\n",
        "    self.CT2d_7 = deconv_layer(self.gf_dim * 1 + self.eighth, 3, k_size = (5,5), s = (1,1), pad = (2,2), activation = False)\n",
        "\n",
        "\n",
        "  def forward_z(self, z):\n",
        "    self.bs = z.shape[0]\n",
        "      \n",
        "    # define generator here\n",
        "    # input: bs * 100\n",
        "    # Linear (z_dim, gf_dim * 7 * 4 * 4), bias = (True, init with zero), \n",
        "    # Reshape (bs, gf_dim * 7 * 4 * 4) -> (bs, gf_dim * 7, 4 , 4)\n",
        "    # Virtual Batch Norm = VBN\n",
        "    # ReLU\n",
        "    # h0 <- relu output\n",
        "    h0 = F.relu(self.BN_(self.z_(z).contiguous().view(self.bs, -1, 4, 4)))\n",
        "    assert h0.shape[2:] == (4, 4), \"Non-expected shape, it shoud be (4,4)\"\n",
        "\n",
        "    # h0z = self.make_z([bs, gf_dim, 4, 4])\n",
        "    # h0 = torch.cat([h0, h0z], dim=1)\n",
        "    # h1 = deconv(gf_dim * 8, gf_dim * 4, kernel = (5, 5), stride = (2,2), padding = (2,2), bias = (True, 0))\n",
        "    # h1 = ReLU(VBN(h1))\n",
        "    h0z = self.make_z([self.bs, self.gf_dim, 4, 4])\n",
        "    h0 = torch.cat([h0, h0z], dim=1)\n",
        "    h1 = self.CT2d_1(h0)\n",
        "    assert h1.shape[2:] == (7, 7), \"Non-expected shape, it shoud be (7,7)\"\n",
        "\n",
        "    # h1z = self.make_z([bs, gf_dim, 7, 7])\n",
        "    # h1 = torch.cat([h1, h1z], dim=1)\n",
        "    # h2 = deconv(gf_dim * 5, gf_dim * 2, kernel = (5, 5), stride = (2,2), padding = (2,2), bias = (True, 0))\n",
        "    # h2 = ReLU(VBN(h2))\n",
        "    # assert output size (14,14)\n",
        "    h1z = self.make_z([self.bs, self.gf_dim, 7, 7])\n",
        "    h1 = torch.cat([h1, h1z], dim=1)\n",
        "    h2 = self.CT2d_2(h1)\n",
        "    assert h2.shape[2:] == (14,14), \"Non-expected shape, it shoud be (14,14)\"\n",
        "\n",
        "    # h2z = self.make_z([bs, half, 14, 14])\n",
        "    # h2 = torch.cat([h2, h2z], dim=1)\n",
        "    # h3 = deconv(gf_dim  2 + half, gf_dim  1, kernel = (5, 5), stride = (2,2), padding = (2,2), bias = (True, 0))\n",
        "    # h3 = ReLU(VBN(h3))\n",
        "    h2z = self.make_z([self.bs, self.half, 14, 14])\n",
        "    h2 = torch.cat([h2, h2z], dim=1)\n",
        "    h3 = self.CT2d_3(h2)\n",
        "    assert h3.shape[2:] == (28,28), \"Non-expected shape, it shoud be (28,28)\"\n",
        "\n",
        "    # h3z = self.make_z([bs, quarter, 28, 28])\n",
        "    # h3 = torch.cat([h3, h3z], dim=1)\n",
        "    # h4 = deconv(gf_dim * 1 + quarter, gf_dim * 1, kernel = (5, 5), stride = (2,2), padding = (2,2), bias = (True, 0))\n",
        "    # h4 = ReLU(VBN(h4))\n",
        "    h3z = self.make_z([self.bs, self.quarter, 28, 28])\n",
        "    h3 = torch.cat([h3, h3z], dim=1)\n",
        "    h4 = self.CT2d_4(h3)\n",
        "    assert h4.shape[2:] == (56,56), \"Non-expected shape, it shoud be (56,56)\"\n",
        "\n",
        "    # h4z = self.make_z([bs, self.eighth, 56, 56])\n",
        "    # h4 = torch.cat([h4, h4z], dim=1)\n",
        "    # h5 = deconv(gf_dim * 1 + eighth, gf_dim * 1, kernel = (5, 5), stride = (2,2), padding = (2,2), bias = (True, 0))\n",
        "    # h5 = ReLU(VBN(h5))\n",
        "\n",
        "    h4z = self.make_z([self.bs, self.eighth, 56, 56])\n",
        "    h4 = torch.cat([h4, h4z], dim=1)\n",
        "    h5 = self.CT2d_5(h4)\n",
        "    assert h5.shape[2:] == (112,112), \"Non-expected shape, it shoud be (112,112)\"\n",
        "\n",
        "    # h5z = self.make_z([bs, eighth, 112, 112])\n",
        "    # h5 = torch.cat([h5, h5z], dim=1)\n",
        "    # h6 = deconv(gf_dim * 1 + eighth, gf_dim * 1, kernel = (5, 5), stride = (2,2), padding = (2,2), bias = (True, 0))\n",
        "    # h6 = ReLU(VBN(h5))\n",
        "    h5z = self.make_z([self.bs, self.eighth, 112, 112])\n",
        "    h5 = torch.cat([h5, h5z], dim=1)\n",
        "    h6 = self.CT2d_6(h5)\n",
        "    assert h6.shape[2:] == (224,224), \"Non-expected shape, it shoud be (224,224)\"\n",
        "\n",
        "    # h6z = self.make_z([bs, eighth, 224, 224])\n",
        "    # h6 = torch.cat([h6, h6z], dim=1)\n",
        "    # h7 = deconv(gf_dim * 1 + eighth, 3, kernel = (5, 5), stride = (2,2), padding = (2,2), bias = (True, 0))\n",
        "    # h7 = ReLU(VBN(h7))\n",
        "    h6z = self.make_z([self.bs, self.eighth, 224, 224])\n",
        "    h6 = torch.cat([h6, h6z], dim=1)\n",
        "    h7 = self.CT2d_7(h6)\n",
        "    assert h7.shape[2:] == (224,224), \"Non-expected shape, it shoud be (448,448)\"\n",
        "\n",
        "    # out = 10*tanh(h7)\n",
        "\n",
        "    #     return 10 *F.tanh(h7)\n",
        "    ksi = 10.0\n",
        "    output_coeff = ksi / (255.0 * np.mean(imagenet_stats[1])) \n",
        "    # this coeff scales the output to be appropriate for images that are \n",
        "    # normalized using imagenet_stats (and are hence in the approximate [-2.5, 2.5]\n",
        "    # interval)\n",
        "    return output_coeff * torch.tanh(h7)\n",
        "    # return 0.15 * torch.tanh(h7)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    self.bs = inputs.shape[0]\n",
        "    z = inputs.new_empty([self.bs, self.z_dim]).uniform_(-1,1).cuda()\n",
        "    p, n = self.make_triplet_samples(z, 0.1, 0.1, 2.)\n",
        "    \n",
        "    z_out = self.forward_z(z)\n",
        "    p_out = self.forward_z(p)\n",
        "    n_out = self.forward_z(n)\n",
        "    \n",
        "    return z_out, p_out, n_out, inputs\n",
        "  \n",
        "  def forward_single_z(self, z):\n",
        "    return self.forward_z(z[None]).squeeze()\n",
        "           \n",
        "  \n",
        "  def make_triplet_samples(self, z, margin, r2, r3):\n",
        "    positive_sample = z + self.random_vector_volume(z.shape, 0, margin).cuda() \n",
        "    negative_sample = z + self.random_vector_volume(z.shape, r2, r3).cuda()\n",
        "#     negative_sample = z + self.random_vector_volume(z.shape, margin, margin * scale).cuda()\n",
        "    return positive_sample, negative_sample\n",
        "\n",
        "  def random_vector_surface(self, shape, r = 1.):\n",
        "    mat = torch.randn(size=shape).cuda()\n",
        "    norm = torch.norm(mat, p=2, dim=1, keepdim = True).cuda()\n",
        "    return (mat/norm) * r\n",
        "\n",
        "#   def random_vector_volume(shape, inner_r = 0, outer_r):\n",
        "#     d = torch.zeros(shape[0]).uniform_()   ** (1/int(np.prod(shape[0])))\n",
        "#     d.unsqueeze_(-1)\n",
        "#     return random_vector_surface(shape, outer_r) * d\n",
        "  \n",
        "  def random_vector_volume(self, shape, inner_r, outer_r):\n",
        "#     d = torch.zeros(shape[0]).uniform_(0, outer_r - inner_r).cuda()\n",
        "    fraction = torch.empty(shape[0]).uniform_(inner_r, outer_r).cuda()\n",
        "    fraction = ((fraction / outer_r) ** (1 / shape[1])) * outer_r # volume-normalize the fraction\n",
        "    fraction.unsqueeze_(-1)\n",
        "#     return self.random_vector_surface(shape, 1) * d + inner_r\n",
        "    return self.random_vector_surface(shape, 1) * fraction\n",
        "\n",
        "  def make_z(self, in_shape):\n",
        "    return torch.empty(in_shape).cuda().uniform_(-1,1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wULy7qXNYeVv",
        "colab": {}
      },
      "source": [
        "def load_starting_point(learn, name, z_dim):\n",
        "  if detect_env() != \"colab\":\n",
        "    raise NotImplementedError(\"load_starting_point not implemented for non-colab environments yet.\")\n",
        "  import os\n",
        "  identity_token = name + '-zdim' + str(z_dim)\n",
        "  address = '/content/gdrive/My Drive/DL/model_starting_points/' + identity_token\n",
        "  starting_point_exists = os.path.isfile(address + '.pth')\n",
        "  if not starting_point_exists:\n",
        "    print(\"\\n\\nno starting point found for model:\" + identity_token + \". creating one from the current learner.\\n\\n\")\n",
        "    learn.save(address)\n",
        "  learn.load(address)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8KJQaKHZANA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.set_printoptions(precision=2, sci_mode=False, threshold=5000)\n",
        "\n",
        "def print_softmax_tensor(x):\n",
        "  print(\"[\", end=\"\")\n",
        "  for i, x_i in enumerate(x.data):\n",
        "    if abs(x_i) > 0.01:\n",
        "      print(\"{}: {:.2f}\".format(i, x_i.item()), end=(\", \" if (i < x.shape[0]-1) else \"\"))\n",
        "  print(\"]\")\n",
        "  \n",
        "# print_softmax_tensor(torch.tensor([0.01, 2.5, 5.]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NkfbLWEQqRA_",
        "colab": {}
      },
      "source": [
        "def js_distance(x1, x2):\n",
        "  m = 0.5 * (x1 + x2)\n",
        "  return 0.5 * (F.kl_div(x1, m) + F.kl_div(x2, m))\n",
        "\n",
        "def kl_distance(x1, x2):\n",
        "  return F.kl_div(x1, x2, reduction='batchmean')\n",
        "\n",
        "def wasserstein_distance(x1, x2):\n",
        "  pass\n",
        "\n",
        "def l1_distance(x1, x2):\n",
        "  return F.l1_loss(x1, x2)\n",
        "\n",
        "def l2_distance(x1, x2):\n",
        "  return F.mse_loss(x1 * 10, x2 * 10)\n",
        "\n",
        "def cos_distance(x1, x2):\n",
        "    return -1 * torch.mean(F.cosine_similarity(x1, x2))\n",
        "\n",
        "triplet_call_cnt = 0\n",
        "\n",
        "def triplet_loss(anchor, positive, negative, distance_func, margin):\n",
        "  # max distance when using l1_distance is 2\n",
        "  # max distacne when using l2-distance is sqrt(2)\n",
        "#   print(\"anchor: \", anchor.min(), anchor.max())\n",
        "  ap_dist = distance_func(anchor, positive)\n",
        "  an_dist = distance_func(anchor, negative)\n",
        "\n",
        "  global triplet_call_cnt\n",
        "  triplet_call_cnt += 1\n",
        "  if triplet_call_cnt % 10 == 0:\n",
        "    print(\"a: \", end=\"\"); print_softmax_tensor(anchor[0])\n",
        "    print(\"p: \", end=\"\"); print_softmax_tensor(positive[0])\n",
        "    print(\"n: \", end=\"\"); print_softmax_tensor(negative[0])\n",
        "    print(\"ap_dist: {}, an_dist: {}\".format(ap_dist, an_dist))\n",
        "    \n",
        "  return torch.mean(F.relu(ap_dist - an_dist + margin))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hsFgfiN8EV7z",
        "colab": {}
      },
      "source": [
        "def diversity_loss(input, target):\n",
        "#   return -1 * torch.mean(torch.pow(f_x_a-f_x_s,2))\n",
        "  if input.shape[0] != batch_size:\n",
        "    print(\"input shape: \", input.shape)\n",
        "    print(\"target shape: \", target.shape, \"\\n\\n\")\n",
        "  return torch.mean(F.cosine_similarity(\n",
        "    input.view([batch_size, -1]),\n",
        "    target.view([batch_size, -1]), \n",
        "  ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqJsujkVZANH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# z1 = torch.tensor([[1., 0.]])\n",
        "# z2 = torch.tensor([[-1., 0]])\n",
        "# cos_sim(z1,z2)\n",
        "\n",
        "# z1 = torch.tensor([[0.5, 0.5]])\n",
        "# z2 = torch.tensor([[0.55, 0.45]])\n",
        "# F.kl_div(z1, z2, reduction='batchmean')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4FVegHeYovws",
        "colab": {}
      },
      "source": [
        "class FeatureLoss(nn.Module):\n",
        "    def __name__(self):\n",
        "      return \"feature_loss\"\n",
        "  \n",
        "    def __init__(self, dis, layers, layer_weights):\n",
        "        super().__init__()\n",
        "        \n",
        "        # define generator here \n",
        "        self.dis = dis\n",
        "        self.diversity_layers = layers\n",
        "        self.hooks = hook_outputs(self.diversity_layers, detach=False)\n",
        "        self.weights = layer_weights\n",
        "        #self.metric_names = [\"fool_loss\"] + [f\"div_loss_{i}\" for i in range(len(layers))] + ['triplet_loss']# Maybe Gram\n",
        "        self.metric_names = [\"fool_loss\"] + [f\"div_loss_{i}\" for i in range(len(layers))]# Maybe Gram\n",
        "        self.triplet_weight = 10.\n",
        "    \n",
        "    def make_features(self, x, clone=False):\n",
        "        y = self.dis(x)\n",
        "        return y, [(o.clone() if clone else o) for o in self.hooks.stored]\n",
        "    \n",
        "    def forward(self, inp, target):\n",
        "        sigma_B, sigma_pos, sigma_neg, X_B = inp\n",
        "\n",
        "        X_A = self.add_perturbation(X_B, sigma_B) \n",
        "#        # TEMPORARY: disabled the TRIPLET LOSS function\n",
        "#         X_A_pos = self.add_perturbation(X_B, sigma_pos)\n",
        "#         X_A_neg = self.add_perturbation(X_B, sigma_neg) \n",
        "        \n",
        "        X_S = self.add_perturbation_shuffled(X_B, sigma_B) # Shuffled Addversarial Examples\n",
        "        \n",
        "        B_Y, _ = self.make_features(X_B)\n",
        "        A_Y, A_feat = self.make_features(X_A)\n",
        "        _, S_feat = self.make_features(X_S)\n",
        "#         pos_softmax, _ = self.make_features(X_A_pos)\n",
        "#         neg_softmax, _ = self.make_features(X_A_neg)\n",
        "        \n",
        "        \n",
        "        fooling_loss =  fool_loss(A_Y, B_Y)\n",
        "      \n",
        "        raw_diversity_losses = [diversity_loss(a_f, s_f) for a_f, s_f in zip(A_feat, S_feat)]\n",
        "        weighted_diversity_losses = [diversity_loss(a_f, s_f) * weight for a_f, s_f, weight in zip(A_feat, S_feat, self.weights)]\n",
        "#         raw_triplet_loss = triplet_loss(A_Y, pos_softmax, neg_softmax, l2_distance, 10.)\n",
        "#         weighted_triplet_loss = raw_triplet_loss * self.triplet_weight\n",
        "    \n",
        "#         self.losses = [fooling_loss] + weighted_diversity_losses + [weighted_triplet_loss]\n",
        "#         self.metrics = dict(zip(self.metric_names, [fooling_loss] + raw_diversity_losses + [weighted_triplet_loss]))\n",
        "        self.losses = [fooling_loss] + weighted_diversity_losses\n",
        "        self.metrics = dict(zip(self.metric_names, [fooling_loss] + raw_diversity_losses))\n",
        "\n",
        "        return sum(self.losses)\n",
        "\n",
        "#     def forward(self, inp, target):\n",
        "#       sigma_B, sigma_pos, sigma_neg, X_B = inp\n",
        "\n",
        "#       X_A = self.add_perturbation(X_B, sigma_B) \n",
        "\n",
        "#       X_S = self.add_perturbation_shuffled(X_B, sigma_B) # Shuffled Addversarial Examples\n",
        "\n",
        "#       B_Y, _ = self.make_features(X_B)\n",
        "#       A_Y, A_feat = self.make_features(X_A)\n",
        "#       _, S_feat = self.make_features(X_S)\n",
        "\n",
        "#       fooling_loss =  fool_loss(A_Y, B_Y)\n",
        "\n",
        "#       raw_diversity_losses = [diversity_loss(a_f, s_f) for a_f, s_f in zip(A_feat, S_feat)]\n",
        "#       weighted_diversity_losses = [diversity_loss(a_f, s_f) * weight for a_f, s_f, weight in zip(A_feat, S_feat, self.weights)]\n",
        "\n",
        "#       raw_triplet_loss = triplet_loss(sigma_B, sigma_pos, sigma_neg, l2_distance, 5.)\n",
        "#       weighted_triplet_loss = raw_triplet_loss * self.triplet_weight\n",
        "\n",
        "#       self.losses = [fooling_loss] + weighted_diversity_losses + [weighted_triplet_loss]\n",
        "#       self.metrics = dict(zip(self.metric_names, [fooling_loss] + raw_diversity_losses + [weighted_triplet_loss]))\n",
        "\n",
        "#       return sum(self.losses)\n",
        "  \n",
        "  \n",
        "    def add_perturbation(self, inp, perturbation):\n",
        "        return inp.add(perturbation)\n",
        "  \n",
        "    def add_perturbation_shuffled(self, inp, perturbation):\n",
        "#         j = torch.randperm(inp.shape[0])\n",
        "        j = derangement(inp.shape[0])\n",
        "        return inp.add(perturbation[j])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qd9gXUy_ovww",
        "colab": {}
      },
      "source": [
        "feat_loss = FeatureLoss(arch, layers, layer_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IfZKdYD2MSdi",
        "colab": {}
      },
      "source": [
        "env.save_filename = 'vgg16_11'\n",
        "\n",
        "if Path(env.get_csv_path() + '.csv').exists(): raise FileExistsError(\"csv_path already exists\")\n",
        "if Path(env.get_models_path()).exists(): raise FileExistsError(\"models_path already exists\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b9J20CBLS8S9",
        "colab": {}
      },
      "source": [
        "learn = None; gc.collect()\n",
        "csv_logger = partial(ImmediateCSVLogger, filename= env.temp_csv_path + '/' + env.save_filename)\n",
        "# learn = Learner(data, Gen(z_dim=10), loss_func = feat_loss, metrics=[validation], callback_fns=LossMetrics, opt_func = optim.SGD)\n",
        "# learn = Learner(data, Gen(z_dim=z_dim), loss_func = feat_loss, metrics=[validation], callback_fns=[LossMetrics, DiversityWeightsScheduler])\n",
        "learn = Learner(data, Gen(z_dim=z_dim), loss_func = feat_loss, metrics=[validation], callback_fns=[LossMetrics, csv_logger])\n",
        "# load_starting_point(learn, model_name, z_dim)\n",
        "# random_seed(42, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wk9E0AUm9rmn",
        "colab": {}
      },
      "source": [
        "# learn.lr_find(1e-6, 1000)\n",
        "# learn.recorder.plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0wOZYzOHDEdB",
        "colab": {}
      },
      "source": [
        "!cp \"/content/gdrive/My Drive/DL/models/vgg16_12-last.pth\"  \"/content/\"\n",
        "learn.load('/content/vgg16_12-last')\n",
        "\n",
        "# learn.load('/root/Derakhshani/adversarial/models/vgg16_10/vgg16_10_29')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LA1ffVbbEwQS",
        "outputId": "682ac419-ee54-497a-b89f-496f789cf368",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "if mode == \"sanity_check\":\n",
        "  print(\"\\n\\n\\nWARNING: you are training on a sanity_check dataset.\\n\\n\\n\\n\")\n",
        "if len(learn.callback_fns) == 1:\n",
        "  print(\"\\n\\n\\nWARNING: you are not using the DiversityWeightsScheduler callback.\\n\\n\\n\")\n",
        "\n",
        "    \n",
        "saver_best = SaveModelCallback(learn, every='improvement', monitor='validation', name=env.save_filename + \"-best\")\n",
        "saver_every_epoch = SaveModelCallback(learn, every='epoch', name=env.save_filename)\n",
        "\n",
        "# import cProfile\n",
        "\n",
        "# pr = cProfile.Profile()\n",
        "# pr.enable()\n",
        "learn.fit(30, lr=5e-03, callbacks=[saver_best, saver_every_epoch])\n",
        "# pr.disable()\n",
        "\n",
        "# learn.fit(30, lr=5e-03, wd=0.005, callbacks=[saver_best, saver_every_epoch])\n",
        "# learn.fit_one_cycle(20, max_lr=5e-1, callbacks=[saver_callback])\n",
        "# learn.fit_one_cycle(8, max_lr=5e-01) #mohammad's setting that got 77 validation start on resnet with diversity loss on AdaptiveAvgPool2d\n",
        "# learn.fit_one_cycle(5, max_lr=2e-2) #used for vgg-19-bn\n",
        "# learn.fit_one_cycle(5, max_lr=3e-3) # used for resnet50\n",
        "\n",
        "shutil.copyfile(env.temp_csv_path + '/' + env.save_filename + \".csv\", env.get_csv_path() + '.csv')\n",
        "shutil.copytree(env.data_path/\"models\", env.get_models_path())\n",
        "\n",
        "# pr.print_stats()\n",
        "\n",
        "# shutil.copyfile(\"/content/dataset/models/\" + save_filename + \"-best.pth\", \"/content/gdrive/My Drive/DL/models/\" + save_filename + \".pth\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='30', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/30 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>validation</th>\n",
              "      <th>fool_loss</th>\n",
              "      <th>div_loss_0</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='186' class='' max='1125', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      16.53% [186/1125 00:52<04:27 1.4521]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-BmJ8cESVIay",
        "colab": {}
      },
      "source": [
        "!cp \"/content/gdrive/My Drive/DL/models/resnet50-dir/resnet50-dir-best.pth\" \"/content/resnet50-best.pth\"\n",
        "learn.load(\"/content/resnet50-best\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "obTWhste2pZo",
        "colab": {}
      },
      "source": [
        "learn.fit(1, lr = 0., wd=0.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zUz0oXLbVVB0",
        "colab": {}
      },
      "source": [
        "learn.validate(metrics=[feat_loss])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MO2fZ-hSSUzJ",
        "colab": {}
      },
      "source": [
        "z1 = torch.empty(10).uniform_(-1,1).cuda()\n",
        "z2 = torch.empty(10).uniform_(-1,1).cuda()\n",
        "# print(\"z1: \", z1)\n",
        "# print(\"z2: \", z2)\n",
        "print(\"distance: \", torch.norm(z1-z2,p=2))\n",
        "model = learn.model.eval()\n",
        "\n",
        "z_s = interpolate(z1, z2, 0.15)\n",
        "print(len(z_s))\n",
        "for i,z in enumerate(z_s):\n",
        "  img = noise_to_image(model.forward_single_z(z))\n",
        "  img.show()\n",
        "  img.save('./pics/' + str(i) + '.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DGuGN7B7V0Xt",
        "colab": {}
      },
      "source": [
        "def generate_perturbations(learn, n_perturbations):\n",
        "  initial_training_mode = learn.model.training\n",
        "  \n",
        "  model = learn.model.eval()\n",
        "  input_img = (learn.data.valid_ds[0][0].data)[None].cuda()\n",
        "  perturbations = []\n",
        "  for i in range(n_perturbations):\n",
        "    perturbation = model(input_img)[0].squeeze()\n",
        "    perturbations.append(perturbation)\n",
        "    \n",
        "  learn.model.train(initial_training_mode)  \n",
        "  return perturbations\n",
        "  \n",
        "  \n",
        "# def compute_mean_prediction_histogram(learn, perturbations):\n",
        "#   pred_histogram = [0] * 1000\n",
        "#   for j, perturbation in enumerate(perturbations):\n",
        "#     for i in range(len(learn.data.valid_ds)):\n",
        "#       img = learn.data.valid_ds[i][0].data[None].cuda()\n",
        "#       perturbed_img = img + perturbation\n",
        "#       pred = torch.argmax(arch(perturbed_img).squeeze())\n",
        "#       pred_histogram[pred]+= 1./len(perturbations)\n",
        "#     print(\"finished creating histogram for the %dth perturbation\"%j)\n",
        "#   return pred_histogram\n",
        "\n",
        "  \n",
        "def compute_mean_prediction_histogram(learn, perturbations):\n",
        "  pred_histogram = [0] * 1000\n",
        "  for j, perturbation in enumerate(perturbations):\n",
        "    batch_no = -1\n",
        "    for batch, _ in learn.data.valid_dl:\n",
        "      batch_no += 1\n",
        "      if batch_no % 100 == 0 : print(\"at batch no {}\".format(batch_no))\n",
        "      perturbed_batch = batch + perturbation[None]\n",
        "      preds = arch(perturbed_batch).argmax(1)\n",
        "      for pred in preds:\n",
        "        pred_histogram[pred]+= 1. / len(perturbations)\n",
        "    print(\"finished creating histogram for the %dth perturbation\"%j)\n",
        "\n",
        "  pred_histogram = np.asarray(np.array(pred_histogram) / len(perturbations))\n",
        "\n",
        "  return pred_histogram\n",
        "\n",
        "\n",
        "def diversity(learn, n_perturbations, percentage):\n",
        "  pred_histogram = compute_mean_prediction_histogram(\n",
        "      learn, generate_perturbations(learn, n_perturbations)\n",
        "  )\n",
        "  print(\"finished creating the prediction histogram\")\n",
        "  pred_histogram_sum = np.sum(pred_histogram)\n",
        "  \n",
        "  indexed_pred_histogram = [(i, hist_element) for i,hist_element in  \n",
        "                            enumerate(pred_histogram)]\n",
        "  \n",
        "  indexed_pred_histogram.sort(key=lambda x: x[1], reverse = True)\n",
        "  \n",
        "  cumulative_percent = 0\n",
        "  n_used_classes = 0\n",
        "  top_classes = []\n",
        "  while cumulative_percent < percentage:\n",
        "    hist_elem = indexed_pred_histogram[n_used_classes]\n",
        "    cumulative_percent += (hist_elem[1] / pred_histogram_sum) * 100.\n",
        "    top_classes.append(hist_elem[0])\n",
        "    n_used_classes += 1\n",
        "  \n",
        "  #top_classes is a useful piece of info that is currently unused\n",
        "  return n_used_classes, indexed_pred_histogram, top_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q8VUc3YH4vj5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 978
        },
        "outputId": "aff7c648-2f10-4938-c9cd-378f6c8d0c91"
      },
      "source": [
        "n, hist, tk = diversity(learn, 10, 95)\n",
        "n, hist, tk"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-7c9baef4156b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiversity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-21a978e47b6b>\u001b[0m in \u001b[0;36mdiversity\u001b[0;34m(learn, n_perturbations, percentage)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdiversity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_perturbations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m   pred_histogram = compute_mean_prediction_histogram(\n\u001b[0;32m---> 47\u001b[0;31m       \u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate_perturbations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_perturbations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m   )\n\u001b[1;32m     49\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"finished creating the prediction histogram\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-21a978e47b6b>\u001b[0m in \u001b[0;36mgenerate_perturbations\u001b[0;34m(learn, n_perturbations)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0minput_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_ds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mperturbations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_perturbations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/data_block.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idxs)\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0midxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtry_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m   \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfms\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfmargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/data_block.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idxs)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;34m\"returns a single item based if `idxs` is an integer or a new `ItemList` object if `idxs` is a range.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0midxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtry_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/vision/data.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/data_block.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;34m\"Subclass if you want to customize how to create item `i` from `self.items`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FAgk-YyWc3rG",
        "colab": {}
      },
      "source": [
        "# learn.recorder.plot_losses()\n",
        "# learn.recorder.plot_lr()\n",
        "# learn.recorder.plot_metrics()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YTHG4Bt7VDYp",
        "colab": {}
      },
      "source": [
        "fooling_rates = []\n",
        "model = learn.model.eval()\n",
        "learn.metrics = [validation_single_perturbation]\n",
        "for i in range(10):\n",
        "  global_perturbations = model(torch.rand(1, 3, 224, 244).cuda())[0]\n",
        "  nag_util.global_perturbations = global_perturbations\n",
        "  fooling_rates.append(learn.validate()[1].cpu().item())\n",
        "  print(\"%d : %f\"%(i, fooling_rates[-1]))\n",
        "\n",
        "mean = np.mean(fooling_rates)\n",
        "stddev = np.std(fooling_rates)\n",
        "print(mean, stddev); print(fooling_rates)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OFCjzI7UaY3C",
        "colab": {}
      },
      "source": [
        "#the Image works good for floats in range [0..1]\n",
        "model = learn.model.eval()\n",
        "\n",
        "x_img = learn.data.train_ds[4][0]\n",
        "x = x_img.data.cuda()\n",
        "z = torch.tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.float32).cuda()\n",
        "# z = torch.empty(z_dim).uniform_(-1,1).cuda()\n",
        "p = model.forward_single_z(z).detach()\n",
        "x = normalize(x)\n",
        "\n",
        "p_x = x + p\n",
        "p_x = denormalize(p_x)\n",
        "p_x.clamp_(0,1)\n",
        "\n",
        "\n",
        "#prepare images\n",
        "p_x_img = Image(p_x)\n",
        "p = scale_to_range(p, [0., 1.])\n",
        "p_img = Image(p)\n",
        "# x_img.show()\n",
        "p_img.show()\n",
        "# p_x_img.show()\n",
        "\n",
        "# print_range(p)\n",
        "# print_range(x)\n",
        "# print_range(p_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzwsI2P1ZANz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z1 = torch.tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1], dtype=torch.float32).cuda()\n",
        "p1 = model.forward_single_z(z1)\n",
        "\n",
        "z2 = torch.tensor([1, -1, -1, -1, -1, -1, -1, -1, -1, -1], dtype=torch.float32).cuda()\n",
        "p2 = model.forward_single_z(z2)\n",
        "\n",
        "z3 = torch.tensor([1, 1, -1, -1, -1, -1, -1, -1, -1, -1], dtype=torch.float32).cuda()\n",
        "p3 = model.forward_single_z(z3)\n",
        "\n",
        "l2_distance(p1, p3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eroI82OKSnAL",
        "colab": {}
      },
      "source": [
        "#the Image works good for floats in range [0..1]\n",
        "model = learn.model.eval()\n",
        "\n",
        "x_img = learn.data.train_ds[4][0]\n",
        "x = x_img.data[None].cuda()\n",
        "p = model(x)[0].squeeze().detach() \n",
        "x = x.squeeze()\n",
        "x = normalize(x)\n",
        "\n",
        "p_x = x + p\n",
        "p_x = denormalize(p_x)\n",
        "p_x.clamp_(0,1)\n",
        "\n",
        "\n",
        "#prepare images\n",
        "p_x_img = Image(p_x)\n",
        "p = scale_to_range(p, [0.,1.])\n",
        "p_img = Image(p)\n",
        "# x_img.show()\n",
        "p_img.show()\n",
        "# p_x_img.show()\n",
        "\n",
        "print_range(p)\n",
        "print_range(x)\n",
        "print_range(p_x)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}