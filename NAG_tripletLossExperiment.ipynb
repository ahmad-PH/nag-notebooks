{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ahmad-PH/nag-notebooks/blob/master/NAG_tripletLossExperiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cqeZpz16do4y"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "def run_shell_command(cmd):\n",
    "  p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)\n",
    "  print(str(p.communicate()[0], 'utf-8'))\n",
    "  \n",
    "def detect_env():\n",
    "    import os\n",
    "    if 'content' in os.listdir('/'):\n",
    "      return \"colab\"\n",
    "    else:\n",
    "      return \"IBM\"\n",
    "    \n",
    "def create_env():\n",
    "  if detect_env() == \"IBM\":\n",
    "    return IBMEnv()\n",
    "  elif detect_env() == \"colab\":\n",
    "    return ColabEnv()\n",
    "\n",
    "\n",
    "class Env:\n",
    "  def get_nag_util_files(self):\n",
    "      import os\n",
    "      \n",
    "      print(\"\\ngetting git files ...\")\n",
    "      if os.path.isdir(self.python_files_path):\n",
    "        os.chdir(self.python_files_path)\n",
    "        run_shell_command('git pull')\n",
    "        os.chdir(self.root_folder)\n",
    "      else:\n",
    "        run_shell_command('git clone https://github.com/ahmad-PH/nag-public.git')\n",
    "      print(\"done.\")\n",
    "  \n",
    "\n",
    "class IBMEnv(Env):\n",
    "    def __init__(self):\n",
    "      self.root_folder = \"/root/Derakhshani/adversarial\"\n",
    "      self.temp_csv_path = self.root_folder + \"/temp\"\n",
    "      self.python_files_path = self.root_folder + \"/nag-public\"\n",
    "      self.python_files_dir = \"NAG-11May-beforeDenoiser\"\n",
    "      \n",
    "      import sys\n",
    "      sys.path.append('./nag/nag_util')\n",
    "      \n",
    "    def get_csv_path(self):\n",
    "      return self.root_folder + \"/textual notes/CSVs/\" + self.save_filename\n",
    "    \n",
    "    def get_models_path(self):\n",
    "      return self.root_folder + \"/models/\" + self.save_filename\n",
    "      \n",
    "    def setup(self):\n",
    "      self.get_nag_util_files()\n",
    "      \n",
    "    def load_dataset(self, compressed_name, unpacked_name):\n",
    "      pass\n",
    "\n",
    "    def load_test_dataset(root_folder):\n",
    "        raise NotImplementedError(\"test dataset on IBM needs work...\")\n",
    "    \n",
    "    def set_data_path(self, path):\n",
    "      self.data_path = self.root_folder + '/datasets/' + path\n",
    "    \n",
    "        \n",
    "class ColabEnv(Env):\n",
    "    def __init__(self):\n",
    "      self.root_folder = '/content'\n",
    "      self.temp_csv_path = self.root_folder\n",
    "      self.python_files_path = self.root_folder + '/nag-public'\n",
    "      self.python_files_dir = \"NAG-11May-beforeDenoiser\"\n",
    "      self.torchvision_upgraded = False\n",
    "      \n",
    "    def get_csv_path(self):\n",
    "      return self.root_folder + '/gdrive/My Drive/DL/textual notes/CSVs/' + self.save_filename\n",
    "    \n",
    "    def get_models_path(self):\n",
    "      return self.root_folder + \"/gdrive/My Drive/DL/models/\" + self.save_filename\n",
    "        \n",
    "    def setup(self):\n",
    "        # ######################################################\n",
    "        # # TODO remove this once torchvision 0.3 is present by\n",
    "        # # default in Colab\n",
    "        # ######################################################\n",
    "        if not self.torchvision_upgraded:\n",
    "          !pip uninstall -y torchvision\n",
    "          !pip install https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl\n",
    "          self.torchvision_upgraded = True\n",
    "        else:\n",
    "          print(\"torchvision already upgraded\")\n",
    "          \n",
    "        \n",
    "        drive.mount('/content/gdrive')\n",
    "        \n",
    "        self.get_nag_util_files()\n",
    "        \n",
    "    def load_dataset(self, compressed_name, unpacked_name):\n",
    "      if compressed_name not in os.listdir('.'):\n",
    "        print(compressed_name + ' not found, getting it from drive')\n",
    "        shutil.copyfile(\"/content/gdrive/My Drive/DL/{}.tar.gz\".format(compressed_name), \"./{}.tar.gz\".format(compressed_name))\n",
    "\n",
    "        gunzip_arg = \"./{}.tar.gz\".format(compressed_name)\n",
    "        !gunzip -f $gunzip_arg\n",
    "\n",
    "        tar_arg = \"./{}.tar\".format(compressed_name)\n",
    "        !tar -xvf $tar_arg > /dev/null\n",
    "\n",
    "        os.rename(unpacked_name, compressed_name)\n",
    "\n",
    "    #     ls_arg = \"./{}/train/n01440764\".format(compressed_name)\n",
    "    #     !ls $ls_arg\n",
    "\n",
    "        !rm $tar_arg\n",
    "\n",
    "        print(\"done\") \n",
    "      else:\n",
    "        print(compressed_name + \" found\")\n",
    "        \n",
    "    def load_test_dataset(root_folder):\n",
    "      test_folder = root_folder + '/test/'\n",
    "      if 'test' not in os.listdir(root_folder):\n",
    "        os.mkdir(test_folder)\n",
    "        for i in range(1,11):\n",
    "          shutil.copy(\"/content/gdrive/My Drive/DL/full_test_folder/{}.zip\".format(i), test_folder)\n",
    "          shutil.unpack_archive(test_folder + \"/{}.zip\".format(i), test_folder)\n",
    "          os.remove(test_folder + \"/{}.zip\".format(i))\n",
    "          print(\"done with the {}th fragment\".format(i))\n",
    "        \n",
    "    def set_data_path(self, path):\n",
    "      self.data_path = './' + path\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HEh6FehKT7DD"
   },
   "outputs": [],
   "source": [
    "if detect_env() == \"colab\":\n",
    "  from google.colab import drive\n",
    "\n",
    "env = create_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no error\n"
     ]
    }
   ],
   "source": [
    "env.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "q6NbXsNmUHh7",
    "outputId": "76335e6a-42f4-4d7a-83d9-c5de12f6079a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "getting git files ...\n",
      "Already up-to-date.\n",
      "\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "env.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Ev7jcRKoARg"
   },
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.imports import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.utils.mem import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import sys; import os; import shutil\n",
    "sys.path.append(env.python_files_path + '/' + env.python_files_dir)\n",
    "\n",
    "\n",
    "from nag_util import *\n",
    "import nag_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tltucTv2ep9-"
   },
   "outputs": [],
   "source": [
    "# mode = \"sanity_check\"\n",
    "mode = \"normal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SO1h55obXzOv",
    "outputId": "b2207318-8433-48f9-be2c-10fc09b32796"
   },
   "outputs": [],
   "source": [
    "if mode == \"normal\":\n",
    "  env.load_dataset('dataset','data')\n",
    "  env.set_data_path('dataset')\n",
    "elif mode == \"sanity_check\":\n",
    "  env.load_dataset('dataset_sanity_check_small', 'dataset_sanity_check_small')  \n",
    "  env.set_data_path('dataset_sanity_check_small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "koaQZmjMom7w"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "gpu_flag = True\n",
    "nag_util.batch_size = batch_size; nag_util.gpu_flag = gpu_flag;\n",
    "# nag_util.set_globals(gpu_flag, batch_size)\n",
    "tfms = get_transforms(do_flip=False, max_rotate=0)\n",
    "data = (ImageList.from_folder(env.data_path)\n",
    "        .split_by_folder()\n",
    "        .label_from_folder()\n",
    "        .transform(tfms, size=224)\n",
    "        .databunch(bs=batch_size, num_workers=1)\n",
    "        .normalize(imagenet_stats))\n",
    "\n",
    "# data.show_batch(rows=2, figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kDBkRV8yovwV"
   },
   "outputs": [],
   "source": [
    "# model = models.resnet50\n",
    "model = models.vgg16_bn\n",
    "# model = torchvision.models.googlenet\n",
    "model_name = model.__name__\n",
    "z_dim = 10\n",
    "\n",
    "class SoftmaxWrapper(nn.Module):\n",
    "  def __init__(self, m):\n",
    "    super().__init__()\n",
    "    self.m = m\n",
    "    self.softmax = nn.Softmax(dim=-1)\n",
    "    \n",
    "  def forward(self, inp):\n",
    "    out = self.m(inp)\n",
    "    return self.softmax(out)\n",
    "  \n",
    "arch = SoftmaxWrapper(model(pretrained=True).cuda().eval())\n",
    "nag_util.arch = arch\n",
    "requires_grad(arch, False)\n",
    "\n",
    "# vgg:\n",
    "# layers = []\n",
    "# blocks = [i-1 for i,o in enumerate(children(arch.features)) if isinstance(o, nn.MaxPool2d)]\n",
    "# layers = [arch.features[i] for i in blocks]\n",
    "# layer_weights = [1] * len(layers)\n",
    "\n",
    "# resnet:\n",
    "# layers = [\n",
    "#   arch.layer2[0].downsample,\n",
    "#   arch.layer3[0].downsample,\n",
    "#   arch.layer4[0].downsample\n",
    "# ]\n",
    "layers = [\n",
    "    arch.softmax\n",
    "]\n",
    "\n",
    "layer_weights = [1.] * len(layers)\n",
    "\n",
    "# layers = []\n",
    "# last_layer = None\n",
    "# for o in children(arch):\n",
    "#   if isinstance(o, nn.AdaptiveAvgPool2d):\n",
    "#     layers.append(last_layer)\n",
    "#   last_layer = o\n",
    "    \n",
    "# # layers = [arch.fc]\n",
    "\n",
    "# layer_weights = [1] * len(layers)\n",
    "\n",
    "# inception:\n",
    "# layers = [\n",
    "#     arch.Conv2d_1a_3x3,\n",
    "#     arch.Mixed_6e,\n",
    "#     arch.Mixed_7a,\n",
    "#     arch.fc    \n",
    "# ]\n",
    "# layer_weights = [1.0/4.0] * len(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QdqhsfBNWx66"
   },
   "outputs": [],
   "source": [
    "class Gen(nn.Module):\n",
    "  def __init__(self, z_dim, gf_dim=64, y_dim = None, df_dim = 64, image_shape = [3,128,128]):\n",
    "    super(Gen, self).__init__()\n",
    "\n",
    "    self.bs = None\n",
    "    self.z_dim = z_dim\n",
    "    self.gf_dim = gf_dim\n",
    "    self.y_dim = y_dim\n",
    "    self.df_dim = df_dim\n",
    "    self.image_shape = image_shape\n",
    "\n",
    "    self.z_ = nn.Linear(self.z_dim, self.gf_dim * 7 * 4 * 4, bias=True)\n",
    "    self.z_.bias.data.fill_(0)\n",
    "    self.BN_ = nn.BatchNorm2d(self.gf_dim * 7)\n",
    "\n",
    "    self.CT2d_1 = deconv_layer(self.gf_dim * 8, \n",
    "                             self.gf_dim * 4,\n",
    "                              k_size = (5,5), s = (2,2), pad = (2,2))\n",
    "    self.CT2d_2 = deconv_layer(self.gf_dim * 5, self.gf_dim * 2)\n",
    "\n",
    "    self.half = self.gf_dim // 2\n",
    "    if self.half == 0:\n",
    "      self.half == 1\n",
    "    self.CT2d_3 = deconv_layer(self.gf_dim * 2 + self.half, self.gf_dim * 1)\n",
    "\n",
    "    self.quarter = self.gf_dim // 4\n",
    "    if self.quarter == 0:\n",
    "      self.quarter == 1\n",
    "    self.CT2d_4 = deconv_layer(self.gf_dim * 1 + self.quarter, self.gf_dim * 1)\n",
    "\n",
    "    self.eighth = self.gf_dim // 8\n",
    "    if self.eighth == 0:\n",
    "      self.eighth == 1\n",
    "    self.CT2d_5 = deconv_layer(self.gf_dim * 1 + self.eighth, self.gf_dim * 1)\n",
    "\n",
    "    # sixteenth = self.gf_dim // 16\n",
    "    # if half == 0:\n",
    "      # half == 1\n",
    "    self.CT2d_6 = deconv_layer(self.gf_dim * 1 + self.eighth, self.gf_dim * 1)\n",
    "\n",
    "    # sixteenth = self.gf_dim // 16\n",
    "    # if half == 0:\n",
    "      # half == 1\n",
    "    self.CT2d_7 = deconv_layer(self.gf_dim * 1 + self.eighth, 3, k_size = (5,5), s = (1,1), pad = (2,2), activation = False)\n",
    "\n",
    "\n",
    "  def forward_z(self, z):\n",
    "    self.bs = z.shape[0]\n",
    "      \n",
    "    # define generator here\n",
    "    # input: bs * 100\n",
    "    # Linear (z_dim, gf_dim * 7 * 4 * 4), bias = (True, init with zero), \n",
    "    # Reshape (bs, gf_dim * 7 * 4 * 4) -> (bs, gf_dim * 7, 4 , 4)\n",
    "    # Virtual Batch Norm = VBN\n",
    "    # ReLU\n",
    "    # h0 <- relu output\n",
    "    h0 = F.relu(self.BN_(self.z_(z).contiguous().view(self.bs, -1, 4, 4)))\n",
    "    assert h0.shape[2:] == (4, 4), \"Non-expected shape, it shoud be (4,4)\"\n",
    "\n",
    "    # h0z = self.make_z([bs, gf_dim, 4, 4])\n",
    "    # h0 = torch.cat([h0, h0z], dim=1)\n",
    "    # h1 = deconv(gf_dim * 8, gf_dim * 4, kernel = (5, 5), stride = (2,2), padding = (2,2), bias = (True, 0))\n",
    "    # h1 = ReLU(VBN(h1))\n",
    "    h0z = self.make_z([self.bs, self.gf_dim, 4, 4])\n",
    "    h0 = torch.cat([h0, h0z], dim=1)\n",
    "    h1 = self.CT2d_1(h0)\n",
    "    assert h1.shape[2:] == (7, 7), \"Non-expected shape, it shoud be (7,7)\"\n",
    "\n",
    "    # h1z = self.make_z([bs, gf_dim, 7, 7])\n",
    "    # h1 = torch.cat([h1, h1z], dim=1)\n",
    "    # h2 = deconv(gf_dim * 5, gf_dim * 2, kernel = (5, 5), stride = (2,2), padding = (2,2), bias = (True, 0))\n",
    "    # h2 = ReLU(VBN(h2))\n",
    "    # assert output size (14,14)\n",
    "    h1z = self.make_z([self.bs, self.gf_dim, 7, 7])\n",
    "    h1 = torch.cat([h1, h1z], dim=1)\n",
    "    h2 = self.CT2d_2(h1)\n",
    "    assert h2.shape[2:] == (14,14), \"Non-expected shape, it shoud be (14,14)\"\n",
    "\n",
    "    # h2z = self.make_z([bs, half, 14, 14])\n",
    "    # h2 = torch.cat([h2, h2z], dim=1)\n",
    "    # h3 = deconv(gf_dim  2 + half, gf_dim  1, kernel = (5, 5), stride = (2,2), padding = (2,2), bias = (True, 0))\n",
    "    # h3 = ReLU(VBN(h3))\n",
    "    h2z = self.make_z([self.bs, self.half, 14, 14])\n",
    "    h2 = torch.cat([h2, h2z], dim=1)\n",
    "    h3 = self.CT2d_3(h2)\n",
    "    assert h3.shape[2:] == (28,28), \"Non-expected shape, it shoud be (28,28)\"\n",
    "\n",
    "    # h3z = self.make_z([bs, quarter, 28, 28])\n",
    "    # h3 = torch.cat([h3, h3z], dim=1)\n",
    "    # h4 = deconv(gf_dim * 1 + quarter, gf_dim * 1, kernel = (5, 5), stride = (2,2), padding = (2,2), bias = (True, 0))\n",
    "    # h4 = ReLU(VBN(h4))\n",
    "    h3z = self.make_z([self.bs, self.quarter, 28, 28])\n",
    "    h3 = torch.cat([h3, h3z], dim=1)\n",
    "    h4 = self.CT2d_4(h3)\n",
    "    assert h4.shape[2:] == (56,56), \"Non-expected shape, it shoud be (56,56)\"\n",
    "\n",
    "    # h4z = self.make_z([bs, self.eighth, 56, 56])\n",
    "    # h4 = torch.cat([h4, h4z], dim=1)\n",
    "    # h5 = deconv(gf_dim * 1 + eighth, gf_dim * 1, kernel = (5, 5), stride = (2,2), padding = (2,2), bias = (True, 0))\n",
    "    # h5 = ReLU(VBN(h5))\n",
    "\n",
    "    h4z = self.make_z([self.bs, self.eighth, 56, 56])\n",
    "    h4 = torch.cat([h4, h4z], dim=1)\n",
    "    h5 = self.CT2d_5(h4)\n",
    "    assert h5.shape[2:] == (112,112), \"Non-expected shape, it shoud be (112,112)\"\n",
    "\n",
    "    # h5z = self.make_z([bs, eighth, 112, 112])\n",
    "    # h5 = torch.cat([h5, h5z], dim=1)\n",
    "    # h6 = deconv(gf_dim * 1 + eighth, gf_dim * 1, kernel = (5, 5), stride = (2,2), padding = (2,2), bias = (True, 0))\n",
    "    # h6 = ReLU(VBN(h5))\n",
    "    h5z = self.make_z([self.bs, self.eighth, 112, 112])\n",
    "    h5 = torch.cat([h5, h5z], dim=1)\n",
    "    h6 = self.CT2d_6(h5)\n",
    "    assert h6.shape[2:] == (224,224), \"Non-expected shape, it shoud be (224,224)\"\n",
    "\n",
    "    # h6z = self.make_z([bs, eighth, 224, 224])\n",
    "    # h6 = torch.cat([h6, h6z], dim=1)\n",
    "    # h7 = deconv(gf_dim * 1 + eighth, 3, kernel = (5, 5), stride = (2,2), padding = (2,2), bias = (True, 0))\n",
    "    # h7 = ReLU(VBN(h7))\n",
    "    h6z = self.make_z([self.bs, self.eighth, 224, 224])\n",
    "    h6 = torch.cat([h6, h6z], dim=1)\n",
    "    h7 = self.CT2d_7(h6)\n",
    "    assert h7.shape[2:] == (224,224), \"Non-expected shape, it shoud be (448,448)\"\n",
    "\n",
    "    # out = 10*tanh(h7)\n",
    "\n",
    "    #     return 10 *F.tanh(h7)\n",
    "    ksi = 10.0\n",
    "    output_coeff = ksi / (255.0 * np.mean(imagenet_stats[1])) \n",
    "    # this coeff scales the output to be appropriate for images that are \n",
    "    # normalized using imagenet_stats (and are hence in the approximate [-2.5, 2.5]\n",
    "    # interval)\n",
    "    return output_coeff * torch.tanh(h7)\n",
    "    # return 0.15 * torch.tanh(h7)\n",
    "\n",
    "  def forward(self, inputs):\n",
    "    self.bs = inputs.shape[0]\n",
    "    z = inputs.new_empty([self.bs, self.z_dim]).uniform_(-1,1).cuda()\n",
    "    p, n = self.make_triplet_samples(z, 0.1, 0.1, 2.)\n",
    "    \n",
    "    z_out = self.forward_z(z)\n",
    "    p_out = self.forward_z(p)\n",
    "    n_out = self.forward_z(n)\n",
    "    \n",
    "    return z_out, p_out, n_out, inputs\n",
    "  \n",
    "  def forward_single_z(self, z):\n",
    "    return self.forward_z(z[None]).squeeze()\n",
    "           \n",
    "  \n",
    "  def make_triplet_samples(self, z, margin, r2, r3):\n",
    "    positive_sample = z + self.random_vector_volume(z.shape, 0, margin).cuda() \n",
    "    negative_sample = z + self.random_vector_volume(z.shape, r2, r3).cuda()\n",
    "#     negative_sample = z + self.random_vector_volume(z.shape, margin, margin * scale).cuda()\n",
    "    return positive_sample, negative_sample\n",
    "\n",
    "  def random_vector_surface(self, shape, r = 1.):\n",
    "    mat = torch.randn(size=shape).cuda()\n",
    "    norm = torch.norm(mat, p=2, dim=1, keepdim = True).cuda()\n",
    "    return (mat/norm) * r\n",
    "\n",
    "#   def random_vector_volume(shape, inner_r = 0, outer_r):\n",
    "#     d = torch.zeros(shape[0]).uniform_()   ** (1/int(np.prod(shape[0])))\n",
    "#     d.unsqueeze_(-1)\n",
    "#     return random_vector_surface(shape, outer_r) * d\n",
    "  \n",
    "  def random_vector_volume(self, shape, inner_r, outer_r):\n",
    "#     d = torch.zeros(shape[0]).uniform_(0, outer_r - inner_r).cuda()\n",
    "    fraction = torch.empty(shape[0]).uniform_(inner_r, outer_r).cuda()\n",
    "    fraction = ((fraction / outer_r) ** (1 / shape[1])) * outer_r # volume-normalize the fraction\n",
    "    fraction.unsqueeze_(-1)\n",
    "#     return self.random_vector_surface(shape, 1) * d + inner_r\n",
    "    return self.random_vector_surface(shape, 1) * fraction\n",
    "\n",
    "   \n",
    "  def make_z(self, in_shape):\n",
    "    result = torch.empty(in_shape).uniform_(-1,1).cuda()\n",
    "    return self.move_gpu(result)\n",
    "\n",
    "  def move_gpu(self, inp):\n",
    "    if gpu_flag:\n",
    "        return inp.cuda()\n",
    "    else:\n",
    "        return inp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wULy7qXNYeVv"
   },
   "outputs": [],
   "source": [
    "def load_starting_point(learn, name, z_dim):\n",
    "  if detect_env() != \"colab\":\n",
    "    raise NotImplementedError(\"load_starting_point not implemented for non-colab environments yet.\")\n",
    "  import os\n",
    "  identity_token = name + '-zdim' + str(z_dim)\n",
    "  address = '/content/gdrive/My Drive/DL/model_starting_points/' + identity_token\n",
    "  starting_point_exists = os.path.isfile(address + '.pth')\n",
    "  if not starting_point_exists:\n",
    "    print(\"\\n\\nno starting point found for model:\" + identity_token + \". creating one from the current learner.\\n\\n\")\n",
    "    learn.save(address)\n",
    "  learn.load(address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NkfbLWEQqRA_"
   },
   "outputs": [],
   "source": [
    "def js_distance(x1, x2):\n",
    "  m = 0.5 * (x1 + x2)\n",
    "  return 0.5 * (F.kl_div(x1, m) + F.kl_div(x2, m))\n",
    "\n",
    "def kl_distance(x1, x2):\n",
    "  return F.kl_div(x1, x2)\n",
    "\n",
    "def wasserstein_distance(x1, x2):\n",
    "  pass\n",
    "\n",
    "def l1_distance(x1, x2):\n",
    "  return F.l1_loss(x1, x2)\n",
    "\n",
    "def l2_distance(x1, x2):\n",
    "  return F.mse_loss(x1 * 10, x2 * 10)\n",
    "\n",
    "triplet_call_cnt = 0\n",
    "\n",
    "def triplet_loss(anchor, positive, negative, distance_func, margin):\n",
    "  # max distance when using l1_distance is 2\n",
    "  # max distacne when using l2-distance is sqrt(2)\n",
    "#   print(\"anchor: \", anchor.min(), anchor.max())\n",
    "  ap_dist = distance_func(anchor, positive)\n",
    "  an_dist = distance_func(anchor, negative)\n",
    "\n",
    "  global triplet_call_cnt\n",
    "  triplet_call_cnt += 1\n",
    "  if triplet_call_cnt % 200 == 0:\n",
    "    print(\"ap_dist: {}, an_dist: {}\".format(ap_dist, an_dist))\n",
    "    \n",
    "  return torch.mean(F.relu(ap_dist - an_dist + margin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hsFgfiN8EV7z"
   },
   "outputs": [],
   "source": [
    "def diversity_loss(input, target):\n",
    "#   return -1 * torch.mean(torch.pow(f_x_a-f_x_s,2))\n",
    "  if input.shape[0] != batch_size:\n",
    "    print(\"input shape: \", input.shape)\n",
    "    print(\"target shape: \", target.shape, \"\\n\\n\")\n",
    "  return torch.mean(torch.nn.functional.cosine_similarity(\n",
    "    input.view([batch_size, -1]),\n",
    "    target.view([batch_size, -1]), \n",
    "  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4FVegHeYovws"
   },
   "outputs": [],
   "source": [
    "class FeatureLoss(nn.Module):\n",
    "    def __name__(self):\n",
    "      return \"feature_loss\"\n",
    "  \n",
    "    def __init__(self, dis, layers, layer_weights):\n",
    "        super().__init__()\n",
    "        \n",
    "        # define generator here \n",
    "        self.dis = dis\n",
    "        self.diversity_layers = layers\n",
    "        self.hooks = hook_outputs(self.diversity_layers, detach=False)\n",
    "        self.weights = layer_weights\n",
    "        self.metric_names = [\"fool_loss\"] + [f\"div_loss_{i}\" for i in range(len(layers))] + ['triplet_loss']# Maybe Gram\n",
    "        self.triplet_weight = 4\n",
    "    \n",
    "    def make_features(self, x, clone=False):\n",
    "        y = self.dis(x)\n",
    "        return y, [(o.clone() if clone else o) for o in self.hooks.stored]\n",
    "    \n",
    "#     def forward(self, inp, target):\n",
    "#         sigma_B, sigma_pos, sigma_neg, X_B = inp\n",
    "\n",
    "#         X_A = self.add_perturbation(X_B, sigma_B) \n",
    "#         X_A_pos = self.add_perturbation(X_B, sigma_pos)\n",
    "#         X_A_neg = self.add_perturbation(X_B, sigma_neg) \n",
    "        \n",
    "#         X_S = self.add_perturbation_shuffled(X_B, sigma_B) # Shuffled Addversarial Examples\n",
    "        \n",
    "#         B_Y, _ = self.make_features(X_B)\n",
    "#         A_Y, A_feat = self.make_features(X_A)\n",
    "#         _, S_feat = self.make_features(X_S)\n",
    "#         pos_softmax, _ = self.make_features(X_A_pos)\n",
    "#         neg_softmax, _ = self.make_features(X_A_neg)\n",
    "        \n",
    "        \n",
    "#         fooling_loss =  fool_loss(A_Y, B_Y)\n",
    "      \n",
    "#         raw_diversity_losses = [diversity_loss(a_f, s_f) for a_f, s_f in zip(A_feat, S_feat)]\n",
    "#         weighted_diversity_losses = [diversity_loss(a_f, s_f) * weight for a_f, s_f, weight in zip(A_feat, S_feat, self.weights)]\n",
    "        \n",
    "#         raw_triplet_loss = triplet_loss(A_Y, pos_softmax, neg_softmax, l2_distance, 4.)\n",
    "#         weighted_triplet_loss = raw_triplet_loss * self.triplet_weight\n",
    "    \n",
    "#         self.losses = [fooling_loss] + weighted_diversity_losses + [weighted_triplet_loss]\n",
    "#         self.metrics = dict(zip(self.metric_names, [fooling_loss] + raw_diversity_losses + [weighted_triplet_loss]))\n",
    "        \n",
    "#         return sum(self.losses)\n",
    "\n",
    "    def forward(self, inp, target):\n",
    "      sigma_B, sigma_pos, sigma_neg, X_B = inp\n",
    "\n",
    "      X_A = self.add_perturbation(X_B, sigma_B) \n",
    "\n",
    "      X_S = self.add_perturbation_shuffled(X_B, sigma_B) # Shuffled Addversarial Examples\n",
    "\n",
    "      B_Y, _ = self.make_features(X_B)\n",
    "      A_Y, A_feat = self.make_features(X_A)\n",
    "      _, S_feat = self.make_features(X_S)\n",
    "\n",
    "      fooling_loss =  fool_loss(A_Y, B_Y)\n",
    "\n",
    "      raw_diversity_losses = [diversity_loss(a_f, s_f) for a_f, s_f in zip(A_feat, S_feat)]\n",
    "      weighted_diversity_losses = [diversity_loss(a_f, s_f) * weight for a_f, s_f, weight in zip(A_feat, S_feat, self.weights)]\n",
    "\n",
    "      raw_triplet_loss = triplet_loss(sigma_B, sigma_pos, sigma_neg, l2_distance, 4.)\n",
    "      weighted_triplet_loss = raw_triplet_loss * self.triplet_weight\n",
    "\n",
    "      self.losses = [fooling_loss] + weighted_diversity_losses + [weighted_triplet_loss]\n",
    "      self.metrics = dict(zip(self.metric_names, [fooling_loss] + raw_diversity_losses + [weighted_triplet_loss]))\n",
    "\n",
    "      return sum(self.losses)\n",
    "  \n",
    "  \n",
    "    def add_perturbation(self, inp, perturbation):\n",
    "        return inp.add(perturbation)\n",
    "  \n",
    "    def add_perturbation_shuffled(self, inp, perturbation):\n",
    "#         j = torch.randperm(inp.shape[0])\n",
    "        j = derangement(inp.shape[0])\n",
    "        return inp.add(perturbation[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qd9gXUy_ovww"
   },
   "outputs": [],
   "source": [
    "feat_loss = FeatureLoss(arch, layers, layer_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IfZKdYD2MSdi"
   },
   "outputs": [],
   "source": [
    "env.save_filename = 'vgg16_11'\n",
    "\n",
    "if Path(env.get_csv_path() + '.csv').exists(): raise FileExistsError(\"csv_path already exists\")\n",
    "if Path(env.get_models_path()).exists(): raise FileExistsError(\"models_path already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b9J20CBLS8S9"
   },
   "outputs": [],
   "source": [
    "learn = None; gc.collect()\n",
    "csv_logger = partial(ImmediateCSVLogger, filename= env.temp_csv_path + '/' + env.save_filename)\n",
    "# learn = Learner(data, Gen(z_dim=10), loss_func = feat_loss, metrics=[validation], callback_fns=LossMetrics, opt_func = optim.SGD)\n",
    "# learn = Learner(data, Gen(z_dim=z_dim), loss_func = feat_loss, metrics=[validation], callback_fns=[LossMetrics, DiversityWeightsScheduler])\n",
    "learn = Learner(data, Gen(z_dim=z_dim), loss_func = feat_loss, metrics=[validation], callback_fns=[LossMetrics, csv_logger])\n",
    "# load_starting_point(learn, model_name, z_dim)\n",
    "# random_seed(42, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wk9E0AUm9rmn"
   },
   "outputs": [],
   "source": [
    "# learn.lr_find(1e-6, 1000)\n",
    "# learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0wOZYzOHDEdB"
   },
   "outputs": [],
   "source": [
    "# !cp \"/content/gdrive/My Drive/DL/models/vgg-16_2.pth\"  \"/content/\"\n",
    "# learn.load('/content/vgg-16_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "LA1ffVbbEwQS",
    "outputId": "682ac419-ee54-497a-b89f-496f789cf368"
   },
   "outputs": [],
   "source": [
    "if mode == \"sanity_check\":\n",
    "  print(\"\\n\\n\\nWARNING: you are training on a sanity_check dataset.\\n\\n\\n\\n\")\n",
    "if len(learn.callback_fns) == 1:\n",
    "  print(\"\\n\\n\\nWARNING: you are not using the DiversityWeightsScheduler callback.\\n\\n\\n\")\n",
    "\n",
    "    \n",
    "saver_best = SaveModelCallback(learn, every='improvement', monitor='validation', name=env.save_filename + \"-best\")\n",
    "saver_every_epoch = SaveModelCallback(learn, every='epoch', name=env.save_filename)\n",
    "\n",
    "import cProfile\n",
    "\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()\n",
    "learn.fit(3, lr=5e-03, callbacks=[saver_best, saver_every_epoch])\n",
    "pr.disable()\n",
    "# learn.fit(30, lr=5e-03, wd=0.005, callbacks=[saver_best, saver_every_epoch])\n",
    "# learn.fit_one_cycle(20, max_lr=5e-1, callbacks=[saver_callback])\n",
    "\n",
    "# learn.fit_one_cycle(8, max_lr=5e-01) #mohammad's setting that got 77 validation start on resnet with diversity loss on AdaptiveAvgPool2d\n",
    "# learn.fit_one_cycle(5, max_lr=2e-2) #used for vgg-19-bn\n",
    "# learn.fit_one_cycle(5, max_lr=3e-3) # used for resnet50\n",
    "\n",
    "shutil.copyfile(\"/content/\" + save_filename + \".csv\", csv_path + '.csv')\n",
    "shutil.copytree(env.data_path/\"models\", models_path)\n",
    "\n",
    "pr.print_stats()\n",
    "\n",
    "# shutil.copyfile(\"/content/dataset/models/\" + save_filename + \"-best.pth\", \"/content/gdrive/My Drive/DL/models/\" + save_filename + \".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-BmJ8cESVIay"
   },
   "outputs": [],
   "source": [
    "!cp \"/content/gdrive/My Drive/DL/models/resnet50-dir/resnet50-dir-best.pth\" \"/content/resnet50-best.pth\"\n",
    "learn.load(\"/content/resnet50-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "obTWhste2pZo"
   },
   "outputs": [],
   "source": [
    "learn.fit(1, lr = 0., wd=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zUz0oXLbVVB0",
    "outputId": "0380e919-8e41-4f24-f4ac-843283434125"
   },
   "outputs": [],
   "source": [
    "learn.validate(metrics=[feat_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MO2fZ-hSSUzJ"
   },
   "outputs": [],
   "source": [
    "z1 = torch.empty(10).uniform_(-1,1).cuda()\n",
    "z2 = torch.empty(10).uniform_(-1,1).cuda()\n",
    "# print(\"z1: \", z1)\n",
    "# print(\"z2: \", z2)\n",
    "print(\"distance: \", torch.norm(z1-z2,p=2))\n",
    "model = learn.model.eval()\n",
    "\n",
    "z_s = interpolate(z1, z2, 0.15)\n",
    "print(len(z_s))\n",
    "for i,z in enumerate(z_s):\n",
    "  img = noise_to_image(model.forward_single_z(z))\n",
    "  img.show()\n",
    "  img.save('./pics/' + str(i) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DGuGN7B7V0Xt"
   },
   "outputs": [],
   "source": [
    "def generate_perturbations(learn, n_perturbations):\n",
    "  initial_training_mode = learn.model.training\n",
    "  \n",
    "  model = learn.model.eval()\n",
    "  input_img = (learn.data.valid_ds[0][0].data)[None].cuda()\n",
    "  perturbations = []\n",
    "  for i in range(n_perturbations):\n",
    "    perturbation = model(input_img)[0].squeeze()\n",
    "    perturbations.append(perturbation)\n",
    "    \n",
    "  learn.model.train(initial_training_mode)  \n",
    "  return perturbations\n",
    "  \n",
    "  \n",
    "# def compute_mean_prediction_histogram(learn, perturbations):\n",
    "#   pred_histogram = [0] * 1000\n",
    "#   for j, perturbation in enumerate(perturbations):\n",
    "#     for i in range(len(learn.data.valid_ds)):\n",
    "#       img = learn.data.valid_ds[i][0].data[None].cuda()\n",
    "#       perturbed_img = img + perturbation\n",
    "#       pred = torch.argmax(arch(perturbed_img).squeeze())\n",
    "#       pred_histogram[pred]+= 1./len(perturbations)\n",
    "#     print(\"finished creating histogram for the %dth perturbation\"%j)\n",
    "#   return pred_histogram\n",
    "\n",
    "  \n",
    "def compute_mean_prediction_histogram(learn, perturbations):\n",
    "  pred_histogram = [0] * 1000\n",
    "  for j, perturbation in enumerate(perturbations):\n",
    "    batch_no = -1\n",
    "    for batch, _ in learn.data.valid_dl:\n",
    "      batch_no += 1\n",
    "      if batch_no % 100 == 0 : print(\"at batch no {}\".format(batch_no))\n",
    "      perturbed_batch = batch + perturbation[None]\n",
    "      preds = arch(perturbed_batch).argmax(1)\n",
    "      for pred in preds:\n",
    "        pred_histogram[pred]+= 1. / len(perturbations)\n",
    "    print(\"finished creating histogram for the %dth perturbation\"%j)\n",
    "\n",
    "  pred_histogram = np.asarray(np.array(pred_histogram) / len(perturbations))\n",
    "\n",
    "  return pred_histogram\n",
    "\n",
    "\n",
    "def diversity(learn, n_perturbations, percentage):\n",
    "  pred_histogram = compute_mean_prediction_histogram(\n",
    "      learn, generate_perturbations(learn, n_perturbations)\n",
    "  )\n",
    "  print(\"finished creating the prediction histogram\")\n",
    "  pred_histogram_sum = np.sum(pred_histogram)\n",
    "  \n",
    "  indexed_pred_histogram = [(i, hist_element) for i,hist_element in  \n",
    "                            enumerate(pred_histogram)]\n",
    "  \n",
    "  indexed_pred_histogram.sort(key=lambda x: x[1], reverse = True)\n",
    "  \n",
    "  cumulative_percent = 0\n",
    "  n_used_classes = 0\n",
    "  top_classes = []\n",
    "  while cumulative_percent < percentage:\n",
    "    hist_elem = indexed_pred_histogram[n_used_classes]\n",
    "    cumulative_percent += (hist_elem[1] / pred_histogram_sum) * 100.\n",
    "    top_classes.append(hist_elem[0])\n",
    "    n_used_classes += 1\n",
    "  \n",
    "  #top_classes is a useful piece of info that is currently unused\n",
    "  return n_used_classes, indexed_pred_histogram, top_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q8VUc3YH4vj5"
   },
   "outputs": [],
   "source": [
    "n, hist, tk = diversity(learn, 10, 95)\n",
    "n, hist, tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FAgk-YyWc3rG"
   },
   "outputs": [],
   "source": [
    "# learn.recorder.plot_losses()\n",
    "# learn.recorder.plot_lr()\n",
    "# learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YTHG4Bt7VDYp"
   },
   "outputs": [],
   "source": [
    "fooling_rates = []\n",
    "model = learn.model.eval()\n",
    "learn.metrics = [validation_single_perturbation]\n",
    "for i in range(10):\n",
    "  global_perturbations = model(torch.rand(1, 3, 224, 244).cuda())[0]\n",
    "  nag_util.global_perturbations = global_perturbations\n",
    "  fooling_rates.append(learn.validate()[1].cpu().item())\n",
    "  print(\"%d : %f\"%(i, fooling_rates[-1]))\n",
    "\n",
    "mean = np.mean(fooling_rates)\n",
    "stddev = np.std(fooling_rates)\n",
    "print(mean, stddev); print(fooling_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 662
    },
    "colab_type": "code",
    "id": "OFCjzI7UaY3C",
    "outputId": "96210715-2e99-4463-a62b-a3fa8e774376"
   },
   "outputs": [],
   "source": [
    "#the Image works good for floats in range [0..1]\n",
    "model = learn.model.eval()\n",
    "\n",
    "x_img = learn.data.train_ds[4][0]\n",
    "x = x_img.data.cuda()\n",
    "z = torch.empty(z_dim).uniform_(-1,1).cuda()\n",
    "p = model.forward_single_z(z).detach()\n",
    "x = normalize(x)\n",
    "\n",
    "p_x = x + p\n",
    "p_x = denormalize(p_x)\n",
    "p_x.clamp_(0,1)\n",
    "\n",
    "\n",
    "#prepare images\n",
    "p_x_img = Image(p_x)\n",
    "p = scale_to_range(p, [0., 1.])\n",
    "p_img = Image(p)\n",
    "x_img.show()\n",
    "p_img.show()\n",
    "p_x_img.show()\n",
    "\n",
    "print_range(p)\n",
    "print_range(x)\n",
    "print_range(p_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "colab_type": "code",
    "id": "eroI82OKSnAL",
    "outputId": "ca7ba0a5-a8e8-4692-d962-a8e0e508842e"
   },
   "outputs": [],
   "source": [
    "#the Image works good for floats in range [0..1]\n",
    "model = learn.model.eval()\n",
    "\n",
    "x_img = learn.data.train_ds[4][0]\n",
    "x = x_img.data[None].cuda()\n",
    "p = model(x)[0].squeeze().detach() \n",
    "x = x.squeeze()\n",
    "x = normalize(x)\n",
    "\n",
    "p_x = x + p\n",
    "p_x = denormalize(p_x)\n",
    "p_x.clamp_(0,1)\n",
    "\n",
    "\n",
    "#prepare images\n",
    "p_x_img = Image(p_x)\n",
    "p = scale_to_range(p, [0.,1.])\n",
    "p_img = Image(p)\n",
    "# x_img.show()\n",
    "p_img.show()\n",
    "# p_x_img.show()\n",
    "\n",
    "print_range(p)\n",
    "print_range(x)\n",
    "print_range(p_x)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "NAG-tripletLossExperiment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
