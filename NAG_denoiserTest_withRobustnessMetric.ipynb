{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ahmad-PH/nag-notebooks/blob/master/NAG_tripletLossExperiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "cqeZpz16do4y",
    "outputId": "19e7e40d-3281-46ee-99b5-d8cf518ff9b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up-to-date.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "\n",
    "import os; import subprocess\n",
    "\n",
    "def detect_env():\n",
    "    if 'content' in os.listdir('/'):\n",
    "      return 'colab'\n",
    "    elif 'mlcm-deep' in os.listdir('/home'):\n",
    "      return 'mlcm'\n",
    "    else:\n",
    "      return 'IBM'\n",
    "  \n",
    "def run_shell_command(cmd):\n",
    "  p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)\n",
    "  print(str(p.communicate()[0], 'utf-8'))\n",
    "  \n",
    "if detect_env() == 'colab': root_folder = '/content'\n",
    "elif detect_env() == 'IBM' : root_folder = '/root/Derakhshani/adversarial'\n",
    "elif detect_env() == 'mlcm' : root_folder = '/home/mlcm-deep/AhmadPourihosseini/NAG'\n",
    "python_files_path = root_folder + '/nag-public'\n",
    "if os.path.isdir(python_files_path):\n",
    "  initial_dir = os.getcwd()\n",
    "  os.chdir(python_files_path)\n",
    "  run_shell_command('git pull')\n",
    "  os.chdir(initial_dir)\n",
    "else:\n",
    "  os.chdir(root_folder)\n",
    "  run_shell_command('git clone https://github.com/ahmad-PH/nag-public.git')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oEHu0mgxuV7e"
   },
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.imports import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.utils.mem import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import sys; import os; import shutil\n",
    "# import art #INSTALL LATER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "I9kHEmcwuV7h",
    "outputId": "617dbc71-9537-41ca-c842-21c579e8306b"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(python_files_path + '/NAG-11May-beforeDenoiser')\n",
    "\n",
    "from nag_util import *\n",
    "import nag_util\n",
    "from environment import *\n",
    "from visualization import *\n",
    "from utility import *\n",
    "from create_perturbed_dataset import *\n",
    "\n",
    "env = create_env()\n",
    "env.setup(cuda_index = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0NUgmvPSuV7k"
   },
   "outputs": [],
   "source": [
    "gen_arch = \"targeted\"\n",
    "# gen_arch = \"non-targeted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MOC5e4SpuV7m"
   },
   "outputs": [],
   "source": [
    "class GeneralRelu(nn.Module):\n",
    "  def __init__(self, leak=None, sub=None, maxv=None):\n",
    "    super().__init__()\n",
    "    self.leak,self.sub,self.maxv = leak,sub,maxv\n",
    "\n",
    "  def forward(self, x): \n",
    "    x = F.leaky_relu(x,self.leak) if self.leak is not None else F.relu(x)\n",
    "    if self.sub is not None: x.sub_(self.sub)\n",
    "    if self.maxv is not None: x.clamp_max_(self.maxv)\n",
    "    return x\n",
    "  \n",
    "class deconv_layer(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k_size = (4,4), s = (2,2), pad = (1,1), b = True, activation = True):\n",
    "        super(deconv_layer, self).__init__()\n",
    "\n",
    "        self.CT2d = nn.ConvTranspose2d(in_channels = in_ch,\n",
    "                                  out_channels = out_ch,\n",
    "                                  kernel_size = k_size,\n",
    "                                  stride = s, \n",
    "                                  padding = pad,\n",
    "                                  bias = b)\n",
    "        self.BN2d = nn.BatchNorm2d(out_ch)\n",
    "        \n",
    "        self.activation = activation\n",
    "        if self.activation:\n",
    "            self.relu = GeneralRelu(0, 0.2, 5)\n",
    "        \n",
    "        self.weight_init()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        if self.activation:\n",
    "            return self.relu(self.BN2d(self.CT2d(input)))\n",
    "        else:\n",
    "            return self.BN2d(self.CT2d(input))\n",
    "\n",
    "    def weight_init(self):\n",
    "        self.CT2d.weight.data.normal_(mean = 0, std = 0.02)\n",
    "        self.CT2d.bias.data.fill_(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VxqpShBnuV7p"
   },
   "outputs": [],
   "source": [
    "class deconv_layer(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k_size = (4,4), s = (2,2), pad = (1,1), b = True, activation = True):\n",
    "        super(deconv_layer, self).__init__()\n",
    "\n",
    "        self.CT2d = nn.ConvTranspose2d(in_channels = in_ch,\n",
    "                                  out_channels = out_ch,\n",
    "                                  kernel_size = k_size,\n",
    "                                  stride = s, \n",
    "                                  padding = pad,\n",
    "                                  bias = b)\n",
    "        self.BN2d = nn.BatchNorm2d(out_ch)\n",
    "        self.activation = activation\n",
    "\n",
    "        self.weight_init()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        if self.activation:\n",
    "            return F.relu(self.BN2d(self.CT2d(input)), inplace=True)\n",
    "        else:\n",
    "            return self.BN2d(self.CT2d(input))\n",
    "\n",
    "    def weight_init(self):\n",
    "        self.CT2d.weight.data.normal_(mean = 0, std = 0.02)\n",
    "        self.CT2d.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YFFluyiPuV7r"
   },
   "outputs": [],
   "source": [
    "if gen_arch == \"targeted\":\n",
    "  class Gen(nn.Module):\n",
    "    def __init__(self, z_dim, active_labels = (0, 1000), gf_dim=64, y_dim = None,\n",
    "                 df_dim = 64, image_shape = [3,128,128]):\n",
    "      super(Gen, self).__init__()\n",
    "      \n",
    "      self.bs = None\n",
    "      self.z_dim = z_dim\n",
    "      self.gf_dim = gf_dim\n",
    "      self.y_dim = y_dim\n",
    "      self.df_dim = df_dim\n",
    "      self.image_shape = image_shape\n",
    "      self.active_labels = active_labels\n",
    "      \n",
    "      self.n_unit_coeffs = [10, 7, 4, 2, 1, 1, 1]\n",
    "      self.n_units = [coeff * self.gf_dim for coeff in self.n_unit_coeffs]\n",
    "      \n",
    "      self.z_ = nn.Linear(self.z_dim, self.n_units[0] * 4 * 4, bias=True)\n",
    "      self.z_.bias.data.fill_(0)\n",
    "      self.BN_ = nn.BatchNorm2d(self.n_units[0])\n",
    "\n",
    "      self.half = max(self.gf_dim // 2, 1) \n",
    "      self.quarter = max(self.gf_dim // 4, 1)\n",
    "      self.eighth = max(self.gf_dim // 8, 1)\n",
    "      # sixteenth = max(self.gf_dim // 16, 1)\n",
    "\n",
    "      self.CT2d_1 = deconv_layer(self.n_units[0], self.n_units[1], k_size = (5,5), pad = (2,2))\n",
    "      self.CT2d_2 = deconv_layer(self.n_units[1], self.n_units[2])    \n",
    "      self.CT2d_3 = deconv_layer(self.n_units[2], self.n_units[3])\n",
    "      self.CT2d_4 = deconv_layer(self.n_units[3], self.n_units[4])\n",
    "      self.CT2d_5 = deconv_layer(self.n_units[4], self.n_units[5])\n",
    "      self.CT2d_6 = deconv_layer(self.n_units[5], self.n_units[6])\n",
    "      self.CT2d_7 = deconv_layer(self.n_units[6], 3, k_size = (5,5), s = (1,1), pad = (2,2), activation = False)\n",
    "      \n",
    "    # static variables:\n",
    "    ksi = 10.0\n",
    "    output_coeff = ksi / (255.0 * np.mean(imagenet_stats[1]))\n",
    "    \n",
    "    def randomized_deconv_layer(self, h_input, z_size_0, z_size_1, deconv_layer, expected_output_size):\n",
    "      h_input_z = self.make_z([self.bs, z_size_0, z_size_1, z_size_1])\n",
    "      h_input = torch.cat([h_input, h_input_z], dim = 1)\n",
    "      output = deconv_layer(h_input)\n",
    "      assert output.shape[2:] == (expected_output_size, expected_output_size), \\\n",
    "              \"Unexpected output shape at randomized_deconv_layer. expected\" + \\\n",
    "              \"({0},{0}), got {1}\".format(expected_output_size, output.shape[2:])\n",
    "      return output\n",
    "\n",
    "    def forward_z(self, z):\n",
    "      self.bs = z.shape[0]\n",
    "\n",
    "      h0 = F.relu(self.BN_(self.z_(z).contiguous().view(self.bs, -1, 4, 4)))\n",
    "      assert h0.shape[2:] == (4, 4), \"Unexpected shape, it shoud be (4,4)\"\n",
    "\n",
    "      h1 = self.CT2d_1(h0)\n",
    "      h2 = self.CT2d_2(h1)\n",
    "      h3 = self.CT2d_3(h2)\n",
    "      h4 = self.CT2d_4(h3)\n",
    "      h5 = self.CT2d_5(h4)\n",
    "      h6 = self.CT2d_6(h5)\n",
    "      h7 = self.CT2d_7(h6)\n",
    "      \n",
    "#       h1 = self.randomized_deconv_layer(h0, self.gf_dim, 4, self.CT2d_1, 7)\n",
    "#       h2 = self.randomized_deconv_layer(h1, self.gf_dim, 7, self.CT2d_2, 14)\n",
    "#       h3 = self.randomized_deconv_layer(h2, self.half, 14, self.CT2d_3, 28)\n",
    "#       h4 = self.randomized_deconv_layer(h3, self.quarter, 28, self.CT2d_4, 56)\n",
    "#       h5 = self.randomized_deconv_layer(h4, self.eighth, 56, self.CT2d_5, 112)\n",
    "#       h6 = self.randomized_deconv_layer(h5, self.eighth, 112, self.CT2d_6, 224)\n",
    "#       h7 = self.randomized_deconv_layer(h6, self.eighth, 224, self.CT2d_7, 224)\n",
    "\n",
    "      # this coeff scales the output to be appropriate for images that are \n",
    "      # normalized using imagenet_stats (and are hence in the approximate [-2.5, 2.5]\n",
    "      # interval)\n",
    "      return Gen.output_coeff * torch.tanh(h7)\n",
    "\n",
    "  #   # blind-selection\n",
    "    def forward(self, inputs):\n",
    "      self.bs = inputs.shape[0]\n",
    "\n",
    "      benign_preds_onehot = arch(inputs)\n",
    "#       benign_preds = torch.argmax(benign_preds_onehot, dim = 1)\n",
    "      worst_preds = torch.argmin(benign_preds_onehot, dim = 1)\n",
    "#       second_best_preds = torch.topk(benign_preds_onehot, 2, dim=1)[1][:, 1]\n",
    "      \n",
    "      z = torch.zeros([self.bs, 1000]).cuda()\n",
    "      for i in range(self.bs):\n",
    "        random_label = worst_preds[i].item()\n",
    "        z[i][random_label] = 1.\n",
    "\n",
    "      z_out = self.forward_z(z)\n",
    "\n",
    "      return z_out, None, None, inputs, benign_preds_onehot, z\n",
    "\n",
    "  #   #second-best selection: made validation so much worse\n",
    "  #   def forward(self, inputs):\n",
    "  #     self.bs = inputs.shape[0]\n",
    "\n",
    "  #     benign_preds_onehot = arch(inputs)\n",
    "  #     target_preds = torch.topk(benign_preds_onehot, 2, dim = 1).indices[:, 1:]\n",
    "\n",
    "  #     z = torch.zeros([self.bs, 1000]).cuda()\n",
    "  #     for i in range(self.bs):\n",
    "  #       z[i][target_preds[i]] = 1.\n",
    "\n",
    "  #     z_out = self.forward_z(z)\n",
    "\n",
    "  #     return z_out, None, None, inputs, benign_preds_onehot, z\n",
    "\n",
    "  #    def forward(self, inputs):\n",
    "  #     self.bs = inputs.shape[0]\n",
    "\n",
    "  #     benign_preds_onehot = arch(inputs)\n",
    "  #     benign_preds = torch.argmax(benign_preds_onehot, dim = 1)\n",
    "\n",
    "  #     z = torch.zeros([self.bs, 1000]).cuda()\n",
    "  #     random_label = self.randint(0,1000, exclude = benign_preds.tolist())\n",
    "  #     for i in range(self.bs):\n",
    "  #       z[i][random_label] = 1.\n",
    "\n",
    "  #     z_out = self.forward_z(z)\n",
    "\n",
    "  #     return z_out, None, None, inputs, benign_preds_onehot, z\n",
    "\n",
    "    @staticmethod\n",
    "    def randint(low, high, exclude):\n",
    "      if exclude >= low and exclude < high:\n",
    "        temp = np.random.randint(low, high - 1)\n",
    "        if temp >= exclude:\n",
    "          temp = temp + 1\n",
    "        return temp\n",
    "      else:\n",
    "        return np.random.randint(low, high)\n",
    "\n",
    "    def forward_single_z(self, z):\n",
    "      return self.forward_z(z[None]).squeeze()\n",
    "\n",
    "    def generate_single_noise(self):\n",
    "      z = torch.empty(self.z_dim).uniform_(-1,1).cuda()\n",
    "      return self.forward_single_z(z)         \n",
    "\n",
    "    def make_triplet_samples(self, z, margin, r2, r3):\n",
    "      positive_sample = z + self.random_vector_volume(z.shape, 0, margin).cuda() \n",
    "      negative_sample = z + self.random_vector_volume(z.shape, r2, r3).cuda()\n",
    "      return positive_sample, negative_sample\n",
    "\n",
    "    def random_vector_surface(self, shape, r = 1.):\n",
    "      mat = torch.randn(size=shape).cuda()\n",
    "      norm = torch.norm(mat, p=2, dim=1, keepdim = True).cuda()\n",
    "      return (mat/norm) * r\n",
    "\n",
    "\n",
    "    def random_vector_volume(self, shape, inner_r, outer_r):\n",
    "      fraction = torch.empty(shape[0]).uniform_(inner_r, outer_r).cuda()\n",
    "      fraction = ((fraction / outer_r) ** (1 / shape[1])) * outer_r # volume-normalize the fraction\n",
    "      fraction.unsqueeze_(-1)\n",
    "      return self.random_vector_surface(shape, 1) * fraction\n",
    "\n",
    "    def make_z(self, in_shape):\n",
    "      return torch.empty(in_shape).cuda().uniform_(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "anIZD0Q4uV7u"
   },
   "outputs": [],
   "source": [
    "# g = Gen(z_dim = 1000).cuda()\n",
    "# t = torch.empty(1000).uniform_().cuda()\n",
    "# g.forward_single_z(t).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tLqK8jNyuV7x"
   },
   "outputs": [],
   "source": [
    "if gen_arch == \"non-targeted\":\n",
    "  class Gen(nn.Module):\n",
    "    def __init__(self, z_dim, gf_dim=64, y_dim = None, df_dim = 64, image_shape = [3,128,128]):\n",
    "      super(Gen, self).__init__()\n",
    "\n",
    "      self.bs = None\n",
    "      self.z_dim = z_dim\n",
    "      self.gf_dim = gf_dim\n",
    "      self.y_dim = y_dim\n",
    "      self.df_dim = df_dim\n",
    "      self.image_shape = image_shape\n",
    "\n",
    "      self.z_ = nn.Linear(self.z_dim, self.gf_dim * 7 * 4 * 4, bias=True)\n",
    "      self.z_.bias.data.fill_(0)\n",
    "      self.BN_ = nn.BatchNorm2d(self.gf_dim * 7)\n",
    "\n",
    "      self.half = max(self.gf_dim // 2, 1) \n",
    "      self.quarter = max(self.gf_dim // 4, 1)\n",
    "      self.eighth = max(self.gf_dim // 8, 1)\n",
    "      # sixteenth = max(self.gf_dim // 16, 1)\n",
    "\n",
    "      self.CT2d_1 = deconv_layer(self.gf_dim * 8, self.gf_dim * 4, k_size = (5,5), pad = (2,2))\n",
    "      self.CT2d_2 = deconv_layer(self.gf_dim * 5, self.gf_dim * 2)    \n",
    "      self.CT2d_3 = deconv_layer(self.gf_dim * 2 + self.half, self.gf_dim * 1)\n",
    "      self.CT2d_4 = deconv_layer(self.gf_dim * 1 + self.quarter, self.gf_dim * 1)\n",
    "      self.CT2d_5 = deconv_layer(self.gf_dim * 1 + self.eighth, self.gf_dim * 1)\n",
    "      self.CT2d_6 = deconv_layer(self.gf_dim * 1 + self.eighth, self.gf_dim * 1)\n",
    "      self.CT2d_7 = deconv_layer(self.gf_dim * 1 + self.eighth, 3, k_size = (5,5), s = (1,1), pad = (2,2), activation = False)\n",
    "\n",
    "    ksi = 10.0\n",
    "    output_coeff = ksi / (255.0 * np.mean(imagenet_stats[1])) \n",
    "      \n",
    "    def randomized_deconv_layer(self, h_input, z_size_0, z_size_1, deconv_layer, expected_output_size):\n",
    "      h_input_z = self.make_z([self.bs, z_size_0, z_size_1, z_size_1])\n",
    "      h_input = torch.cat([h_input, h_input_z], dim = 1)\n",
    "      output = deconv_layer(h_input)\n",
    "      assert output.shape[2:] == (expected_output_size, expected_output_size), \\\n",
    "              \"Unexpected output shape at randomized_deconv_layer. expected\" + \\\n",
    "              \"({0},{0}), got {1}\".format(expected_output_size, output.shape[2:])\n",
    "      return output\n",
    "\n",
    "    def forward_z(self, z):\n",
    "      self.bs = z.shape[0]\n",
    "\n",
    "      h0 = F.relu(self.BN_(self.z_(z).contiguous().view(self.bs, -1, 4, 4)))\n",
    "      assert h0.shape[2:] == (4, 4), \"Non-expected shape, it shoud be (4,4)\"\n",
    "\n",
    "      h1 = self.randomized_deconv_layer(h0, self.gf_dim, 4, self.CT2d_1, 7)\n",
    "      h2 = self.randomized_deconv_layer(h1, self.gf_dim, 7, self.CT2d_2, 14)\n",
    "      h3 = self.randomized_deconv_layer(h2, self.half, 14, self.CT2d_3, 28)\n",
    "      h4 = self.randomized_deconv_layer(h3, self.quarter, 28, self.CT2d_4, 56)\n",
    "      h5 = self.randomized_deconv_layer(h4, self.eighth, 56, self.CT2d_5, 112)\n",
    "      h6 = self.randomized_deconv_layer(h5, self.eighth, 112, self.CT2d_6, 224)\n",
    "      h7 = self.randomized_deconv_layer(h6, self.eighth, 224, self.CT2d_7, 224)\n",
    "\n",
    "      # this coeff scales the output to be appropriate for images that are \n",
    "      # normalized using imagenet_stats (and are hence in the approximate [-2.5, 2.5]\n",
    "      # interval)\n",
    "      return Gen.output_coeff * torch.tanh(h7)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "      self.bs = inputs.shape[0]\n",
    "      z = inputs.new_empty([self.bs, self.z_dim]).uniform_(-1,1).cuda()\n",
    "      p, n = self.make_triplet_samples(z, 0.1, 0.1, 2.)\n",
    "\n",
    "      z_out = self.forward_z(z)\n",
    "#       p_out = self.forward_z(p)\n",
    "#       n_out = self.forward_z(n)\n",
    "\n",
    "#       return z_out, p_out, n_out, inputs, z\n",
    "      return z_out, None, None, inputs, z\n",
    "\n",
    "    def forward_single_z(self, z):\n",
    "      return self.forward_z(z[None]).squeeze()\n",
    "\n",
    "    def generate_single_noise(self):\n",
    "      z = torch.empty(self.z_dim).uniform_(-1,1).cuda()\n",
    "      return self.forward_single_z(z)\n",
    "\n",
    "\n",
    "    def make_triplet_samples(self, z, margin, r2, r3):\n",
    "      positive_sample = z + self.random_vector_volume(z.shape, 0, margin).cuda() \n",
    "      negative_sample = z + self.random_vector_volume(z.shape, r2, r3).cuda()\n",
    "      return positive_sample, negative_sample\n",
    "\n",
    "    def random_vector_surface(self, shape, r = 1.):\n",
    "      mat = torch.randn(size=shape).cuda()\n",
    "      norm = torch.norm(mat, p=2, dim=1, keepdim = True).cuda()\n",
    "      return (mat/norm) * r\n",
    "\n",
    "\n",
    "    def random_vector_volume(self, shape, inner_r, outer_r):\n",
    "      fraction = torch.empty(shape[0]).uniform_(inner_r, outer_r).cuda()\n",
    "      fraction = ((fraction / outer_r) ** (1 / shape[1])) * outer_r # volume-normalize the fraction\n",
    "      fraction.unsqueeze_(-1)\n",
    "      return self.random_vector_surface(shape, 1) * fraction\n",
    "\n",
    "    def make_z(self, in_shape):\n",
    "      return torch.empty(in_shape).cuda().uniform_(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jGpb4lMluV79"
   },
   "outputs": [],
   "source": [
    "def js_distance(x1, x2):\n",
    "  m = 0.5 * (x1 + x2)\n",
    "  return 0.5 * (F.kl_div(x1, m) + F.kl_div(x2, m))\n",
    "\n",
    "def kl_distance(x1, x2):\n",
    "  inp = torch.log(x1)\n",
    "  target = x2\n",
    "  return F.kl_div(inp, target, reduction='batchmean')\n",
    "\n",
    "def distrib_distance(x1, x2):\n",
    "  x1 = tensorify(x1)\n",
    "  x2 = tensorify(x2)\n",
    "  x1 = x1 / torch.sum(x1)\n",
    "  x2 = x2 / torch.sum(x2)\n",
    "  return kl_distance(x1[None], x2[None])\n",
    "\n",
    "def distrib_distance(x1, x2):\n",
    "  if not isinstance(x1, torch.Tensor): x1 = torch.tensor(x1)\n",
    "  if not isinstance(x2, torch.Tensor): x2 = torch.tensor(x2)\n",
    "  x1 = x1 * 100. / torch.sum(x1)\n",
    "  x2 = x2 * 100. / torch.sum(x2)\n",
    "  return torch.norm(x1 - x2, 2)\n",
    "\n",
    "def distance_from_uniform(x):\n",
    "  return distrib_distance(x, [1.] * len(x))\n",
    "\n",
    "def wasserstein_distance(x1, x2):\n",
    "  return torch.mean(x1 - x2)\n",
    "\n",
    "def l1_distance(x1, x2):\n",
    "  return F.l1_loss(x1, x2)\n",
    "\n",
    "def l2_distance(x1, x2):\n",
    "  return F.mse_loss(x1 * 10, x2 * 10)\n",
    "\n",
    "def mse_loss(x1, x2):\n",
    "  return F.mse_loss(x1, x2)\n",
    "\n",
    "def cos_distance(x1, x2, dim = 1):\n",
    "  return -1 * torch.mean(F.cosine_similarity(x1, x2, dim=dim))\n",
    "\n",
    "\n",
    "def triplet_loss(anchor, positive, negative, distance_func, margin):\n",
    "  # max distance when using l1_distance is 2\n",
    "  # max distacne when using l2-distance is sqrt(2)\n",
    "  ap_dist = distance_func(anchor, positive)\n",
    "  an_dist = distance_func(anchor, negative)\n",
    "\n",
    "  triplet_loss.call_count += 1\n",
    "  if triplet_loss.call_count % 200 == 0 : #and anchor.shape[1] == 1000:\n",
    "#     print(\"a: \", end=\"\"); print_big_vector(anchor[0])\n",
    "#     print(\"p: \", end=\"\"); print_big_vector(positive[0])\n",
    "#     print(\"n: \", end=\"\"); print_big_vector(negative[0])\n",
    "    print(\"func:{}, ap_dist: {}, an_dist: {}\".format(distance_func.__name__, ap_dist, an_dist))\n",
    "    \n",
    "  return torch.mean(F.relu(ap_dist - an_dist + margin))\n",
    "\n",
    "triplet_loss.call_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AZ55e3NVuV8E"
   },
   "outputs": [],
   "source": [
    "# def diversity_loss(embeddings, z_s):\n",
    "#   size = z_s.shape[0]\n",
    "#   result = 0\n",
    "#   for i in range(size):\n",
    "#     for j in range(i+1, size):\n",
    "# #       a = F.cosine_similarity(embeddings[i], embeddings[j], dim = 0)\n",
    "# #       b = torch.norm(z_s[i] - z_s[j], 2, dim = 0)\n",
    "# #       print('embeddings: ')\n",
    "# #       print_big_vector(embeddings[i])\n",
    "# #       print_big_vector(embeddings[j])\n",
    "# #       print(f'a: {a}, b:{b}, multiple: {a*b}')\n",
    "#       result += F.cosine_similarity(embeddings[i], embeddings[j], dim = 0) * \\\n",
    "#                 torch.norm(z_s[i] - z_s[j], 2, dim = 0)\n",
    "#   n_pairs = (size * (size - 1)) / 2\n",
    "#   mean = result / n_pairs \n",
    "# #   print(f'result {result}, n_pairs {n_pairs}, mean {mean}')\n",
    "#   return mean\n",
    "  \n",
    "\n",
    "# # normalized with shuffling\n",
    "# def diversity_loss(embeddings, deranged_embeddings, z_s, deranged_z_s):\n",
    "#     cos_similarity = F.cosine_similarity(embeddings, deranged_embeddings)\n",
    "#     z_distance = torch.norm(z_s - deranged_z_s, 2, dim = 1)\n",
    "#     return torch.mean(cos_similarity * z_distance)\n",
    "  \n",
    "# # normalized with shuffling\n",
    "# def diversity_loss(embeddings, z_s):\n",
    "#     deranged_embeddings, deranged_z_s = derange(embeddings, z_s)\n",
    "#     cos_similarity = F.cosine_similarity(embeddings, deranged_embeddings)\n",
    "#     z_distance = torch.norm(z_s - deranged_z_s, dim = 1)\n",
    "#     max_possible_z_distance = 6.3246\n",
    "#     return torch.mean(cos_similarity * (z_distance/max_possible_z_distance))\n",
    "\n",
    "\n",
    "def diversity_loss(input, target):\n",
    "#   return -1 * torch.mean(torch.pow(f_x_a-f_x_s,2))\n",
    "  if input.shape[0] != batch_size:\n",
    "    print(\"input shape: \", input.shape)\n",
    "    print(\"target shape: \", target.shape, \"\\n\\n\")\n",
    "  return torch.mean(F.cosine_similarity(\n",
    "    input.view([batch_size, -1]),\n",
    "    target.view([batch_size, -1]), \n",
    "  ))\n",
    "\n",
    "\n",
    "if gen_arch == 'non-targeted':\n",
    "  def fool_loss(input, target):\n",
    "    true_class = torch.argmax(target, dim=1).view(-1,1).long().cuda()\n",
    "    target_probabilities = input.gather(1, true_class)\n",
    "    epsilon = 1e-10\n",
    "    result =  torch.mean(-1 * torch.log(1 - target_probabilities + epsilon))\n",
    "\n",
    "    fool_loss.call_count += 1\n",
    "    if fool_loss.call_count % 200 == 0:\n",
    "      print(\"target probs {}, loss: {}: \".format(target_probabilities, result))\n",
    "\n",
    "    return result\n",
    "\n",
    "  fool_loss.call_count = 0\n",
    "\n",
    "if gen_arch == 'targeted':\n",
    "  def fool_loss(model_output, target_labels):\n",
    "    target_labels = target_labels.view(-1, 1).long().cuda()\n",
    "    target_probabilities = model_output.gather(1, target_labels)\n",
    "    epsilon = 1e-10\n",
    "    # highest possible fool_loss is - log(1e-10) == 23\n",
    "    result = torch.mean(-1 * torch.log(target_probabilities + epsilon))\n",
    "\n",
    "    fool_loss.call_count += 1\n",
    "    if fool_loss.call_count % 200 == 0:\n",
    "      print(\"target probs {}, loss: {}: \".format(target_probabilities, result))\n",
    "\n",
    "    return result\n",
    "\n",
    "  fool_loss.call_count = 0\n",
    "\n",
    "\n",
    "def targeted_validation(gen_output, target):\n",
    "  perturbations, _, _, clean_images, _, z = gen_output\n",
    "  perturbed_images = clean_images + perturbations\n",
    "  target_labels = torch.argmax(z, 1)\n",
    "  adversary_preds = torch.argmax(arch(perturbed_images), 1)\n",
    "#   print('adv preds: ', adversary_preds.shape, adversary_preds)\n",
    "#   print('target_labels: ', target_labels.shape, target_labels)\n",
    "#   print('eq: ', (adversary_preds == target_labels))\n",
    "  return (adversary_preds == target_labels).float().mean()\n",
    "  \n",
    "\n",
    "# # targeted \n",
    "# def validation(gen_output, target):\n",
    "#   perturbations, _, _, clean_images, _, _ = gen_output\n",
    "#   return validation_(perturbations, clean_images)\n",
    "\n",
    "# # non-targeted\n",
    "# def validation(gen_output, target):\n",
    "#   perturbations, _, _, clean_images, _ = gen_output\n",
    "#   return validation_(perturbations, clean_images)\n",
    "\n",
    "# # general\n",
    "def validation(gen_output, target):\n",
    "  perturbations = gen_output[0]\n",
    "  clean_images = gen_output[3]\n",
    "  return validation_(perturbations, clean_images, target)\n",
    "\n",
    "unfooled_histogram = np.array([0.] * 1000)\n",
    "fooled_histogram = np.array([0.] * 1000)\n",
    "valid_cnt = 0\n",
    "\n",
    "def print_hist(unfooled, fooled):\n",
    "  indexed = [(i, u) for i, u in enumerate(unfooled)]\n",
    "  summarized = list(filter(lambda x: x[1] > 0.0, indexed))\n",
    "  total = fooled + unfooled\n",
    "\n",
    "  percent_total = [(i, 100. * u / (total[i] + 1e-10), total[i]) for i, u in enumerate(unfooled)]\n",
    "  sorted_percent_total = sorted(percent_total, key =lambda x: x[1], reverse = True)\n",
    "\n",
    "  print('\\npercent_total: ')\n",
    "  print(list(filter(lambda x: x[1] > 0.0, sorted_percent_total)))\n",
    "  print('\\n')\n",
    "  \n",
    "  return sorted_percent_total\n",
    "\n",
    "def validation_(perturbations, clean_images, target):\n",
    "  # THE CLAMP BELOW IS EXPERIMENTAL, REMOVE THEM ASAP\n",
    "  # THE COMPARISON WITH TARGET IS EXPERIMENTAL TOO, REMOVE IT ASAP\n",
    "  perturbed_images = clean_images + perturbations\n",
    "#   perturbed_images = nag_util.normalize(torch.clamp(nag_util.denormalize(perturbed_images), 0., 1.))\n",
    "  benign_preds = torch.argmax(arch(clean_images), 1)\n",
    "  adversary_preds = torch.argmax(arch(perturbed_images), 1)\n",
    "\n",
    "  is_unfooled = (benign_preds == adversary_preds)\n",
    "  for i , unfooled in enumerate(is_unfooled):\n",
    "    if unfooled == 1:\n",
    "      unfooled_histogram[benign_preds[i]] += 1\n",
    "    else:\n",
    "      fooled_histogram[benign_preds[i]] += 1\n",
    "  \n",
    "#   global valid_cnt\n",
    "#   valid_cnt += 1\n",
    "#   if valid_cnt % 10 == 0:\n",
    "#     print_hist(unfooled_histogram, fooled_histogram)\n",
    "    \n",
    "  return (benign_preds != adversary_preds).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LrJhunt5uV8J"
   },
   "outputs": [],
   "source": [
    "if gen_arch == 'targeted':\n",
    "  class FeatureLoss(nn.Module):\n",
    "      def __name__(self):\n",
    "        return \"feature_loss\"\n",
    "\n",
    "      def __init__(self, dis, layers, layer_weights):\n",
    "          super().__init__()\n",
    "\n",
    "          # define generator here \n",
    "          self.dis = dis\n",
    "          self.diversity_layers = layers\n",
    "          self.hooks = hook_outputs(self.diversity_layers, detach=False)\n",
    "          self.weights = layer_weights\n",
    "          self.metric_names = [\"fool_loss\"] #+ [f\"div_loss_{i}\" for i in range(len(layers))] #maybe Gram\n",
    "  #         self.triplet_hooks = hook_outputs([arch.m.features[4]], detach=False)\n",
    "\n",
    "      def make_features(self, x, clone=False):\n",
    "          y = self.dis(x)\n",
    "          return y, [(o.clone() if clone else o) for o in self.hooks.stored]\n",
    "\n",
    "      def forward(self, inp, target):\n",
    "        sigma_B, _, _, X_B, B_Y, z = inp\n",
    "\n",
    "        X_A = X_B + sigma_B\n",
    "  #       X_S = self.add_perturbation_shuffled(X_B, sigma_B) # Shuffled Addversarial Examples\n",
    "\n",
    "        A_Y, A_feat = self.make_features(X_A)\n",
    "  #       _, S_feat = self.make_features(X_S)\n",
    "\n",
    "        chosen_labels = z.argmax(dim=1)\n",
    "        fooling_loss =  fool_loss(A_Y, chosen_labels)\n",
    "\n",
    "  #       raw_diversity_losses = [diversity_loss(a_f, s_f) for a_f, s_f in zip(A_feat, S_feat)]\n",
    "  #       weighted_diversity_losses = [diversity_loss(a_f, s_f) * weight for a_f, s_f, weight in zip(A_feat, S_feat, self.weights)]\n",
    "\n",
    "  #       self.losses = [fooling_loss] + weighted_diversity_losses\n",
    "  #       self.metrics = dict(zip(self.metric_names, [fooling_loss] + raw_diversity_losses))\n",
    "\n",
    "        self.losses = [fooling_loss]\n",
    "        self.metrics = dict(zip(self.metric_names, [fooling_loss]))\n",
    "\n",
    "        return sum(self.losses)\n",
    "\n",
    "      def add_perturbation_shuffled(self, inp, perturbation):\n",
    "  #       j = torch.randperm(inp.shape[0])\n",
    "          j = derangement(inp.shape[0])\n",
    "          return inp.add(perturbation[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CMBxuBUXuV8N"
   },
   "outputs": [],
   "source": [
    "def derange(*args):\n",
    "  if len(args) == 0: raise ValueError('shuffle function needs atleast one argument')\n",
    "  deranged_indexes = derangement(args[0].shape[0])\n",
    "  if not all([args[0].shape[0] == arg.shape[0] for arg in args]): \n",
    "    raise ValueError('inputs to shuffle must all have the same 0th dimension')\n",
    "  return [arg[deranged_indexes] for arg in args]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nelYZyzhuV8R"
   },
   "outputs": [],
   "source": [
    "if gen_arch == 'non-targeted':\n",
    "  class FeatureLoss(nn.Module):\n",
    "      def __name__(self):\n",
    "        return \"feature_loss\"\n",
    "\n",
    "      def __init__(self, dis, layers, layer_weights):\n",
    "          super().__init__()\n",
    "\n",
    "          self.dis = dis\n",
    "          self.diversity_layers = layers\n",
    "          self.hooks = hook_outputs(self.diversity_layers, detach=False)\n",
    "          self.weights = layer_weights\n",
    "\n",
    "  #         self.metric_names = [\"fool_loss\"] + [f\"div_loss_{i}\" for i in range(len(layers))] + ['triplet_loss']# Maybe Gram\n",
    "  #         self.metric_names = [\"div_loss\"] + ['triplet_loss']# Maybe Gram\n",
    "          self.metric_names = [\"fool_loss\"] + ['div_loss']# Maybe Gram\n",
    "          self.triplet_weight = 4.\n",
    "          self.div_weight = 1.\n",
    "          self.fooling_weight = 1.\n",
    "\n",
    "      def make_features(self, x, clone=False):\n",
    "          y = self.dis(x)\n",
    "          return y, [(o.clone() if clone else o) for o in self.hooks.stored]\n",
    "\n",
    "      # contrastive loss\n",
    "      def forward(self, inp, target):\n",
    "          sigma_B, sigma_pos, sigma_neg, X_B, z_B = inp\n",
    "\n",
    "          deranged_perturbations, deranged_z_s = derange(sigma_B, z_B)\n",
    "\n",
    "          X_A = X_B + sigma_B\n",
    "          X_S = X_B + deranged_perturbations\n",
    "#           X_A_pos = X_B + sigma_pos\n",
    "#           X_A_neg = X_B + sigma_neg\n",
    "\n",
    "          B_Y, _ = self.make_features(X_B)\n",
    "          A_Y, A_feat = self.make_features(X_A)\n",
    "          _, S_feat = self.make_features(X_S)\n",
    "#           pos_softmax, _ = self.make_features(X_A_pos)\n",
    "#           neg_softmax, _ = self.make_features(X_A_neg)\n",
    "\n",
    "          raw_fooling_loss =  fool_loss(A_Y, B_Y)\n",
    "          weighted_fooling_loss = self.fooling_weight * raw_fooling_loss\n",
    "\n",
    "#           raw_diversity_loss = diversity_loss(A_feat[0], S_feat[0], z_B, deranged_z_s)\n",
    "          raw_diversity_loss = diversity_loss(A_feat[0], S_feat[0])\n",
    "          weighted_diversity_loss = raw_diversity_loss * self.div_weight\n",
    "\n",
    "#           raw_triplet_loss = triplet_loss(A_Y, pos_softmax, neg_softmax, cos_distance, 1.4)\n",
    "#           weighted_triplet_loss = raw_triplet_loss * self.triplet_weight\n",
    "\n",
    "  #         self.losses = weighted_diversity_losses + [weighted_triplet_loss]\n",
    "  #         raw_losses = raw_diversity_losses + [raw_triplet_loss]\n",
    "\n",
    "          self.losses = [weighted_fooling_loss] + [weighted_diversity_loss] #+ [weighted_triplet_loss]\n",
    "          raw_losses = [raw_fooling_loss] + [raw_diversity_loss] #+ [raw_triplet_loss]\n",
    "\n",
    "  #         self.losses = [fooling_loss] + [weighted_triplet_loss]\n",
    "  #         self.metrics = dict(zip(self.metric_names, [fooling_loss] + [raw_triplet_loss]))\n",
    "\n",
    "          if len(self.metric_names) != len(raw_losses):\n",
    "            raise Exception(\"length of metric names unequals length of losses\")\n",
    "\n",
    "          self.metrics = dict(zip(self.metric_names, raw_losses))\n",
    "          return sum(self.losses)\n",
    "\n",
    "\n",
    "\n",
    "  # #     triplet loss\n",
    "  #     def forward(self, inp, target):\n",
    "  #         sigma_B, sigma_pos, sigma_neg, X_B, _ = inp\n",
    "\n",
    "  #         X_A = self.add_perturbation(X_B, sigma_B) \n",
    "  #         X_A_pos = self.add_perturbation(X_B, sigma_pos)\n",
    "  #         X_A_neg = self.add_perturbation(X_B, sigma_neg) \n",
    "  #         X_S = self.add_perturbation_shuffled(X_B, sigma_B) # Shuffled Addversarial Examples\n",
    "\n",
    "  # #         B_Y, _ = self.make_features(X_B)\n",
    "  #         A_Y, A_feat = self.make_features(X_A)\n",
    "  # #         _, S_feat = self.make_features(X_S)\n",
    "  #         pos_softmax, _ = self.make_features(X_A_pos)\n",
    "  #         neg_softmax, _ = self.make_features(X_A_neg)\n",
    "\n",
    "  # #         raw_fooling_loss =  fool_loss(A_Y, B_Y)\n",
    "  # #         weighted_fooling_loss = self.fooling_weight * raw_fooling_loss\n",
    "\n",
    "  #         raw_diversity_losses = [diversity_loss(a_f, s_f, sigma_B, ) for a_f, s_f in zip(A_feat, S_feat)]\n",
    "  #         weighted_diversity_losses = [diversity_loss(a_f, s_f) * weight * self.div_weight for a_f, s_f, weight in zip(A_feat, S_feat, self.weights)]\n",
    "  #         raw_triplet_loss = triplet_loss(A_Y, pos_softmax, neg_softmax, cos_distance, 1.4)\n",
    "  #         weighted_triplet_loss = raw_triplet_loss * self.triplet_weight\n",
    "\n",
    "  #         self.losses = weighted_diversity_losses + [weighted_triplet_loss]\n",
    "  #         raw_losses = raw_diversity_losses + [raw_triplet_loss]\n",
    "\n",
    "  # #         self.losses = [weighted_fooling_loss] + weighted_diversity_losses + [weighted_triplet_loss]\n",
    "  # #         raw_losses = [raw_fooling_loss] + raw_diversity_losses + [raw_triplet_loss]\n",
    "\n",
    "  # #         self.losses = [fooling_loss] + [weighted_triplet_loss]\n",
    "  # #         self.metrics = dict(zip(self.metric_names, [fooling_loss] + [raw_triplet_loss]))\n",
    "\n",
    "  #         if len(self.metric_names) != len(raw_losses):\n",
    "  #           raise Exception(\"length of metric names unequals length of losses\")\n",
    "\n",
    "  #         self.metrics = dict(zip(self.metric_names, raw_losses))\n",
    "  #         return sum(self.losses)\n",
    "\n",
    "\n",
    "  #     #use two types of triplet losses\n",
    "  #     def forward(self, inp, target):\n",
    "  #       sigma_B, sigma_pos, sigma_neg, X_B = inp\n",
    "\n",
    "  #       X_A = self.add_perturbation(X_B, sigma_B) \n",
    "  #       X_A_pos = self.add_perturbation(X_B, sigma_pos)\n",
    "  #       X_A_neg = self.add_perturbation(X_B, sigma_neg) \n",
    "\n",
    "  #       X_S = self.add_perturbation_shuffled(X_B, sigma_B) # Shuffled Addversarial Examples\n",
    "\n",
    "  #       B_Y, _ = self.make_features(X_B)\n",
    "  #       A_Y, A_feat = self.make_features(X_A)\n",
    "  #       _, S_feat = self.make_features(X_S)\n",
    "  #       pos_softmax, _ = self.make_features(X_A_pos)\n",
    "  #       neg_softmax, _ = self.make_features(X_A_neg)\n",
    "\n",
    "  #       fooling_loss =  fool_loss(A_Y, B_Y)\n",
    "\n",
    "  #       raw_diversity_losses = [diversity_loss(a_f, s_f) for a_f, s_f in zip(A_feat, S_feat)]\n",
    "  #       weighted_diversity_losses = [diversity_loss(a_f, s_f) * weight * self.div_weight for a_f, s_f, weight in zip(A_feat, S_feat, self.weights)]\n",
    "\n",
    "  #       raw_triplet_loss_sm = triplet_loss(A_Y, pos_softmax, neg_softmax, cos_distance, 1.4)\n",
    "  #       weighted_triplet_loss_sm = raw_triplet_loss_sm * self.triplet_weight_sm\n",
    "\n",
    "  #       raw_triplet_loss_noise = triplet_loss(sigma_B, sigma_pos, sigma_neg, l2_distance, 5.)\n",
    "  #       weighted_triplet_loss_noise = raw_triplet_loss_noise * self.triplet_weight_noise\n",
    "\n",
    "  #       self.losses = [fooling_loss] + weighted_diversity_losses + [weighted_triplet_loss_sm, weighted_triplet_loss_noise] \n",
    "  #       self.metrics = dict(zip(self.metric_names, [fooling_loss] + raw_diversity_losses + [weighted_triplet_loss_sm, weighted_triplet_loss_noise]))\n",
    "\n",
    "  #       return sum(self.losses)\n",
    "\n",
    "  #     # just fooling and diversity\n",
    "  #     def forward(self, inp, target):\n",
    "  #       sigma_B, sigma_pos, sigma_neg, X_B = inp\n",
    "\n",
    "  #       X_A = self.add_perturbation(X_B, sigma_B) \n",
    "\n",
    "  #       X_S = self.add_perturbation_shuffled(X_B, sigma_B) # Shuffled Addversarial Examples\n",
    "\n",
    "  #       B_Y, _ = self.make_features(X_B)\n",
    "  #       A_Y, A_feat = self.make_features(X_A)\n",
    "  #       _, S_feat = self.make_features(X_S)\n",
    "\n",
    "  #       fooling_loss =  fool_loss(A_Y, B_Y)\n",
    "\n",
    "  #       raw_diversity_losses = [diversity_loss(a_f, s_f) for a_f, s_f in zip(A_feat, S_feat)]\n",
    "  #       weighted_diversity_losses = [diversity_loss(a_f, s_f) * weight * self.div_weight for a_f, s_f, weight in zip(A_feat, S_feat, self.weights)]\n",
    "\n",
    "  #       self.losses = [fooling_loss] + weighted_diversity_losses\n",
    "  #       self.metrics = dict(zip(self.metric_names, [fooling_loss] + raw_diversity_losses))\n",
    "\n",
    "  #       return sum(self.losses)\n",
    "\n",
    "\n",
    "      def add_perturbation_shuffled(self, inp, perturbation):\n",
    "        j = derangement(inp.shape[0])\n",
    "        return inp.add(perturbation[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WNg_ej-1uV8V"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def produce_summary(root_folder, n_files):\n",
    "  def writeline(file, values, fmt_string):\n",
    "    file.write(', '.join(fmt_string.format(v) for v in values) + '\\n')\n",
    "  \n",
    "  last_rows = []\n",
    "  for i in range(n_files):\n",
    "    prefix = '/root/Derakhshani/adversarial/textual_notes/CSVs'\n",
    "    df = pd.read_csv(\"{}/{}/{}.csv\".format(prefix, root_folder, i))\n",
    "    last_rows.append(df.iloc[-1][1:-1].values.tolist())\n",
    "  \n",
    "  last_rows = np.array(last_rows)\n",
    "  \n",
    "  labels = list(df.columns[1:-1])\n",
    "  means = np.mean(last_rows, axis=0).tolist()\n",
    "  outfile = open('{}/{}/summary.txt'.format(prefix, root_folder), 'w+')\n",
    "  outfile.write('means: \\n')\n",
    "  writeline(outfile, labels, '{: >20}')\n",
    "  writeline(outfile, means, '{: >20.3}')\n",
    "  outfile.write('\\n')\n",
    "      \n",
    "  operations = []\n",
    "  for column in df.columns[1:-1]:\n",
    "    if column in ['train_loss', 'valid_loss', 'fool_loss', 'triplet_loss'] or column[:8] == 'div_loss':\n",
    "      operations.append('min')\n",
    "    elif column in ['validation', 'targeted_validation', 'div_metric', 'entropy']:\n",
    "      operations.append('max')\n",
    "    else:\n",
    "      raise ValueError('column {} is not recognized'.format(column))\n",
    "    \n",
    "  results = []\n",
    "  indexes = []\n",
    "  \n",
    "  for i in range(len(operations)):\n",
    "    values = last_rows[:, i]\n",
    "    if operations[i] == 'max': operation = np.max\n",
    "    elif operations[i] == 'min': operation = np.min\n",
    "    result = operation(values)\n",
    "    results.append(result)\n",
    "    indexes.append(values.tolist().index(result))\n",
    "  \n",
    "  outfile.write('bests: \\n')\n",
    "  writeline(outfile, labels, '{: >20}')\n",
    "  writeline(outfile, operations, '{: >20}')\n",
    "  writeline(outfile, results, '{: >20.3}')\n",
    "  writeline(outfile, indexes, '{: >20}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IuYuRqozuV8Y"
   },
   "outputs": [],
   "source": [
    "from distutils import dir_util \n",
    "\n",
    "def investigate_initial_settings(n_settings, n_epochs, lr, wd, results_dir):\n",
    "  os.mkdir(env.get_csv_dir() + results_dir)\n",
    "  os.mkdir(env.get_models_dir() + results_dir)\n",
    "  \n",
    "  for setting_ind in range(n_settings):\n",
    "    print(f\"investigation no: {setting_ind}\")\n",
    "    learn = None; gen = None; gc.collect()\n",
    "    gen = Gen(z_dim = z_dim)\n",
    "    init_cnn(gen, True)\n",
    "    \n",
    "    tmp_csv_filename =  env.temp_csv_path + '/' + results_dir + '/' + str(setting_ind)\n",
    "    csv_logger = partial(ImmediateCSVLogger, filename=tmp_csv_filename)\n",
    "\n",
    "    if gen_arch == 'non-targeted':\n",
    "      metrics = [validation]\n",
    "    elif gen_arch == 'targeted':\n",
    "      metrics = [validation, targeted_validation]\n",
    "      \n",
    "    learn = Learner(data, gen, loss_func = feat_loss, metrics=metrics, \n",
    "                    model_dir = env.get_learner_models_dir(), \n",
    "                    callback_fns=[DiversityMetric, LossMetrics, csv_logger])\n",
    "    \n",
    "    saver_best = SaveModelCallback(learn, every='improvement', monitor='validation', name=model.__name__ + \"-best\")\n",
    "    saver_every_epoch = SaveModelCallback(learn, every='epoch', name=model.__name__)\n",
    "\n",
    "    learn.fit(n_epochs, lr=lr, wd = wd, callbacks=[saver_best, saver_every_epoch])\n",
    "    \n",
    "    shutil.copyfile(tmp_csv_filename + \".csv\", env.get_csv_dir() + results_dir + '/' + str(setting_ind) + '.csv')\n",
    "    \n",
    "    model_dest = env.get_models_dir() + results_dir + '/' + str(setting_ind)\n",
    "    os.mkdir(model_dest)\n",
    "    dir_util.copy_tree(env.data_path/env.get_learner_models_dir(), model_dest)\n",
    "    shutil.rmtree(env.data_path/env.get_learner_models_dir())  \n",
    "    \n",
    "  produce_summary(results_dir, n_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97oO_lhduV8a"
   },
   "outputs": [],
   "source": [
    "def generate_perturbations(learn, n_perturbations):\n",
    "  initial_training_mode = learn.model.training\n",
    "  gen = learn.model.eval()\n",
    "  perturbations = [gen.generate_single_noise() for _ in range(n_perturbations)]\n",
    "  learn.model.train(initial_training_mode)  \n",
    "  return perturbations\n",
    "\n",
    "def compute_prediction_histogram(learn, perturbation, verbose=False):\n",
    "  pred_hist = [0] * 1000\n",
    "  batch_no = -1\n",
    "  for batch, _ in learn.data.valid_dl:\n",
    "    batch_no += 1\n",
    "    if batch_no % 100 == 0 and verbose: print (\"at batch no {}\".format(batch_no))\n",
    "    perturbed_batch = batch + perturbation[None]\n",
    "    preds = arch(perturbed_batch).argmax(1)\n",
    "    for pred in preds:\n",
    "      pred_hist[pred] += 1\n",
    "  return pred_hist\n",
    "\n",
    "\n",
    "def compute_mean_prediction_histogram(learn, perturbations, verbose=False):\n",
    "  pred_hist = torch.tensor([0] * 1000).detach_()\n",
    "  batch_no = -1\n",
    "  for batch, _ in learn.data.valid_dl:\n",
    "    batch_no += 1\n",
    "    if batch_no % 5 == 0 and verbose: print(f\"at batch no {batch_no}\")\n",
    "    for j, perturbation in enumerate(perturbations):\n",
    "      perturbed_batch = batch + perturbation[None]\n",
    "      preds = arch(perturbed_batch).argmax(1)\n",
    "      for pred in preds:\n",
    "        pred_hist[pred] += 1\n",
    "  pred_hist = pred_hist.float() / len(perturbations)\n",
    "  return pred_hist.tolist()\n",
    "\n",
    "\n",
    "def classes_needed_to_reach(percentage, hist):\n",
    "  hist_sum = np.sum(hist)\n",
    "  indexed_hist = [(i, hist_element) for i,hist_element in  \n",
    "                          enumerate(hist)]\n",
    "  sorted_hist = sorted(indexed_hist, key=lambda x: x[1], reverse = True)\n",
    "  \n",
    "  cumulative_percent = 0\n",
    "  n_used_classes = 0\n",
    "  while cumulative_percent < percentage:\n",
    "    hist_elem = sorted_hist[n_used_classes]\n",
    "    cumulative_percent += (hist_elem[1] / hist_sum) * 100.\n",
    "    n_used_classes += 1\n",
    "\n",
    "  return n_used_classes, sorted_hist\n",
    "\n",
    "def diversity(learn, n_perturbations, percentage = 95, verbose = True):\n",
    "  pred_histogram = compute_mean_prediction_histogram(\n",
    "      learn, generate_perturbations(learn, n_perturbations), verbose\n",
    "  )\n",
    "  print(\"finished creating the prediction histogram\")\n",
    "\n",
    "  return classes_needed_to_reach(95, pred_histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2erFgTn8uV8d"
   },
   "outputs": [],
   "source": [
    "class DiversityMetric(LearnerCallback):\n",
    "  _order = -20 # Needs to run before the recorder\n",
    "  \n",
    "  def __init__(self, learn):\n",
    "    super().__init__(learn)\n",
    "    self.average_over = 4\n",
    "    self.n_perturbations = 10\n",
    "    self.percentage = 95\n",
    "  \n",
    "  def on_train_begin(self, **kwargs):\n",
    "    self.learn.recorder.add_metric_names(['div_metric', 'entropy'])\n",
    "    \n",
    "  def on_epoch_begin(self, **kwargs):\n",
    "    global learn\n",
    "    self.perturbations_list = [generate_perturbations(self.learn, self.n_perturbations) \\\n",
    "                          for _ in range(self.average_over)]\n",
    "    self.pred_hist_list = [torch.tensor([0] * 1000).detach_() for _ in range(self.average_over)]\n",
    "    \n",
    "  def on_batch_end(self, last_output, train, **kwargs):\n",
    "    if not train:\n",
    "      images = last_output[3]; assert(images.shape[1:] == (3,224, 224))\n",
    "      for perturbations, pred_hist in zip(self.perturbations_list, self.pred_hist_list):\n",
    "        for j, perturbation in enumerate(perturbations):\n",
    "          perturbed_batch = images + perturbation[None]\n",
    "          preds = arch(perturbed_batch).argmax(1)\n",
    "          for pred in preds:\n",
    "            pred_hist[pred] += 1\n",
    "  \n",
    "  def on_epoch_end(self, last_metrics, **kwargs):\n",
    "    for i in range(len(self.pred_hist_list)):\n",
    "      self.pred_hist_list[i] = (self.pred_hist_list[i].float() / self.n_perturbations).tolist()\n",
    "    \n",
    "    div_metric_list = [classes_needed_to_reach(self.percentage, pred_hist)[0] \\\n",
    "                          for pred_hist in self.pred_hist_list]\n",
    "    entropy_list = [entropy(pred_hist) for pred_hist in self.pred_hist_list]\n",
    "    return add_metrics(last_metrics, [np.mean(div_metric_list), np.mean(entropy_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "itHU97Y_uV8h"
   },
   "outputs": [],
   "source": [
    "class TargetedDiversityMetric(DiversityMetric):\n",
    "    def __init__(self, n_perturbations, percentage):\n",
    "      super().__init__(n_perturbations, percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xnByiCgVuV8t"
   },
   "outputs": [],
   "source": [
    "class FoolingWeightScheduler(LearnerCallback):\n",
    "  def __init__(self, learn: Learner):\n",
    "    super().__init__(learn)\n",
    "    self.weights_history = []\n",
    "    self.fooling_loss_history = []\n",
    "  \n",
    "  def get_metric_value(self, metric_name):\n",
    "    for value, name in zip(self.learn.recorder.metrics[-1],self.learn.recorder.names[3:-1]):\n",
    "      if name == metric_name:\n",
    "        return value\n",
    "    raise ValueError('Could not find {} metric.'.format(metric_name))\n",
    "  \n",
    "  def on_epoch_end(self, last_metrics, **kwargs):\n",
    "    # history keeping\n",
    "    self.weights_history.append((kwargs['epoch'], self.learn.loss_func.fooling_weight))\n",
    "    \n",
    "    # the actual functionality\n",
    "    fooling_loss = self.get_metric_value('fool_loss')\n",
    "    self.fooling_loss_history.append(fooling_loss)\n",
    "    \n",
    "    if len(self.weights_history) < 2:\n",
    "      return\n",
    "    \n",
    "    if self.fooling_loss_history[-1] > self.fooling_loss_history[-2]:\n",
    "      self.learn.loss_func.fooling_weight += 0.3    \n",
    "      print('fooling weight increased to {} at the end of epoch {}'.format(\n",
    "        self.learn.loss_func.fooling_weight, kwargs['epoch']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wElU0RSRuV80"
   },
   "outputs": [],
   "source": [
    "class CyclicalLRScheduler(LearnerCallback):\n",
    "  def __init__(self, learn, max_lr, min_lr, cycle_len):\n",
    "    super().__init__(learn)\n",
    "    self.max_lr = max_lr\n",
    "    self.min_lr = min_lr\n",
    "    self.cycle_len = cycle_len\n",
    "    \n",
    "  def on_train_begin(self, **kwargs):\n",
    "    self.n_iter_per_epoch = len(self.learn.data.train_dl)\n",
    "    self.cycle_len_iters = self.cycle_len * self.n_iter_per_epoch\n",
    "    self.learn.opt.lr = self.min_lr\n",
    "    \n",
    "    \n",
    "  def on_batch_end(self, iteration, train, **kwargs):\n",
    "    if train:\n",
    "      cycle_index = iteration % self.cycle_len_iters\n",
    "      half_cycle_len = self.cycle_len_iters / 2\n",
    "\n",
    "      if cycle_index < half_cycle_len:\n",
    "        new_lr = float(self.max_lr - self.min_lr) / half_cycle_len * cycle_index + self.min_lr\n",
    "      else:\n",
    "        new_lr = float(self.min_lr - self.max_lr) / half_cycle_len * (cycle_index - half_cycle_len) + self.max_lr\n",
    "\n",
    "#       print('iter: {}, lr: {}'.format(iteration, new_lr))\n",
    "      self.opt.lr = new_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YtQh1qcsuV87"
   },
   "outputs": [],
   "source": [
    "# def get_data(src, path, bs, size):\n",
    "#     data = (src.label_from_func(lambda x: path/x.name)\n",
    "#            .databunch(bs=bs))\n",
    "#     data.c = 3\n",
    "#     return data\n",
    "\n",
    "def get_unet_model(arch):\n",
    "    data_path = env.data_path/\"train\"\n",
    "#     data_path = Path(\"/content/dataset/train\")\n",
    "#     data_path = env.data_path.parent/\"dataset_dummy_denoiser\"\n",
    "    src = ImageImageList.from_folder(data_path).split_none()\n",
    "    data = (src.label_from_func(lambda x: x)\n",
    "            .transform(get_transforms(), size=224)\n",
    "            .databunch(bs = batch_size)\n",
    "           )\n",
    "    data.c = 3\n",
    "    learn = unet_learner(data, arch, norm_type=NormType.Weight)\n",
    "    learn.unfreeze()\n",
    "    return learn.model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# denoiser_type = \"online\"\n",
    "denoiser_type = \"offline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fP_fcudauV8-"
   },
   "outputs": [],
   "source": [
    "if denoiser_type == \"online\":\n",
    "  class Denoiser(nn.Module):\n",
    "    def __init__(self, generator):\n",
    "      super().__init__()\n",
    "      self.generator = generator.eval()\n",
    "      requires_grad(self.generator, False)\n",
    "      self.denoiser = get_unet_model(models.resnet18)\n",
    "\n",
    "    def forward(self, input_img):\n",
    "  #     print('defended fw call:')\n",
    "      perturbation = self.generator(input_img)[0].detach()\n",
    "      perturbed_img = (input_img + perturbation).detach()\n",
    "      # self.denoiser(perturbed_img)\n",
    "      predicted_noise = self.generator.output_coeff * torch.tanh(self.denoiser(perturbed_img))\n",
    "      restored_img = perturbed_img - predicted_noise\n",
    "  #     print(('orig label: {} \\npert label: {} \\nrest label: {}\\n' \\\n",
    "  #           'predicted_noise: ({},{}), {} \\nperturbation:({}, {}), {} \\n').format(\n",
    "  #       arch(input_img).argmax(dim=1), arch(perturbed_img).argmax(dim=1), arch(restored_img).argmax(dim=1),\n",
    "  #       predicted_noise.min(), predicted_noise.max(), predicted_noise.shape,\n",
    "  #       perturbation.min(), perturbation.max(), perturbation.shape\n",
    "  #     ))\n",
    "      return restored_img, perturbation, input_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "if denoiser_type == \"offline\":\n",
    "  class Denoiser(nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self.denoiser = get_unet_model(models.resnet18)\n",
    "\n",
    "    def forward(self, perturbed_img):\n",
    "      perturbed_img.detach_()\n",
    "      predicted_noise = Gen.output_coeff * torch.tanh(self.denoiser(perturbed_img))\n",
    "      restored_img = perturbed_img - predicted_noise\n",
    "  #     print(('orig label: {} \\npert label: {} \\nrest label: {}\\n' \\\n",
    "  #           'predicted_noise: ({},{}), {} \\nperturbation:({}, {}), {} \\n').format(\n",
    "  #       arch(input_img).argmax(dim=1), arch(perturbed_img).argmax(dim=1), arch(restored_img).argmax(dim=1),\n",
    "  #       predicted_noise.min(), predicted_noise.max(), predicted_noise.shape,\n",
    "  #       perturbation.min(), perturbation.max(), perturbation.shape\n",
    "  #     ))\n",
    "      return restored_img, perturbed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EWErjJ0kuV9B"
   },
   "outputs": [],
   "source": [
    "def denoiser_validation(defended_classifier_output, target):\n",
    "  restored_images, _, clean_images = defended_classifier_output\n",
    "  \n",
    "  original_preds = torch.argmax(arch(clean_images), 1)\n",
    "  restored_preds = torch.argmax(arch(restored_images), 1)\n",
    "  \n",
    "  return (original_preds == restored_preds).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pp7UY97FuV9E"
   },
   "outputs": [],
   "source": [
    "dloss_cnt = 0\n",
    "class DenoiserLoss(nn.Module):\n",
    "  def __name__(self):\n",
    "    return \"denoiser_loss\"\n",
    "  \n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.metric_names = [\"denoiser_loss\"]\n",
    "    self.hooks = hook_outputs([arch.m.fc], detach=False)\n",
    "    \n",
    "  def make_features(self, inputs):\n",
    "    y = arch(inputs)\n",
    "    return y, self.hooks.stored[0]\n",
    "       \n",
    "  def forward(self, defended_classifier_output, target):\n",
    "    restored_img, perturbations, clean_images = defended_classifier_output\n",
    "    \n",
    "    restored_pred, restored_feats = self.make_features(restored_img)\n",
    "    original_pred, original_feats = self.make_features(clean_images)\n",
    "#     print('restored: {}, orig: {}'.format(restored_feats.shape, original_feats.shape))\n",
    "#     winning_class = original_prediction_vector.argmax(dim=1)\n",
    "#     denoiser_loss = F.cross_entropy(restored_prediction_vector, winning_class)\n",
    "\n",
    "    denoiser_loss = F.l1_loss(restored_feats, original_feats)\n",
    "    # denoiser_loss = -1 * torch.mean(F.cosine_similarity(restored_pred, original_pred, dim=1))\n",
    "    \n",
    "    global dloss_cnt\n",
    "    if dloss_cnt % 10 == 0: print('denoser_loss:', denoiser_loss)\n",
    "    dloss_cnt+=1\n",
    "  \n",
    "    self.losses = [denoiser_loss]\n",
    "    self.metrics = dict(zip(self.metric_names, self.losses))\n",
    "    \n",
    "    return denoiser_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tltucTv2ep9-"
   },
   "outputs": [],
   "source": [
    "# mode = 'sanity_check'\n",
    "mode = 'normal'\n",
    "# mode = 'div_metric_calc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CLbgT7gAuV9K"
   },
   "outputs": [],
   "source": [
    "model = models.resnet50\n",
    "# model = models.resnet152\n",
    "# model = models.vgg16_bn\n",
    "# model = torchvision.models.googlenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SO1h55obXzOv",
    "outputId": "2a8f20da-21e6-420f-de2f-16e9ec691764"
   },
   "outputs": [],
   "source": [
    "if mode == \"normal\":\n",
    "  env.load_dataset('dataset','data')\n",
    "  env.set_data_path('dataset')\n",
    "elif mode == \"sanity_check\":\n",
    "  env.load_dataset('dataset_sanity_check_small', 'dataset_sanity_check_small')  \n",
    "  env.set_data_path('dataset_sanity_check_small')\n",
    "elif mode == \"div_metric_calc\":\n",
    "  env.load_dataset('dataset','data')\n",
    "  env.set_data_path('dataset')\n",
    "  env.load_test_dataset(str(env.data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "id": "koaQZmjMom7w",
    "outputId": "99dc7e0d-d739-4cc2-b0dd-85041e5bc0ca"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "gpu_flag = True\n",
    "nag_util.batch_size = batch_size; nag_util.gpu_flag = gpu_flag;\n",
    "tfms = get_transforms(do_flip=False, max_rotate=0)\n",
    "data = (ImageList.from_folder(env.data_path)\n",
    "        .split_by_folder(valid=('test' if mode == 'div_metric_calc' else 'valid'))\n",
    "        .label_from_folder()\n",
    "        .transform(tfms, size=224)\n",
    "        .databunch(bs=batch_size, num_workers=1)\n",
    "        .normalize(imagenet_stats))\n",
    "\n",
    "# data.show_batch(rows=2, figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_perturbed = (ImageList.from_folder('/home/mlcm-deep/AhmadPourihosseini/NAG/datasets/perturbed_resnet50_72')\n",
    "        .split_by_folder(valid=('test' if mode == 'div_metric_calc' else 'valid'))\n",
    "        .label_from_folder()\n",
    "        .transform(None, size=224)\n",
    "        .databunch(bs=batch_size, num_workers=1)\n",
    "        .normalize(imagenet_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO CONTINUE:\n",
    "import os\n",
    "\n",
    "def denoiser_label_func(x):\n",
    "  dataset_type = x.parts[-3]\n",
    "  class_name = x.parts[-2]\n",
    "  img_name = os.path.splitext(x.parts[-1])[0]\n",
    "  return os.path.join(*x.parts[:-4], 'dataset', dataset_type, class_name, img_name + '.jpg')\n",
    "\n",
    "data_denoiser = (ImageImageList.from_folder('/home/mlcm-deep/AhmadPourihosseini/NAG/datasets/perturbed_resnet50_72')\n",
    "        .split_by_folder(valid=('test' if mode == 'div_metric_calc' else 'valid'))\n",
    "        .label_from_func(denoiser_label_func)\n",
    "        .transform(None, size=224, tfm_y=True)\n",
    "        .databunch(bs=batch_size, num_workers=1)\n",
    "        .normalize(imagenet_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# j = 0\n",
    "# for i, (d, t) in enumerate(data.fix_dl):\n",
    "#   print(data.fix_ds.items[i], t[0])\n",
    "#   Image(nag_util.denormalize(d)).show()\n",
    "#   j += 1\n",
    "#   if j == 20:\n",
    "#     break\n",
    "  \n",
    "\n",
    "# # for d, t in data_denoiser.train_dl:\n",
    "# #   im1 = Image(d[0])\n",
    "# #   im2 = Image(t[0])\n",
    "# #   im1.show(), im2.show()\n",
    "# #   break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test site:\n",
    "# l = Learner(data_perturbed, model(True), metrics = [accuracy])\n",
    "# l.validate(data_perturbed.valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = Learner(data, model(True), metrics = [accuracy])\n",
    "# l.validate(data.valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rename_imagenet_folders(root_folder):\n",
    "#     name_map = {}\n",
    "#     with open('/home/mlcm-deep/AhmadPourihosseini/NAG/nag-public/NAG-11May-beforeDenoiser/imagenet_clsidx_to_id.txt', 'r') as f:\n",
    "#         for line in f:\n",
    "#             cls_idx, name_id = line.strip().split(' ')\n",
    "#             name_map[int(cls_idx)] = name_id\n",
    "\n",
    "#     for idx, name in name_map.items():\n",
    "#       if Path('{}/{}'.format(root_folder, idx)).exists():\n",
    "#         os.rename('{}/{}'.format(root_folder, idx), '{}/{}'.format(root_folder, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename_imagenet_folders('/home/mlcm-deep/AhmadPourihosseini/NAG/datasets/perturbed/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kDBkRV8yovwV"
   },
   "outputs": [],
   "source": [
    "if gen_arch == \"non-targeted\":\n",
    "  z_dim = 10\n",
    "elif gen_arch == \"targeted\":\n",
    "  z_dim = 1000\n",
    "  \n",
    "arch = SoftmaxWrapper(model(pretrained=True).cuda().eval())\n",
    "nag_util.arch = arch\n",
    "requires_grad(arch, False)\n",
    "\n",
    "# vgg:\n",
    "# layers = []\n",
    "# blocks = [i-1 for i,o in enumerate(children(arch.features)) if isinstance(o, nn.MaxPool2d)]\n",
    "# layers = [arch.features[i] for i in blocks]\n",
    "# layer_weights = [1] * len(layers)\n",
    "\n",
    "layers = [\n",
    "    arch.softmax\n",
    "]\n",
    "\n",
    "layer_weights = [1.] * len(layers)\n",
    "\n",
    "# inception:\n",
    "# layers = [\n",
    "#     arch.Conv2d_1a_3x3,\n",
    "#     arch.Mixed_6e,\n",
    "#     arch.Mixed_7a,\n",
    "#     arch.fc    \n",
    "# ]\n",
    "# layer_weights = [1.0/4.0] * len(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qd9gXUy_ovww"
   },
   "outputs": [],
   "source": [
    "feat_loss = FeatureLoss(arch, layers, layer_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZJe5W7IfuV9n"
   },
   "outputs": [],
   "source": [
    "class LRAnneal(LearnerCallback):\n",
    "  _order = -20 # Needs to run before the recorder\n",
    "  \n",
    "  def __init__(self, learn, final_value):\n",
    "    super().__init__(learn)\n",
    "    self.final_value = final_value\n",
    "  \n",
    "  def on_train_begin(self, **kwargs):\n",
    "    self.initial_value = self.opt.lr\n",
    "    self.learn.recorder.add_metric_names(['lr'])\n",
    "  \n",
    "  def on_epoch_end(self, epoch, n_epochs, last_metrics, **kwargs):\n",
    "    self.opt.lr = annealing_linear(self.initial_value, self.final_value, float(epoch) / n_epochs)\n",
    "    return add_metrics(last_metrics, self.opt.lr)\n",
    "  \n",
    "# class LRMonitor(LearnerCallBack):\n",
    "#   def __init__(self, learn):\n",
    "#     super().__init__(learn)\n",
    "#     self.name = 'lr'\n",
    "    \n",
    "#   def on_epoch_end(self, last_metrics, **kwargs):\n",
    "#     return add_metrics(last_metrics, self.opt.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N80J714juV9q"
   },
   "outputs": [],
   "source": [
    "# env.save_filename = 'resnet50_65' #resnet50_64\n",
    "# env.save_filename = 'resnet50_17'\n",
    "env.save_filename = 'unet_resnet50_72_1'\n",
    "\n",
    "if Path(env.get_csv_path() + '.csv').exists(): raise FileExistsError(\"csv_path already exists\")\n",
    "if Path(env.get_models_path()).exists(): raise FileExistsError(\"models_path already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b9J20CBLS8S9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models_directory returned is:  models/738\n"
     ]
    }
   ],
   "source": [
    "learn = None; gen = None; gc.collect()\n",
    "csv_logger = partial(ImmediateCSVLogger, filename= env.temp_csv_path + '/' + env.save_filename)\n",
    "gen = Gen(z_dim=z_dim)\n",
    "init_cnn(gen, True)\n",
    "\n",
    "if gen_arch == 'non-targeted':\n",
    "  metrics = [validation]\n",
    "elif gen_arch == 'targeted':\n",
    "  metrics = [validation, targeted_validation]\n",
    "    \n",
    "gen_learn = Learner(data, gen, loss_func = feat_loss,\n",
    "                    model_dir = env.get_learner_models_dir(),\n",
    "                    metrics=metrics, callback_fns=[DiversityMetric, LossMetrics, csv_logger])\n",
    "\n",
    "# learn = Learner(data, Gen(z_dim=10), loss_func = feat_loss, metrics=[validation], callback_fns=LossMetrics, opt_func = optim.SGD)\n",
    "# learn = Learner(data, Gen(z_dim=z_dim), loss_func = feat_loss, metrics=[validation], callback_fns=[LossMetrics, DiversityWeightsScheduler])\n",
    "\n",
    "# load_starting_point(learn, model.__name__, z_dim)\n",
    "# random_seed(42, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "0wOZYzOHDEdB",
    "outputId": "7436dbf1-33ad-4c5d-a652-73f10e59a024"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (9000 items)\n",
       "x: ImageList\n",
       "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
       "y: CategoryList\n",
       "n02643566,n02643566,n02643566,n02643566,n02643566\n",
       "Path: /home/mlcm-deep/AhmadPourihosseini/NAG/datasets/dataset;\n",
       "\n",
       "Valid: LabelList (1000 items)\n",
       "x: ImageList\n",
       "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
       "y: CategoryList\n",
       "n02643566,n02091244,n04367480,n03877472,n03710637\n",
       "Path: /home/mlcm-deep/AhmadPourihosseini/NAG/datasets/dataset;\n",
       "\n",
       "Test: None, model=Gen(\n",
       "  (z_): Linear(in_features=1000, out_features=10240, bias=True)\n",
       "  (BN_): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (CT2d_1): deconv_layer(\n",
       "    (CT2d): ConvTranspose2d(640, 448, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (BN2d): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (CT2d_2): deconv_layer(\n",
       "    (CT2d): ConvTranspose2d(448, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (BN2d): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (CT2d_3): deconv_layer(\n",
       "    (CT2d): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (BN2d): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (CT2d_4): deconv_layer(\n",
       "    (CT2d): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (BN2d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (CT2d_5): deconv_layer(\n",
       "    (CT2d): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (BN2d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (CT2d_6): deconv_layer(\n",
       "    (CT2d): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (BN2d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (CT2d_7): deconv_layer(\n",
       "    (CT2d): ConvTranspose2d(64, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (BN2d): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FeatureLoss(\n",
       "  (dis): SoftmaxWrapper(\n",
       "    (m): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "    )\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  )\n",
       "), metrics=[<function validation at 0x7f67406f2ea0>, <function targeted_validation at 0x7f672c2cb048>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/home/mlcm-deep/AhmadPourihosseini/NAG/datasets/dataset'), model_dir='models/738', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class '__main__.DiversityMetric'>, <class 'fastai.callbacks.loss_metrics.LossMetrics'>, functools.partial(<class 'nag_util.ImmediateCSVLogger'>, filename='/home/mlcm-deep/AhmadPourihosseini/NAG/temp/unet_resnet50_72_1')], callbacks=[], layer_groups=[Sequential(\n",
       "  (0): Linear(in_features=1000, out_features=10240, bias=True)\n",
       "  (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ConvTranspose2d(640, 448, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "  (3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): ConvTranspose2d(448, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (10): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (12): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (14): ConvTranspose2d(64, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (15): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !cp \"/content/gdrive/My Drive/DL/models/vgg16_12-last.pth\"  \"/content/\"\n",
    "# learn.load('/content/vgg16_12-last')\n",
    "\n",
    "# load_filename = 'resnet50-11_39'\n",
    "# load_filename = 'resnet50_startpoint_0'\n",
    "# load_filename = 'googlenet_13_attempt5/googlenet_13_attempt5_29'\n",
    "# load_filename = 'investigate_googlenet_4/1/googlenet_1'\n",
    "# load_filename = 'vgg16_30/vgg16_30_69'\n",
    "# load_filename = 'vgg16_12-last'\n",
    "# load_filename = 'googlenet_25_attempt2/googlenet_25_attempt2_399'\n",
    "# load_filename = 'googlenet_28_labelset1/googlenet_28_labelset1_59'\n",
    "# load_filename = 'googlenet_32/googlenet_32_99' # targ\n",
    "# load_filename = 'investigate_googlenet_5/1/googlenet_2'\n",
    "# load_filename = None\n",
    "\n",
    "# load_filename = 'googlenet_15/googlenet_15_89' # non-targ\n",
    "load_filename = 'resnet50_72/resnet50_72_99'\n",
    "# load_filename = 'vgg16_38/vgg16_38_99'\n",
    "\n",
    "gen_learn.load(env.get_models_dir() + '/' + load_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test/transform site:\n",
    "# gen_learn.validate(metrics=[validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_dataset(env: Env, trainOrValid: str, model: torch.nn.Module, dest_folder: str):\n",
    "  data = (ImageList.from_folder(env.data_path)\n",
    "          .split_by_folder(valid='valid')\n",
    "          .label_from_folder()\n",
    "          .transform(None, size=224, resize_method=ResizeMethod.SQUISH)\n",
    "          .databunch(bs=32, num_workers=1)\n",
    "          .normalize(imagenet_stats))\n",
    "\n",
    "  if trainOrValid == 'train':\n",
    "    dataloader = data.train_dl.new(shuffle=False)\n",
    "    items = data.train_ds.items\n",
    "  elif trainOrValid == 'valid':\n",
    "    dataloader = data.valid_dl\n",
    "    items = data.valid_ds.items\n",
    "  else:\n",
    "    raise ValueError('invalid value for trainOrValid')\n",
    "\n",
    "  for i in range(1000):\n",
    "    os.makedirs(\"{}/{}\".format(dest_folder, data.classes[i]))\n",
    "\n",
    "  model = model.eval()\n",
    "  # next_filename_per_label = [0] * 1000\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for i, (batch, target_labels) in enumerate(dataloader):\n",
    "      perturbation = model(batch)[0]\n",
    "      perturbed_batch = batch + perturbation\n",
    "      # The image is denormalized with imagenet stats from the range [-2.5, 2.5] to the range [0.,1.].\n",
    "      denormalized_batch = torch.clamp(nag_util.denormalize(perturbed_batch), 0., 1.)\n",
    "      for j, image_data in enumerate(denormalized_batch):\n",
    "        image =Image(image_data)\n",
    "        target_label = target_labels[j].item()\n",
    "        print(items[i * batch_size + j])\n",
    "        image.save(\"{}/{}/{}.png\".format(dest_folder, data.classes[target_label],\n",
    "                                         os.path.splitext(items[i * batch_size + j].parts[-1])[0]))\n",
    "        # image.save(\"{}/{}/{}.png\".format(dest_folder, data.classes[target_label], next_filename_per_label[target_label]))\n",
    "        # next_filename_per_label[target_label] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perturb_dataset(env, 'valid', gen_learn.model, '/home/mlcm-deep/AhmadPourihosseini/NAG/transformed_resnet50_valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 768
    },
    "colab_type": "code",
    "id": "0m6LtLWzuV9y",
    "outputId": "6f8ebffe-9167-48e8-d216-120c36db97ea",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models_directory returned is:  models/738\n"
     ]
    }
   ],
   "source": [
    "env.set_data_path('perturbed_resnet50_72')\n",
    "denoiser_learn = Learner(data, Denoiser(), loss_func = DenoiserLoss(), \n",
    "                        model_dir = env.get_learner_models_dir(),\n",
    "                        metrics=denoiser_validation, callback_fns = [LossMetrics, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FpkcsitGuV91"
   },
   "outputs": [],
   "source": [
    "# load_filename = 'unet_3xxx/unet_3xxx_4'\n",
    "# denoiser_learn.load(env.get_models_dir() + '/' + load_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "67ASjRfAuV95"
   },
   "outputs": [],
   "source": [
    "# class ArtWrapper(nn.Module):\n",
    "#   def __init__(self, wrap_around):\n",
    "#     super().__init__()\n",
    "#     self.wrap_around = wrap_around\n",
    "    \n",
    "#   def forward(self, inp):\n",
    "# #     print('passed input:', inp.shape)\n",
    "# #     print('converted: ', inp[None].shape)\n",
    "#     out = self.wrap_around(inp[None])\n",
    "# #     print('out shape: ', out[0].shape)\n",
    "#     final_out = arch(out[0]).squeeze()\n",
    "# #     print('final out shape: ', final_out.shape)\n",
    "#     return final_out\n",
    "\n",
    "# class BasicClassifierLoss(nn.Module):\n",
    "#   def __init__(self):\n",
    "#       super().__init__()\n",
    "    \n",
    "#   def forward(self, inp, target):\n",
    "# #     return -1 * torch.log(torch.gather(inp, 1, target.unsqueeze(0)))\n",
    "#     return -1 * torch.log(torch.gather(inp, 0, target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WQK3R_ibuV97",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from art import metrics\n",
    "# from art.classifiers import PyTorchClassifier\n",
    "\n",
    "# x =  denoiser_learn.data.train_ds[0][0].data.numpy()\n",
    "# y =  denoiser_learn.data.train_ds[0][1]\n",
    "# one_hot = [0.] * 1000\n",
    "# one_hot[363] = 1.\n",
    "# y = np.array(one_hot)\n",
    "# print(x.shape, y.shape)\n",
    "\n",
    "# wrapped_model = ArtWrapper(denoiser_learn.model)\n",
    "# # WARNING: omitting clip values\n",
    "# art_classifier = PyTorchClassifier(model = wrapped_model, loss = BasicClassifierLoss(), #feat_loss\n",
    "#                                    optimizer = denoiser_learn.opt, input_shape = x.shape,\n",
    "#                                    nb_classes = 1000)\n",
    "\n",
    "# # metrics.empirical_robustness(art_classifier, x, 'fgsm')\n",
    "# metrics.loss_sensitivity(art_classifier, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7wNKhI_quV9_"
   },
   "outputs": [],
   "source": [
    "# learn.lr_find(1e-6, 100)\n",
    "# learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2UGfpASmuV-K"
   },
   "outputs": [],
   "source": [
    "# results_dir = 'investigate_googlenet_4'\n",
    "# investigate_initial_settings(4, 2, lr = 1e-2, wd = 0.0, results_dir = results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yEUcLde8uV-P"
   },
   "outputs": [],
   "source": [
    "# shutil.rmtree(env.get_models_dir() + results_dir)\n",
    "# shutil.rmtree(env.get_csv_dir() + results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "0375tKI1uV-X",
    "outputId": "97d6f817-8c3c-4d6e-94ef-28e580def24d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the selected settings are : \n",
      "\tmode: normal \n",
      "\tnetw-under-attack: resnet50 \n",
      "\tload filename: resnet50_72/resnet50_72_99 \n",
      "      \tsave filename: unet_resnet50_72_1\n",
      "\tmetric names: ['fool_loss']\n",
      "\tgen arch: targeted\n",
      "\n",
      "please MAKE SURE that the config is correct.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  load_filename\n",
    "except NameError:\n",
    "  load_filename = None\n",
    "\n",
    "print(\"the selected settings are : \")\n",
    "print('''\\tmode: {} \\n\\tnetw-under-attack: {} \\n\\tload filename: {} \n",
    "      \\tsave filename: {}\\n\\tmetric names: {}\\n\\tgen arch: {}\\n'''.format(\n",
    "      mode, model.__name__, load_filename , env.save_filename, feat_loss.metric_names,\n",
    "      gen_arch\n",
    "))\n",
    "print(\"please MAKE SURE that the config is correct.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OHpw9RJkuV-d"
   },
   "outputs": [],
   "source": [
    "# learn.lr_find(1e-6, 100)\n",
    "# learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Bttj6lx7uV-g",
    "outputId": "a1380bcb-116d-42c5-b8b9-660325776041"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='5', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/5 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>denoiser_validation</th>\n",
       "      <th>denoiser_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='562', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-168fe4047187>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# callbacks.append(cyclical_sched)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdenoiser_learn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# with Hooks(gen, append_stats_normal) as hooks:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/ahmadph/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/ahmadph/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/ahmadph/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/ahmadph/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-119-8cec1d5cd4cb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, defended_classifier_output, target)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefended_classifier_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mrestored_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperturbations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefended_classifier_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mrestored_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestored_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestored_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "# RUN SITE\n",
    "if 'x' in env.save_filename and mode != 'sanity_check':\n",
    "  raise ValueError('save_filename contains x')\n",
    "\n",
    "saver_best = SaveModelCallback(denoiser_learn, every='improvement', monitor='validation', name=env.save_filename + \"-best\")\n",
    "saver_every_epoch = SaveModelCallback(denoiser_learn, every='epoch', name=env.save_filename)\n",
    "# fooling_weight_scheduler = FoolingWeightScheduler(learn)\n",
    "# lr_anneal = LRAnneal(learn, 1e-4)\n",
    "# file_ctrl = FileControl(learn, '/root/Derakhshani/adversarial/ctrl', learn.model)\n",
    "# cyclical_sched = CyclicalLRScheduler(learn, 3e-2, 6e-4, 4)\n",
    "\n",
    "callbacks = [saver_best, saver_every_epoch]\n",
    "# callbacks.append(lr_anneal)\n",
    "# callbacks.append(fooling_weight_scheduler)\n",
    "# callbacks.append(file_ctrl)\n",
    "# callbacks.append(cyclical_sched)\n",
    "\n",
    "denoiser_learn.fit(5, lr=1e-2, callbacks=callbacks)\n",
    "\n",
    "# with Hooks(gen, append_stats_normal) as hooks:\n",
    "#   learn.fit(1, lr=5e-03, wd = 0., callbacks=[saver_best, saver_every_epoch])\n",
    "\n",
    "# for i in range(10):\n",
    "#   learn.fit_one_cycle(7, wd = 0.,max_lr=1., div_factor = 1000.) \n",
    "\n",
    "shutil.copyfile(env.temp_csv_path + '/' + env.save_filename + \".csv\", env.get_csv_path() + '.csv')\n",
    "shutil.copytree(env.data_path/env.get_learner_models_dir(), env.get_models_path())\n",
    "shutil.rmtree(env.data_path/env.get_learner_models_dir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0KeEvBoXuV-k",
    "outputId": "96c51d41-9601-4c26-c25e-4bc440ea044f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "denoiser_learn.recorder.plot_losses()\n",
    "denoiser_learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "loqpojwPuV-r",
    "outputId": "e9a36e41-004f-4910-94c2-4d5b8971c391"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up folder:  googlenet_32\n",
      "files that will be kept are: ['googlenet_32_99.pth', 'googlenet_32-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  unet_1\n",
      "files that will be kept are: ['unet_1_4.pth', 'unet_1-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "new file in keep_file: 'unet_1-best.pth' doesnt exist. fix it and then press enter to continue.\n",
      "\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/16\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/19\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/15\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/3\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/2\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/5\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/1\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/13\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/0\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/4\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/10\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/18\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/9\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/12\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/14\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/8\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/6\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/11\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/7\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/17\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_vgg16_2/3\n",
      "no file found with the pattern \"model_name_index.pth\", ignoring the directory.\n",
      "cleaning up folder:  investigate_vgg16_2/2\n",
      "no file found with the pattern \"model_name_index.pth\", ignoring the directory.\n",
      "cleaning up folder:  investigate_vgg16_2/5\n",
      "no file found with the pattern \"model_name_index.pth\", ignoring the directory.\n",
      "cleaning up folder:  investigate_vgg16_2/1\n",
      "no file found with the pattern \"model_name_index.pth\", ignoring the directory.\n",
      "cleaning up folder:  investigate_vgg16_2/0\n",
      "no file found with the pattern \"model_name_index.pth\", ignoring the directory.\n",
      "cleaning up folder:  investigate_vgg16_2/4\n",
      "no file found with the pattern \"model_name_index.pth\", ignoring the directory.\n",
      "cleaning up folder:  investigate_vgg16_2/9\n",
      "no file found with the pattern \"model_name_index.pth\", ignoring the directory.\n",
      "cleaning up folder:  investigate_vgg16_2/8\n",
      "no file found with the pattern \"model_name_index.pth\", ignoring the directory.\n",
      "cleaning up folder:  investigate_vgg16_2/6\n",
      "no file found with the pattern \"model_name_index.pth\", ignoring the directory.\n",
      "cleaning up folder:  investigate_vgg16_2/7\n",
      "no file found with the pattern \"model_name_index.pth\", ignoring the directory.\n",
      "cleaning up folder:  googlenet_33\n",
      "files that will be kept are: ['googlenet_33_29.pth', 'googlenet_33-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_googlenet_5/3\n",
      "files that will be kept are: ['googlenet_2.pth', 'googlenet-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_googlenet_5/2\n",
      "files that will be kept are: ['googlenet_2.pth', 'googlenet-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_googlenet_5/5\n",
      "files that will be kept are: ['googlenet_2.pth', 'googlenet-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_googlenet_5/1\n",
      "files that will be kept are: ['googlenet_2.pth', 'googlenet-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_googlenet_5/0\n",
      "files that will be kept are: ['googlenet_2.pth', 'googlenet-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_googlenet_5/4\n",
      "files that will be kept are: ['googlenet_2.pth', 'googlenet-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_googlenet_5/9\n",
      "files that will be kept are: ['googlenet_2.pth', 'googlenet-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_googlenet_5/8\n",
      "files that will be kept are: ['googlenet_2.pth', 'googlenet-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_googlenet_5/6\n",
      "files that will be kept are: ['googlenet_2.pth', 'googlenet-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_googlenet_5/7\n",
      "files that will be kept are: ['googlenet_2.pth', 'googlenet-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  unet_2\n",
      "files that will be kept are: ['unet_2_4.pth', 'unet_2-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "new file in keep_file: 'unet_2-best.pth' doesnt exist. fix it and then press enter to continue.\n",
      "\n",
      "done.\n",
      "cleaning up folder:  resnet50_72\n",
      "files that will be kept are: ['resnet50_72_99.pth', 'resnet50_72-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      "done.\n",
      "cleaning up folder:  googlenet_34\n",
      "files that will be kept are: ['googlenet_34_29.pth', 'googlenet_34-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  vgg16_38\n",
      "files that will be kept are: ['vgg16_38_99.pth', 'vgg16_38-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "from cleanup import cleanup_models_folder\n",
    "cleanup_models_folder('/root/Derakhshani/adversarial/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VRbN4D5xuV-1"
   },
   "outputs": [],
   "source": [
    "#plot histogram\n",
    "fig, axes = plt.subplots(len(hooks),1, figsize=(30,12))\n",
    "for ax,h in zip(axes.flatten(), hooks):\n",
    "  ax.imshow(get_hist(h), origin='lower')\n",
    "  ax.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8iaI8Kk3uV-6"
   },
   "outputs": [],
   "source": [
    "# plot mean and std\n",
    "fig,(ax0,ax1) = plt.subplots(1,2, figsize=(10,4))\n",
    "for h in hooks:\n",
    "  ms, ss, _ = h.stats\n",
    "  ax0.plot(ms[:100])\n",
    "  ax1.plot(ss[:100])\n",
    "plt.legend(range(len(hooks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0yodfGr-uV-_"
   },
   "outputs": [],
   "source": [
    "fig,(ax0,ax1) = plt.subplots(1,2, figsize=(10,4))\n",
    "for h in hooks:\n",
    "  ms, ss, _ = h.stats\n",
    "  ax0.plot(ms)\n",
    "  ax1.plot(ss)\n",
    "plt.legend(range(len(hooks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c_DunxBouV_C"
   },
   "outputs": [],
   "source": [
    "# zero precentage:\n",
    "fig,axes = plt.subplots(len(hooks),1, figsize=(30,30))\n",
    "for ax,h in zip(axes.flatten(), hooks):\n",
    "    ax.plot(get_min(h))\n",
    "    ax.set_ylim(0,1)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MO2fZ-hSSUzJ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# z1 = torch.empty(10).uniform_(-1,1).cuda()\n",
    "# z2 = torch.empty(10).uniform_(-1,1).cuda()\n",
    "z1 = torch.tensor([0.8, -0.5] * 5).cuda()\n",
    "z2 = torch.tensor([-1.] * 10).cuda()\n",
    "print(\"z1: \", z1)\n",
    "print(\"z2: \", z2)\n",
    "print(\"distance: \", torch.norm(z1-z2,p=2))\n",
    "model = learn.model.eval()\n",
    "\n",
    "z_s = interpolate(z1, z2, 0.1)\n",
    "print(len(z_s))\n",
    "\n",
    "for i,z in enumerate(z_s):\n",
    "  img = noise_to_image(model.forward_single_z(z))\n",
    "  img.show()\n",
    "  #img.save('./pics/' + str(i) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DunkwbVVuV_I"
   },
   "outputs": [],
   "source": [
    "# idea : have 200 noises (1 for each class), then start iterating the dataset, and for each image, randomly apply one noise and record the result\n",
    "def targeted_diversity(learn, n_perturbations = 200, percentage = 95):\n",
    "  model = learn.model.eval()\n",
    "\n",
    "  one_hot_conditions = [torch.empty(z_dim).uniform_(0,1).cuda().detach() for _ in range(n_perturbations)]\n",
    "#   for i in range(z_dim):\n",
    "#     one_hot_conditions[i][i] = 1.\n",
    "\n",
    "  perturbations = [model.forward_single_z(z) for z in one_hot_conditions]\n",
    "\n",
    "  hist = [0.] * 1000\n",
    "  batch_no = -1\n",
    "  for batch, _ in learn.data.valid_dl:\n",
    "    batch_no += 1\n",
    "    if batch_no % 100 == 0 : print(\"at batch_no {}\".format(batch_no))\n",
    "    perturbed_batch = batch + perturbations[np.random.randint(0,len(perturbations))][None]\n",
    "    preds = arch(perturbed_batch).argmax(1)\n",
    "    for pred in preds:\n",
    "      hist[pred] += 1\n",
    "\n",
    "  pred_histogram_sum = np.sum(hist)\n",
    "  indexed_pred_histogram = [(i, hist_element) for i,hist_element in  \n",
    "                            enumerate(hist)]\n",
    "\n",
    "  indexed_pred_histogram.sort(key=lambda x: x[1], reverse = True)\n",
    "\n",
    "  cumulative_percent = 0\n",
    "  n_used_classes = 0\n",
    "  while cumulative_percent < percentage:\n",
    "    hist_elem = indexed_pred_histogram[n_used_classes]\n",
    "    cumulative_percent += (hist_elem[1] / pred_histogram_sum) * 100.\n",
    "    n_used_classes += 1\n",
    "\n",
    "  return n_used_classes, indexed_pred_histogram\n",
    "\n",
    "def targeted_diversity_average(learn, n_perturbations = 200, percentage = 95, average_over = 4):\n",
    "  results = []\n",
    "  for i in range(average_over):\n",
    "    n, _ = targeted_diversity(learn, n_perturbations, percentage)\n",
    "    print(f'done with the {i}th calculation: {n}')\n",
    "    results.append(n)\n",
    "  return np.mean(results)\n",
    "\n",
    "def diversity_average(learn, n_perturbations = 10, percentage = 95, average_over = 4):\n",
    "  results = []\n",
    "  for i in range(average_over):\n",
    "    n, _ = diversity(learn, n_perturbations, percentage, verbose = False)\n",
    "    print(f'done with the {i}th calculation: {n}')\n",
    "    results.append(n)\n",
    "  return np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8DDlxWkUuV_J",
    "outputId": "08883a1e-4f25-4560-caa7-3a442a45e3d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at batch no 0\n",
      "at batch no 5\n",
      "at batch no 10\n",
      "at batch no 15\n",
      "at batch no 20\n",
      "at batch no 25\n",
      "at batch no 30\n",
      "at batch no 35\n",
      "at batch no 40\n",
      "at batch no 45\n",
      "at batch no 50\n",
      "at batch no 55\n",
      "at batch no 60\n",
      "finished creating the prediction histogram\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(566,\n",
       " [(794, 50.099998474121094),\n",
       "  (599, 21.100000381469727),\n",
       "  (668, 20.200000762939453),\n",
       "  (904, 15.0),\n",
       "  (973, 13.600000381469727),\n",
       "  (490, 12.899999618530273),\n",
       "  (39, 12.699999809265137),\n",
       "  (770, 12.600000381469727),\n",
       "  (741, 11.300000190734863),\n",
       "  (828, 11.100000381469727),\n",
       "  (109, 9.199999809265137),\n",
       "  (556, 8.600000381469727),\n",
       "  (489, 8.399999618530273),\n",
       "  (955, 8.399999618530273),\n",
       "  (887, 8.300000190734863),\n",
       "  (669, 8.100000381469727),\n",
       "  (84, 7.400000095367432),\n",
       "  (855, 7.0),\n",
       "  (538, 6.800000190734863),\n",
       "  (108, 6.599999904632568),\n",
       "  (124, 6.0),\n",
       "  (397, 5.900000095367432),\n",
       "  (48, 5.800000190734863),\n",
       "  (61, 5.5),\n",
       "  (777, 4.900000095367432),\n",
       "  (721, 4.800000190734863),\n",
       "  (401, 4.5),\n",
       "  (971, 4.400000095367432),\n",
       "  (893, 4.300000190734863),\n",
       "  (857, 4.099999904632568),\n",
       "  (591, 4.0),\n",
       "  (711, 3.9000000953674316),\n",
       "  (709, 3.799999952316284),\n",
       "  (455, 3.700000047683716),\n",
       "  (55, 3.5999999046325684),\n",
       "  (414, 3.5),\n",
       "  (906, 3.5),\n",
       "  (151, 3.4000000953674316),\n",
       "  (389, 3.4000000953674316),\n",
       "  (406, 3.4000000953674316),\n",
       "  (865, 3.299999952316284),\n",
       "  (750, 3.200000047683716),\n",
       "  (581, 3.0),\n",
       "  (0, 2.9000000953674316),\n",
       "  (1, 2.9000000953674316),\n",
       "  (476, 2.9000000953674316),\n",
       "  (915, 2.9000000953674316),\n",
       "  (363, 2.799999952316284),\n",
       "  (837, 2.799999952316284),\n",
       "  (982, 2.799999952316284),\n",
       "  (110, 2.700000047683716),\n",
       "  (46, 2.5999999046325684),\n",
       "  (62, 2.5999999046325684),\n",
       "  (593, 2.5999999046325684),\n",
       "  (640, 2.5999999046325684),\n",
       "  (735, 2.5999999046325684),\n",
       "  (819, 2.5999999046325684),\n",
       "  (94, 2.5),\n",
       "  (126, 2.5),\n",
       "  (431, 2.5),\n",
       "  (611, 2.4000000953674316),\n",
       "  (864, 2.4000000953674316),\n",
       "  (868, 2.4000000953674316),\n",
       "  (222, 2.299999952316284),\n",
       "  (558, 2.299999952316284),\n",
       "  (572, 2.299999952316284),\n",
       "  (850, 2.299999952316284),\n",
       "  (115, 2.200000047683716),\n",
       "  (410, 2.200000047683716),\n",
       "  (698, 2.200000047683716),\n",
       "  (763, 2.200000047683716),\n",
       "  (772, 2.200000047683716),\n",
       "  (779, 2.200000047683716),\n",
       "  (97, 2.0999999046325684),\n",
       "  (238, 2.0999999046325684),\n",
       "  (440, 2.0999999046325684),\n",
       "  (447, 2.0999999046325684),\n",
       "  (464, 2.0999999046325684),\n",
       "  (872, 2.0999999046325684),\n",
       "  (898, 2.0999999046325684),\n",
       "  (68, 2.0),\n",
       "  (118, 2.0),\n",
       "  (182, 2.0),\n",
       "  (242, 2.0),\n",
       "  (292, 2.0),\n",
       "  (393, 2.0),\n",
       "  (520, 2.0),\n",
       "  (621, 2.0),\n",
       "  (60, 1.899999976158142),\n",
       "  (188, 1.899999976158142),\n",
       "  (189, 1.899999976158142),\n",
       "  (192, 1.899999976158142),\n",
       "  (342, 1.899999976158142),\n",
       "  (411, 1.899999976158142),\n",
       "  (472, 1.899999976158142),\n",
       "  (570, 1.899999976158142),\n",
       "  (619, 1.899999976158142),\n",
       "  (620, 1.899999976158142),\n",
       "  (724, 1.899999976158142),\n",
       "  (791, 1.899999976158142),\n",
       "  (800, 1.899999976158142),\n",
       "  (199, 1.7999999523162842),\n",
       "  (290, 1.7999999523162842),\n",
       "  (348, 1.7999999523162842),\n",
       "  (423, 1.7999999523162842),\n",
       "  (761, 1.7999999523162842),\n",
       "  (762, 1.7999999523162842),\n",
       "  (870, 1.7999999523162842),\n",
       "  (920, 1.7999999523162842),\n",
       "  (72, 1.7000000476837158),\n",
       "  (128, 1.7000000476837158),\n",
       "  (155, 1.7000000476837158),\n",
       "  (195, 1.7000000476837158),\n",
       "  (334, 1.7000000476837158),\n",
       "  (526, 1.7000000476837158),\n",
       "  (547, 1.7000000476837158),\n",
       "  (671, 1.7000000476837158),\n",
       "  (725, 1.7000000476837158),\n",
       "  (775, 1.7000000476837158),\n",
       "  (783, 1.7000000476837158),\n",
       "  (824, 1.7000000476837158),\n",
       "  (871, 1.7000000476837158),\n",
       "  (123, 1.600000023841858),\n",
       "  (375, 1.600000023841858),\n",
       "  (457, 1.600000023841858),\n",
       "  (468, 1.600000023841858),\n",
       "  (492, 1.600000023841858),\n",
       "  (508, 1.600000023841858),\n",
       "  (550, 1.600000023841858),\n",
       "  (562, 1.600000023841858),\n",
       "  (803, 1.600000023841858),\n",
       "  (817, 1.600000023841858),\n",
       "  (953, 1.600000023841858),\n",
       "  (963, 1.600000023841858),\n",
       "  (107, 1.5),\n",
       "  (119, 1.5),\n",
       "  (202, 1.5),\n",
       "  (230, 1.5),\n",
       "  (420, 1.5),\n",
       "  (477, 1.5),\n",
       "  (564, 1.5),\n",
       "  (748, 1.5),\n",
       "  (815, 1.5),\n",
       "  (907, 1.5),\n",
       "  (76, 1.399999976158142),\n",
       "  (83, 1.399999976158142),\n",
       "  (193, 1.399999976158142),\n",
       "  (231, 1.399999976158142),\n",
       "  (274, 1.399999976158142),\n",
       "  (293, 1.399999976158142),\n",
       "  (305, 1.399999976158142),\n",
       "  (314, 1.399999976158142),\n",
       "  (336, 1.399999976158142),\n",
       "  (552, 1.399999976158142),\n",
       "  (565, 1.399999976158142),\n",
       "  (579, 1.399999976158142),\n",
       "  (597, 1.399999976158142),\n",
       "  (624, 1.399999976158142),\n",
       "  (679, 1.399999976158142),\n",
       "  (784, 1.399999976158142),\n",
       "  (786, 1.399999976158142),\n",
       "  (801, 1.399999976158142),\n",
       "  (891, 1.399999976158142),\n",
       "  (902, 1.399999976158142),\n",
       "  (33, 1.2999999523162842),\n",
       "  (57, 1.2999999523162842),\n",
       "  (96, 1.2999999523162842),\n",
       "  (120, 1.2999999523162842),\n",
       "  (247, 1.2999999523162842),\n",
       "  (275, 1.2999999523162842),\n",
       "  (328, 1.2999999523162842),\n",
       "  (355, 1.2999999523162842),\n",
       "  (409, 1.2999999523162842),\n",
       "  (441, 1.2999999523162842),\n",
       "  (505, 1.2999999523162842),\n",
       "  (586, 1.2999999523162842),\n",
       "  (588, 1.2999999523162842),\n",
       "  (633, 1.2999999523162842),\n",
       "  (638, 1.2999999523162842),\n",
       "  (821, 1.2999999523162842),\n",
       "  (842, 1.2999999523162842),\n",
       "  (892, 1.2999999523162842),\n",
       "  (58, 1.2000000476837158),\n",
       "  (65, 1.2000000476837158),\n",
       "  (171, 1.2000000476837158),\n",
       "  (204, 1.2000000476837158),\n",
       "  (205, 1.2000000476837158),\n",
       "  (219, 1.2000000476837158),\n",
       "  (307, 1.2000000476837158),\n",
       "  (308, 1.2000000476837158),\n",
       "  (327, 1.2000000476837158),\n",
       "  (331, 1.2000000476837158),\n",
       "  (353, 1.2000000476837158),\n",
       "  (366, 1.2000000476837158),\n",
       "  (443, 1.2000000476837158),\n",
       "  (454, 1.2000000476837158),\n",
       "  (474, 1.2000000476837158),\n",
       "  (495, 1.2000000476837158),\n",
       "  (563, 1.2000000476837158),\n",
       "  (574, 1.2000000476837158),\n",
       "  (602, 1.2000000476837158),\n",
       "  (641, 1.2000000476837158),\n",
       "  (654, 1.2000000476837158),\n",
       "  (658, 1.2000000476837158),\n",
       "  (781, 1.2000000476837158),\n",
       "  (823, 1.2000000476837158),\n",
       "  (848, 1.2000000476837158),\n",
       "  (854, 1.2000000476837158),\n",
       "  (858, 1.2000000476837158),\n",
       "  (883, 1.2000000476837158),\n",
       "  (24, 1.100000023841858),\n",
       "  (41, 1.100000023841858),\n",
       "  (51, 1.100000023841858),\n",
       "  (113, 1.100000023841858),\n",
       "  (116, 1.100000023841858),\n",
       "  (236, 1.100000023841858),\n",
       "  (249, 1.100000023841858),\n",
       "  (253, 1.100000023841858),\n",
       "  (271, 1.100000023841858),\n",
       "  (281, 1.100000023841858),\n",
       "  (300, 1.100000023841858),\n",
       "  (310, 1.100000023841858),\n",
       "  (317, 1.100000023841858),\n",
       "  (318, 1.100000023841858),\n",
       "  (319, 1.100000023841858),\n",
       "  (350, 1.100000023841858),\n",
       "  (381, 1.100000023841858),\n",
       "  (395, 1.100000023841858),\n",
       "  (396, 1.100000023841858),\n",
       "  (491, 1.100000023841858),\n",
       "  (496, 1.100000023841858),\n",
       "  (497, 1.100000023841858),\n",
       "  (506, 1.100000023841858),\n",
       "  (507, 1.100000023841858),\n",
       "  (527, 1.100000023841858),\n",
       "  (544, 1.100000023841858),\n",
       "  (575, 1.100000023841858),\n",
       "  (609, 1.100000023841858),\n",
       "  (626, 1.100000023841858),\n",
       "  (759, 1.100000023841858),\n",
       "  (787, 1.100000023841858),\n",
       "  (796, 1.100000023841858),\n",
       "  (806, 1.100000023841858),\n",
       "  (820, 1.100000023841858),\n",
       "  (834, 1.100000023841858),\n",
       "  (863, 1.100000023841858),\n",
       "  (882, 1.100000023841858),\n",
       "  (894, 1.100000023841858),\n",
       "  (918, 1.100000023841858),\n",
       "  (981, 1.100000023841858),\n",
       "  (996, 1.100000023841858),\n",
       "  (7, 1.0),\n",
       "  (8, 1.0),\n",
       "  (10, 1.0),\n",
       "  (15, 1.0),\n",
       "  (17, 1.0),\n",
       "  (19, 1.0),\n",
       "  (25, 1.0),\n",
       "  (28, 1.0),\n",
       "  (37, 1.0),\n",
       "  (42, 1.0),\n",
       "  (45, 1.0),\n",
       "  (49, 1.0),\n",
       "  (52, 1.0),\n",
       "  (53, 1.0),\n",
       "  (63, 1.0),\n",
       "  (70, 1.0),\n",
       "  (75, 1.0),\n",
       "  (79, 1.0),\n",
       "  (86, 1.0),\n",
       "  (87, 1.0),\n",
       "  (90, 1.0),\n",
       "  (91, 1.0),\n",
       "  (92, 1.0),\n",
       "  (98, 1.0),\n",
       "  (102, 1.0),\n",
       "  (105, 1.0),\n",
       "  (117, 1.0),\n",
       "  (134, 1.0),\n",
       "  (139, 1.0),\n",
       "  (140, 1.0),\n",
       "  (141, 1.0),\n",
       "  (144, 1.0),\n",
       "  (158, 1.0),\n",
       "  (161, 1.0),\n",
       "  (162, 1.0),\n",
       "  (163, 1.0),\n",
       "  (164, 1.0),\n",
       "  (173, 1.0),\n",
       "  (183, 1.0),\n",
       "  (186, 1.0),\n",
       "  (196, 1.0),\n",
       "  (197, 1.0),\n",
       "  (198, 1.0),\n",
       "  (206, 1.0),\n",
       "  (213, 1.0),\n",
       "  (218, 1.0),\n",
       "  (228, 1.0),\n",
       "  (235, 1.0),\n",
       "  (260, 1.0),\n",
       "  (273, 1.0),\n",
       "  (284, 1.0),\n",
       "  (289, 1.0),\n",
       "  (291, 1.0),\n",
       "  (301, 1.0),\n",
       "  (304, 1.0),\n",
       "  (306, 1.0),\n",
       "  (312, 1.0),\n",
       "  (313, 1.0),\n",
       "  (316, 1.0),\n",
       "  (321, 1.0),\n",
       "  (323, 1.0),\n",
       "  (337, 1.0),\n",
       "  (347, 1.0),\n",
       "  (360, 1.0),\n",
       "  (376, 1.0),\n",
       "  (378, 1.0),\n",
       "  (387, 1.0),\n",
       "  (392, 1.0),\n",
       "  (398, 1.0),\n",
       "  (417, 1.0),\n",
       "  (425, 1.0),\n",
       "  (428, 1.0),\n",
       "  (429, 1.0),\n",
       "  (433, 1.0),\n",
       "  (445, 1.0),\n",
       "  (451, 1.0),\n",
       "  (483, 1.0),\n",
       "  (488, 1.0),\n",
       "  (498, 1.0),\n",
       "  (518, 1.0),\n",
       "  (528, 1.0),\n",
       "  (530, 1.0),\n",
       "  (531, 1.0),\n",
       "  (533, 1.0),\n",
       "  (566, 1.0),\n",
       "  (580, 1.0),\n",
       "  (608, 1.0),\n",
       "  (612, 1.0),\n",
       "  (616, 1.0),\n",
       "  (625, 1.0),\n",
       "  (629, 1.0),\n",
       "  (637, 1.0),\n",
       "  (645, 1.0),\n",
       "  (646, 1.0),\n",
       "  (651, 1.0),\n",
       "  (655, 1.0),\n",
       "  (661, 1.0),\n",
       "  (684, 1.0),\n",
       "  (687, 1.0),\n",
       "  (691, 1.0),\n",
       "  (692, 1.0),\n",
       "  (694, 1.0),\n",
       "  (716, 1.0),\n",
       "  (719, 1.0),\n",
       "  (734, 1.0),\n",
       "  (738, 1.0),\n",
       "  (746, 1.0),\n",
       "  (753, 1.0),\n",
       "  (768, 1.0),\n",
       "  (793, 1.0),\n",
       "  (802, 1.0),\n",
       "  (816, 1.0),\n",
       "  (826, 1.0),\n",
       "  (830, 1.0),\n",
       "  (831, 1.0),\n",
       "  (847, 1.0),\n",
       "  (873, 1.0),\n",
       "  (884, 1.0),\n",
       "  (905, 1.0),\n",
       "  (923, 1.0),\n",
       "  (932, 1.0),\n",
       "  (934, 1.0),\n",
       "  (937, 1.0),\n",
       "  (939, 1.0),\n",
       "  (944, 1.0),\n",
       "  (946, 1.0),\n",
       "  (957, 1.0),\n",
       "  (959, 1.0),\n",
       "  (984, 1.0),\n",
       "  (985, 1.0),\n",
       "  (987, 1.0),\n",
       "  (989, 1.0),\n",
       "  (992, 1.0),\n",
       "  (9, 0.8999999761581421),\n",
       "  (18, 0.8999999761581421),\n",
       "  (21, 0.8999999761581421),\n",
       "  (36, 0.8999999761581421),\n",
       "  (47, 0.8999999761581421),\n",
       "  (85, 0.8999999761581421),\n",
       "  (135, 0.8999999761581421),\n",
       "  (142, 0.8999999761581421),\n",
       "  (145, 0.8999999761581421),\n",
       "  (176, 0.8999999761581421),\n",
       "  (187, 0.8999999761581421),\n",
       "  (263, 0.8999999761581421),\n",
       "  (266, 0.8999999761581421),\n",
       "  (303, 0.8999999761581421),\n",
       "  (315, 0.8999999761581421),\n",
       "  (326, 0.8999999761581421),\n",
       "  (365, 0.8999999761581421),\n",
       "  (384, 0.8999999761581421),\n",
       "  (390, 0.8999999761581421),\n",
       "  (391, 0.8999999761581421),\n",
       "  (408, 0.8999999761581421),\n",
       "  (459, 0.8999999761581421),\n",
       "  (463, 0.8999999761581421),\n",
       "  (482, 0.8999999761581421),\n",
       "  (503, 0.8999999761581421),\n",
       "  (534, 0.8999999761581421),\n",
       "  (535, 0.8999999761581421),\n",
       "  (555, 0.8999999761581421),\n",
       "  (577, 0.8999999761581421),\n",
       "  (635, 0.8999999761581421),\n",
       "  (663, 0.8999999761581421),\n",
       "  (674, 0.8999999761581421),\n",
       "  (702, 0.8999999761581421),\n",
       "  (703, 0.8999999761581421),\n",
       "  (712, 0.8999999761581421),\n",
       "  (743, 0.8999999761581421),\n",
       "  (757, 0.8999999761581421),\n",
       "  (764, 0.8999999761581421),\n",
       "  (776, 0.8999999761581421),\n",
       "  (788, 0.8999999761581421),\n",
       "  (808, 0.8999999761581421),\n",
       "  (832, 0.8999999761581421),\n",
       "  (833, 0.8999999761581421),\n",
       "  (900, 0.8999999761581421),\n",
       "  (968, 0.8999999761581421),\n",
       "  (988, 0.8999999761581421),\n",
       "  (997, 0.8999999761581421),\n",
       "  (38, 0.800000011920929),\n",
       "  (77, 0.800000011920929),\n",
       "  (93, 0.800000011920929),\n",
       "  (100, 0.800000011920929),\n",
       "  (160, 0.800000011920929),\n",
       "  (246, 0.800000011920929),\n",
       "  (254, 0.800000011920929),\n",
       "  (280, 0.800000011920929),\n",
       "  (294, 0.800000011920929),\n",
       "  (344, 0.800000011920929),\n",
       "  (372, 0.800000011920929),\n",
       "  (377, 0.800000011920929),\n",
       "  (399, 0.800000011920929),\n",
       "  (407, 0.800000011920929),\n",
       "  (415, 0.800000011920929),\n",
       "  (430, 0.800000011920929),\n",
       "  (432, 0.800000011920929),\n",
       "  (439, 0.800000011920929),\n",
       "  (458, 0.800000011920929),\n",
       "  (514, 0.800000011920929),\n",
       "  (545, 0.800000011920929),\n",
       "  (546, 0.800000011920929),\n",
       "  (595, 0.800000011920929),\n",
       "  (603, 0.800000011920929),\n",
       "  (643, 0.800000011920929),\n",
       "  (644, 0.800000011920929),\n",
       "  (672, 0.800000011920929),\n",
       "  (696, 0.800000011920929),\n",
       "  (729, 0.800000011920929),\n",
       "  (732, 0.800000011920929),\n",
       "  (809, 0.800000011920929),\n",
       "  (822, 0.800000011920929),\n",
       "  (829, 0.800000011920929),\n",
       "  (838, 0.800000011920929),\n",
       "  (843, 0.800000011920929),\n",
       "  (852, 0.800000011920929),\n",
       "  (885, 0.800000011920929),\n",
       "  (889, 0.800000011920929),\n",
       "  (901, 0.800000011920929),\n",
       "  (956, 0.800000011920929),\n",
       "  (34, 0.699999988079071),\n",
       "  (50, 0.699999988079071),\n",
       "  (99, 0.699999988079071),\n",
       "  (112, 0.699999988079071),\n",
       "  (168, 0.699999988079071),\n",
       "  (184, 0.699999988079071),\n",
       "  (214, 0.699999988079071),\n",
       "  (216, 0.699999988079071),\n",
       "  (217, 0.699999988079071),\n",
       "  (232, 0.699999988079071),\n",
       "  (270, 0.699999988079071),\n",
       "  (320, 0.699999988079071),\n",
       "  (330, 0.699999988079071),\n",
       "  (335, 0.699999988079071),\n",
       "  (345, 0.699999988079071),\n",
       "  (361, 0.699999988079071),\n",
       "  (388, 0.699999988079071),\n",
       "  (412, 0.699999988079071),\n",
       "  (512, 0.699999988079071),\n",
       "  (561, 0.699999988079071),\n",
       "  (576, 0.699999988079071),\n",
       "  (632, 0.699999988079071),\n",
       "  (695, 0.699999988079071),\n",
       "  (805, 0.699999988079071),\n",
       "  (879, 0.699999988079071),\n",
       "  (886, 0.699999988079071),\n",
       "  (952, 0.699999988079071),\n",
       "  (32, 0.6000000238418579),\n",
       "  (88, 0.6000000238418579),\n",
       "  (146, 0.6000000238418579),\n",
       "  (148, 0.6000000238418579),\n",
       "  (209, 0.6000000238418579),\n",
       "  (211, 0.6000000238418579),\n",
       "  (322, 0.6000000238418579),\n",
       "  (340, 0.6000000238418579),\n",
       "  (343, 0.6000000238418579),\n",
       "  (442, 0.6000000238418579),\n",
       "  (450, 0.6000000238418579),\n",
       "  (470, 0.6000000238418579),\n",
       "  (532, 0.6000000238418579),\n",
       "  (539, 0.6000000238418579),\n",
       "  (554, 0.6000000238418579),\n",
       "  (560, 0.6000000238418579),\n",
       "  (571, 0.6000000238418579),\n",
       "  (584, 0.6000000238418579),\n",
       "  (589, 0.6000000238418579),\n",
       "  (656, 0.6000000238418579),\n",
       "  (699, 0.6000000238418579),\n",
       "  (736, 0.6000000238418579),\n",
       "  (754, 0.6000000238418579),\n",
       "  (758, 0.6000000238418579),\n",
       "  (765, 0.6000000238418579),\n",
       "  (790, 0.6000000238418579),\n",
       "  (888, 0.6000000238418579),\n",
       "  (890, 0.6000000238418579),\n",
       "  (972, 0.6000000238418579),\n",
       "  (979, 0.6000000238418579),\n",
       "  (12, 0.5),\n",
       "  (16, 0.5),\n",
       "  (22, 0.5),\n",
       "  (143, 0.5),\n",
       "  (157, 0.5),\n",
       "  (166, 0.5),\n",
       "  (203, 0.5),\n",
       "  (212, 0.5),\n",
       "  (221, 0.5),\n",
       "  (224, 0.5),\n",
       "  (229, 0.5),\n",
       "  (234, 0.5),\n",
       "  (237, 0.5),\n",
       "  (252, 0.5),\n",
       "  (276, 0.5),\n",
       "  (282, 0.5),\n",
       "  (288, 0.5),\n",
       "  (295, 0.5),\n",
       "  (296, 0.5),\n",
       "  (309, 0.5),\n",
       "  (329, 0.5),\n",
       "  (402, 0.5),\n",
       "  (413, 0.5),\n",
       "  (436, 0.5),\n",
       "  (444, 0.5),\n",
       "  (448, 0.5),\n",
       "  (471, 0.5),\n",
       "  (540, 0.5),\n",
       "  (604, 0.5),\n",
       "  (639, 0.5),\n",
       "  (647, 0.5),\n",
       "  (683, 0.5),\n",
       "  (697, 0.5),\n",
       "  (715, 0.5),\n",
       "  (752, 0.5),\n",
       "  (755, 0.5),\n",
       "  (795, 0.5),\n",
       "  (811, 0.5),\n",
       "  (839, 0.5),\n",
       "  (853, 0.5),\n",
       "  (862, 0.5),\n",
       "  (877, 0.5),\n",
       "  (897, 0.5),\n",
       "  (910, 0.5),\n",
       "  (911, 0.5),\n",
       "  (927, 0.5),\n",
       "  (977, 0.5),\n",
       "  (20, 0.4000000059604645),\n",
       "  (29, 0.4000000059604645),\n",
       "  (69, 0.4000000059604645),\n",
       "  (122, 0.4000000059604645),\n",
       "  (125, 0.4000000059604645),\n",
       "  (130, 0.4000000059604645),\n",
       "  (132, 0.4000000059604645),\n",
       "  (178, 0.4000000059604645),\n",
       "  (180, 0.4000000059604645),\n",
       "  (256, 0.4000000059604645),\n",
       "  (264, 0.4000000059604645),\n",
       "  (298, 0.4000000059604645),\n",
       "  (370, 0.4000000059604645),\n",
       "  (419, 0.4000000059604645),\n",
       "  (424, 0.4000000059604645),\n",
       "  (480, 0.4000000059604645),\n",
       "  (484, 0.4000000059604645),\n",
       "  (509, 0.4000000059604645),\n",
       "  (511, 0.4000000059604645),\n",
       "  (537, 0.4000000059604645),\n",
       "  (582, 0.4000000059604645),\n",
       "  (587, 0.4000000059604645),\n",
       "  (590, 0.4000000059604645),\n",
       "  (606, 0.4000000059604645),\n",
       "  (615, 0.4000000059604645),\n",
       "  (652, 0.4000000059604645),\n",
       "  (670, 0.4000000059604645),\n",
       "  (689, 0.4000000059604645),\n",
       "  (700, 0.4000000059604645),\n",
       "  (707, 0.4000000059604645),\n",
       "  (720, 0.4000000059604645),\n",
       "  (727, 0.4000000059604645),\n",
       "  (745, 0.4000000059604645),\n",
       "  (804, 0.4000000059604645),\n",
       "  (844, 0.4000000059604645),\n",
       "  (866, 0.4000000059604645),\n",
       "  (878, 0.4000000059604645),\n",
       "  (881, 0.4000000059604645),\n",
       "  (896, 0.4000000059604645),\n",
       "  (925, 0.4000000059604645),\n",
       "  (2, 0.30000001192092896),\n",
       "  (5, 0.30000001192092896),\n",
       "  (74, 0.30000001192092896),\n",
       "  (78, 0.30000001192092896),\n",
       "  (81, 0.30000001192092896),\n",
       "  (89, 0.30000001192092896),\n",
       "  (101, 0.30000001192092896),\n",
       "  (136, 0.30000001192092896),\n",
       "  (138, 0.30000001192092896),\n",
       "  (169, 0.30000001192092896),\n",
       "  (190, 0.30000001192092896),\n",
       "  (207, 0.30000001192092896),\n",
       "  (208, 0.30000001192092896),\n",
       "  (215, 0.30000001192092896),\n",
       "  (243, 0.30000001192092896),\n",
       "  (250, 0.30000001192092896),\n",
       "  (285, 0.30000001192092896),\n",
       "  (286, 0.30000001192092896),\n",
       "  (302, 0.30000001192092896),\n",
       "  (332, 0.30000001192092896),\n",
       "  (341, 0.30000001192092896),\n",
       "  (357, 0.30000001192092896),\n",
       "  (364, 0.30000001192092896),\n",
       "  (369, 0.30000001192092896),\n",
       "  (386, 0.30000001192092896),\n",
       "  (403, 0.30000001192092896),\n",
       "  (438, 0.30000001192092896),\n",
       "  (456, 0.30000001192092896),\n",
       "  (461, 0.30000001192092896),\n",
       "  (487, 0.30000001192092896),\n",
       "  (523, 0.30000001192092896),\n",
       "  (541, 0.30000001192092896),\n",
       "  (542, 0.30000001192092896),\n",
       "  (607, 0.30000001192092896),\n",
       "  (613, 0.30000001192092896),\n",
       "  (636, 0.30000001192092896),\n",
       "  (650, 0.30000001192092896),\n",
       "  (704, 0.30000001192092896),\n",
       "  (740, 0.30000001192092896),\n",
       "  (818, 0.30000001192092896),\n",
       "  (867, 0.30000001192092896),\n",
       "  (6, 0.20000000298023224),\n",
       "  (11, 0.20000000298023224),\n",
       "  (14, 0.20000000298023224),\n",
       "  (23, 0.20000000298023224),\n",
       "  (35, 0.20000000298023224),\n",
       "  (40, 0.20000000298023224),\n",
       "  (44, 0.20000000298023224),\n",
       "  (56, 0.20000000298023224),\n",
       "  (71, 0.20000000298023224),\n",
       "  (114, 0.20000000298023224),\n",
       "  (159, 0.20000000298023224),\n",
       "  (201, 0.20000000298023224),\n",
       "  (223, 0.20000000298023224),\n",
       "  (241, 0.20000000298023224),\n",
       "  (248, 0.20000000298023224),\n",
       "  (261, 0.20000000298023224),\n",
       "  (265, 0.20000000298023224),\n",
       "  (269, 0.20000000298023224),\n",
       "  (272, 0.20000000298023224),\n",
       "  (352, 0.20000000298023224),\n",
       "  (394, 0.20000000298023224),\n",
       "  (453, 0.20000000298023224),\n",
       "  (486, 0.20000000298023224),\n",
       "  (502, 0.20000000298023224),\n",
       "  (513, 0.20000000298023224),\n",
       "  (516, 0.20000000298023224),\n",
       "  (524, 0.20000000298023224),\n",
       "  (529, 0.20000000298023224),\n",
       "  (567, 0.20000000298023224),\n",
       "  (592, 0.20000000298023224),\n",
       "  (601, 0.20000000298023224),\n",
       "  (614, 0.20000000298023224),\n",
       "  (634, 0.20000000298023224),\n",
       "  (642, 0.20000000298023224),\n",
       "  (649, 0.20000000298023224),\n",
       "  (662, 0.20000000298023224),\n",
       "  (664, 0.20000000298023224),\n",
       "  (667, 0.20000000298023224),\n",
       "  (678, 0.20000000298023224),\n",
       "  (680, 0.20000000298023224),\n",
       "  (688, 0.20000000298023224),\n",
       "  (706, 0.20000000298023224),\n",
       "  (751, 0.20000000298023224),\n",
       "  (766, 0.20000000298023224),\n",
       "  (773, 0.20000000298023224),\n",
       "  (799, 0.20000000298023224),\n",
       "  (827, 0.20000000298023224),\n",
       "  (859, 0.20000000298023224),\n",
       "  (962, 0.20000000298023224),\n",
       "  (976, 0.20000000298023224),\n",
       "  (978, 0.20000000298023224),\n",
       "  (994, 0.20000000298023224),\n",
       "  (4, 0.10000000149011612),\n",
       "  (31, 0.10000000149011612),\n",
       "  (67, 0.10000000149011612),\n",
       "  (95, 0.10000000149011612),\n",
       "  (121, 0.10000000149011612),\n",
       "  (150, 0.10000000149011612),\n",
       "  (170, 0.10000000149011612),\n",
       "  (181, 0.10000000149011612),\n",
       "  (226, 0.10000000149011612),\n",
       "  (227, 0.10000000149011612),\n",
       "  (245, 0.10000000149011612),\n",
       "  (257, 0.10000000149011612),\n",
       "  (259, 0.10000000149011612),\n",
       "  (267, 0.10000000149011612),\n",
       "  (279, 0.10000000149011612),\n",
       "  (297, 0.10000000149011612),\n",
       "  (311, 0.10000000149011612),\n",
       "  (324, 0.10000000149011612),\n",
       "  (354, 0.10000000149011612),\n",
       "  (358, 0.10000000149011612),\n",
       "  (359, 0.10000000149011612),\n",
       "  (362, 0.10000000149011612),\n",
       "  (379, 0.10000000149011612),\n",
       "  (380, 0.10000000149011612),\n",
       "  (382, 0.10000000149011612),\n",
       "  (383, 0.10000000149011612),\n",
       "  (385, 0.10000000149011612),\n",
       "  (400, 0.10000000149011612),\n",
       "  (422, 0.10000000149011612),\n",
       "  (434, 0.10000000149011612),\n",
       "  (452, 0.10000000149011612),\n",
       "  (501, 0.10000000149011612),\n",
       "  (517, 0.10000000149011612),\n",
       "  (568, 0.10000000149011612),\n",
       "  (578, 0.10000000149011612),\n",
       "  (585, 0.10000000149011612),\n",
       "  (605, 0.10000000149011612),\n",
       "  (618, 0.10000000149011612),\n",
       "  (628, 0.10000000149011612),\n",
       "  (657, 0.10000000149011612),\n",
       "  (665, 0.10000000149011612),\n",
       "  (676, 0.10000000149011612),\n",
       "  (685, 0.10000000149011612),\n",
       "  (690, 0.10000000149011612),\n",
       "  (701, 0.10000000149011612),\n",
       "  (710, 0.10000000149011612),\n",
       "  (749, 0.10000000149011612),\n",
       "  (771, 0.10000000149011612),\n",
       "  (774, 0.10000000149011612),\n",
       "  (778, 0.10000000149011612),\n",
       "  (782, 0.10000000149011612),\n",
       "  (797, 0.10000000149011612),\n",
       "  (814, 0.10000000149011612),\n",
       "  (825, 0.10000000149011612),\n",
       "  (849, 0.10000000149011612),\n",
       "  (869, 0.10000000149011612),\n",
       "  (874, 0.10000000149011612),\n",
       "  (875, 0.10000000149011612),\n",
       "  (903, 0.10000000149011612),\n",
       "  (919, 0.10000000149011612),\n",
       "  (921, 0.10000000149011612),\n",
       "  (933, 0.10000000149011612),\n",
       "  (938, 0.10000000149011612),\n",
       "  (943, 0.10000000149011612),\n",
       "  (949, 0.10000000149011612),\n",
       "  (983, 0.10000000149011612),\n",
       "  (990, 0.10000000149011612),\n",
       "  (3, 0.0),\n",
       "  (13, 0.0),\n",
       "  (26, 0.0),\n",
       "  (27, 0.0),\n",
       "  (30, 0.0),\n",
       "  (43, 0.0),\n",
       "  (54, 0.0),\n",
       "  (59, 0.0),\n",
       "  (64, 0.0),\n",
       "  (66, 0.0),\n",
       "  (73, 0.0),\n",
       "  (80, 0.0),\n",
       "  (82, 0.0),\n",
       "  (103, 0.0),\n",
       "  (104, 0.0),\n",
       "  (106, 0.0),\n",
       "  (111, 0.0),\n",
       "  (127, 0.0),\n",
       "  (129, 0.0),\n",
       "  (131, 0.0),\n",
       "  (133, 0.0),\n",
       "  (137, 0.0),\n",
       "  (147, 0.0),\n",
       "  (149, 0.0),\n",
       "  (152, 0.0),\n",
       "  (153, 0.0),\n",
       "  (154, 0.0),\n",
       "  (156, 0.0),\n",
       "  (165, 0.0),\n",
       "  (167, 0.0),\n",
       "  (172, 0.0),\n",
       "  (174, 0.0),\n",
       "  (175, 0.0),\n",
       "  (177, 0.0),\n",
       "  (179, 0.0),\n",
       "  (185, 0.0),\n",
       "  (191, 0.0),\n",
       "  (194, 0.0),\n",
       "  (200, 0.0),\n",
       "  (210, 0.0),\n",
       "  (220, 0.0),\n",
       "  (225, 0.0),\n",
       "  (233, 0.0),\n",
       "  (239, 0.0),\n",
       "  (240, 0.0),\n",
       "  (244, 0.0),\n",
       "  (251, 0.0),\n",
       "  (255, 0.0),\n",
       "  (258, 0.0),\n",
       "  (262, 0.0),\n",
       "  (268, 0.0),\n",
       "  (277, 0.0),\n",
       "  (278, 0.0),\n",
       "  (283, 0.0),\n",
       "  (287, 0.0),\n",
       "  (299, 0.0),\n",
       "  (325, 0.0),\n",
       "  (333, 0.0),\n",
       "  (338, 0.0),\n",
       "  (339, 0.0),\n",
       "  (346, 0.0),\n",
       "  (349, 0.0),\n",
       "  (351, 0.0),\n",
       "  (356, 0.0),\n",
       "  (367, 0.0),\n",
       "  (368, 0.0),\n",
       "  (371, 0.0),\n",
       "  (373, 0.0),\n",
       "  (374, 0.0),\n",
       "  (404, 0.0),\n",
       "  (405, 0.0),\n",
       "  (416, 0.0),\n",
       "  (418, 0.0),\n",
       "  (421, 0.0),\n",
       "  (426, 0.0),\n",
       "  (427, 0.0),\n",
       "  (435, 0.0),\n",
       "  (437, 0.0),\n",
       "  (446, 0.0),\n",
       "  (449, 0.0),\n",
       "  (460, 0.0),\n",
       "  (462, 0.0),\n",
       "  (465, 0.0),\n",
       "  (466, 0.0),\n",
       "  (467, 0.0),\n",
       "  (469, 0.0),\n",
       "  (473, 0.0),\n",
       "  (475, 0.0),\n",
       "  (478, 0.0),\n",
       "  (479, 0.0),\n",
       "  (481, 0.0),\n",
       "  (485, 0.0),\n",
       "  (493, 0.0),\n",
       "  (494, 0.0),\n",
       "  (499, 0.0),\n",
       "  (500, 0.0),\n",
       "  (504, 0.0),\n",
       "  (510, 0.0),\n",
       "  (515, 0.0),\n",
       "  (519, 0.0),\n",
       "  (521, 0.0),\n",
       "  (522, 0.0),\n",
       "  (525, 0.0),\n",
       "  (536, 0.0),\n",
       "  (543, 0.0),\n",
       "  (548, 0.0),\n",
       "  (549, 0.0),\n",
       "  (551, 0.0),\n",
       "  (553, 0.0),\n",
       "  (557, 0.0),\n",
       "  (559, 0.0),\n",
       "  (569, 0.0),\n",
       "  (573, 0.0),\n",
       "  (583, 0.0),\n",
       "  (594, 0.0),\n",
       "  (596, 0.0),\n",
       "  (598, 0.0),\n",
       "  (600, 0.0),\n",
       "  (610, 0.0),\n",
       "  (617, 0.0),\n",
       "  (622, 0.0),\n",
       "  (623, 0.0),\n",
       "  (627, 0.0),\n",
       "  (630, 0.0),\n",
       "  (631, 0.0),\n",
       "  (648, 0.0),\n",
       "  (653, 0.0),\n",
       "  (659, 0.0),\n",
       "  (660, 0.0),\n",
       "  (666, 0.0),\n",
       "  (673, 0.0),\n",
       "  (675, 0.0),\n",
       "  (677, 0.0),\n",
       "  (681, 0.0),\n",
       "  (682, 0.0),\n",
       "  (686, 0.0),\n",
       "  (693, 0.0),\n",
       "  (705, 0.0),\n",
       "  (708, 0.0),\n",
       "  (713, 0.0),\n",
       "  (714, 0.0),\n",
       "  (717, 0.0),\n",
       "  (718, 0.0),\n",
       "  (722, 0.0),\n",
       "  (723, 0.0),\n",
       "  (726, 0.0),\n",
       "  (728, 0.0),\n",
       "  (730, 0.0),\n",
       "  (731, 0.0),\n",
       "  (733, 0.0),\n",
       "  (737, 0.0),\n",
       "  (739, 0.0),\n",
       "  (742, 0.0),\n",
       "  (744, 0.0),\n",
       "  (747, 0.0),\n",
       "  (756, 0.0),\n",
       "  (760, 0.0),\n",
       "  (767, 0.0),\n",
       "  (769, 0.0),\n",
       "  (780, 0.0),\n",
       "  (785, 0.0),\n",
       "  (789, 0.0),\n",
       "  (792, 0.0),\n",
       "  (798, 0.0),\n",
       "  (807, 0.0),\n",
       "  (810, 0.0),\n",
       "  (812, 0.0),\n",
       "  (813, 0.0),\n",
       "  (835, 0.0),\n",
       "  (836, 0.0),\n",
       "  (840, 0.0),\n",
       "  (841, 0.0),\n",
       "  (845, 0.0),\n",
       "  (846, 0.0),\n",
       "  (851, 0.0),\n",
       "  (856, 0.0),\n",
       "  (860, 0.0),\n",
       "  (861, 0.0),\n",
       "  (876, 0.0),\n",
       "  (880, 0.0),\n",
       "  (895, 0.0),\n",
       "  (899, 0.0),\n",
       "  (908, 0.0),\n",
       "  (909, 0.0),\n",
       "  (912, 0.0),\n",
       "  (913, 0.0),\n",
       "  (914, 0.0),\n",
       "  (916, 0.0),\n",
       "  (917, 0.0),\n",
       "  (922, 0.0),\n",
       "  (924, 0.0),\n",
       "  (926, 0.0),\n",
       "  (928, 0.0),\n",
       "  (929, 0.0),\n",
       "  (930, 0.0),\n",
       "  (931, 0.0),\n",
       "  (935, 0.0),\n",
       "  (936, 0.0),\n",
       "  (940, 0.0),\n",
       "  (941, 0.0),\n",
       "  (942, 0.0),\n",
       "  (945, 0.0),\n",
       "  (947, 0.0),\n",
       "  (948, 0.0),\n",
       "  (950, 0.0),\n",
       "  (951, 0.0),\n",
       "  (954, 0.0),\n",
       "  (958, 0.0),\n",
       "  (960, 0.0),\n",
       "  (961, 0.0),\n",
       "  (964, 0.0),\n",
       "  (965, 0.0),\n",
       "  (966, 0.0),\n",
       "  (967, 0.0),\n",
       "  (969, 0.0),\n",
       "  (970, 0.0),\n",
       "  (974, 0.0),\n",
       "  (975, 0.0),\n",
       "  (980, 0.0),\n",
       "  (986, 0.0),\n",
       "  (991, 0.0),\n",
       "  (993, 0.0),\n",
       "  (995, 0.0),\n",
       "  (998, 0.0),\n",
       "  (999, 0.0)])"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, hist = diversity(learn, 10, 95)\n",
    "n, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bTtz6Su-uV_M",
    "outputId": "f4cc9f8a-3c7c-4176-bfe4-a455364552f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at batch_no 0\n",
      "done with the 0th calculation: 717\n",
      "at batch_no 0\n",
      "done with the 1th calculation: 718\n",
      "at batch_no 0\n",
      "done with the 2th calculation: 720\n",
      "at batch_no 0\n",
      "done with the 3th calculation: 718\n",
      "result for n_pert: 10 is 718.25\n",
      "at batch_no 0\n",
      "done with the 0th calculation: 713\n",
      "at batch_no 0\n",
      "done with the 1th calculation: 724\n",
      "at batch_no 0\n",
      "done with the 2th calculation: 715\n",
      "at batch_no 0\n",
      "done with the 3th calculation: 719\n",
      "result for n_pert: 20 is 717.75\n",
      "at batch_no 0\n",
      "done with the 0th calculation: 712\n",
      "at batch_no 0\n",
      "done with the 1th calculation: 722\n",
      "at batch_no 0\n",
      "done with the 2th calculation: 720\n",
      "at batch_no 0\n",
      "done with the 3th calculation: 717\n",
      "result for n_pert: 30 is 717.75\n",
      "at batch_no 0\n",
      "done with the 0th calculation: 716\n",
      "at batch_no 0\n",
      "done with the 1th calculation: 717\n",
      "at batch_no 0\n",
      "done with the 2th calculation: 713\n",
      "at batch_no 0\n",
      "done with the 3th calculation: 714\n",
      "result for n_pert: 40 is 715.0\n",
      "at batch_no 0\n",
      "done with the 0th calculation: 717\n",
      "at batch_no 0\n",
      "done with the 1th calculation: 723\n",
      "at batch_no 0\n",
      "done with the 2th calculation: 722\n",
      "at batch_no 0\n",
      "done with the 3th calculation: 720\n",
      "result for n_pert: 50 is 720.5\n",
      "at batch_no 0\n",
      "done with the 0th calculation: 719\n",
      "at batch_no 0\n",
      "done with the 1th calculation: 712\n",
      "at batch_no 0\n",
      "done with the 2th calculation: 712\n",
      "at batch_no 0\n",
      "done with the 3th calculation: 720\n",
      "result for n_pert: 60 is 715.75\n",
      "at batch_no 0\n",
      "done with the 0th calculation: 723\n",
      "at batch_no 0\n",
      "done with the 1th calculation: 721\n",
      "at batch_no 0\n",
      "done with the 2th calculation: 722\n",
      "at batch_no 0\n",
      "done with the 3th calculation: 711\n",
      "result for n_pert: 70 is 719.25\n",
      "at batch_no 0\n",
      "done with the 0th calculation: 715\n",
      "at batch_no 0\n",
      "done with the 1th calculation: 715\n",
      "at batch_no 0\n",
      "done with the 2th calculation: 717\n",
      "at batch_no 0\n",
      "done with the 3th calculation: 715\n",
      "result for n_pert: 80 is 715.5\n",
      "at batch_no 0\n",
      "done with the 0th calculation: 721\n",
      "at batch_no 0\n",
      "done with the 1th calculation: 716\n",
      "at batch_no 0\n",
      "done with the 2th calculation: 716\n",
      "at batch_no 0\n",
      "done with the 3th calculation: 714\n",
      "result for n_pert: 90 is 716.75\n",
      "at batch_no 0\n",
      "done with the 0th calculation: 718\n",
      "at batch_no 0\n",
      "done with the 1th calculation: 719\n",
      "at batch_no 0\n",
      "done with the 2th calculation: 724\n",
      "at batch_no 0\n",
      "done with the 3th calculation: 723\n",
      "result for n_pert: 100 is 721.0\n"
     ]
    }
   ],
   "source": [
    "results_1 = []\n",
    "for n_pert in range(10, 110, 10):\n",
    "  n = targeted_diversity_average(learn, n_pert, 95, 4)\n",
    "  print(f'result for n_pert: {n_pert} is {n}')\n",
    "  results_1.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "2k_xUjeuuV_P",
    "outputId": "f9b82d92-7ad6-4fc3-8d9f-89e865e48b84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7feac1262b70>]"
      ]
     },
     "execution_count": 209,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = list(range(10, 110, 10))\n",
    "plt.ylim(0, 800)\n",
    "plt.plot(x, results_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "shwVAyTluV_Q",
    "outputId": "f1058ff8-f0ee-41df-9d8d-ad18cf3d4b0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished creating the prediction histogram\n",
      "done with the 0th calculation: 548\n",
      "finished creating the prediction histogram\n",
      "done with the 1th calculation: 524\n",
      "finished creating the prediction histogram\n",
      "done with the 2th calculation: 519\n",
      "result for n_pert: 10 is 530.3333333333334\n",
      "finished creating the prediction histogram\n",
      "done with the 0th calculation: 524\n",
      "finished creating the prediction histogram\n",
      "done with the 1th calculation: 546\n",
      "finished creating the prediction histogram\n",
      "done with the 2th calculation: 518\n",
      "result for n_pert: 20 is 529.3333333333334\n",
      "finished creating the prediction histogram\n",
      "done with the 0th calculation: 561\n",
      "finished creating the prediction histogram\n",
      "done with the 1th calculation: 543\n",
      "finished creating the prediction histogram\n",
      "done with the 2th calculation: 523\n",
      "result for n_pert: 30 is 542.3333333333334\n",
      "finished creating the prediction histogram\n",
      "done with the 0th calculation: 571\n",
      "finished creating the prediction histogram\n",
      "done with the 1th calculation: 548\n",
      "finished creating the prediction histogram\n",
      "done with the 2th calculation: 548\n",
      "result for n_pert: 40 is 555.6666666666666\n",
      "finished creating the prediction histogram\n",
      "done with the 0th calculation: 552\n",
      "finished creating the prediction histogram\n",
      "done with the 1th calculation: 535\n",
      "finished creating the prediction histogram\n",
      "done with the 2th calculation: 538\n",
      "result for n_pert: 50 is 541.6666666666666\n",
      "finished creating the prediction histogram\n",
      "done with the 0th calculation: 558\n",
      "finished creating the prediction histogram\n",
      "done with the 1th calculation: 540\n",
      "finished creating the prediction histogram\n",
      "done with the 0th calculation: 540\n",
      "finished creating the prediction histogram\n",
      "done with the 1th calculation: 534\n",
      "finished creating the prediction histogram\n",
      "done with the 2th calculation: 534\n",
      "result for n_pert: 70 is 536.0\n",
      "finished creating the prediction histogram\n",
      "done with the 0th calculation: 547\n",
      "finished creating the prediction histogram\n",
      "done with the 1th calculation: 521\n",
      "finished creating the prediction histogram\n",
      "done with the 2th calculation: 542\n",
      "result for n_pert: 80 is 536.6666666666666\n",
      "finished creating the prediction histogram\n",
      "done with the 0th calculation: 539\n",
      "finished creating the prediction histogram\n",
      "done with the 1th calculation: 564\n",
      "finished creating the prediction histogram\n",
      "done with the 2th calculation: 530\n",
      "result for n_pert: 90 is 544.3333333333334\n",
      "finished creating the prediction histogram\n",
      "done with the 0th calculation: 550\n",
      "finished creating the prediction histogram\n",
      "done with the 1th calculation: 540\n",
      "finished creating the prediction histogram\n",
      "done with the 2th calculation: 540\n",
      "result for n_pert: 100 is 543.3333333333334\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for n_pert in range(10, 110, 10):\n",
    "  n = diversity_average(learn, n_pert, 95, 3)\n",
    "  print(f'result for n_pert: {n_pert} is {n}')\n",
    "  results.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "RrwMO6CHuV_S",
    "outputId": "2531eb5c-6d2e-4100-cca7-10a5ff3aef72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fea6868afd0>]"
      ]
     },
     "execution_count": 206,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = list(range(10, 110, 10))\n",
    "plt.ylim(0, 600)\n",
    "plt.plot(x, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZzZ3yqwGuV_h"
   },
   "outputs": [],
   "source": [
    "#targeted:\n",
    "targeted_div_metrics = results_1\n",
    "div_metrics = results\n",
    "\n",
    "#non-targeted:\n",
    "n_targeted_div_metrics = [244.0, 247.0, 265.3333333333333, 246.66666666666666, 241.0, 231.33333333333334, \n",
    "                          247.66666666666666, 229.0, 222.33333333333334, 236.0]\n",
    "n_div_metrics = [132, 118, 122, 135, 133, 129, 136, 132, 124, 143]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "mYDVgQzHuV_m",
    "outputId": "34c71536-a358-43de-cebe-cebedc8e5b18"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, targeted_div_metrics)\n",
    "plt.plot(x, n_targeted_div_metrics)\n",
    "plt.title('targeted_div_metric')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "5qDnbPG0uV_s",
    "outputId": "4aeae69a-ba3f-4062-afda-9f35db532685"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, div_metrics)\n",
    "plt.plot(x, n_div_metrics)\n",
    "plt.title('div_metric')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8h1LVsfwuV_w"
   },
   "outputs": [],
   "source": [
    "#on validation\n",
    "%precision 2\n",
    "# n, hist = targeted_diversity(learn, 150, 95)\n",
    "# n, hist\n",
    "n, hist = diversity(learn, 10, 95)\n",
    "n, hist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5B6PIMPYuV_z"
   },
   "outputs": [],
   "source": [
    "#on validation\n",
    "%precision 2\n",
    "# n, hist = targeted_diversity(learn, 150, 95)\n",
    "# n, hist\n",
    "n, hist = diversity(learn, 10, 95)\n",
    "n, hist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "SgrIh3yVuV_2",
    "outputId": "8ab23c09-7c99-40cb-9ce0-7d65cb528ca1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at batch no 0\n",
      "at batch no 5\n",
      "at batch no 10\n",
      "at batch no 15\n",
      "at batch no 20\n",
      "at batch no 25\n",
      "at batch no 30\n",
      "at batch no 35\n",
      "at batch no 40\n",
      "at batch no 45\n",
      "at batch no 50\n",
      "at batch no 55\n",
      "at batch no 60\n",
      "finished creating the prediction histogram\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(364,\n",
       " [(721, 143.20),\n",
       "  (750, 49.40),\n",
       "  (971, 48.40),\n",
       "  (794, 47.10),\n",
       "  (431, 35.10),\n",
       "  (669, 35.10),\n",
       "  (414, 30.60),\n",
       "  (588, 28.40),\n",
       "  (520, 24.90),\n",
       "  (61, 24.20),\n",
       "  (904, 18.30),\n",
       "  (411, 14.30),\n",
       "  (828, 13.50),\n",
       "  (39, 11.70),\n",
       "  (556, 11.40),\n",
       "  (581, 9.20),\n",
       "  (651, 8.30),\n",
       "  (489, 7.80),\n",
       "  (599, 6.60),\n",
       "  (84, 5.50),\n",
       "  (572, 4.80),\n",
       "  (907, 4.70),\n",
       "  (987, 4.40),\n",
       "  (401, 4.30),\n",
       "  (490, 4.30),\n",
       "  (614, 4.30),\n",
       "  (60, 4.00),\n",
       "  (955, 3.50),\n",
       "  (711, 3.30),\n",
       "  (48, 3.20),\n",
       "  (691, 3.10),\n",
       "  (709, 3.00),\n",
       "  (419, 2.90),\n",
       "  (770, 2.90),\n",
       "  (815, 2.90),\n",
       "  (864, 2.80),\n",
       "  (879, 2.80),\n",
       "  (108, 2.70),\n",
       "  (441, 2.70),\n",
       "  (632, 2.70),\n",
       "  (56, 2.50),\n",
       "  (604, 2.50),\n",
       "  (55, 2.40),\n",
       "  (464, 2.30),\n",
       "  (549, 2.30),\n",
       "  (575, 2.20),\n",
       "  (893, 2.20),\n",
       "  (973, 2.20),\n",
       "  (96, 2.10),\n",
       "  (496, 2.10),\n",
       "  (518, 2.10),\n",
       "  (412, 2.00),\n",
       "  (641, 2.00),\n",
       "  (762, 2.00),\n",
       "  (801, 2.00),\n",
       "  (872, 2.00),\n",
       "  (858, 1.90),\n",
       "  (871, 1.90),\n",
       "  (580, 1.80),\n",
       "  (621, 1.80),\n",
       "  (746, 1.80),\n",
       "  (806, 1.80),\n",
       "  (46, 1.70),\n",
       "  (151, 1.70),\n",
       "  (171, 1.70),\n",
       "  (633, 1.70),\n",
       "  (781, 1.70),\n",
       "  (790, 1.70),\n",
       "  (850, 1.70),\n",
       "  (424, 1.60),\n",
       "  (443, 1.60),\n",
       "  (453, 1.60),\n",
       "  (646, 1.60),\n",
       "  (981, 1.60),\n",
       "  (128, 1.50),\n",
       "  (360, 1.50),\n",
       "  (457, 1.50),\n",
       "  (545, 1.50),\n",
       "  (680, 1.50),\n",
       "  (722, 1.50),\n",
       "  (743, 1.50),\n",
       "  (1, 1.40),\n",
       "  (94, 1.40),\n",
       "  (230, 1.40),\n",
       "  (292, 1.40),\n",
       "  (406, 1.40),\n",
       "  (410, 1.40),\n",
       "  (440, 1.40),\n",
       "  (506, 1.40),\n",
       "  (847, 1.40),\n",
       "  (897, 1.40),\n",
       "  (67, 1.30),\n",
       "  (68, 1.30),\n",
       "  (124, 1.30),\n",
       "  (417, 1.30),\n",
       "  (538, 1.30),\n",
       "  (706, 1.30),\n",
       "  (779, 1.30),\n",
       "  (791, 1.30),\n",
       "  (826, 1.30),\n",
       "  (865, 1.30),\n",
       "  (898, 1.30),\n",
       "  (937, 1.30),\n",
       "  (953, 1.30),\n",
       "  (242, 1.20),\n",
       "  (310, 1.20),\n",
       "  (408, 1.20),\n",
       "  (582, 1.20),\n",
       "  (591, 1.20),\n",
       "  (698, 1.20),\n",
       "  (857, 1.20),\n",
       "  (896, 1.20),\n",
       "  (963, 1.20),\n",
       "  (83, 1.10),\n",
       "  (90, 1.10),\n",
       "  (92, 1.10),\n",
       "  (123, 1.10),\n",
       "  (293, 1.10),\n",
       "  (300, 1.10),\n",
       "  (316, 1.10),\n",
       "  (393, 1.10),\n",
       "  (407, 1.10),\n",
       "  (468, 1.10),\n",
       "  (612, 1.10),\n",
       "  (619, 1.10),\n",
       "  (645, 1.10),\n",
       "  (656, 1.10),\n",
       "  (738, 1.10),\n",
       "  (783, 1.10),\n",
       "  (805, 1.10),\n",
       "  (817, 1.10),\n",
       "  (906, 1.10),\n",
       "  (7, 1.00),\n",
       "  (25, 1.00),\n",
       "  (31, 1.00),\n",
       "  (33, 1.00),\n",
       "  (37, 1.00),\n",
       "  (57, 1.00),\n",
       "  (75, 1.00),\n",
       "  (88, 1.00),\n",
       "  (91, 1.00),\n",
       "  (102, 1.00),\n",
       "  (115, 1.00),\n",
       "  (120, 1.00),\n",
       "  (163, 1.00),\n",
       "  (176, 1.00),\n",
       "  (186, 1.00),\n",
       "  (195, 1.00),\n",
       "  (218, 1.00),\n",
       "  (231, 1.00),\n",
       "  (247, 1.00),\n",
       "  (260, 1.00),\n",
       "  (274, 1.00),\n",
       "  (281, 1.00),\n",
       "  (290, 1.00),\n",
       "  (306, 1.00),\n",
       "  (307, 1.00),\n",
       "  (314, 1.00),\n",
       "  (318, 1.00),\n",
       "  (334, 1.00),\n",
       "  (376, 1.00),\n",
       "  (392, 1.00),\n",
       "  (429, 1.00),\n",
       "  (474, 1.00),\n",
       "  (483, 1.00),\n",
       "  (488, 1.00),\n",
       "  (492, 1.00),\n",
       "  (498, 1.00),\n",
       "  (507, 1.00),\n",
       "  (516, 1.00),\n",
       "  (528, 1.00),\n",
       "  (530, 1.00),\n",
       "  (533, 1.00),\n",
       "  (562, 1.00),\n",
       "  (566, 1.00),\n",
       "  (602, 1.00),\n",
       "  (625, 1.00),\n",
       "  (637, 1.00),\n",
       "  (661, 1.00),\n",
       "  (684, 1.00),\n",
       "  (694, 1.00),\n",
       "  (716, 1.00),\n",
       "  (725, 1.00),\n",
       "  (734, 1.00),\n",
       "  (787, 1.00),\n",
       "  (816, 1.00),\n",
       "  (822, 1.00),\n",
       "  (824, 1.00),\n",
       "  (837, 1.00),\n",
       "  (873, 1.00),\n",
       "  (923, 1.00),\n",
       "  (934, 1.00),\n",
       "  (944, 1.00),\n",
       "  (992, 1.00),\n",
       "  (997, 1.00),\n",
       "  (40, 0.90),\n",
       "  (62, 0.90),\n",
       "  (105, 0.90),\n",
       "  (164, 0.90),\n",
       "  (301, 0.90),\n",
       "  (347, 0.90),\n",
       "  (369, 0.90),\n",
       "  (397, 0.90),\n",
       "  (425, 0.90),\n",
       "  (444, 0.90),\n",
       "  (753, 0.90),\n",
       "  (819, 0.90),\n",
       "  (868, 0.90),\n",
       "  (889, 0.90),\n",
       "  (982, 0.90),\n",
       "  (47, 0.80),\n",
       "  (72, 0.80),\n",
       "  (86, 0.80),\n",
       "  (97, 0.80),\n",
       "  (118, 0.80),\n",
       "  (254, 0.80),\n",
       "  (275, 0.80),\n",
       "  (304, 0.80),\n",
       "  (331, 0.80),\n",
       "  (463, 0.80),\n",
       "  (509, 0.80),\n",
       "  (532, 0.80),\n",
       "  (576, 0.80),\n",
       "  (586, 0.80),\n",
       "  (606, 0.80),\n",
       "  (638, 0.80),\n",
       "  (703, 0.80),\n",
       "  (732, 0.80),\n",
       "  (772, 0.80),\n",
       "  (786, 0.80),\n",
       "  (803, 0.80),\n",
       "  (829, 0.80),\n",
       "  (878, 0.80),\n",
       "  (899, 0.80),\n",
       "  (905, 0.80),\n",
       "  (915, 0.80),\n",
       "  (984, 0.80),\n",
       "  (8, 0.70),\n",
       "  (15, 0.70),\n",
       "  (38, 0.70),\n",
       "  (42, 0.70),\n",
       "  (109, 0.70),\n",
       "  (116, 0.70),\n",
       "  (144, 0.70),\n",
       "  (155, 0.70),\n",
       "  (189, 0.70),\n",
       "  (235, 0.70),\n",
       "  (313, 0.70),\n",
       "  (341, 0.70),\n",
       "  (353, 0.70),\n",
       "  (355, 0.70),\n",
       "  (387, 0.70),\n",
       "  (438, 0.70),\n",
       "  (476, 0.70),\n",
       "  (497, 0.70),\n",
       "  (508, 0.70),\n",
       "  (517, 0.70),\n",
       "  (526, 0.70),\n",
       "  (547, 0.70),\n",
       "  (552, 0.70),\n",
       "  (564, 0.70),\n",
       "  (570, 0.70),\n",
       "  (579, 0.70),\n",
       "  (620, 0.70),\n",
       "  (629, 0.70),\n",
       "  (727, 0.70),\n",
       "  (741, 0.70),\n",
       "  (752, 0.70),\n",
       "  (778, 0.70),\n",
       "  (788, 0.70),\n",
       "  (814, 0.70),\n",
       "  (925, 0.70),\n",
       "  (17, 0.60),\n",
       "  (19, 0.60),\n",
       "  (87, 0.60),\n",
       "  (289, 0.60),\n",
       "  (291, 0.60),\n",
       "  (294, 0.60),\n",
       "  (327, 0.60),\n",
       "  (375, 0.60),\n",
       "  (398, 0.60),\n",
       "  (409, 0.60),\n",
       "  (433, 0.60),\n",
       "  (445, 0.60),\n",
       "  (472, 0.60),\n",
       "  (482, 0.60),\n",
       "  (535, 0.60),\n",
       "  (544, 0.60),\n",
       "  (565, 0.60),\n",
       "  (671, 0.60),\n",
       "  (679, 0.60),\n",
       "  (696, 0.60),\n",
       "  (701, 0.60),\n",
       "  (751, 0.60),\n",
       "  (760, 0.60),\n",
       "  (796, 0.60),\n",
       "  (797, 0.60),\n",
       "  (820, 0.60),\n",
       "  (867, 0.60),\n",
       "  (892, 0.60),\n",
       "  (902, 0.60),\n",
       "  (920, 0.60),\n",
       "  (998, 0.60),\n",
       "  (0, 0.50),\n",
       "  (45, 0.50),\n",
       "  (50, 0.50),\n",
       "  (52, 0.50),\n",
       "  (107, 0.50),\n",
       "  (149, 0.50),\n",
       "  (159, 0.50),\n",
       "  (336, 0.50),\n",
       "  (342, 0.50),\n",
       "  (348, 0.50),\n",
       "  (391, 0.50),\n",
       "  (495, 0.50),\n",
       "  (515, 0.50),\n",
       "  (523, 0.50),\n",
       "  (527, 0.50),\n",
       "  (539, 0.50),\n",
       "  (555, 0.50),\n",
       "  (605, 0.50),\n",
       "  (607, 0.50),\n",
       "  (609, 0.50),\n",
       "  (626, 0.50),\n",
       "  (654, 0.50),\n",
       "  (655, 0.50),\n",
       "  (664, 0.50),\n",
       "  (674, 0.50),\n",
       "  (705, 0.50),\n",
       "  (719, 0.50),\n",
       "  (745, 0.50),\n",
       "  (754, 0.50),\n",
       "  (759, 0.50),\n",
       "  (768, 0.50),\n",
       "  (823, 0.50),\n",
       "  (853, 0.50),\n",
       "  (900, 0.50),\n",
       "  (917, 0.50),\n",
       "  (985, 0.50),\n",
       "  (9, 0.40),\n",
       "  (23, 0.40),\n",
       "  (24, 0.40),\n",
       "  (28, 0.40),\n",
       "  (63, 0.40),\n",
       "  (77, 0.40),\n",
       "  (126, 0.40),\n",
       "  (134, 0.40),\n",
       "  (140, 0.40),\n",
       "  (168, 0.40),\n",
       "  (192, 0.40),\n",
       "  (197, 0.40),\n",
       "  (205, 0.40),\n",
       "  (219, 0.40),\n",
       "  (224, 0.40),\n",
       "  (236, 0.40),\n",
       "  (249, 0.40),\n",
       "  (305, 0.40),\n",
       "  (319, 0.40),\n",
       "  (321, 0.40),\n",
       "  (332, 0.40),\n",
       "  (363, 0.40),\n",
       "  (381, 0.40),\n",
       "  (383, 0.40),\n",
       "  (388, 0.40),\n",
       "  (389, 0.40),\n",
       "  (396, 0.40),\n",
       "  (473, 0.40),\n",
       "  (481, 0.40),\n",
       "  (491, 0.40),\n",
       "  (522, 0.40),\n",
       "  (546, 0.40),\n",
       "  (574, 0.40),\n",
       "  (584, 0.40),\n",
       "  (672, 0.40),\n",
       "  (692, 0.40),\n",
       "  (697, 0.40),\n",
       "  (712, 0.40),\n",
       "  (802, 0.40),\n",
       "  (843, 0.40),\n",
       "  (854, 0.40),\n",
       "  (870, 0.40),\n",
       "  (880, 0.40),\n",
       "  (882, 0.40),\n",
       "  (890, 0.40),\n",
       "  (918, 0.40),\n",
       "  (938, 0.40),\n",
       "  (991, 0.40),\n",
       "  (41, 0.30),\n",
       "  (65, 0.30),\n",
       "  (71, 0.30),\n",
       "  (74, 0.30),\n",
       "  (113, 0.30),\n",
       "  (183, 0.30),\n",
       "  (191, 0.30),\n",
       "  (196, 0.30),\n",
       "  (202, 0.30),\n",
       "  (228, 0.30),\n",
       "  (232, 0.30),\n",
       "  (253, 0.30),\n",
       "  (303, 0.30),\n",
       "  (320, 0.30),\n",
       "  (337, 0.30),\n",
       "  (350, 0.30),\n",
       "  (358, 0.30),\n",
       "  (364, 0.30),\n",
       "  (399, 0.30),\n",
       "  (452, 0.30),\n",
       "  (454, 0.30),\n",
       "  (477, 0.30),\n",
       "  (480, 0.30),\n",
       "  (512, 0.30),\n",
       "  (537, 0.30),\n",
       "  (550, 0.30),\n",
       "  (554, 0.30),\n",
       "  (560, 0.30),\n",
       "  (593, 0.30),\n",
       "  (640, 0.30),\n",
       "  (644, 0.30),\n",
       "  (683, 0.30),\n",
       "  (707, 0.30),\n",
       "  (720, 0.30),\n",
       "  (729, 0.30),\n",
       "  (748, 0.30),\n",
       "  (757, 0.30),\n",
       "  (758, 0.30),\n",
       "  (777, 0.30),\n",
       "  (811, 0.30),\n",
       "  (831, 0.30),\n",
       "  (840, 0.30),\n",
       "  (846, 0.30),\n",
       "  (875, 0.30),\n",
       "  (883, 0.30),\n",
       "  (932, 0.30),\n",
       "  (939, 0.30),\n",
       "  (951, 0.30),\n",
       "  (957, 0.30),\n",
       "  (968, 0.30),\n",
       "  (995, 0.30),\n",
       "  (58, 0.20),\n",
       "  (82, 0.20),\n",
       "  (93, 0.20),\n",
       "  (98, 0.20),\n",
       "  (99, 0.20),\n",
       "  (100, 0.20),\n",
       "  (117, 0.20),\n",
       "  (122, 0.20),\n",
       "  (131, 0.20),\n",
       "  (138, 0.20),\n",
       "  (153, 0.20),\n",
       "  (161, 0.20),\n",
       "  (178, 0.20),\n",
       "  (188, 0.20),\n",
       "  (198, 0.20),\n",
       "  (206, 0.20),\n",
       "  (238, 0.20),\n",
       "  (283, 0.20),\n",
       "  (284, 0.20),\n",
       "  (317, 0.20),\n",
       "  (323, 0.20),\n",
       "  (326, 0.20),\n",
       "  (340, 0.20),\n",
       "  (344, 0.20),\n",
       "  (379, 0.20),\n",
       "  (395, 0.20),\n",
       "  (420, 0.20),\n",
       "  (432, 0.20),\n",
       "  (435, 0.20),\n",
       "  (436, 0.20),\n",
       "  (455, 0.20),\n",
       "  (484, 0.20),\n",
       "  (485, 0.20),\n",
       "  (487, 0.20),\n",
       "  (502, 0.20),\n",
       "  (505, 0.20),\n",
       "  (514, 0.20),\n",
       "  (534, 0.20),\n",
       "  (557, 0.20),\n",
       "  (585, 0.20),\n",
       "  (595, 0.20),\n",
       "  (618, 0.20),\n",
       "  (635, 0.20),\n",
       "  (643, 0.20),\n",
       "  (681, 0.20),\n",
       "  (700, 0.20),\n",
       "  (717, 0.20),\n",
       "  (723, 0.20),\n",
       "  (728, 0.20),\n",
       "  (736, 0.20),\n",
       "  (747, 0.20),\n",
       "  (785, 0.20),\n",
       "  (800, 0.20),\n",
       "  (808, 0.20),\n",
       "  (809, 0.20),\n",
       "  (818, 0.20),\n",
       "  (821, 0.20),\n",
       "  (825, 0.20),\n",
       "  (832, 0.20),\n",
       "  (844, 0.20),\n",
       "  (852, 0.20),\n",
       "  (876, 0.20),\n",
       "  (881, 0.20),\n",
       "  (926, 0.20),\n",
       "  (962, 0.20),\n",
       "  (966, 0.20),\n",
       "  (996, 0.20),\n",
       "  (11, 0.10),\n",
       "  (18, 0.10),\n",
       "  (21, 0.10),\n",
       "  (22, 0.10),\n",
       "  (26, 0.10),\n",
       "  (66, 0.10),\n",
       "  (70, 0.10),\n",
       "  (76, 0.10),\n",
       "  (79, 0.10),\n",
       "  (95, 0.10),\n",
       "  (111, 0.10),\n",
       "  (114, 0.10),\n",
       "  (121, 0.10),\n",
       "  (125, 0.10),\n",
       "  (129, 0.10),\n",
       "  (132, 0.10),\n",
       "  (139, 0.10),\n",
       "  (141, 0.10),\n",
       "  (142, 0.10),\n",
       "  (146, 0.10),\n",
       "  (158, 0.10),\n",
       "  (173, 0.10),\n",
       "  (179, 0.10),\n",
       "  (193, 0.10),\n",
       "  (214, 0.10),\n",
       "  (222, 0.10),\n",
       "  (229, 0.10),\n",
       "  (237, 0.10),\n",
       "  (252, 0.10),\n",
       "  (256, 0.10),\n",
       "  (268, 0.10),\n",
       "  (273, 0.10),\n",
       "  (276, 0.10),\n",
       "  (278, 0.10),\n",
       "  (282, 0.10),\n",
       "  (295, 0.10),\n",
       "  (298, 0.10),\n",
       "  (308, 0.10),\n",
       "  (309, 0.10),\n",
       "  (311, 0.10),\n",
       "  (315, 0.10),\n",
       "  (330, 0.10),\n",
       "  (343, 0.10),\n",
       "  (346, 0.10),\n",
       "  (351, 0.10),\n",
       "  (352, 0.10),\n",
       "  (356, 0.10),\n",
       "  (361, 0.10),\n",
       "  (365, 0.10),\n",
       "  (366, 0.10),\n",
       "  (377, 0.10),\n",
       "  (413, 0.10),\n",
       "  (423, 0.10),\n",
       "  (427, 0.10),\n",
       "  (428, 0.10),\n",
       "  (439, 0.10),\n",
       "  (442, 0.10),\n",
       "  (447, 0.10),\n",
       "  (448, 0.10),\n",
       "  (450, 0.10),\n",
       "  (451, 0.10),\n",
       "  (459, 0.10),\n",
       "  (475, 0.10),\n",
       "  (486, 0.10),\n",
       "  (493, 0.10),\n",
       "  (504, 0.10),\n",
       "  (521, 0.10),\n",
       "  (540, 0.10),\n",
       "  (551, 0.10),\n",
       "  (563, 0.10),\n",
       "  (569, 0.10),\n",
       "  (577, 0.10),\n",
       "  (603, 0.10),\n",
       "  (611, 0.10),\n",
       "  (613, 0.10),\n",
       "  (615, 0.10),\n",
       "  (616, 0.10),\n",
       "  (636, 0.10),\n",
       "  (639, 0.10),\n",
       "  (650, 0.10),\n",
       "  (665, 0.10),\n",
       "  (668, 0.10),\n",
       "  (673, 0.10),\n",
       "  (730, 0.10),\n",
       "  (735, 0.10),\n",
       "  (755, 0.10),\n",
       "  (756, 0.10),\n",
       "  (761, 0.10),\n",
       "  (763, 0.10),\n",
       "  (764, 0.10),\n",
       "  (765, 0.10),\n",
       "  (775, 0.10),\n",
       "  (792, 0.10),\n",
       "  (804, 0.10),\n",
       "  (813, 0.10),\n",
       "  (830, 0.10),\n",
       "  (833, 0.10),\n",
       "  (834, 0.10),\n",
       "  (836, 0.10),\n",
       "  (839, 0.10),\n",
       "  (842, 0.10),\n",
       "  (855, 0.10),\n",
       "  (856, 0.10),\n",
       "  (863, 0.10),\n",
       "  (866, 0.10),\n",
       "  (884, 0.10),\n",
       "  (885, 0.10),\n",
       "  (901, 0.10),\n",
       "  (927, 0.10),\n",
       "  (946, 0.10),\n",
       "  (950, 0.10),\n",
       "  (952, 0.10),\n",
       "  (954, 0.10),\n",
       "  (978, 0.10),\n",
       "  (983, 0.10),\n",
       "  (988, 0.10),\n",
       "  (999, 0.10),\n",
       "  (2, 0.00),\n",
       "  (3, 0.00),\n",
       "  (4, 0.00),\n",
       "  (5, 0.00),\n",
       "  (6, 0.00),\n",
       "  (10, 0.00),\n",
       "  (12, 0.00),\n",
       "  (13, 0.00),\n",
       "  (14, 0.00),\n",
       "  (16, 0.00),\n",
       "  (20, 0.00),\n",
       "  (27, 0.00),\n",
       "  (29, 0.00),\n",
       "  (30, 0.00),\n",
       "  (32, 0.00),\n",
       "  (34, 0.00),\n",
       "  (35, 0.00),\n",
       "  (36, 0.00),\n",
       "  (43, 0.00),\n",
       "  (44, 0.00),\n",
       "  (49, 0.00),\n",
       "  (51, 0.00),\n",
       "  (53, 0.00),\n",
       "  (54, 0.00),\n",
       "  (59, 0.00),\n",
       "  (64, 0.00),\n",
       "  (69, 0.00),\n",
       "  (73, 0.00),\n",
       "  (78, 0.00),\n",
       "  (80, 0.00),\n",
       "  (81, 0.00),\n",
       "  (85, 0.00),\n",
       "  (89, 0.00),\n",
       "  (101, 0.00),\n",
       "  (103, 0.00),\n",
       "  (104, 0.00),\n",
       "  (106, 0.00),\n",
       "  (110, 0.00),\n",
       "  (112, 0.00),\n",
       "  (119, 0.00),\n",
       "  (127, 0.00),\n",
       "  (130, 0.00),\n",
       "  (133, 0.00),\n",
       "  (135, 0.00),\n",
       "  (136, 0.00),\n",
       "  (137, 0.00),\n",
       "  (143, 0.00),\n",
       "  (145, 0.00),\n",
       "  (147, 0.00),\n",
       "  (148, 0.00),\n",
       "  (150, 0.00),\n",
       "  (152, 0.00),\n",
       "  (154, 0.00),\n",
       "  (156, 0.00),\n",
       "  (157, 0.00),\n",
       "  (160, 0.00),\n",
       "  (162, 0.00),\n",
       "  (165, 0.00),\n",
       "  (166, 0.00),\n",
       "  (167, 0.00),\n",
       "  (169, 0.00),\n",
       "  (170, 0.00),\n",
       "  (172, 0.00),\n",
       "  (174, 0.00),\n",
       "  (175, 0.00),\n",
       "  (177, 0.00),\n",
       "  (180, 0.00),\n",
       "  (181, 0.00),\n",
       "  (182, 0.00),\n",
       "  (184, 0.00),\n",
       "  (185, 0.00),\n",
       "  (187, 0.00),\n",
       "  (190, 0.00),\n",
       "  (194, 0.00),\n",
       "  (199, 0.00),\n",
       "  (200, 0.00),\n",
       "  (201, 0.00),\n",
       "  (203, 0.00),\n",
       "  (204, 0.00),\n",
       "  (207, 0.00),\n",
       "  (208, 0.00),\n",
       "  (209, 0.00),\n",
       "  (210, 0.00),\n",
       "  (211, 0.00),\n",
       "  (212, 0.00),\n",
       "  (213, 0.00),\n",
       "  (215, 0.00),\n",
       "  (216, 0.00),\n",
       "  (217, 0.00),\n",
       "  (220, 0.00),\n",
       "  (221, 0.00),\n",
       "  (223, 0.00),\n",
       "  (225, 0.00),\n",
       "  (226, 0.00),\n",
       "  (227, 0.00),\n",
       "  (233, 0.00),\n",
       "  (234, 0.00),\n",
       "  (239, 0.00),\n",
       "  (240, 0.00),\n",
       "  (241, 0.00),\n",
       "  (243, 0.00),\n",
       "  (244, 0.00),\n",
       "  (245, 0.00),\n",
       "  (246, 0.00),\n",
       "  (248, 0.00),\n",
       "  (250, 0.00),\n",
       "  (251, 0.00),\n",
       "  (255, 0.00),\n",
       "  (257, 0.00),\n",
       "  (258, 0.00),\n",
       "  (259, 0.00),\n",
       "  (261, 0.00),\n",
       "  (262, 0.00),\n",
       "  (263, 0.00),\n",
       "  (264, 0.00),\n",
       "  (265, 0.00),\n",
       "  (266, 0.00),\n",
       "  (267, 0.00),\n",
       "  (269, 0.00),\n",
       "  (270, 0.00),\n",
       "  (271, 0.00),\n",
       "  (272, 0.00),\n",
       "  (277, 0.00),\n",
       "  (279, 0.00),\n",
       "  (280, 0.00),\n",
       "  (285, 0.00),\n",
       "  (286, 0.00),\n",
       "  (287, 0.00),\n",
       "  (288, 0.00),\n",
       "  (296, 0.00),\n",
       "  (297, 0.00),\n",
       "  (299, 0.00),\n",
       "  (302, 0.00),\n",
       "  (312, 0.00),\n",
       "  (322, 0.00),\n",
       "  (324, 0.00),\n",
       "  (325, 0.00),\n",
       "  (328, 0.00),\n",
       "  (329, 0.00),\n",
       "  (333, 0.00),\n",
       "  (335, 0.00),\n",
       "  (338, 0.00),\n",
       "  (339, 0.00),\n",
       "  (345, 0.00),\n",
       "  (349, 0.00),\n",
       "  (354, 0.00),\n",
       "  (357, 0.00),\n",
       "  (359, 0.00),\n",
       "  (362, 0.00),\n",
       "  (367, 0.00),\n",
       "  (368, 0.00),\n",
       "  (370, 0.00),\n",
       "  (371, 0.00),\n",
       "  (372, 0.00),\n",
       "  (373, 0.00),\n",
       "  (374, 0.00),\n",
       "  (378, 0.00),\n",
       "  (380, 0.00),\n",
       "  (382, 0.00),\n",
       "  (384, 0.00),\n",
       "  (385, 0.00),\n",
       "  (386, 0.00),\n",
       "  (390, 0.00),\n",
       "  (394, 0.00),\n",
       "  (400, 0.00),\n",
       "  (402, 0.00),\n",
       "  (403, 0.00),\n",
       "  (404, 0.00),\n",
       "  (405, 0.00),\n",
       "  (415, 0.00),\n",
       "  (416, 0.00),\n",
       "  (418, 0.00),\n",
       "  (421, 0.00),\n",
       "  (422, 0.00),\n",
       "  (426, 0.00),\n",
       "  (430, 0.00),\n",
       "  (434, 0.00),\n",
       "  (437, 0.00),\n",
       "  (446, 0.00),\n",
       "  (449, 0.00),\n",
       "  (456, 0.00),\n",
       "  (458, 0.00),\n",
       "  (460, 0.00),\n",
       "  (461, 0.00),\n",
       "  (462, 0.00),\n",
       "  (465, 0.00),\n",
       "  (466, 0.00),\n",
       "  (467, 0.00),\n",
       "  (469, 0.00),\n",
       "  (470, 0.00),\n",
       "  (471, 0.00),\n",
       "  (478, 0.00),\n",
       "  (479, 0.00),\n",
       "  (494, 0.00),\n",
       "  (499, 0.00),\n",
       "  (500, 0.00),\n",
       "  (501, 0.00),\n",
       "  (503, 0.00),\n",
       "  (510, 0.00),\n",
       "  (511, 0.00),\n",
       "  (513, 0.00),\n",
       "  (519, 0.00),\n",
       "  (524, 0.00),\n",
       "  (525, 0.00),\n",
       "  (529, 0.00),\n",
       "  (531, 0.00),\n",
       "  (536, 0.00),\n",
       "  (541, 0.00),\n",
       "  (542, 0.00),\n",
       "  (543, 0.00),\n",
       "  (548, 0.00),\n",
       "  (553, 0.00),\n",
       "  (558, 0.00),\n",
       "  (559, 0.00),\n",
       "  (561, 0.00),\n",
       "  (567, 0.00),\n",
       "  (568, 0.00),\n",
       "  (571, 0.00),\n",
       "  (573, 0.00),\n",
       "  (578, 0.00),\n",
       "  (583, 0.00),\n",
       "  (587, 0.00),\n",
       "  (589, 0.00),\n",
       "  (590, 0.00),\n",
       "  (592, 0.00),\n",
       "  (594, 0.00),\n",
       "  (596, 0.00),\n",
       "  (597, 0.00),\n",
       "  (598, 0.00),\n",
       "  (600, 0.00),\n",
       "  (601, 0.00),\n",
       "  (608, 0.00),\n",
       "  (610, 0.00),\n",
       "  (617, 0.00),\n",
       "  (622, 0.00),\n",
       "  (623, 0.00),\n",
       "  (624, 0.00),\n",
       "  (627, 0.00),\n",
       "  (628, 0.00),\n",
       "  (630, 0.00),\n",
       "  (631, 0.00),\n",
       "  (634, 0.00),\n",
       "  (642, 0.00),\n",
       "  (647, 0.00),\n",
       "  (648, 0.00),\n",
       "  (649, 0.00),\n",
       "  (652, 0.00),\n",
       "  (653, 0.00),\n",
       "  (657, 0.00),\n",
       "  (658, 0.00),\n",
       "  (659, 0.00),\n",
       "  (660, 0.00),\n",
       "  (662, 0.00),\n",
       "  (663, 0.00),\n",
       "  (666, 0.00),\n",
       "  (667, 0.00),\n",
       "  (670, 0.00),\n",
       "  (675, 0.00),\n",
       "  (676, 0.00),\n",
       "  (677, 0.00),\n",
       "  (678, 0.00),\n",
       "  (682, 0.00),\n",
       "  (685, 0.00),\n",
       "  (686, 0.00),\n",
       "  (687, 0.00),\n",
       "  (688, 0.00),\n",
       "  (689, 0.00),\n",
       "  (690, 0.00),\n",
       "  (693, 0.00),\n",
       "  (695, 0.00),\n",
       "  (699, 0.00),\n",
       "  (702, 0.00),\n",
       "  (704, 0.00),\n",
       "  (708, 0.00),\n",
       "  (710, 0.00),\n",
       "  (713, 0.00),\n",
       "  (714, 0.00),\n",
       "  (715, 0.00),\n",
       "  (718, 0.00),\n",
       "  (724, 0.00),\n",
       "  (726, 0.00),\n",
       "  (731, 0.00),\n",
       "  (733, 0.00),\n",
       "  (737, 0.00),\n",
       "  (739, 0.00),\n",
       "  (740, 0.00),\n",
       "  (742, 0.00),\n",
       "  (744, 0.00),\n",
       "  (749, 0.00),\n",
       "  (766, 0.00),\n",
       "  (767, 0.00),\n",
       "  (769, 0.00),\n",
       "  (771, 0.00),\n",
       "  (773, 0.00),\n",
       "  (774, 0.00),\n",
       "  (776, 0.00),\n",
       "  (780, 0.00),\n",
       "  (782, 0.00),\n",
       "  (784, 0.00),\n",
       "  (789, 0.00),\n",
       "  (793, 0.00),\n",
       "  (795, 0.00),\n",
       "  (798, 0.00),\n",
       "  (799, 0.00),\n",
       "  (807, 0.00),\n",
       "  (810, 0.00),\n",
       "  (812, 0.00),\n",
       "  (827, 0.00),\n",
       "  (835, 0.00),\n",
       "  (838, 0.00),\n",
       "  (841, 0.00),\n",
       "  (845, 0.00),\n",
       "  (848, 0.00),\n",
       "  (849, 0.00),\n",
       "  (851, 0.00),\n",
       "  (859, 0.00),\n",
       "  (860, 0.00),\n",
       "  (861, 0.00),\n",
       "  (862, 0.00),\n",
       "  (869, 0.00),\n",
       "  (874, 0.00),\n",
       "  (877, 0.00),\n",
       "  (886, 0.00),\n",
       "  (887, 0.00),\n",
       "  (888, 0.00),\n",
       "  (891, 0.00),\n",
       "  (894, 0.00),\n",
       "  (895, 0.00),\n",
       "  (903, 0.00),\n",
       "  (908, 0.00),\n",
       "  (909, 0.00),\n",
       "  (910, 0.00),\n",
       "  (911, 0.00),\n",
       "  (912, 0.00),\n",
       "  (913, 0.00),\n",
       "  (914, 0.00),\n",
       "  (916, 0.00),\n",
       "  (919, 0.00),\n",
       "  (921, 0.00),\n",
       "  (922, 0.00),\n",
       "  (924, 0.00),\n",
       "  (928, 0.00),\n",
       "  (929, 0.00),\n",
       "  (930, 0.00),\n",
       "  (931, 0.00),\n",
       "  (933, 0.00),\n",
       "  (935, 0.00),\n",
       "  (936, 0.00),\n",
       "  (940, 0.00),\n",
       "  (941, 0.00),\n",
       "  (942, 0.00),\n",
       "  (943, 0.00),\n",
       "  (945, 0.00),\n",
       "  (947, 0.00),\n",
       "  (948, 0.00),\n",
       "  (949, 0.00),\n",
       "  (956, 0.00),\n",
       "  (958, 0.00),\n",
       "  (959, 0.00),\n",
       "  (960, 0.00),\n",
       "  (961, 0.00),\n",
       "  (964, 0.00),\n",
       "  (965, 0.00),\n",
       "  (967, 0.00),\n",
       "  (969, 0.00),\n",
       "  (970, 0.00),\n",
       "  (972, 0.00),\n",
       "  (974, 0.00),\n",
       "  (975, 0.00),\n",
       "  (976, 0.00),\n",
       "  (977, 0.00),\n",
       "  (979, 0.00),\n",
       "  (980, 0.00),\n",
       "  (986, 0.00),\n",
       "  (989, 0.00),\n",
       "  (990, 0.00),\n",
       "  (993, 0.00),\n",
       "  (994, 0.00)])"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#on validation\n",
    "%precision 2\n",
    "# n, hist = targeted_diversity(learn, 150, 95)\n",
    "# n, hist\n",
    "n, hist = diversity(learn, 10, 95)\n",
    "n, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U6dnR1-3uV_4",
    "outputId": "5f9f3716-2737-444a-c2c5-5e19f6956e3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f59cf2afe48>]"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_hist = sorted(hist, key=lambda x: x[0], reverse = False)\n",
    "values = [elem[1] for elem in sorted_hist]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HEE2CXq3uV_5",
    "outputId": "0dd14d6b-3274-4725-e93e-b000d52daf13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.6468)"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WIUnUh6PuV_-",
    "outputId": "ae887125-3923-4a18-ae13-44268f2b2d3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at batch_no 0\n",
      "at batch_no 100\n",
      "at batch_no 200\n",
      "at batch_no 300\n",
      "at batch_no 400\n",
      "at batch_no 500\n",
      "at batch_no 600\n",
      "at batch_no 700\n",
      "at batch_no 800\n",
      "at batch_no 900\n",
      "at batch_no 1000\n",
      "at batch_no 1100\n",
      "at batch_no 1200\n",
      "at batch_no 1300\n",
      "at batch_no 1400\n",
      "at batch_no 1500\n",
      "at batch_no 1600\n",
      "at batch_no 1700\n",
      "at batch_no 1800\n",
      "at batch_no 1900\n",
      "at batch_no 2000\n",
      "at batch_no 2100\n",
      "at batch_no 2200\n",
      "at batch_no 2300\n",
      "at batch_no 2400\n",
      "at batch_no 2500\n",
      "at batch_no 2600\n",
      "at batch_no 2700\n",
      "at batch_no 2800\n",
      "at batch_no 2900\n",
      "at batch_no 3000\n",
      "at batch_no 3100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(885,\n",
       " [(815, 234.00),\n",
       "  (652, 177.00),\n",
       "  (646, 163.00),\n",
       "  (580, 160.00),\n",
       "  (611, 156.00),\n",
       "  (489, 145.00),\n",
       "  (591, 144.00),\n",
       "  (621, 141.00),\n",
       "  (737, 139.00),\n",
       "  (904, 130.00),\n",
       "  (94, 129.00),\n",
       "  (868, 127.00),\n",
       "  (582, 125.00),\n",
       "  (497, 123.00),\n",
       "  (893, 120.00),\n",
       "  (794, 118.00),\n",
       "  (116, 115.00),\n",
       "  (955, 115.00),\n",
       "  (979, 114.00),\n",
       "  (679, 112.00),\n",
       "  (721, 109.00),\n",
       "  (39, 108.00),\n",
       "  (565, 108.00),\n",
       "  (741, 106.00),\n",
       "  (491, 105.00),\n",
       "  (562, 103.00),\n",
       "  (839, 102.00),\n",
       "  (109, 101.00),\n",
       "  (162, 101.00),\n",
       "  (549, 99.00),\n",
       "  (46, 97.00),\n",
       "  (48, 96.00),\n",
       "  (84, 95.00),\n",
       "  (750, 95.00),\n",
       "  (82, 94.00),\n",
       "  (973, 94.00),\n",
       "  (151, 93.00),\n",
       "  (492, 93.00),\n",
       "  (695, 93.00),\n",
       "  (199, 91.00),\n",
       "  (843, 89.00),\n",
       "  (51, 88.00),\n",
       "  (971, 88.00),\n",
       "  (640, 87.00),\n",
       "  (424, 86.00),\n",
       "  (669, 86.00),\n",
       "  (692, 86.00),\n",
       "  (879, 86.00),\n",
       "  (281, 85.00),\n",
       "  (47, 84.00),\n",
       "  (783, 84.00),\n",
       "  (203, 83.00),\n",
       "  (310, 83.00),\n",
       "  (382, 83.00),\n",
       "  (411, 83.00),\n",
       "  (866, 83.00),\n",
       "  (743, 82.00),\n",
       "  (364, 81.00),\n",
       "  (577, 81.00),\n",
       "  (197, 80.00),\n",
       "  (318, 80.00),\n",
       "  (319, 80.00),\n",
       "  (406, 80.00),\n",
       "  (725, 80.00),\n",
       "  (828, 80.00),\n",
       "  (180, 79.00),\n",
       "  (189, 79.00),\n",
       "  (208, 79.00),\n",
       "  (298, 79.00),\n",
       "  (703, 79.00),\n",
       "  (754, 79.00),\n",
       "  (905, 79.00),\n",
       "  (956, 79.00),\n",
       "  (847, 78.00),\n",
       "  (76, 77.00),\n",
       "  (182, 77.00),\n",
       "  (342, 77.00),\n",
       "  (455, 77.00),\n",
       "  (572, 77.00),\n",
       "  (711, 77.00),\n",
       "  (762, 77.00),\n",
       "  (896, 77.00),\n",
       "  (963, 77.00),\n",
       "  (217, 76.00),\n",
       "  (440, 76.00),\n",
       "  (824, 76.00),\n",
       "  (830, 76.00),\n",
       "  (55, 75.00),\n",
       "  (219, 75.00),\n",
       "  (270, 75.00),\n",
       "  (700, 75.00),\n",
       "  (730, 75.00),\n",
       "  (791, 75.00),\n",
       "  (128, 74.00),\n",
       "  (849, 74.00),\n",
       "  (938, 74.00),\n",
       "  (982, 74.00),\n",
       "  (237, 73.00),\n",
       "  (343, 73.00),\n",
       "  (363, 73.00),\n",
       "  (454, 73.00),\n",
       "  (570, 73.00),\n",
       "  (645, 73.00),\n",
       "  (735, 73.00),\n",
       "  (778, 73.00),\n",
       "  (825, 73.00),\n",
       "  (222, 72.00),\n",
       "  (304, 72.00),\n",
       "  (436, 72.00),\n",
       "  (483, 72.00),\n",
       "  (800, 72.00),\n",
       "  (826, 72.00),\n",
       "  (61, 71.00),\n",
       "  (74, 71.00),\n",
       "  (471, 71.00),\n",
       "  (472, 71.00),\n",
       "  (805, 71.00),\n",
       "  (806, 71.00),\n",
       "  (916, 71.00),\n",
       "  (30, 70.00),\n",
       "  (496, 70.00),\n",
       "  (716, 70.00),\n",
       "  (23, 69.00),\n",
       "  (341, 69.00),\n",
       "  (425, 69.00),\n",
       "  (775, 69.00),\n",
       "  (808, 69.00),\n",
       "  (878, 69.00),\n",
       "  (556, 68.00),\n",
       "  (620, 68.00),\n",
       "  (845, 68.00),\n",
       "  (184, 67.00),\n",
       "  (192, 67.00),\n",
       "  (195, 67.00),\n",
       "  (300, 67.00),\n",
       "  (361, 67.00),\n",
       "  (671, 67.00),\n",
       "  (887, 67.00),\n",
       "  (912, 67.00),\n",
       "  (37, 66.00),\n",
       "  (178, 66.00),\n",
       "  (313, 66.00),\n",
       "  (458, 66.00),\n",
       "  (654, 66.00),\n",
       "  (772, 66.00),\n",
       "  (820, 66.00),\n",
       "  (863, 66.00),\n",
       "  (870, 66.00),\n",
       "  (77, 65.00),\n",
       "  (124, 65.00),\n",
       "  (423, 65.00),\n",
       "  (655, 65.00),\n",
       "  (949, 65.00),\n",
       "  (988, 65.00),\n",
       "  (6, 64.00),\n",
       "  (211, 64.00),\n",
       "  (506, 64.00),\n",
       "  (688, 64.00),\n",
       "  (926, 64.00),\n",
       "  (972, 64.00),\n",
       "  (234, 63.00),\n",
       "  (272, 63.00),\n",
       "  (293, 63.00),\n",
       "  (481, 63.00),\n",
       "  (595, 63.00),\n",
       "  (852, 63.00),\n",
       "  (871, 63.00),\n",
       "  (895, 63.00),\n",
       "  (953, 63.00),\n",
       "  (975, 63.00),\n",
       "  (992, 63.00),\n",
       "  (90, 62.00),\n",
       "  (463, 62.00),\n",
       "  (505, 62.00),\n",
       "  (561, 62.00),\n",
       "  (697, 62.00),\n",
       "  (809, 62.00),\n",
       "  (864, 62.00),\n",
       "  (944, 62.00),\n",
       "  (987, 62.00),\n",
       "  (97, 61.00),\n",
       "  (99, 61.00),\n",
       "  (118, 61.00),\n",
       "  (125, 61.00),\n",
       "  (135, 61.00),\n",
       "  (155, 61.00),\n",
       "  (238, 61.00),\n",
       "  (292, 61.00),\n",
       "  (331, 61.00),\n",
       "  (468, 61.00),\n",
       "  (474, 61.00),\n",
       "  (597, 61.00),\n",
       "  (788, 61.00),\n",
       "  (834, 61.00),\n",
       "  (913, 61.00),\n",
       "  (50, 60.00),\n",
       "  (311, 60.00),\n",
       "  (401, 60.00),\n",
       "  (404, 60.00),\n",
       "  (420, 60.00),\n",
       "  (457, 60.00),\n",
       "  (476, 60.00),\n",
       "  (515, 60.00),\n",
       "  (532, 60.00),\n",
       "  (586, 60.00),\n",
       "  (594, 60.00),\n",
       "  (635, 60.00),\n",
       "  (649, 60.00),\n",
       "  (781, 60.00),\n",
       "  (850, 60.00),\n",
       "  (880, 60.00),\n",
       "  (892, 60.00),\n",
       "  (937, 60.00),\n",
       "  (946, 60.00),\n",
       "  (33, 59.00),\n",
       "  (129, 59.00),\n",
       "  (263, 59.00),\n",
       "  (372, 59.00),\n",
       "  (519, 59.00),\n",
       "  (564, 59.00),\n",
       "  (607, 59.00),\n",
       "  (724, 59.00),\n",
       "  (766, 59.00),\n",
       "  (770, 59.00),\n",
       "  (875, 59.00),\n",
       "  (957, 59.00),\n",
       "  (85, 58.00),\n",
       "  (119, 58.00),\n",
       "  (161, 58.00),\n",
       "  (181, 58.00),\n",
       "  (249, 58.00),\n",
       "  (259, 58.00),\n",
       "  (280, 58.00),\n",
       "  (348, 58.00),\n",
       "  (383, 58.00),\n",
       "  (441, 58.00),\n",
       "  (522, 58.00),\n",
       "  (539, 58.00),\n",
       "  (552, 58.00),\n",
       "  (563, 58.00),\n",
       "  (601, 58.00),\n",
       "  (619, 58.00),\n",
       "  (696, 58.00),\n",
       "  (748, 58.00),\n",
       "  (816, 58.00),\n",
       "  (21, 57.00),\n",
       "  (69, 57.00),\n",
       "  (89, 57.00),\n",
       "  (113, 57.00),\n",
       "  (115, 57.00),\n",
       "  (218, 57.00),\n",
       "  (232, 57.00),\n",
       "  (250, 57.00),\n",
       "  (284, 57.00),\n",
       "  (316, 57.00),\n",
       "  (407, 57.00),\n",
       "  (428, 57.00),\n",
       "  (488, 57.00),\n",
       "  (581, 57.00),\n",
       "  (603, 57.00),\n",
       "  (614, 57.00),\n",
       "  (626, 57.00),\n",
       "  (698, 57.00),\n",
       "  (774, 57.00),\n",
       "  (777, 57.00),\n",
       "  (784, 57.00),\n",
       "  (790, 57.00),\n",
       "  (842, 57.00),\n",
       "  (962, 57.00),\n",
       "  (8, 56.00),\n",
       "  (31, 56.00),\n",
       "  (57, 56.00),\n",
       "  (60, 56.00),\n",
       "  (171, 56.00),\n",
       "  (225, 56.00),\n",
       "  (275, 56.00),\n",
       "  (317, 56.00),\n",
       "  (334, 56.00),\n",
       "  (391, 56.00),\n",
       "  (443, 56.00),\n",
       "  (490, 56.00),\n",
       "  (527, 56.00),\n",
       "  (569, 56.00),\n",
       "  (593, 56.00),\n",
       "  (609, 56.00),\n",
       "  (642, 56.00),\n",
       "  (792, 56.00),\n",
       "  (819, 56.00),\n",
       "  (857, 56.00),\n",
       "  (924, 56.00),\n",
       "  (952, 56.00),\n",
       "  (24, 55.00),\n",
       "  (25, 55.00),\n",
       "  (67, 55.00),\n",
       "  (229, 55.00),\n",
       "  (231, 55.00),\n",
       "  (283, 55.00),\n",
       "  (291, 55.00),\n",
       "  (308, 55.00),\n",
       "  (328, 55.00),\n",
       "  (386, 55.00),\n",
       "  (396, 55.00),\n",
       "  (410, 55.00),\n",
       "  (509, 55.00),\n",
       "  (512, 55.00),\n",
       "  (612, 55.00),\n",
       "  (661, 55.00),\n",
       "  (822, 55.00),\n",
       "  (858, 55.00),\n",
       "  (884, 55.00),\n",
       "  (950, 55.00),\n",
       "  (985, 55.00),\n",
       "  (986, 55.00),\n",
       "  (991, 55.00),\n",
       "  (88, 54.00),\n",
       "  (159, 54.00),\n",
       "  (170, 54.00),\n",
       "  (206, 54.00),\n",
       "  (228, 54.00),\n",
       "  (241, 54.00),\n",
       "  (269, 54.00),\n",
       "  (276, 54.00),\n",
       "  (285, 54.00),\n",
       "  (327, 54.00),\n",
       "  (487, 54.00),\n",
       "  (547, 54.00),\n",
       "  (657, 54.00),\n",
       "  (709, 54.00),\n",
       "  (768, 54.00),\n",
       "  (780, 54.00),\n",
       "  (801, 54.00),\n",
       "  (832, 54.00),\n",
       "  (855, 54.00),\n",
       "  (936, 54.00),\n",
       "  (990, 54.00),\n",
       "  (995, 54.00),\n",
       "  (3, 53.00),\n",
       "  (35, 53.00),\n",
       "  (58, 53.00),\n",
       "  (70, 53.00),\n",
       "  (104, 53.00),\n",
       "  (138, 53.00),\n",
       "  (177, 53.00),\n",
       "  (251, 53.00),\n",
       "  (254, 53.00),\n",
       "  (274, 53.00),\n",
       "  (307, 53.00),\n",
       "  (367, 53.00),\n",
       "  (444, 53.00),\n",
       "  (452, 53.00),\n",
       "  (477, 53.00),\n",
       "  (508, 53.00),\n",
       "  (524, 53.00),\n",
       "  (526, 53.00),\n",
       "  (528, 53.00),\n",
       "  (533, 53.00),\n",
       "  (641, 53.00),\n",
       "  (653, 53.00),\n",
       "  (665, 53.00),\n",
       "  (668, 53.00),\n",
       "  (739, 53.00),\n",
       "  (818, 53.00),\n",
       "  (835, 53.00),\n",
       "  (888, 53.00),\n",
       "  (903, 53.00),\n",
       "  (922, 53.00),\n",
       "  (1, 52.00),\n",
       "  (92, 52.00),\n",
       "  (164, 52.00),\n",
       "  (176, 52.00),\n",
       "  (216, 52.00),\n",
       "  (239, 52.00),\n",
       "  (431, 52.00),\n",
       "  (448, 52.00),\n",
       "  (478, 52.00),\n",
       "  (701, 52.00),\n",
       "  (738, 52.00),\n",
       "  (752, 52.00),\n",
       "  (779, 52.00),\n",
       "  (787, 52.00),\n",
       "  (829, 52.00),\n",
       "  (833, 52.00),\n",
       "  (840, 52.00),\n",
       "  (877, 52.00),\n",
       "  (917, 52.00),\n",
       "  (939, 52.00),\n",
       "  (943, 52.00),\n",
       "  (133, 51.00),\n",
       "  (160, 51.00),\n",
       "  (188, 51.00),\n",
       "  (196, 51.00),\n",
       "  (212, 51.00),\n",
       "  (221, 51.00),\n",
       "  (286, 51.00),\n",
       "  (362, 51.00),\n",
       "  (377, 51.00),\n",
       "  (416, 51.00),\n",
       "  (419, 51.00),\n",
       "  (514, 51.00),\n",
       "  (545, 51.00),\n",
       "  (592, 51.00),\n",
       "  (636, 51.00),\n",
       "  (637, 51.00),\n",
       "  (746, 51.00),\n",
       "  (757, 51.00),\n",
       "  (764, 51.00),\n",
       "  (776, 51.00),\n",
       "  (902, 51.00),\n",
       "  (927, 51.00),\n",
       "  (13, 50.00),\n",
       "  (36, 50.00),\n",
       "  (102, 50.00),\n",
       "  (114, 50.00),\n",
       "  (126, 50.00),\n",
       "  (261, 50.00),\n",
       "  (277, 50.00),\n",
       "  (289, 50.00),\n",
       "  (294, 50.00),\n",
       "  (295, 50.00),\n",
       "  (301, 50.00),\n",
       "  (352, 50.00),\n",
       "  (358, 50.00),\n",
       "  (373, 50.00),\n",
       "  (449, 50.00),\n",
       "  (467, 50.00),\n",
       "  (604, 50.00),\n",
       "  (608, 50.00),\n",
       "  (618, 50.00),\n",
       "  (639, 50.00),\n",
       "  (659, 50.00),\n",
       "  (685, 50.00),\n",
       "  (765, 50.00),\n",
       "  (997, 50.00),\n",
       "  (0, 49.00),\n",
       "  (9, 49.00),\n",
       "  (123, 49.00),\n",
       "  (172, 49.00),\n",
       "  (267, 49.00),\n",
       "  (325, 49.00),\n",
       "  (375, 49.00),\n",
       "  (376, 49.00),\n",
       "  (378, 49.00),\n",
       "  (387, 49.00),\n",
       "  (388, 49.00),\n",
       "  (398, 49.00),\n",
       "  (523, 49.00),\n",
       "  (535, 49.00),\n",
       "  (541, 49.00),\n",
       "  (566, 49.00),\n",
       "  (583, 49.00),\n",
       "  (602, 49.00),\n",
       "  (667, 49.00),\n",
       "  (704, 49.00),\n",
       "  (763, 49.00),\n",
       "  (771, 49.00),\n",
       "  (874, 49.00),\n",
       "  (11, 48.00),\n",
       "  (12, 48.00),\n",
       "  (14, 48.00),\n",
       "  (15, 48.00),\n",
       "  (16, 48.00),\n",
       "  (18, 48.00),\n",
       "  (41, 48.00),\n",
       "  (71, 48.00),\n",
       "  (78, 48.00),\n",
       "  (134, 48.00),\n",
       "  (137, 48.00),\n",
       "  (141, 48.00),\n",
       "  (156, 48.00),\n",
       "  (194, 48.00),\n",
       "  (209, 48.00),\n",
       "  (214, 48.00),\n",
       "  (255, 48.00),\n",
       "  (264, 48.00),\n",
       "  (279, 48.00),\n",
       "  (288, 48.00),\n",
       "  (290, 48.00),\n",
       "  (312, 48.00),\n",
       "  (336, 48.00),\n",
       "  (340, 48.00),\n",
       "  (349, 48.00),\n",
       "  (354, 48.00),\n",
       "  (413, 48.00),\n",
       "  (451, 48.00),\n",
       "  (517, 48.00),\n",
       "  (628, 48.00),\n",
       "  (683, 48.00),\n",
       "  (684, 48.00),\n",
       "  (758, 48.00),\n",
       "  (797, 48.00),\n",
       "  (865, 48.00),\n",
       "  (872, 48.00),\n",
       "  (881, 48.00),\n",
       "  (890, 48.00),\n",
       "  (891, 48.00),\n",
       "  (915, 48.00),\n",
       "  (951, 48.00),\n",
       "  (994, 48.00),\n",
       "  (40, 47.00),\n",
       "  (53, 47.00),\n",
       "  (100, 47.00),\n",
       "  (101, 47.00),\n",
       "  (110, 47.00),\n",
       "  (130, 47.00),\n",
       "  (136, 47.00),\n",
       "  (227, 47.00),\n",
       "  (243, 47.00),\n",
       "  (253, 47.00),\n",
       "  (256, 47.00),\n",
       "  (265, 47.00),\n",
       "  (321, 47.00),\n",
       "  (333, 47.00),\n",
       "  (335, 47.00),\n",
       "  (337, 47.00),\n",
       "  (350, 47.00),\n",
       "  (351, 47.00),\n",
       "  (395, 47.00),\n",
       "  (426, 47.00),\n",
       "  (503, 47.00),\n",
       "  (518, 47.00),\n",
       "  (560, 47.00),\n",
       "  (576, 47.00),\n",
       "  (606, 47.00),\n",
       "  (707, 47.00),\n",
       "  (732, 47.00),\n",
       "  (759, 47.00),\n",
       "  (769, 47.00),\n",
       "  (807, 47.00),\n",
       "  (886, 47.00),\n",
       "  (5, 46.00),\n",
       "  (22, 46.00),\n",
       "  (56, 46.00),\n",
       "  (63, 46.00),\n",
       "  (65, 46.00),\n",
       "  (72, 46.00),\n",
       "  (79, 46.00),\n",
       "  (87, 46.00),\n",
       "  (95, 46.00),\n",
       "  (108, 46.00),\n",
       "  (149, 46.00),\n",
       "  (157, 46.00),\n",
       "  (201, 46.00),\n",
       "  (215, 46.00),\n",
       "  (266, 46.00),\n",
       "  (320, 46.00),\n",
       "  (323, 46.00),\n",
       "  (324, 46.00),\n",
       "  (366, 46.00),\n",
       "  (370, 46.00),\n",
       "  (397, 46.00),\n",
       "  (422, 46.00),\n",
       "  (432, 46.00),\n",
       "  (433, 46.00),\n",
       "  (434, 46.00),\n",
       "  (530, 46.00),\n",
       "  (616, 46.00),\n",
       "  (658, 46.00),\n",
       "  (664, 46.00),\n",
       "  (751, 46.00),\n",
       "  (753, 46.00),\n",
       "  (796, 46.00),\n",
       "  (823, 46.00),\n",
       "  (848, 46.00),\n",
       "  (867, 46.00),\n",
       "  (882, 46.00),\n",
       "  (918, 46.00),\n",
       "  (983, 46.00),\n",
       "  (989, 46.00),\n",
       "  (993, 46.00),\n",
       "  (2, 45.00),\n",
       "  (28, 45.00),\n",
       "  (66, 45.00),\n",
       "  (96, 45.00),\n",
       "  (105, 45.00),\n",
       "  (121, 45.00),\n",
       "  (139, 45.00),\n",
       "  (144, 45.00),\n",
       "  (169, 45.00),\n",
       "  (191, 45.00),\n",
       "  (247, 45.00),\n",
       "  (273, 45.00),\n",
       "  (299, 45.00),\n",
       "  (326, 45.00),\n",
       "  (332, 45.00),\n",
       "  (339, 45.00),\n",
       "  (344, 45.00),\n",
       "  (355, 45.00),\n",
       "  (365, 45.00),\n",
       "  (389, 45.00),\n",
       "  (392, 45.00),\n",
       "  (445, 45.00),\n",
       "  (571, 45.00),\n",
       "  (599, 45.00),\n",
       "  (625, 45.00),\n",
       "  (674, 45.00),\n",
       "  (734, 45.00),\n",
       "  (755, 45.00),\n",
       "  (817, 45.00),\n",
       "  (853, 45.00),\n",
       "  (900, 45.00),\n",
       "  (910, 45.00),\n",
       "  (75, 44.00),\n",
       "  (131, 44.00),\n",
       "  (186, 44.00),\n",
       "  (223, 44.00),\n",
       "  (244, 44.00),\n",
       "  (252, 44.00),\n",
       "  (405, 44.00),\n",
       "  (412, 44.00),\n",
       "  (417, 44.00),\n",
       "  (473, 44.00),\n",
       "  (475, 44.00),\n",
       "  (486, 44.00),\n",
       "  (579, 44.00),\n",
       "  (613, 44.00),\n",
       "  (682, 44.00),\n",
       "  (702, 44.00),\n",
       "  (706, 44.00),\n",
       "  (727, 44.00),\n",
       "  (821, 44.00),\n",
       "  (941, 44.00),\n",
       "  (968, 44.00),\n",
       "  (984, 44.00),\n",
       "  (44, 43.00),\n",
       "  (83, 43.00),\n",
       "  (107, 43.00),\n",
       "  (142, 43.00),\n",
       "  (198, 43.00),\n",
       "  (268, 43.00),\n",
       "  (330, 43.00),\n",
       "  (353, 43.00),\n",
       "  (357, 43.00),\n",
       "  (360, 43.00),\n",
       "  (381, 43.00),\n",
       "  (384, 43.00),\n",
       "  (414, 43.00),\n",
       "  (495, 43.00),\n",
       "  (537, 43.00),\n",
       "  (542, 43.00),\n",
       "  (717, 43.00),\n",
       "  (782, 43.00),\n",
       "  (844, 43.00),\n",
       "  (873, 43.00),\n",
       "  (907, 43.00),\n",
       "  (920, 43.00),\n",
       "  (959, 43.00),\n",
       "  (998, 43.00),\n",
       "  (7, 42.00),\n",
       "  (17, 42.00),\n",
       "  (19, 42.00),\n",
       "  (42, 42.00),\n",
       "  (80, 42.00),\n",
       "  (93, 42.00),\n",
       "  (112, 42.00),\n",
       "  (132, 42.00),\n",
       "  (154, 42.00),\n",
       "  (174, 42.00),\n",
       "  (193, 42.00),\n",
       "  (245, 42.00),\n",
       "  (260, 42.00),\n",
       "  (306, 42.00),\n",
       "  (309, 42.00),\n",
       "  (421, 42.00),\n",
       "  (429, 42.00),\n",
       "  (437, 42.00),\n",
       "  (447, 42.00),\n",
       "  (464, 42.00),\n",
       "  (485, 42.00),\n",
       "  (507, 42.00),\n",
       "  (510, 42.00),\n",
       "  (538, 42.00),\n",
       "  (575, 42.00),\n",
       "  (633, 42.00),\n",
       "  (656, 42.00),\n",
       "  (666, 42.00),\n",
       "  (690, 42.00),\n",
       "  (710, 42.00),\n",
       "  (799, 42.00),\n",
       "  (889, 42.00),\n",
       "  (894, 42.00),\n",
       "  (919, 42.00),\n",
       "  (932, 42.00),\n",
       "  (933, 42.00),\n",
       "  (981, 42.00),\n",
       "  (999, 42.00),\n",
       "  (117, 41.00),\n",
       "  (127, 41.00),\n",
       "  (153, 41.00),\n",
       "  (190, 41.00),\n",
       "  (224, 41.00),\n",
       "  (258, 41.00),\n",
       "  (278, 41.00),\n",
       "  (322, 41.00),\n",
       "  (390, 41.00),\n",
       "  (393, 41.00),\n",
       "  (430, 41.00),\n",
       "  (574, 41.00),\n",
       "  (712, 41.00),\n",
       "  (723, 41.00),\n",
       "  (795, 41.00),\n",
       "  (854, 41.00),\n",
       "  (898, 41.00),\n",
       "  (929, 41.00),\n",
       "  (27, 40.00),\n",
       "  (230, 40.00),\n",
       "  (242, 40.00),\n",
       "  (257, 40.00),\n",
       "  (287, 40.00),\n",
       "  (418, 40.00),\n",
       "  (500, 40.00),\n",
       "  (546, 40.00),\n",
       "  (548, 40.00),\n",
       "  (558, 40.00),\n",
       "  (573, 40.00),\n",
       "  (584, 40.00),\n",
       "  (600, 40.00),\n",
       "  (610, 40.00),\n",
       "  (713, 40.00),\n",
       "  (736, 40.00),\n",
       "  (749, 40.00),\n",
       "  (837, 40.00),\n",
       "  (862, 40.00),\n",
       "  (921, 40.00),\n",
       "  (925, 40.00),\n",
       "  (996, 40.00),\n",
       "  (173, 39.00),\n",
       "  (183, 39.00),\n",
       "  (262, 39.00),\n",
       "  (296, 39.00),\n",
       "  (297, 39.00),\n",
       "  (302, 39.00),\n",
       "  (329, 39.00),\n",
       "  (368, 39.00),\n",
       "  (435, 39.00),\n",
       "  (470, 39.00),\n",
       "  (480, 39.00),\n",
       "  (513, 39.00),\n",
       "  (520, 39.00),\n",
       "  (529, 39.00),\n",
       "  (553, 39.00),\n",
       "  (670, 39.00),\n",
       "  (672, 39.00),\n",
       "  (677, 39.00),\n",
       "  (694, 39.00),\n",
       "  (722, 39.00),\n",
       "  (726, 39.00),\n",
       "  (756, 39.00),\n",
       "  (812, 39.00),\n",
       "  (945, 39.00),\n",
       "  (43, 38.00),\n",
       "  (91, 38.00),\n",
       "  (210, 38.00),\n",
       "  (235, 38.00),\n",
       "  (236, 38.00),\n",
       "  (305, 38.00),\n",
       "  (314, 38.00),\n",
       "  (439, 38.00),\n",
       "  (442, 38.00),\n",
       "  (456, 38.00),\n",
       "  (462, 38.00),\n",
       "  (466, 38.00),\n",
       "  (501, 38.00),\n",
       "  (540, 38.00),\n",
       "  (555, 38.00),\n",
       "  (559, 38.00),\n",
       "  (643, 38.00),\n",
       "  (687, 38.00),\n",
       "  (699, 38.00),\n",
       "  (708, 38.00),\n",
       "  (719, 38.00),\n",
       "  (38, 37.00),\n",
       "  (52, 37.00),\n",
       "  (111, 37.00),\n",
       "  (140, 37.00),\n",
       "  (175, 37.00),\n",
       "  (204, 37.00),\n",
       "  (248, 37.00),\n",
       "  (338, 37.00),\n",
       "  (346, 37.00),\n",
       "  (379, 37.00),\n",
       "  (450, 37.00),\n",
       "  (494, 37.00),\n",
       "  (554, 37.00),\n",
       "  (615, 37.00),\n",
       "  (630, 37.00),\n",
       "  (650, 37.00),\n",
       "  (678, 37.00),\n",
       "  (693, 37.00),\n",
       "  (714, 37.00),\n",
       "  (761, 37.00),\n",
       "  (814, 37.00),\n",
       "  (831, 37.00),\n",
       "  (934, 37.00),\n",
       "  (10, 36.00),\n",
       "  (26, 36.00),\n",
       "  (45, 36.00),\n",
       "  (62, 36.00),\n",
       "  (98, 36.00),\n",
       "  (120, 36.00),\n",
       "  (145, 36.00),\n",
       "  (200, 36.00),\n",
       "  (207, 36.00),\n",
       "  (408, 36.00),\n",
       "  (427, 36.00),\n",
       "  (453, 36.00),\n",
       "  (511, 36.00),\n",
       "  (588, 36.00),\n",
       "  (827, 36.00),\n",
       "  (851, 36.00),\n",
       "  (20, 35.00),\n",
       "  (143, 35.00),\n",
       "  (148, 35.00),\n",
       "  (220, 35.00),\n",
       "  (347, 35.00),\n",
       "  (374, 35.00),\n",
       "  (380, 35.00),\n",
       "  (409, 35.00),\n",
       "  (415, 35.00),\n",
       "  (543, 35.00),\n",
       "  (605, 35.00),\n",
       "  (627, 35.00),\n",
       "  (745, 35.00),\n",
       "  (760, 35.00),\n",
       "  (793, 35.00),\n",
       "  (798, 35.00),\n",
       "  (846, 35.00),\n",
       "  (958, 35.00),\n",
       "  (73, 34.00),\n",
       "  (226, 34.00),\n",
       "  (399, 34.00),\n",
       "  (465, 34.00),\n",
       "  (720, 34.00),\n",
       "  (786, 34.00),\n",
       "  (802, 34.00),\n",
       "  (861, 34.00),\n",
       "  (897, 34.00),\n",
       "  (928, 34.00),\n",
       "  (81, 33.00),\n",
       "  (152, 33.00),\n",
       "  (158, 33.00),\n",
       "  (205, 33.00),\n",
       "  (213, 33.00),\n",
       "  (385, 33.00),\n",
       "  (647, 33.00),\n",
       "  (803, 33.00),\n",
       "  (859, 33.00),\n",
       "  (964, 33.00),\n",
       "  (59, 32.00),\n",
       "  (86, 32.00),\n",
       "  (146, 32.00),\n",
       "  (356, 32.00),\n",
       "  (359, 32.00),\n",
       "  (371, 32.00),\n",
       "  (402, 32.00),\n",
       "  (629, 32.00),\n",
       "  (883, 32.00),\n",
       "  (947, 32.00),\n",
       "  (980, 32.00),\n",
       "  (106, 31.00),\n",
       "  (179, 31.00),\n",
       "  (233, 31.00),\n",
       "  (403, 31.00),\n",
       "  (459, 31.00),\n",
       "  (502, 31.00),\n",
       "  (521, 31.00),\n",
       "  (744, 31.00),\n",
       "  (914, 31.00),\n",
       "  (923, 31.00),\n",
       "  (954, 31.00),\n",
       "  (64, 30.00),\n",
       "  (166, 30.00),\n",
       "  (202, 30.00),\n",
       "  (345, 30.00),\n",
       "  (469, 30.00),\n",
       "  (484, 30.00),\n",
       "  (531, 30.00),\n",
       "  (551, 30.00),\n",
       "  (568, 30.00),\n",
       "  (578, 30.00),\n",
       "  (589, 30.00),\n",
       "  (634, 30.00),\n",
       "  (663, 30.00),\n",
       "  (705, 30.00),\n",
       "  (948, 30.00),\n",
       "  (187, 29.00),\n",
       "  (461, 29.00),\n",
       "  (498, 29.00),\n",
       "  (557, 29.00),\n",
       "  (585, 29.00),\n",
       "  (617, 29.00),\n",
       "  (860, 29.00),\n",
       "  (966, 29.00),\n",
       "  (4, 28.00),\n",
       "  (29, 28.00),\n",
       "  (122, 28.00),\n",
       "  (596, 28.00),\n",
       "  (632, 28.00),\n",
       "  (676, 28.00),\n",
       "  (691, 28.00),\n",
       "  (733, 28.00),\n",
       "  (747, 28.00),\n",
       "  (49, 27.00),\n",
       "  (54, 27.00),\n",
       "  (147, 27.00),\n",
       "  (150, 27.00),\n",
       "  (271, 27.00),\n",
       "  (303, 27.00),\n",
       "  (369, 27.00),\n",
       "  (567, 27.00),\n",
       "  (587, 27.00),\n",
       "  (624, 27.00),\n",
       "  (644, 27.00),\n",
       "  (660, 27.00),\n",
       "  (718, 27.00),\n",
       "  (767, 27.00),\n",
       "  (789, 27.00),\n",
       "  (32, 26.00),\n",
       "  (516, 26.00),\n",
       "  (544, 26.00),\n",
       "  (631, 26.00),\n",
       "  (731, 26.00),\n",
       "  (804, 26.00),\n",
       "  (869, 26.00),\n",
       "  (965, 26.00),\n",
       "  (163, 25.00),\n",
       "  (168, 25.00),\n",
       "  (394, 25.00),\n",
       "  (479, 25.00),\n",
       "  (482, 25.00),\n",
       "  (536, 25.00),\n",
       "  (590, 25.00),\n",
       "  (623, 25.00),\n",
       "  (686, 25.00),\n",
       "  (838, 25.00),\n",
       "  (908, 25.00),\n",
       "  (165, 24.00),\n",
       "  (785, 24.00),\n",
       "  (901, 24.00),\n",
       "  (931, 24.00),\n",
       "  (942, 24.00),\n",
       "  (185, 23.00),\n",
       "  (240, 23.00),\n",
       "  (499, 23.00),\n",
       "  (638, 23.00),\n",
       "  (680, 23.00),\n",
       "  (876, 23.00),\n",
       "  (974, 23.00),\n",
       "  (68, 22.00),\n",
       "  (525, 22.00),\n",
       "  (740, 22.00),\n",
       "  (773, 22.00),\n",
       "  (811, 22.00),\n",
       "  (856, 22.00),\n",
       "  (909, 22.00),\n",
       "  (911, 22.00),\n",
       "  (246, 21.00),\n",
       "  (438, 21.00),\n",
       "  (675, 21.00),\n",
       "  (885, 21.00),\n",
       "  (315, 20.00),\n",
       "  (400, 20.00),\n",
       "  (662, 20.00),\n",
       "  (715, 20.00),\n",
       "  (977, 20.00),\n",
       "  (598, 19.00),\n",
       "  (729, 19.00),\n",
       "  (622, 18.00),\n",
       "  (651, 18.00),\n",
       "  (103, 17.00),\n",
       "  (550, 17.00),\n",
       "  (648, 17.00),\n",
       "  (728, 17.00),\n",
       "  (841, 17.00),\n",
       "  (976, 17.00),\n",
       "  (460, 16.00),\n",
       "  (504, 16.00),\n",
       "  (836, 16.00),\n",
       "  (930, 16.00),\n",
       "  (970, 16.00),\n",
       "  (282, 15.00),\n",
       "  (446, 15.00),\n",
       "  (493, 15.00),\n",
       "  (534, 15.00),\n",
       "  (906, 15.00),\n",
       "  (813, 14.00),\n",
       "  (969, 13.00),\n",
       "  (742, 12.00),\n",
       "  (940, 12.00),\n",
       "  (34, 11.00),\n",
       "  (167, 11.00),\n",
       "  (689, 11.00),\n",
       "  (967, 11.00),\n",
       "  (978, 11.00),\n",
       "  (681, 9.00),\n",
       "  (899, 9.00),\n",
       "  (960, 9.00),\n",
       "  (673, 8.00),\n",
       "  (810, 7.00),\n",
       "  (935, 6.00),\n",
       "  (961, 2.00)])"
      ]
     },
     "execution_count": 97,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#on test\n",
    "%precision 2\n",
    "# n, hist = targeted_diversity(learn, 150, 95)\n",
    "# n, hist\n",
    "n, hist = targeted_diversity(learn, 10, 95)\n",
    "n, hist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FmSuhirAuWAJ",
    "outputId": "5d5682f7-0d96-437d-f1bb-eb2f02e8e11f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at batch_no 0\n",
      "at batch_no 100\n",
      "at batch_no 200\n",
      "at batch_no 300\n",
      "at batch_no 400\n",
      "at batch_no 500\n",
      "at batch_no 600\n",
      "at batch_no 700\n",
      "at batch_no 800\n",
      "at batch_no 900\n",
      "at batch_no 1000\n",
      "at batch_no 1100\n",
      "at batch_no 1200\n",
      "at batch_no 1300\n",
      "at batch_no 1400\n",
      "at batch_no 1500\n",
      "at batch_no 1600\n",
      "at batch_no 1700\n",
      "at batch_no 1800\n",
      "at batch_no 1900\n",
      "at batch_no 2000\n",
      "at batch_no 2100\n",
      "at batch_no 2200\n",
      "at batch_no 2300\n",
      "at batch_no 2400\n",
      "at batch_no 2500\n",
      "at batch_no 2600\n",
      "at batch_no 2700\n",
      "at batch_no 2800\n",
      "at batch_no 2900\n",
      "at batch_no 3000\n",
      "at batch_no 3100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(885,\n",
       " [(815, 239.00),\n",
       "  (652, 181.00),\n",
       "  (646, 168.00),\n",
       "  (580, 163.00),\n",
       "  (611, 155.00),\n",
       "  (591, 148.00),\n",
       "  (737, 143.00),\n",
       "  (489, 142.00),\n",
       "  (621, 139.00),\n",
       "  (904, 134.00),\n",
       "  (794, 130.00),\n",
       "  (497, 127.00),\n",
       "  (893, 127.00),\n",
       "  (582, 125.00),\n",
       "  (94, 123.00),\n",
       "  (955, 120.00),\n",
       "  (116, 115.00),\n",
       "  (868, 115.00),\n",
       "  (39, 112.00),\n",
       "  (679, 112.00),\n",
       "  (565, 110.00),\n",
       "  (162, 109.00),\n",
       "  (491, 108.00),\n",
       "  (721, 108.00),\n",
       "  (979, 108.00),\n",
       "  (741, 105.00),\n",
       "  (839, 105.00),\n",
       "  (109, 104.00),\n",
       "  (562, 104.00),\n",
       "  (84, 103.00),\n",
       "  (549, 102.00),\n",
       "  (48, 99.00),\n",
       "  (82, 99.00),\n",
       "  (492, 99.00),\n",
       "  (51, 98.00),\n",
       "  (973, 96.00),\n",
       "  (199, 95.00),\n",
       "  (750, 95.00),\n",
       "  (46, 93.00),\n",
       "  (640, 92.00),\n",
       "  (695, 92.00),\n",
       "  (151, 88.00),\n",
       "  (971, 88.00),\n",
       "  (783, 87.00),\n",
       "  (843, 87.00),\n",
       "  (203, 86.00),\n",
       "  (669, 86.00),\n",
       "  (692, 86.00),\n",
       "  (424, 84.00),\n",
       "  (956, 84.00),\n",
       "  (281, 83.00),\n",
       "  (577, 83.00),\n",
       "  (828, 82.00),\n",
       "  (866, 82.00),\n",
       "  (47, 81.00),\n",
       "  (310, 81.00),\n",
       "  (743, 81.00),\n",
       "  (847, 81.00),\n",
       "  (61, 80.00),\n",
       "  (208, 80.00),\n",
       "  (703, 80.00),\n",
       "  (180, 79.00),\n",
       "  (182, 79.00),\n",
       "  (382, 79.00),\n",
       "  (830, 79.00),\n",
       "  (189, 78.00),\n",
       "  (219, 78.00),\n",
       "  (319, 78.00),\n",
       "  (343, 78.00),\n",
       "  (411, 78.00),\n",
       "  (725, 78.00),\n",
       "  (879, 78.00),\n",
       "  (342, 77.00),\n",
       "  (406, 77.00),\n",
       "  (440, 77.00),\n",
       "  (454, 77.00),\n",
       "  (778, 77.00),\n",
       "  (128, 76.00),\n",
       "  (197, 76.00),\n",
       "  (270, 76.00),\n",
       "  (298, 76.00),\n",
       "  (570, 76.00),\n",
       "  (824, 76.00),\n",
       "  (982, 76.00),\n",
       "  (711, 75.00),\n",
       "  (754, 75.00),\n",
       "  (762, 75.00),\n",
       "  (791, 75.00),\n",
       "  (963, 75.00),\n",
       "  (55, 74.00),\n",
       "  (217, 74.00),\n",
       "  (237, 74.00),\n",
       "  (364, 74.00),\n",
       "  (455, 74.00),\n",
       "  (572, 74.00),\n",
       "  (671, 74.00),\n",
       "  (805, 74.00),\n",
       "  (905, 74.00),\n",
       "  (318, 73.00),\n",
       "  (436, 73.00),\n",
       "  (735, 73.00),\n",
       "  (30, 72.00),\n",
       "  (304, 72.00),\n",
       "  (363, 72.00),\n",
       "  (472, 72.00),\n",
       "  (645, 72.00),\n",
       "  (730, 72.00),\n",
       "  (800, 72.00),\n",
       "  (845, 72.00),\n",
       "  (76, 71.00),\n",
       "  (483, 71.00),\n",
       "  (496, 71.00),\n",
       "  (716, 71.00),\n",
       "  (878, 71.00),\n",
       "  (938, 71.00),\n",
       "  (23, 70.00),\n",
       "  (50, 70.00),\n",
       "  (313, 70.00),\n",
       "  (471, 70.00),\n",
       "  (654, 70.00),\n",
       "  (700, 70.00),\n",
       "  (806, 70.00),\n",
       "  (826, 70.00),\n",
       "  (192, 69.00),\n",
       "  (820, 69.00),\n",
       "  (825, 69.00),\n",
       "  (896, 69.00),\n",
       "  (195, 68.00),\n",
       "  (425, 68.00),\n",
       "  (849, 68.00),\n",
       "  (916, 68.00),\n",
       "  (74, 67.00),\n",
       "  (222, 67.00),\n",
       "  (341, 67.00),\n",
       "  (468, 67.00),\n",
       "  (808, 67.00),\n",
       "  (949, 67.00),\n",
       "  (37, 66.00),\n",
       "  (77, 66.00),\n",
       "  (556, 66.00),\n",
       "  (688, 66.00),\n",
       "  (850, 66.00),\n",
       "  (912, 66.00),\n",
       "  (944, 66.00),\n",
       "  (972, 66.00),\n",
       "  (655, 65.00),\n",
       "  (775, 65.00),\n",
       "  (926, 65.00),\n",
       "  (97, 64.00),\n",
       "  (124, 64.00),\n",
       "  (178, 64.00),\n",
       "  (293, 64.00),\n",
       "  (772, 64.00),\n",
       "  (863, 64.00),\n",
       "  (870, 64.00),\n",
       "  (880, 64.00),\n",
       "  (992, 64.00),\n",
       "  (125, 63.00),\n",
       "  (181, 63.00),\n",
       "  (184, 63.00),\n",
       "  (211, 63.00),\n",
       "  (238, 63.00),\n",
       "  (272, 63.00),\n",
       "  (300, 63.00),\n",
       "  (311, 63.00),\n",
       "  (331, 63.00),\n",
       "  (420, 63.00),\n",
       "  (458, 63.00),\n",
       "  (506, 63.00),\n",
       "  (515, 63.00),\n",
       "  (620, 63.00),\n",
       "  (864, 63.00),\n",
       "  (892, 63.00),\n",
       "  (953, 63.00),\n",
       "  (90, 62.00),\n",
       "  (135, 62.00),\n",
       "  (155, 62.00),\n",
       "  (161, 62.00),\n",
       "  (234, 62.00),\n",
       "  (505, 62.00),\n",
       "  (561, 62.00),\n",
       "  (619, 62.00),\n",
       "  (784, 62.00),\n",
       "  (819, 62.00),\n",
       "  (871, 62.00),\n",
       "  (975, 62.00),\n",
       "  (988, 62.00),\n",
       "  (6, 61.00),\n",
       "  (249, 61.00),\n",
       "  (292, 61.00),\n",
       "  (476, 61.00),\n",
       "  (527, 61.00),\n",
       "  (635, 61.00),\n",
       "  (724, 61.00),\n",
       "  (788, 61.00),\n",
       "  (895, 61.00),\n",
       "  (937, 61.00),\n",
       "  (946, 61.00),\n",
       "  (99, 60.00),\n",
       "  (225, 60.00),\n",
       "  (423, 60.00),\n",
       "  (463, 60.00),\n",
       "  (481, 60.00),\n",
       "  (586, 60.00),\n",
       "  (595, 60.00),\n",
       "  (626, 60.00),\n",
       "  (748, 60.00),\n",
       "  (781, 60.00),\n",
       "  (792, 60.00),\n",
       "  (875, 60.00),\n",
       "  (884, 60.00),\n",
       "  (887, 60.00),\n",
       "  (231, 59.00),\n",
       "  (316, 59.00),\n",
       "  (327, 59.00),\n",
       "  (361, 59.00),\n",
       "  (391, 59.00),\n",
       "  (401, 59.00),\n",
       "  (474, 59.00),\n",
       "  (509, 59.00),\n",
       "  (593, 59.00),\n",
       "  (597, 59.00),\n",
       "  (641, 59.00),\n",
       "  (697, 59.00),\n",
       "  (790, 59.00),\n",
       "  (952, 59.00),\n",
       "  (8, 58.00),\n",
       "  (115, 58.00),\n",
       "  (118, 58.00),\n",
       "  (348, 58.00),\n",
       "  (404, 58.00),\n",
       "  (410, 58.00),\n",
       "  (478, 58.00),\n",
       "  (532, 58.00),\n",
       "  (594, 58.00),\n",
       "  (609, 58.00),\n",
       "  (614, 58.00),\n",
       "  (770, 58.00),\n",
       "  (809, 58.00),\n",
       "  (957, 58.00),\n",
       "  (962, 58.00),\n",
       "  (991, 58.00),\n",
       "  (24, 57.00),\n",
       "  (33, 57.00),\n",
       "  (113, 57.00),\n",
       "  (129, 57.00),\n",
       "  (275, 57.00),\n",
       "  (308, 57.00),\n",
       "  (407, 57.00),\n",
       "  (441, 57.00),\n",
       "  (457, 57.00),\n",
       "  (477, 57.00),\n",
       "  (522, 57.00),\n",
       "  (539, 57.00),\n",
       "  (564, 57.00),\n",
       "  (581, 57.00),\n",
       "  (607, 57.00),\n",
       "  (698, 57.00),\n",
       "  (774, 57.00),\n",
       "  (816, 57.00),\n",
       "  (834, 57.00),\n",
       "  (842, 57.00),\n",
       "  (877, 57.00),\n",
       "  (913, 57.00),\n",
       "  (25, 56.00),\n",
       "  (57, 56.00),\n",
       "  (119, 56.00),\n",
       "  (171, 56.00),\n",
       "  (280, 56.00),\n",
       "  (284, 56.00),\n",
       "  (317, 56.00),\n",
       "  (334, 56.00),\n",
       "  (396, 56.00),\n",
       "  (428, 56.00),\n",
       "  (443, 56.00),\n",
       "  (488, 56.00),\n",
       "  (601, 56.00),\n",
       "  (642, 56.00),\n",
       "  (649, 56.00),\n",
       "  (661, 56.00),\n",
       "  (696, 56.00),\n",
       "  (852, 56.00),\n",
       "  (950, 56.00),\n",
       "  (987, 56.00),\n",
       "  (21, 55.00),\n",
       "  (60, 55.00),\n",
       "  (69, 55.00),\n",
       "  (85, 55.00),\n",
       "  (88, 55.00),\n",
       "  (104, 55.00),\n",
       "  (170, 55.00),\n",
       "  (232, 55.00),\n",
       "  (250, 55.00),\n",
       "  (254, 55.00),\n",
       "  (259, 55.00),\n",
       "  (274, 55.00),\n",
       "  (283, 55.00),\n",
       "  (291, 55.00),\n",
       "  (328, 55.00),\n",
       "  (367, 55.00),\n",
       "  (372, 55.00),\n",
       "  (375, 55.00),\n",
       "  (452, 55.00),\n",
       "  (512, 55.00),\n",
       "  (547, 55.00),\n",
       "  (563, 55.00),\n",
       "  (569, 55.00),\n",
       "  (603, 55.00),\n",
       "  (608, 55.00),\n",
       "  (618, 55.00),\n",
       "  (653, 55.00),\n",
       "  (766, 55.00),\n",
       "  (780, 55.00),\n",
       "  (797, 55.00),\n",
       "  (801, 55.00),\n",
       "  (822, 55.00),\n",
       "  (829, 55.00),\n",
       "  (840, 55.00),\n",
       "  (857, 55.00),\n",
       "  (903, 55.00),\n",
       "  (936, 55.00),\n",
       "  (206, 54.00),\n",
       "  (228, 54.00),\n",
       "  (251, 54.00),\n",
       "  (263, 54.00),\n",
       "  (285, 54.00),\n",
       "  (307, 54.00),\n",
       "  (386, 54.00),\n",
       "  (419, 54.00),\n",
       "  (448, 54.00),\n",
       "  (524, 54.00),\n",
       "  (701, 54.00),\n",
       "  (768, 54.00),\n",
       "  (777, 54.00),\n",
       "  (832, 54.00),\n",
       "  (835, 54.00),\n",
       "  (888, 54.00),\n",
       "  (902, 54.00),\n",
       "  (924, 54.00),\n",
       "  (939, 54.00),\n",
       "  (943, 54.00),\n",
       "  (985, 54.00),\n",
       "  (986, 54.00),\n",
       "  (31, 53.00),\n",
       "  (58, 53.00),\n",
       "  (159, 53.00),\n",
       "  (256, 53.00),\n",
       "  (294, 53.00),\n",
       "  (383, 53.00),\n",
       "  (487, 53.00),\n",
       "  (533, 53.00),\n",
       "  (541, 53.00),\n",
       "  (612, 53.00),\n",
       "  (657, 53.00),\n",
       "  (664, 53.00),\n",
       "  (667, 53.00),\n",
       "  (709, 53.00),\n",
       "  (858, 53.00),\n",
       "  (917, 53.00),\n",
       "  (922, 53.00),\n",
       "  (990, 53.00),\n",
       "  (995, 53.00),\n",
       "  (997, 53.00),\n",
       "  (0, 52.00),\n",
       "  (89, 52.00),\n",
       "  (164, 52.00),\n",
       "  (218, 52.00),\n",
       "  (229, 52.00),\n",
       "  (269, 52.00),\n",
       "  (276, 52.00),\n",
       "  (289, 52.00),\n",
       "  (352, 52.00),\n",
       "  (451, 52.00),\n",
       "  (490, 52.00),\n",
       "  (528, 52.00),\n",
       "  (545, 52.00),\n",
       "  (665, 52.00),\n",
       "  (752, 52.00),\n",
       "  (771, 52.00),\n",
       "  (927, 52.00),\n",
       "  (13, 51.00),\n",
       "  (36, 51.00),\n",
       "  (67, 51.00),\n",
       "  (70, 51.00),\n",
       "  (78, 51.00),\n",
       "  (126, 51.00),\n",
       "  (133, 51.00),\n",
       "  (177, 51.00),\n",
       "  (194, 51.00),\n",
       "  (196, 51.00),\n",
       "  (209, 51.00),\n",
       "  (239, 51.00),\n",
       "  (241, 51.00),\n",
       "  (261, 51.00),\n",
       "  (264, 51.00),\n",
       "  (286, 51.00),\n",
       "  (295, 51.00),\n",
       "  (362, 51.00),\n",
       "  (388, 51.00),\n",
       "  (431, 51.00),\n",
       "  (508, 51.00),\n",
       "  (526, 51.00),\n",
       "  (602, 51.00),\n",
       "  (616, 51.00),\n",
       "  (685, 51.00),\n",
       "  (738, 51.00),\n",
       "  (739, 51.00),\n",
       "  (1, 50.00),\n",
       "  (3, 50.00),\n",
       "  (92, 50.00),\n",
       "  (100, 50.00),\n",
       "  (138, 50.00),\n",
       "  (172, 50.00),\n",
       "  (216, 50.00),\n",
       "  (277, 50.00),\n",
       "  (325, 50.00),\n",
       "  (340, 50.00),\n",
       "  (358, 50.00),\n",
       "  (373, 50.00),\n",
       "  (378, 50.00),\n",
       "  (433, 50.00),\n",
       "  (519, 50.00),\n",
       "  (552, 50.00),\n",
       "  (639, 50.00),\n",
       "  (668, 50.00),\n",
       "  (683, 50.00),\n",
       "  (684, 50.00),\n",
       "  (746, 50.00),\n",
       "  (757, 50.00),\n",
       "  (779, 50.00),\n",
       "  (833, 50.00),\n",
       "  (865, 50.00),\n",
       "  (9, 49.00),\n",
       "  (14, 49.00),\n",
       "  (15, 49.00),\n",
       "  (35, 49.00),\n",
       "  (63, 49.00),\n",
       "  (66, 49.00),\n",
       "  (96, 49.00),\n",
       "  (123, 49.00),\n",
       "  (160, 49.00),\n",
       "  (176, 49.00),\n",
       "  (212, 49.00),\n",
       "  (214, 49.00),\n",
       "  (267, 49.00),\n",
       "  (326, 49.00),\n",
       "  (333, 49.00),\n",
       "  (336, 49.00),\n",
       "  (349, 49.00),\n",
       "  (376, 49.00),\n",
       "  (377, 49.00),\n",
       "  (387, 49.00),\n",
       "  (416, 49.00),\n",
       "  (444, 49.00),\n",
       "  (467, 49.00),\n",
       "  (583, 49.00),\n",
       "  (604, 49.00),\n",
       "  (606, 49.00),\n",
       "  (628, 49.00),\n",
       "  (659, 49.00),\n",
       "  (704, 49.00),\n",
       "  (732, 49.00),\n",
       "  (765, 49.00),\n",
       "  (776, 49.00),\n",
       "  (787, 49.00),\n",
       "  (855, 49.00),\n",
       "  (11, 48.00),\n",
       "  (16, 48.00),\n",
       "  (18, 48.00),\n",
       "  (22, 48.00),\n",
       "  (41, 48.00),\n",
       "  (95, 48.00),\n",
       "  (102, 48.00),\n",
       "  (114, 48.00),\n",
       "  (188, 48.00),\n",
       "  (191, 48.00),\n",
       "  (243, 48.00),\n",
       "  (253, 48.00),\n",
       "  (265, 48.00),\n",
       "  (290, 48.00),\n",
       "  (337, 48.00),\n",
       "  (344, 48.00),\n",
       "  (365, 48.00),\n",
       "  (397, 48.00),\n",
       "  (432, 48.00),\n",
       "  (449, 48.00),\n",
       "  (514, 48.00),\n",
       "  (535, 48.00),\n",
       "  (566, 48.00),\n",
       "  (576, 48.00),\n",
       "  (592, 48.00),\n",
       "  (633, 48.00),\n",
       "  (674, 48.00),\n",
       "  (706, 48.00),\n",
       "  (707, 48.00),\n",
       "  (764, 48.00),\n",
       "  (853, 48.00),\n",
       "  (874, 48.00),\n",
       "  (890, 48.00),\n",
       "  (891, 48.00),\n",
       "  (915, 48.00),\n",
       "  (5, 47.00),\n",
       "  (12, 47.00),\n",
       "  (53, 47.00),\n",
       "  (72, 47.00),\n",
       "  (79, 47.00),\n",
       "  (121, 47.00),\n",
       "  (134, 47.00),\n",
       "  (144, 47.00),\n",
       "  (156, 47.00),\n",
       "  (169, 47.00),\n",
       "  (193, 47.00),\n",
       "  (201, 47.00),\n",
       "  (255, 47.00),\n",
       "  (279, 47.00),\n",
       "  (288, 47.00),\n",
       "  (301, 47.00),\n",
       "  (321, 47.00),\n",
       "  (350, 47.00),\n",
       "  (351, 47.00),\n",
       "  (366, 47.00),\n",
       "  (413, 47.00),\n",
       "  (503, 47.00),\n",
       "  (560, 47.00),\n",
       "  (571, 47.00),\n",
       "  (753, 47.00),\n",
       "  (769, 47.00),\n",
       "  (796, 47.00),\n",
       "  (823, 47.00),\n",
       "  (867, 47.00),\n",
       "  (886, 47.00),\n",
       "  (889, 47.00),\n",
       "  (951, 47.00),\n",
       "  (989, 47.00),\n",
       "  (28, 46.00),\n",
       "  (65, 46.00),\n",
       "  (87, 46.00),\n",
       "  (101, 46.00),\n",
       "  (110, 46.00),\n",
       "  (130, 46.00),\n",
       "  (136, 46.00),\n",
       "  (139, 46.00),\n",
       "  (149, 46.00),\n",
       "  (221, 46.00),\n",
       "  (227, 46.00),\n",
       "  (273, 46.00),\n",
       "  (312, 46.00),\n",
       "  (323, 46.00),\n",
       "  (392, 46.00),\n",
       "  (395, 46.00),\n",
       "  (398, 46.00),\n",
       "  (414, 46.00),\n",
       "  (486, 46.00),\n",
       "  (523, 46.00),\n",
       "  (530, 46.00),\n",
       "  (625, 46.00),\n",
       "  (727, 46.00),\n",
       "  (751, 46.00),\n",
       "  (758, 46.00),\n",
       "  (795, 46.00),\n",
       "  (872, 46.00),\n",
       "  (881, 46.00),\n",
       "  (882, 46.00),\n",
       "  (907, 46.00),\n",
       "  (959, 46.00),\n",
       "  (983, 46.00),\n",
       "  (994, 46.00),\n",
       "  (2, 45.00),\n",
       "  (56, 45.00),\n",
       "  (71, 45.00),\n",
       "  (131, 45.00),\n",
       "  (137, 45.00),\n",
       "  (141, 45.00),\n",
       "  (157, 45.00),\n",
       "  (247, 45.00),\n",
       "  (320, 45.00),\n",
       "  (324, 45.00),\n",
       "  (335, 45.00),\n",
       "  (339, 45.00),\n",
       "  (354, 45.00),\n",
       "  (384, 45.00),\n",
       "  (417, 45.00),\n",
       "  (422, 45.00),\n",
       "  (426, 45.00),\n",
       "  (475, 45.00),\n",
       "  (517, 45.00),\n",
       "  (599, 45.00),\n",
       "  (613, 45.00),\n",
       "  (666, 45.00),\n",
       "  (702, 45.00),\n",
       "  (759, 45.00),\n",
       "  (763, 45.00),\n",
       "  (818, 45.00),\n",
       "  (821, 45.00),\n",
       "  (848, 45.00),\n",
       "  (873, 45.00),\n",
       "  (900, 45.00),\n",
       "  (918, 45.00),\n",
       "  (44, 44.00),\n",
       "  (75, 44.00),\n",
       "  (105, 44.00),\n",
       "  (107, 44.00),\n",
       "  (112, 44.00),\n",
       "  (215, 44.00),\n",
       "  (244, 44.00),\n",
       "  (252, 44.00),\n",
       "  (258, 44.00),\n",
       "  (332, 44.00),\n",
       "  (390, 44.00),\n",
       "  (445, 44.00),\n",
       "  (456, 44.00),\n",
       "  (518, 44.00),\n",
       "  (579, 44.00),\n",
       "  (658, 44.00),\n",
       "  (690, 44.00),\n",
       "  (717, 44.00),\n",
       "  (755, 44.00),\n",
       "  (807, 44.00),\n",
       "  (920, 44.00),\n",
       "  (941, 44.00),\n",
       "  (984, 44.00),\n",
       "  (993, 44.00),\n",
       "  (80, 43.00),\n",
       "  (108, 43.00),\n",
       "  (142, 43.00),\n",
       "  (174, 43.00),\n",
       "  (198, 43.00),\n",
       "  (242, 43.00),\n",
       "  (268, 43.00),\n",
       "  (287, 43.00),\n",
       "  (306, 43.00),\n",
       "  (330, 43.00),\n",
       "  (355, 43.00),\n",
       "  (357, 43.00),\n",
       "  (381, 43.00),\n",
       "  (421, 43.00),\n",
       "  (434, 43.00),\n",
       "  (473, 43.00),\n",
       "  (495, 43.00),\n",
       "  (510, 43.00),\n",
       "  (637, 43.00),\n",
       "  (672, 43.00),\n",
       "  (812, 43.00),\n",
       "  (817, 43.00),\n",
       "  (894, 43.00),\n",
       "  (929, 43.00),\n",
       "  (933, 43.00),\n",
       "  (981, 43.00),\n",
       "  (998, 43.00),\n",
       "  (7, 42.00),\n",
       "  (42, 42.00),\n",
       "  (153, 42.00),\n",
       "  (173, 42.00),\n",
       "  (257, 42.00),\n",
       "  (266, 42.00),\n",
       "  (299, 42.00),\n",
       "  (360, 42.00),\n",
       "  (370, 42.00),\n",
       "  (389, 42.00),\n",
       "  (418, 42.00),\n",
       "  (442, 42.00),\n",
       "  (520, 42.00),\n",
       "  (538, 42.00),\n",
       "  (573, 42.00),\n",
       "  (723, 42.00),\n",
       "  (734, 42.00),\n",
       "  (756, 42.00),\n",
       "  (837, 42.00),\n",
       "  (898, 42.00),\n",
       "  (910, 42.00),\n",
       "  (968, 42.00),\n",
       "  (19, 41.00),\n",
       "  (38, 41.00),\n",
       "  (40, 41.00),\n",
       "  (83, 41.00),\n",
       "  (132, 41.00),\n",
       "  (223, 41.00),\n",
       "  (260, 41.00),\n",
       "  (302, 41.00),\n",
       "  (305, 41.00),\n",
       "  (353, 41.00),\n",
       "  (405, 41.00),\n",
       "  (429, 41.00),\n",
       "  (430, 41.00),\n",
       "  (437, 41.00),\n",
       "  (537, 41.00),\n",
       "  (558, 41.00),\n",
       "  (574, 41.00),\n",
       "  (575, 41.00),\n",
       "  (636, 41.00),\n",
       "  (694, 41.00),\n",
       "  (710, 41.00),\n",
       "  (712, 41.00),\n",
       "  (851, 41.00),\n",
       "  (919, 41.00),\n",
       "  (932, 41.00),\n",
       "  (996, 41.00),\n",
       "  (93, 40.00),\n",
       "  (117, 40.00),\n",
       "  (190, 40.00),\n",
       "  (224, 40.00),\n",
       "  (236, 40.00),\n",
       "  (245, 40.00),\n",
       "  (278, 40.00),\n",
       "  (322, 40.00),\n",
       "  (380, 40.00),\n",
       "  (447, 40.00),\n",
       "  (485, 40.00),\n",
       "  (500, 40.00),\n",
       "  (507, 40.00),\n",
       "  (542, 40.00),\n",
       "  (555, 40.00),\n",
       "  (559, 40.00),\n",
       "  (584, 40.00),\n",
       "  (643, 40.00),\n",
       "  (682, 40.00),\n",
       "  (699, 40.00),\n",
       "  (713, 40.00),\n",
       "  (726, 40.00),\n",
       "  (799, 40.00),\n",
       "  (862, 40.00),\n",
       "  (925, 40.00),\n",
       "  (945, 40.00),\n",
       "  (999, 40.00),\n",
       "  (10, 39.00),\n",
       "  (17, 39.00),\n",
       "  (27, 39.00),\n",
       "  (91, 39.00),\n",
       "  (111, 39.00),\n",
       "  (127, 39.00),\n",
       "  (140, 39.00),\n",
       "  (145, 39.00),\n",
       "  (148, 39.00),\n",
       "  (186, 39.00),\n",
       "  (329, 39.00),\n",
       "  (338, 39.00),\n",
       "  (379, 39.00),\n",
       "  (393, 39.00),\n",
       "  (439, 39.00),\n",
       "  (480, 39.00),\n",
       "  (501, 39.00),\n",
       "  (546, 39.00),\n",
       "  (670, 39.00),\n",
       "  (722, 39.00),\n",
       "  (749, 39.00),\n",
       "  (761, 39.00),\n",
       "  (883, 39.00),\n",
       "  (204, 38.00),\n",
       "  (230, 38.00),\n",
       "  (297, 38.00),\n",
       "  (309, 38.00),\n",
       "  (314, 38.00),\n",
       "  (368, 38.00),\n",
       "  (412, 38.00),\n",
       "  (470, 38.00),\n",
       "  (529, 38.00),\n",
       "  (540, 38.00),\n",
       "  (548, 38.00),\n",
       "  (553, 38.00),\n",
       "  (656, 38.00),\n",
       "  (687, 38.00),\n",
       "  (708, 38.00),\n",
       "  (714, 38.00),\n",
       "  (736, 38.00),\n",
       "  (782, 38.00),\n",
       "  (831, 38.00),\n",
       "  (844, 38.00),\n",
       "  (854, 38.00),\n",
       "  (20, 37.00),\n",
       "  (52, 37.00),\n",
       "  (152, 37.00),\n",
       "  (154, 37.00),\n",
       "  (175, 37.00),\n",
       "  (183, 37.00),\n",
       "  (210, 37.00),\n",
       "  (235, 37.00),\n",
       "  (262, 37.00),\n",
       "  (296, 37.00),\n",
       "  (347, 37.00),\n",
       "  (435, 37.00),\n",
       "  (462, 37.00),\n",
       "  (466, 37.00),\n",
       "  (494, 37.00),\n",
       "  (554, 37.00),\n",
       "  (600, 37.00),\n",
       "  (610, 37.00),\n",
       "  (630, 37.00),\n",
       "  (678, 37.00),\n",
       "  (814, 37.00),\n",
       "  (921, 37.00),\n",
       "  (98, 36.00),\n",
       "  (200, 36.00),\n",
       "  (205, 36.00),\n",
       "  (207, 36.00),\n",
       "  (399, 36.00),\n",
       "  (408, 36.00),\n",
       "  (453, 36.00),\n",
       "  (511, 36.00),\n",
       "  (513, 36.00),\n",
       "  (650, 36.00),\n",
       "  (693, 36.00),\n",
       "  (719, 36.00),\n",
       "  (720, 36.00),\n",
       "  (861, 36.00),\n",
       "  (928, 36.00),\n",
       "  (934, 36.00),\n",
       "  (120, 35.00),\n",
       "  (143, 35.00),\n",
       "  (248, 35.00),\n",
       "  (346, 35.00),\n",
       "  (356, 35.00),\n",
       "  (605, 35.00),\n",
       "  (802, 35.00),\n",
       "  (43, 34.00),\n",
       "  (45, 34.00),\n",
       "  (62, 34.00),\n",
       "  (86, 34.00),\n",
       "  (220, 34.00),\n",
       "  (359, 34.00),\n",
       "  (374, 34.00),\n",
       "  (450, 34.00),\n",
       "  (464, 34.00),\n",
       "  (615, 34.00),\n",
       "  (677, 34.00),\n",
       "  (745, 34.00),\n",
       "  (793, 34.00),\n",
       "  (798, 34.00),\n",
       "  (827, 34.00),\n",
       "  (947, 34.00),\n",
       "  (958, 34.00),\n",
       "  (964, 34.00),\n",
       "  (59, 33.00),\n",
       "  (158, 33.00),\n",
       "  (213, 33.00),\n",
       "  (226, 33.00),\n",
       "  (233, 33.00),\n",
       "  (402, 33.00),\n",
       "  (403, 33.00),\n",
       "  (409, 33.00),\n",
       "  (415, 33.00),\n",
       "  (588, 33.00),\n",
       "  (691, 33.00),\n",
       "  (954, 33.00),\n",
       "  (26, 32.00),\n",
       "  (64, 32.00),\n",
       "  (73, 32.00),\n",
       "  (106, 32.00),\n",
       "  (385, 32.00),\n",
       "  (427, 32.00),\n",
       "  (465, 32.00),\n",
       "  (543, 32.00),\n",
       "  (627, 32.00),\n",
       "  (760, 32.00),\n",
       "  (786, 32.00),\n",
       "  (859, 32.00),\n",
       "  (897, 32.00),\n",
       "  (948, 32.00),\n",
       "  (980, 32.00),\n",
       "  (122, 31.00),\n",
       "  (371, 31.00),\n",
       "  (461, 31.00),\n",
       "  (469, 31.00),\n",
       "  (484, 31.00),\n",
       "  (502, 31.00),\n",
       "  (521, 31.00),\n",
       "  (531, 31.00),\n",
       "  (551, 31.00),\n",
       "  (568, 31.00),\n",
       "  (578, 31.00),\n",
       "  (644, 31.00),\n",
       "  (647, 31.00),\n",
       "  (705, 31.00),\n",
       "  (744, 31.00),\n",
       "  (789, 31.00),\n",
       "  (846, 31.00),\n",
       "  (914, 31.00),\n",
       "  (81, 30.00),\n",
       "  (146, 30.00),\n",
       "  (166, 30.00),\n",
       "  (179, 30.00),\n",
       "  (345, 30.00),\n",
       "  (459, 30.00),\n",
       "  (557, 30.00),\n",
       "  (589, 30.00),\n",
       "  (617, 30.00),\n",
       "  (629, 30.00),\n",
       "  (632, 30.00),\n",
       "  (803, 30.00),\n",
       "  (966, 30.00),\n",
       "  (303, 29.00),\n",
       "  (498, 29.00),\n",
       "  (585, 29.00),\n",
       "  (634, 29.00),\n",
       "  (4, 28.00),\n",
       "  (29, 28.00),\n",
       "  (54, 28.00),\n",
       "  (567, 28.00),\n",
       "  (587, 28.00),\n",
       "  (631, 28.00),\n",
       "  (663, 28.00),\n",
       "  (718, 28.00),\n",
       "  (731, 28.00),\n",
       "  (767, 28.00),\n",
       "  (860, 28.00),\n",
       "  (876, 28.00),\n",
       "  (909, 28.00),\n",
       "  (923, 28.00),\n",
       "  (147, 27.00),\n",
       "  (187, 27.00),\n",
       "  (202, 27.00),\n",
       "  (479, 27.00),\n",
       "  (482, 27.00),\n",
       "  (660, 27.00),\n",
       "  (733, 27.00),\n",
       "  (965, 27.00),\n",
       "  (49, 26.00),\n",
       "  (150, 26.00),\n",
       "  (271, 26.00),\n",
       "  (624, 26.00),\n",
       "  (676, 26.00),\n",
       "  (686, 26.00),\n",
       "  (785, 26.00),\n",
       "  (869, 26.00),\n",
       "  (931, 26.00),\n",
       "  (32, 25.00),\n",
       "  (163, 25.00),\n",
       "  (240, 25.00),\n",
       "  (369, 25.00),\n",
       "  (544, 25.00),\n",
       "  (804, 25.00),\n",
       "  (885, 25.00),\n",
       "  (516, 24.00),\n",
       "  (536, 24.00),\n",
       "  (590, 24.00),\n",
       "  (596, 24.00),\n",
       "  (747, 24.00),\n",
       "  (856, 24.00),\n",
       "  (901, 24.00),\n",
       "  (168, 23.00),\n",
       "  (185, 23.00),\n",
       "  (315, 23.00),\n",
       "  (394, 23.00),\n",
       "  (438, 23.00),\n",
       "  (623, 23.00),\n",
       "  (680, 23.00),\n",
       "  (811, 23.00),\n",
       "  (838, 23.00),\n",
       "  (908, 23.00),\n",
       "  (911, 23.00),\n",
       "  (974, 23.00),\n",
       "  (165, 22.00),\n",
       "  (550, 22.00),\n",
       "  (638, 22.00),\n",
       "  (675, 22.00),\n",
       "  (942, 22.00),\n",
       "  (499, 21.00),\n",
       "  (525, 21.00),\n",
       "  (773, 21.00),\n",
       "  (68, 20.00),\n",
       "  (662, 20.00),\n",
       "  (715, 20.00),\n",
       "  (729, 20.00),\n",
       "  (740, 20.00),\n",
       "  (246, 19.00),\n",
       "  (400, 19.00),\n",
       "  (598, 19.00),\n",
       "  (622, 19.00),\n",
       "  (648, 18.00),\n",
       "  (651, 18.00),\n",
       "  (728, 18.00),\n",
       "  (836, 18.00),\n",
       "  (977, 18.00),\n",
       "  (504, 17.00),\n",
       "  (813, 17.00),\n",
       "  (906, 17.00),\n",
       "  (976, 17.00),\n",
       "  (460, 16.00),\n",
       "  (534, 16.00),\n",
       "  (841, 16.00),\n",
       "  (930, 16.00),\n",
       "  (970, 15.00),\n",
       "  (103, 14.00),\n",
       "  (282, 14.00),\n",
       "  (742, 14.00),\n",
       "  (969, 14.00),\n",
       "  (34, 13.00),\n",
       "  (446, 13.00),\n",
       "  (493, 13.00),\n",
       "  (967, 12.00),\n",
       "  (167, 11.00),\n",
       "  (940, 11.00),\n",
       "  (978, 11.00),\n",
       "  (689, 10.00),\n",
       "  (899, 9.00),\n",
       "  (960, 9.00),\n",
       "  (673, 8.00),\n",
       "  (681, 8.00),\n",
       "  (810, 8.00),\n",
       "  (935, 8.00),\n",
       "  (961, 2.00)])"
      ]
     },
     "execution_count": 98,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#on test\n",
    "%precision 2\n",
    "# n, hist = targeted_diversity(learn, 150, 95)\n",
    "# n, hist\n",
    "n, hist = targeted_diversity(learn, 10, 95)\n",
    "n, hist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2WgaEtZiuWAM",
    "outputId": "c4663fca-f643-45a3-b943-db9e05510f50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at batch_no 0\n",
      "at batch_no 100\n",
      "at batch_no 200\n",
      "at batch_no 300\n",
      "at batch_no 400\n",
      "at batch_no 500\n",
      "at batch_no 600\n",
      "at batch_no 700\n",
      "at batch_no 800\n",
      "at batch_no 900\n",
      "at batch_no 1000\n",
      "at batch_no 1100\n",
      "at batch_no 1200\n",
      "at batch_no 1300\n",
      "at batch_no 1400\n",
      "at batch_no 1500\n",
      "at batch_no 1600\n",
      "at batch_no 1700\n",
      "at batch_no 1800\n",
      "at batch_no 1900\n",
      "at batch_no 2000\n",
      "at batch_no 2100\n",
      "at batch_no 2200\n",
      "at batch_no 2300\n",
      "at batch_no 2400\n",
      "at batch_no 2500\n",
      "at batch_no 2600\n",
      "at batch_no 2700\n",
      "at batch_no 2800\n",
      "at batch_no 2900\n",
      "at batch_no 3000\n",
      "at batch_no 3100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(885,\n",
       " [(815, 227.00),\n",
       "  (652, 183.00),\n",
       "  (646, 172.00),\n",
       "  (580, 155.00),\n",
       "  (591, 149.00),\n",
       "  (621, 148.00),\n",
       "  (737, 148.00),\n",
       "  (611, 147.00),\n",
       "  (489, 136.00),\n",
       "  (904, 129.00),\n",
       "  (497, 125.00),\n",
       "  (868, 125.00),\n",
       "  (979, 124.00),\n",
       "  (582, 122.00),\n",
       "  (794, 122.00),\n",
       "  (94, 118.00),\n",
       "  (955, 118.00),\n",
       "  (893, 117.00),\n",
       "  (721, 116.00),\n",
       "  (116, 114.00),\n",
       "  (491, 108.00),\n",
       "  (565, 108.00),\n",
       "  (741, 107.00),\n",
       "  (562, 106.00),\n",
       "  (679, 106.00),\n",
       "  (39, 105.00),\n",
       "  (839, 104.00),\n",
       "  (109, 102.00),\n",
       "  (162, 101.00),\n",
       "  (750, 100.00),\n",
       "  (46, 98.00),\n",
       "  (695, 98.00),\n",
       "  (549, 97.00),\n",
       "  (82, 95.00),\n",
       "  (199, 95.00),\n",
       "  (492, 95.00),\n",
       "  (84, 94.00),\n",
       "  (973, 94.00),\n",
       "  (51, 93.00),\n",
       "  (151, 91.00),\n",
       "  (48, 90.00),\n",
       "  (424, 89.00),\n",
       "  (843, 89.00),\n",
       "  (203, 87.00),\n",
       "  (692, 87.00),\n",
       "  (971, 87.00),\n",
       "  (640, 86.00),\n",
       "  (669, 86.00),\n",
       "  (197, 84.00),\n",
       "  (440, 84.00),\n",
       "  (879, 84.00),\n",
       "  (47, 83.00),\n",
       "  (180, 83.00),\n",
       "  (577, 83.00),\n",
       "  (208, 81.00),\n",
       "  (743, 81.00),\n",
       "  (783, 81.00),\n",
       "  (847, 81.00),\n",
       "  (189, 80.00),\n",
       "  (281, 80.00),\n",
       "  (382, 80.00),\n",
       "  (406, 80.00),\n",
       "  (703, 80.00),\n",
       "  (824, 80.00),\n",
       "  (905, 80.00),\n",
       "  (61, 79.00),\n",
       "  (318, 79.00),\n",
       "  (319, 79.00),\n",
       "  (411, 79.00),\n",
       "  (762, 79.00),\n",
       "  (866, 79.00),\n",
       "  (219, 78.00),\n",
       "  (310, 78.00),\n",
       "  (938, 78.00),\n",
       "  (76, 77.00),\n",
       "  (270, 77.00),\n",
       "  (364, 77.00),\n",
       "  (849, 77.00),\n",
       "  (182, 76.00),\n",
       "  (298, 76.00),\n",
       "  (791, 76.00),\n",
       "  (828, 76.00),\n",
       "  (896, 76.00),\n",
       "  (956, 76.00),\n",
       "  (963, 76.00),\n",
       "  (55, 75.00),\n",
       "  (217, 75.00),\n",
       "  (342, 75.00),\n",
       "  (343, 75.00),\n",
       "  (730, 75.00),\n",
       "  (778, 75.00),\n",
       "  (830, 75.00),\n",
       "  (455, 74.00),\n",
       "  (483, 74.00),\n",
       "  (800, 74.00),\n",
       "  (982, 74.00),\n",
       "  (304, 73.00),\n",
       "  (363, 73.00),\n",
       "  (436, 73.00),\n",
       "  (471, 73.00),\n",
       "  (472, 73.00),\n",
       "  (645, 73.00),\n",
       "  (805, 73.00),\n",
       "  (128, 72.00),\n",
       "  (725, 72.00),\n",
       "  (754, 72.00),\n",
       "  (878, 71.00),\n",
       "  (192, 70.00),\n",
       "  (341, 70.00),\n",
       "  (454, 70.00),\n",
       "  (556, 70.00),\n",
       "  (572, 70.00),\n",
       "  (735, 70.00),\n",
       "  (806, 70.00),\n",
       "  (825, 70.00),\n",
       "  (826, 70.00),\n",
       "  (178, 69.00),\n",
       "  (195, 69.00),\n",
       "  (570, 69.00),\n",
       "  (671, 69.00),\n",
       "  (716, 69.00),\n",
       "  (23, 68.00),\n",
       "  (50, 68.00),\n",
       "  (654, 68.00),\n",
       "  (700, 68.00),\n",
       "  (775, 68.00),\n",
       "  (30, 67.00),\n",
       "  (77, 67.00),\n",
       "  (425, 67.00),\n",
       "  (496, 67.00),\n",
       "  (845, 67.00),\n",
       "  (916, 67.00),\n",
       "  (949, 67.00),\n",
       "  (37, 66.00),\n",
       "  (124, 66.00),\n",
       "  (420, 66.00),\n",
       "  (586, 66.00),\n",
       "  (620, 66.00),\n",
       "  (784, 66.00),\n",
       "  (895, 66.00),\n",
       "  (926, 66.00),\n",
       "  (155, 65.00),\n",
       "  (234, 65.00),\n",
       "  (238, 65.00),\n",
       "  (293, 65.00),\n",
       "  (313, 65.00),\n",
       "  (649, 65.00),\n",
       "  (688, 65.00),\n",
       "  (820, 65.00),\n",
       "  (863, 65.00),\n",
       "  (864, 65.00),\n",
       "  (870, 65.00),\n",
       "  (871, 65.00),\n",
       "  (892, 65.00),\n",
       "  (988, 65.00),\n",
       "  (6, 64.00),\n",
       "  (74, 64.00),\n",
       "  (222, 64.00),\n",
       "  (237, 64.00),\n",
       "  (361, 64.00),\n",
       "  (463, 64.00),\n",
       "  (468, 64.00),\n",
       "  (711, 64.00),\n",
       "  (772, 64.00),\n",
       "  (887, 64.00),\n",
       "  (944, 64.00),\n",
       "  (97, 63.00),\n",
       "  (119, 63.00),\n",
       "  (331, 63.00),\n",
       "  (474, 63.00),\n",
       "  (819, 63.00),\n",
       "  (913, 63.00),\n",
       "  (972, 63.00),\n",
       "  (8, 62.00),\n",
       "  (90, 62.00),\n",
       "  (99, 62.00),\n",
       "  (125, 62.00),\n",
       "  (161, 62.00),\n",
       "  (184, 62.00),\n",
       "  (272, 62.00),\n",
       "  (300, 62.00),\n",
       "  (348, 62.00),\n",
       "  (506, 62.00),\n",
       "  (515, 62.00),\n",
       "  (593, 62.00),\n",
       "  (788, 62.00),\n",
       "  (808, 62.00),\n",
       "  (842, 62.00),\n",
       "  (875, 62.00),\n",
       "  (880, 62.00),\n",
       "  (992, 62.00),\n",
       "  (135, 61.00),\n",
       "  (225, 61.00),\n",
       "  (280, 61.00),\n",
       "  (292, 61.00),\n",
       "  (311, 61.00),\n",
       "  (316, 61.00),\n",
       "  (476, 61.00),\n",
       "  (505, 61.00),\n",
       "  (561, 61.00),\n",
       "  (609, 61.00),\n",
       "  (698, 61.00),\n",
       "  (809, 61.00),\n",
       "  (850, 61.00),\n",
       "  (937, 61.00),\n",
       "  (946, 61.00),\n",
       "  (953, 61.00),\n",
       "  (181, 60.00),\n",
       "  (372, 60.00),\n",
       "  (401, 60.00),\n",
       "  (532, 60.00),\n",
       "  (539, 60.00),\n",
       "  (619, 60.00),\n",
       "  (697, 60.00),\n",
       "  (781, 60.00),\n",
       "  (884, 60.00),\n",
       "  (113, 59.00),\n",
       "  (327, 59.00),\n",
       "  (391, 59.00),\n",
       "  (404, 59.00),\n",
       "  (481, 59.00),\n",
       "  (490, 59.00),\n",
       "  (522, 59.00),\n",
       "  (581, 59.00),\n",
       "  (607, 59.00),\n",
       "  (655, 59.00),\n",
       "  (724, 59.00),\n",
       "  (774, 59.00),\n",
       "  (912, 59.00),\n",
       "  (952, 59.00),\n",
       "  (987, 59.00),\n",
       "  (60, 58.00),\n",
       "  (211, 58.00),\n",
       "  (249, 58.00),\n",
       "  (284, 58.00),\n",
       "  (317, 58.00),\n",
       "  (407, 58.00),\n",
       "  (410, 58.00),\n",
       "  (423, 58.00),\n",
       "  (458, 58.00),\n",
       "  (563, 58.00),\n",
       "  (594, 58.00),\n",
       "  (595, 58.00),\n",
       "  (597, 58.00),\n",
       "  (603, 58.00),\n",
       "  (641, 58.00),\n",
       "  (696, 58.00),\n",
       "  (709, 58.00),\n",
       "  (790, 58.00),\n",
       "  (857, 58.00),\n",
       "  (21, 57.00),\n",
       "  (307, 57.00),\n",
       "  (419, 57.00),\n",
       "  (441, 57.00),\n",
       "  (457, 57.00),\n",
       "  (612, 57.00),\n",
       "  (618, 57.00),\n",
       "  (636, 57.00),\n",
       "  (801, 57.00),\n",
       "  (69, 56.00),\n",
       "  (118, 56.00),\n",
       "  (231, 56.00),\n",
       "  (232, 56.00),\n",
       "  (263, 56.00),\n",
       "  (275, 56.00),\n",
       "  (308, 56.00),\n",
       "  (334, 56.00),\n",
       "  (367, 56.00),\n",
       "  (452, 56.00),\n",
       "  (477, 56.00),\n",
       "  (527, 56.00),\n",
       "  (547, 56.00),\n",
       "  (564, 56.00),\n",
       "  (635, 56.00),\n",
       "  (642, 56.00),\n",
       "  (653, 56.00),\n",
       "  (657, 56.00),\n",
       "  (661, 56.00),\n",
       "  (780, 56.00),\n",
       "  (816, 56.00),\n",
       "  (822, 56.00),\n",
       "  (957, 56.00),\n",
       "  (962, 56.00),\n",
       "  (975, 56.00),\n",
       "  (25, 55.00),\n",
       "  (31, 55.00),\n",
       "  (33, 55.00),\n",
       "  (57, 55.00),\n",
       "  (88, 55.00),\n",
       "  (104, 55.00),\n",
       "  (115, 55.00),\n",
       "  (129, 55.00),\n",
       "  (228, 55.00),\n",
       "  (328, 55.00),\n",
       "  (383, 55.00),\n",
       "  (396, 55.00),\n",
       "  (428, 55.00),\n",
       "  (509, 55.00),\n",
       "  (614, 55.00),\n",
       "  (738, 55.00),\n",
       "  (748, 55.00),\n",
       "  (777, 55.00),\n",
       "  (834, 55.00),\n",
       "  (852, 55.00),\n",
       "  (877, 55.00),\n",
       "  (985, 55.00),\n",
       "  (24, 54.00),\n",
       "  (58, 54.00),\n",
       "  (67, 54.00),\n",
       "  (70, 54.00),\n",
       "  (85, 54.00),\n",
       "  (170, 54.00),\n",
       "  (250, 54.00),\n",
       "  (259, 54.00),\n",
       "  (274, 54.00),\n",
       "  (444, 54.00),\n",
       "  (448, 54.00),\n",
       "  (451, 54.00),\n",
       "  (519, 54.00),\n",
       "  (524, 54.00),\n",
       "  (552, 54.00),\n",
       "  (569, 54.00),\n",
       "  (601, 54.00),\n",
       "  (766, 54.00),\n",
       "  (770, 54.00),\n",
       "  (818, 54.00),\n",
       "  (829, 54.00),\n",
       "  (855, 54.00),\n",
       "  (858, 54.00),\n",
       "  (950, 54.00),\n",
       "  (991, 54.00),\n",
       "  (995, 54.00),\n",
       "  (89, 53.00),\n",
       "  (171, 53.00),\n",
       "  (196, 53.00),\n",
       "  (216, 53.00),\n",
       "  (218, 53.00),\n",
       "  (256, 53.00),\n",
       "  (269, 53.00),\n",
       "  (276, 53.00),\n",
       "  (283, 53.00),\n",
       "  (289, 53.00),\n",
       "  (352, 53.00),\n",
       "  (375, 53.00),\n",
       "  (608, 53.00),\n",
       "  (626, 53.00),\n",
       "  (701, 53.00),\n",
       "  (768, 53.00),\n",
       "  (832, 53.00),\n",
       "  (903, 53.00),\n",
       "  (924, 53.00),\n",
       "  (936, 53.00),\n",
       "  (986, 53.00),\n",
       "  (0, 52.00),\n",
       "  (3, 52.00),\n",
       "  (36, 52.00),\n",
       "  (92, 52.00),\n",
       "  (96, 52.00),\n",
       "  (164, 52.00),\n",
       "  (172, 52.00),\n",
       "  (209, 52.00),\n",
       "  (241, 52.00),\n",
       "  (251, 52.00),\n",
       "  (254, 52.00),\n",
       "  (277, 52.00),\n",
       "  (291, 52.00),\n",
       "  (467, 52.00),\n",
       "  (528, 52.00),\n",
       "  (685, 52.00),\n",
       "  (757, 52.00),\n",
       "  (765, 52.00),\n",
       "  (792, 52.00),\n",
       "  (840, 52.00),\n",
       "  (865, 52.00),\n",
       "  (888, 52.00),\n",
       "  (922, 52.00),\n",
       "  (939, 52.00),\n",
       "  (990, 52.00),\n",
       "  (997, 52.00),\n",
       "  (15, 51.00),\n",
       "  (78, 51.00),\n",
       "  (114, 51.00),\n",
       "  (206, 51.00),\n",
       "  (229, 51.00),\n",
       "  (239, 51.00),\n",
       "  (285, 51.00),\n",
       "  (286, 51.00),\n",
       "  (336, 51.00),\n",
       "  (358, 51.00),\n",
       "  (378, 51.00),\n",
       "  (386, 51.00),\n",
       "  (395, 51.00),\n",
       "  (413, 51.00),\n",
       "  (431, 51.00),\n",
       "  (487, 51.00),\n",
       "  (488, 51.00),\n",
       "  (512, 51.00),\n",
       "  (526, 51.00),\n",
       "  (533, 51.00),\n",
       "  (535, 51.00),\n",
       "  (592, 51.00),\n",
       "  (667, 51.00),\n",
       "  (752, 51.00),\n",
       "  (753, 51.00),\n",
       "  (835, 51.00),\n",
       "  (886, 51.00),\n",
       "  (902, 51.00),\n",
       "  (1, 50.00),\n",
       "  (41, 50.00),\n",
       "  (126, 50.00),\n",
       "  (138, 50.00),\n",
       "  (176, 50.00),\n",
       "  (177, 50.00),\n",
       "  (194, 50.00),\n",
       "  (253, 50.00),\n",
       "  (261, 50.00),\n",
       "  (267, 50.00),\n",
       "  (294, 50.00),\n",
       "  (362, 50.00),\n",
       "  (373, 50.00),\n",
       "  (443, 50.00),\n",
       "  (449, 50.00),\n",
       "  (508, 50.00),\n",
       "  (514, 50.00),\n",
       "  (523, 50.00),\n",
       "  (545, 50.00),\n",
       "  (602, 50.00),\n",
       "  (606, 50.00),\n",
       "  (616, 50.00),\n",
       "  (665, 50.00),\n",
       "  (746, 50.00),\n",
       "  (771, 50.00),\n",
       "  (779, 50.00),\n",
       "  (797, 50.00),\n",
       "  (874, 50.00),\n",
       "  (917, 50.00),\n",
       "  (9, 49.00),\n",
       "  (12, 49.00),\n",
       "  (13, 49.00),\n",
       "  (35, 49.00),\n",
       "  (71, 49.00),\n",
       "  (102, 49.00),\n",
       "  (121, 49.00),\n",
       "  (159, 49.00),\n",
       "  (160, 49.00),\n",
       "  (214, 49.00),\n",
       "  (266, 49.00),\n",
       "  (301, 49.00),\n",
       "  (340, 49.00),\n",
       "  (387, 49.00),\n",
       "  (388, 49.00),\n",
       "  (541, 49.00),\n",
       "  (604, 49.00),\n",
       "  (639, 49.00),\n",
       "  (664, 49.00),\n",
       "  (739, 49.00),\n",
       "  (764, 49.00),\n",
       "  (776, 49.00),\n",
       "  (833, 49.00),\n",
       "  (890, 49.00),\n",
       "  (915, 49.00),\n",
       "  (927, 49.00),\n",
       "  (11, 48.00),\n",
       "  (14, 48.00),\n",
       "  (18, 48.00),\n",
       "  (72, 48.00),\n",
       "  (95, 48.00),\n",
       "  (100, 48.00),\n",
       "  (133, 48.00),\n",
       "  (134, 48.00),\n",
       "  (149, 48.00),\n",
       "  (156, 48.00),\n",
       "  (169, 48.00),\n",
       "  (221, 48.00),\n",
       "  (247, 48.00),\n",
       "  (255, 48.00),\n",
       "  (295, 48.00),\n",
       "  (320, 48.00),\n",
       "  (321, 48.00),\n",
       "  (325, 48.00),\n",
       "  (337, 48.00),\n",
       "  (376, 48.00),\n",
       "  (398, 48.00),\n",
       "  (432, 48.00),\n",
       "  (433, 48.00),\n",
       "  (478, 48.00),\n",
       "  (503, 48.00),\n",
       "  (517, 48.00),\n",
       "  (583, 48.00),\n",
       "  (628, 48.00),\n",
       "  (668, 48.00),\n",
       "  (683, 48.00),\n",
       "  (704, 48.00),\n",
       "  (727, 48.00),\n",
       "  (787, 48.00),\n",
       "  (848, 48.00),\n",
       "  (881, 48.00),\n",
       "  (943, 48.00),\n",
       "  (951, 48.00),\n",
       "  (989, 48.00),\n",
       "  (994, 48.00),\n",
       "  (22, 47.00),\n",
       "  (56, 47.00),\n",
       "  (79, 47.00),\n",
       "  (87, 47.00),\n",
       "  (123, 47.00),\n",
       "  (137, 47.00),\n",
       "  (139, 47.00),\n",
       "  (141, 47.00),\n",
       "  (193, 47.00),\n",
       "  (273, 47.00),\n",
       "  (288, 47.00),\n",
       "  (290, 47.00),\n",
       "  (326, 47.00),\n",
       "  (333, 47.00),\n",
       "  (335, 47.00),\n",
       "  (344, 47.00),\n",
       "  (351, 47.00),\n",
       "  (354, 47.00),\n",
       "  (366, 47.00),\n",
       "  (416, 47.00),\n",
       "  (422, 47.00),\n",
       "  (445, 47.00),\n",
       "  (518, 47.00),\n",
       "  (571, 47.00),\n",
       "  (576, 47.00),\n",
       "  (625, 47.00),\n",
       "  (637, 47.00),\n",
       "  (666, 47.00),\n",
       "  (684, 47.00),\n",
       "  (707, 47.00),\n",
       "  (751, 47.00),\n",
       "  (763, 47.00),\n",
       "  (769, 47.00),\n",
       "  (807, 47.00),\n",
       "  (889, 47.00),\n",
       "  (891, 47.00),\n",
       "  (918, 47.00),\n",
       "  (983, 47.00),\n",
       "  (5, 46.00),\n",
       "  (28, 46.00),\n",
       "  (53, 46.00),\n",
       "  (66, 46.00),\n",
       "  (130, 46.00),\n",
       "  (136, 46.00),\n",
       "  (144, 46.00),\n",
       "  (157, 46.00),\n",
       "  (191, 46.00),\n",
       "  (201, 46.00),\n",
       "  (212, 46.00),\n",
       "  (243, 46.00),\n",
       "  (257, 46.00),\n",
       "  (264, 46.00),\n",
       "  (279, 46.00),\n",
       "  (312, 46.00),\n",
       "  (323, 46.00),\n",
       "  (350, 46.00),\n",
       "  (377, 46.00),\n",
       "  (384, 46.00),\n",
       "  (392, 46.00),\n",
       "  (560, 46.00),\n",
       "  (566, 46.00),\n",
       "  (579, 46.00),\n",
       "  (659, 46.00),\n",
       "  (702, 46.00),\n",
       "  (706, 46.00),\n",
       "  (732, 46.00),\n",
       "  (823, 46.00),\n",
       "  (872, 46.00),\n",
       "  (993, 46.00),\n",
       "  (16, 45.00),\n",
       "  (40, 45.00),\n",
       "  (75, 45.00),\n",
       "  (105, 45.00),\n",
       "  (110, 45.00),\n",
       "  (131, 45.00),\n",
       "  (188, 45.00),\n",
       "  (215, 45.00),\n",
       "  (252, 45.00),\n",
       "  (324, 45.00),\n",
       "  (339, 45.00),\n",
       "  (355, 45.00),\n",
       "  (365, 45.00),\n",
       "  (381, 45.00),\n",
       "  (389, 45.00),\n",
       "  (397, 45.00),\n",
       "  (426, 45.00),\n",
       "  (475, 45.00),\n",
       "  (537, 45.00),\n",
       "  (613, 45.00),\n",
       "  (674, 45.00),\n",
       "  (758, 45.00),\n",
       "  (759, 45.00),\n",
       "  (796, 45.00),\n",
       "  (853, 45.00),\n",
       "  (867, 45.00),\n",
       "  (882, 45.00),\n",
       "  (900, 45.00),\n",
       "  (968, 45.00),\n",
       "  (981, 45.00),\n",
       "  (2, 44.00),\n",
       "  (17, 44.00),\n",
       "  (42, 44.00),\n",
       "  (44, 44.00),\n",
       "  (101, 44.00),\n",
       "  (107, 44.00),\n",
       "  (132, 44.00),\n",
       "  (227, 44.00),\n",
       "  (245, 44.00),\n",
       "  (287, 44.00),\n",
       "  (370, 44.00),\n",
       "  (412, 44.00),\n",
       "  (414, 44.00),\n",
       "  (447, 44.00),\n",
       "  (817, 44.00),\n",
       "  (821, 44.00),\n",
       "  (929, 44.00),\n",
       "  (941, 44.00),\n",
       "  (959, 44.00),\n",
       "  (63, 43.00),\n",
       "  (65, 43.00),\n",
       "  (83, 43.00),\n",
       "  (93, 43.00),\n",
       "  (174, 43.00),\n",
       "  (244, 43.00),\n",
       "  (299, 43.00),\n",
       "  (330, 43.00),\n",
       "  (332, 43.00),\n",
       "  (349, 43.00),\n",
       "  (437, 43.00),\n",
       "  (456, 43.00),\n",
       "  (485, 43.00),\n",
       "  (520, 43.00),\n",
       "  (574, 43.00),\n",
       "  (575, 43.00),\n",
       "  (599, 43.00),\n",
       "  (658, 43.00),\n",
       "  (682, 43.00),\n",
       "  (710, 43.00),\n",
       "  (717, 43.00),\n",
       "  (723, 43.00),\n",
       "  (755, 43.00),\n",
       "  (756, 43.00),\n",
       "  (761, 43.00),\n",
       "  (782, 43.00),\n",
       "  (795, 43.00),\n",
       "  (873, 43.00),\n",
       "  (898, 43.00),\n",
       "  (907, 43.00),\n",
       "  (910, 43.00),\n",
       "  (919, 43.00),\n",
       "  (984, 43.00),\n",
       "  (999, 43.00),\n",
       "  (108, 42.00),\n",
       "  (112, 42.00),\n",
       "  (153, 42.00),\n",
       "  (223, 42.00),\n",
       "  (260, 42.00),\n",
       "  (265, 42.00),\n",
       "  (268, 42.00),\n",
       "  (305, 42.00),\n",
       "  (329, 42.00),\n",
       "  (353, 42.00),\n",
       "  (429, 42.00),\n",
       "  (430, 42.00),\n",
       "  (434, 42.00),\n",
       "  (473, 42.00),\n",
       "  (495, 42.00),\n",
       "  (510, 42.00),\n",
       "  (558, 42.00),\n",
       "  (633, 42.00),\n",
       "  (643, 42.00),\n",
       "  (672, 42.00),\n",
       "  (690, 42.00),\n",
       "  (996, 42.00),\n",
       "  (7, 41.00),\n",
       "  (19, 41.00),\n",
       "  (80, 41.00),\n",
       "  (142, 41.00),\n",
       "  (154, 41.00),\n",
       "  (173, 41.00),\n",
       "  (190, 41.00),\n",
       "  (258, 41.00),\n",
       "  (302, 41.00),\n",
       "  (306, 41.00),\n",
       "  (322, 41.00),\n",
       "  (360, 41.00),\n",
       "  (390, 41.00),\n",
       "  (393, 41.00),\n",
       "  (421, 41.00),\n",
       "  (462, 41.00),\n",
       "  (486, 41.00),\n",
       "  (501, 41.00),\n",
       "  (507, 41.00),\n",
       "  (530, 41.00),\n",
       "  (573, 41.00),\n",
       "  (712, 41.00),\n",
       "  (714, 41.00),\n",
       "  (734, 41.00),\n",
       "  (837, 41.00),\n",
       "  (844, 41.00),\n",
       "  (862, 41.00),\n",
       "  (933, 41.00),\n",
       "  (998, 41.00),\n",
       "  (27, 40.00),\n",
       "  (117, 40.00),\n",
       "  (127, 40.00),\n",
       "  (186, 40.00),\n",
       "  (210, 40.00),\n",
       "  (297, 40.00),\n",
       "  (368, 40.00),\n",
       "  (380, 40.00),\n",
       "  (417, 40.00),\n",
       "  (442, 40.00),\n",
       "  (466, 40.00),\n",
       "  (538, 40.00),\n",
       "  (630, 40.00),\n",
       "  (670, 40.00),\n",
       "  (713, 40.00),\n",
       "  (722, 40.00),\n",
       "  (749, 40.00),\n",
       "  (799, 40.00),\n",
       "  (812, 40.00),\n",
       "  (851, 40.00),\n",
       "  (920, 40.00),\n",
       "  (925, 40.00),\n",
       "  (52, 39.00),\n",
       "  (91, 39.00),\n",
       "  (140, 39.00),\n",
       "  (183, 39.00),\n",
       "  (224, 39.00),\n",
       "  (236, 39.00),\n",
       "  (242, 39.00),\n",
       "  (248, 39.00),\n",
       "  (309, 39.00),\n",
       "  (346, 39.00),\n",
       "  (357, 39.00),\n",
       "  (405, 39.00),\n",
       "  (500, 39.00),\n",
       "  (548, 39.00),\n",
       "  (559, 39.00),\n",
       "  (694, 39.00),\n",
       "  (699, 39.00),\n",
       "  (708, 39.00),\n",
       "  (726, 39.00),\n",
       "  (894, 39.00),\n",
       "  (932, 39.00),\n",
       "  (10, 38.00),\n",
       "  (43, 38.00),\n",
       "  (262, 38.00),\n",
       "  (347, 38.00),\n",
       "  (427, 38.00),\n",
       "  (464, 38.00),\n",
       "  (480, 38.00),\n",
       "  (540, 38.00),\n",
       "  (542, 38.00),\n",
       "  (555, 38.00),\n",
       "  (584, 38.00),\n",
       "  (656, 38.00),\n",
       "  (719, 38.00),\n",
       "  (736, 38.00),\n",
       "  (814, 38.00),\n",
       "  (859, 38.00),\n",
       "  (921, 38.00),\n",
       "  (928, 38.00),\n",
       "  (38, 37.00),\n",
       "  (98, 37.00),\n",
       "  (111, 37.00),\n",
       "  (198, 37.00),\n",
       "  (200, 37.00),\n",
       "  (207, 37.00),\n",
       "  (230, 37.00),\n",
       "  (235, 37.00),\n",
       "  (278, 37.00),\n",
       "  (296, 37.00),\n",
       "  (338, 37.00),\n",
       "  (374, 37.00),\n",
       "  (379, 37.00),\n",
       "  (418, 37.00),\n",
       "  (439, 37.00),\n",
       "  (513, 37.00),\n",
       "  (529, 37.00),\n",
       "  (553, 37.00),\n",
       "  (554, 37.00),\n",
       "  (786, 37.00),\n",
       "  (854, 37.00),\n",
       "  (945, 37.00),\n",
       "  (45, 36.00),\n",
       "  (62, 36.00),\n",
       "  (143, 36.00),\n",
       "  (145, 36.00),\n",
       "  (148, 36.00),\n",
       "  (152, 36.00),\n",
       "  (175, 36.00),\n",
       "  (204, 36.00),\n",
       "  (205, 36.00),\n",
       "  (314, 36.00),\n",
       "  (385, 36.00),\n",
       "  (399, 36.00),\n",
       "  (408, 36.00),\n",
       "  (435, 36.00),\n",
       "  (453, 36.00),\n",
       "  (470, 36.00),\n",
       "  (546, 36.00),\n",
       "  (588, 36.00),\n",
       "  (605, 36.00),\n",
       "  (610, 36.00),\n",
       "  (615, 36.00),\n",
       "  (678, 36.00),\n",
       "  (687, 36.00),\n",
       "  (720, 36.00),\n",
       "  (793, 36.00),\n",
       "  (802, 36.00),\n",
       "  (934, 36.00),\n",
       "  (20, 35.00),\n",
       "  (120, 35.00),\n",
       "  (213, 35.00),\n",
       "  (226, 35.00),\n",
       "  (359, 35.00),\n",
       "  (600, 35.00),\n",
       "  (632, 35.00),\n",
       "  (827, 35.00),\n",
       "  (831, 35.00),\n",
       "  (846, 35.00),\n",
       "  (883, 35.00),\n",
       "  (958, 35.00),\n",
       "  (26, 34.00),\n",
       "  (73, 34.00),\n",
       "  (220, 34.00),\n",
       "  (356, 34.00),\n",
       "  (409, 34.00),\n",
       "  (415, 34.00),\n",
       "  (450, 34.00),\n",
       "  (494, 34.00),\n",
       "  (511, 34.00),\n",
       "  (543, 34.00),\n",
       "  (585, 34.00),\n",
       "  (627, 34.00),\n",
       "  (677, 34.00),\n",
       "  (693, 34.00),\n",
       "  (861, 34.00),\n",
       "  (897, 34.00),\n",
       "  (923, 34.00),\n",
       "  (947, 34.00),\n",
       "  (86, 33.00),\n",
       "  (403, 33.00),\n",
       "  (465, 33.00),\n",
       "  (650, 33.00),\n",
       "  (798, 33.00),\n",
       "  (964, 33.00),\n",
       "  (980, 33.00),\n",
       "  (158, 32.00),\n",
       "  (371, 32.00),\n",
       "  (402, 32.00),\n",
       "  (461, 32.00),\n",
       "  (629, 32.00),\n",
       "  (634, 32.00),\n",
       "  (644, 32.00),\n",
       "  (647, 32.00),\n",
       "  (760, 32.00),\n",
       "  (948, 32.00),\n",
       "  (954, 32.00),\n",
       "  (59, 31.00),\n",
       "  (64, 31.00),\n",
       "  (81, 31.00),\n",
       "  (459, 31.00),\n",
       "  (498, 31.00),\n",
       "  (521, 31.00),\n",
       "  (531, 31.00),\n",
       "  (578, 31.00),\n",
       "  (589, 31.00),\n",
       "  (745, 31.00),\n",
       "  (803, 31.00),\n",
       "  (860, 31.00),\n",
       "  (966, 31.00),\n",
       "  (146, 30.00),\n",
       "  (179, 30.00),\n",
       "  (303, 30.00),\n",
       "  (567, 30.00),\n",
       "  (676, 30.00),\n",
       "  (744, 30.00),\n",
       "  (789, 30.00),\n",
       "  (4, 29.00),\n",
       "  (122, 29.00),\n",
       "  (166, 29.00),\n",
       "  (187, 29.00),\n",
       "  (233, 29.00),\n",
       "  (345, 29.00),\n",
       "  (484, 29.00),\n",
       "  (551, 29.00),\n",
       "  (557, 29.00),\n",
       "  (568, 29.00),\n",
       "  (617, 29.00),\n",
       "  (733, 29.00),\n",
       "  (914, 29.00),\n",
       "  (29, 28.00),\n",
       "  (32, 28.00),\n",
       "  (106, 28.00),\n",
       "  (147, 28.00),\n",
       "  (469, 28.00),\n",
       "  (482, 28.00),\n",
       "  (502, 28.00),\n",
       "  (544, 28.00),\n",
       "  (663, 28.00),\n",
       "  (686, 28.00),\n",
       "  (691, 28.00),\n",
       "  (747, 28.00),\n",
       "  (804, 28.00),\n",
       "  (931, 28.00),\n",
       "  (54, 27.00),\n",
       "  (150, 27.00),\n",
       "  (271, 27.00),\n",
       "  (587, 27.00),\n",
       "  (596, 27.00),\n",
       "  (624, 27.00),\n",
       "  (660, 27.00),\n",
       "  (705, 27.00),\n",
       "  (869, 27.00),\n",
       "  (369, 26.00),\n",
       "  (718, 26.00),\n",
       "  (731, 26.00),\n",
       "  (942, 26.00),\n",
       "  (965, 26.00),\n",
       "  (202, 25.00),\n",
       "  (240, 25.00),\n",
       "  (536, 25.00),\n",
       "  (767, 25.00),\n",
       "  (911, 25.00),\n",
       "  (974, 25.00),\n",
       "  (163, 24.00),\n",
       "  (168, 24.00),\n",
       "  (479, 24.00),\n",
       "  (516, 24.00),\n",
       "  (590, 24.00),\n",
       "  (631, 24.00),\n",
       "  (680, 24.00),\n",
       "  (876, 24.00),\n",
       "  (901, 24.00),\n",
       "  (909, 24.00),\n",
       "  (49, 23.00),\n",
       "  (165, 23.00),\n",
       "  (185, 23.00),\n",
       "  (623, 23.00),\n",
       "  (785, 23.00),\n",
       "  (811, 23.00),\n",
       "  (838, 23.00),\n",
       "  (856, 23.00),\n",
       "  (68, 22.00),\n",
       "  (315, 22.00),\n",
       "  (438, 22.00),\n",
       "  (499, 22.00),\n",
       "  (773, 22.00),\n",
       "  (394, 21.00),\n",
       "  (622, 21.00),\n",
       "  (638, 21.00),\n",
       "  (675, 21.00),\n",
       "  (729, 21.00),\n",
       "  (976, 21.00),\n",
       "  (525, 20.00),\n",
       "  (598, 20.00),\n",
       "  (662, 20.00),\n",
       "  (728, 20.00),\n",
       "  (908, 20.00),\n",
       "  (103, 19.00),\n",
       "  (246, 19.00),\n",
       "  (400, 19.00),\n",
       "  (550, 19.00),\n",
       "  (715, 19.00),\n",
       "  (740, 19.00),\n",
       "  (885, 19.00),\n",
       "  (282, 18.00),\n",
       "  (648, 18.00),\n",
       "  (836, 18.00),\n",
       "  (970, 18.00),\n",
       "  (651, 17.00),\n",
       "  (906, 17.00),\n",
       "  (930, 17.00),\n",
       "  (977, 17.00),\n",
       "  (446, 16.00),\n",
       "  (841, 16.00),\n",
       "  (460, 15.00),\n",
       "  (534, 15.00),\n",
       "  (969, 15.00),\n",
       "  (493, 14.00),\n",
       "  (504, 14.00),\n",
       "  (742, 14.00),\n",
       "  (813, 14.00),\n",
       "  (689, 13.00),\n",
       "  (34, 12.00),\n",
       "  (940, 12.00),\n",
       "  (967, 12.00),\n",
       "  (167, 11.00),\n",
       "  (899, 11.00),\n",
       "  (673, 10.00),\n",
       "  (960, 10.00),\n",
       "  (978, 9.00),\n",
       "  (681, 8.00),\n",
       "  (935, 8.00),\n",
       "  (810, 7.00),\n",
       "  (961, 2.00)])"
      ]
     },
     "execution_count": 99,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#on test\n",
    "%precision 2\n",
    "# n, hist = targeted_diversity(learn, 150, 95)\n",
    "# n, hist\n",
    "n, hist = targeted_diversity(learn, 10, 95)\n",
    "n, hist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zCeAMy0tuWAP",
    "outputId": "798d0db2-8a5d-4d9b-d246-1f200b3a9da6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f59b994b4e0>]"
      ]
     },
     "execution_count": 100,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# on test\n",
    "sorted_hist = sorted(hist, key=lambda x: x[0], reverse = False)\n",
    "values = [elem[1] for elem in sorted_hist]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H8I3qCBNuWAS",
    "outputId": "db742e88-7bb5-4c46-ab61-c7dc04cbb226"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.8493)"
      ]
     },
     "execution_count": 101,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#on test\n",
    "entropy(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1fCvFG0VMKts"
   },
   "outputs": [],
   "source": [
    "def make_triplet_samples(z, margin, r2, r3):\n",
    "  positive_sample = z + random_vector_volume(z.shape, 0, margin).cuda() \n",
    "  negative_sample = z + random_vector_volume(z.shape, r2, r3).cuda()\n",
    "  return positive_sample, negative_sample\n",
    "\n",
    "def random_vector_surface(shape, r = 1.):\n",
    "  mat = torch.randn(size=shape).cuda()\n",
    "  norm = torch.norm(mat, p=2, dim=1, keepdim = True).cuda()\n",
    "  return (mat/norm) * r\n",
    "\n",
    "def random_vector_volume(shape, inner_r, outer_r):\n",
    "  fraction = torch.empty(shape[0]).uniform_(inner_r, outer_r).cuda()\n",
    "  fraction = ((fraction / outer_r) ** (1 / shape[1])) * outer_r # volume-normalize the fraction\n",
    "  fraction.unsqueeze_(-1)\n",
    "  return random_vector_surface(shape, 1) * fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PizmBkGqMKtu"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def most_frequent(x):\n",
    "  return Counter(x).most_common(1)[0]\n",
    "\n",
    "def preds_around(center, radius, n_preds, model, dummy_img):\n",
    "  z_s = random_vector_volume([n_preds, 10], radius, radius + 0.01) + center[None]\n",
    "  noises = model.forward_z(z_s)\n",
    "  perturbed_imgs = noises + dummy_img \n",
    "  return torch.argmax(arch(perturbed_imgs), 1)\n",
    "  \n",
    "def most_freq_pred_around(center, radius, n_preds, model, dummy_img):\n",
    "  preds = preds_around(center, radius, n_preds, model, dummy_img)\n",
    "  most_freq = most_frequent(preds.tolist())\n",
    "  return (class_index_to_label(most_freq[0]), most_freq[1]/n_preds)\n",
    "\n",
    "def investigate_neighborhood(z, step, model, dummy_img):\n",
    "  with torch.no_grad():\n",
    "    result = []\n",
    "    for radius in np.arange(0.1, 6., step):\n",
    "#       print(\"creating {} more preds\".format(int(10 + 5 * (radius ** 2))))\n",
    "      most_freq_pred = most_freq_pred_around(z, radius, int(10 + 5 * (radius ** 2)), model, dummy_img)\n",
    "      result.append((radius, most_freq_pred))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d-btRW4qMKtw"
   },
   "outputs": [],
   "source": [
    "#experiment 1\n",
    "\n",
    "z = torch.tensor([0.5] * 10).cuda()\n",
    "# z = torch.empty(10).uniform_(-1, 1).cuda()\n",
    "# z_s = z[None]\n",
    "\n",
    "model = learn.model.eval()\n",
    "x_img = normalize(learn.data.train_ds[50][0].data.cuda())\n",
    "  \n",
    "for i in range(6):\n",
    "  z = torch.empty(10).uniform_(-1, 1).cuda()\n",
    "  print(\"investigation for: \", z)\n",
    "  for elem in investigate_neighborhood(z, 0.5, model, x_img):\n",
    "    print(elem)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M2sOSEVeuWAa"
   },
   "outputs": [],
   "source": [
    "#experiment 1-1: modified investigate_z\n",
    "z_investigate_path = '/root/Derakhshani/adversarial/textual_notes/investigate_z_{}.txt'.format(env.save_filename)\n",
    "if Path(z_investigate_path).exists(): raise FileExistsError(\"file already exists\")\n",
    "file = open(str(z_investigate_path), 'w')\n",
    "        \n",
    "for i, (z, noise) in enumerate(zip(pruned_z_s, pruned_noises)):\n",
    "  hist = compute_prediction_histogram(learn, noise)\n",
    "  indexed_hist = [(i, val) for i, val in enumerate(hist)]\n",
    "  sorted_hist = sorted(indexed_hist, key=lambda x: x[1], reverse=True)\n",
    "  labeled_hist = [(class_index_to_label(i), count) for i, count in sorted_hist]\n",
    "  print(\"result {}:\".format(i))\n",
    "  print(big_vector_to_str(z))\n",
    "  print(labeled_hist[:6])\n",
    "  print(\"\\n\\n\")\n",
    "  \n",
    "  file.write(\"result {}:\\n\".format(i))\n",
    "  file.write(big_vector_to_str(z) + \"\\n\")\n",
    "  file.write(str(labeled_hist[:6]))\n",
    "  file.write(\"\\n\\n\\n\")\n",
    "  file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bp6YOnipMKtz"
   },
   "outputs": [],
   "source": [
    "#experiment 2\n",
    "import itertools\n",
    "z_s = [torch.tensor(t).cuda() for t in itertools.product( *([[-0.33, 0.33]] * 10) )]\n",
    "model = learn.model.eval()\n",
    "noises = []\n",
    "with torch.no_grad():\n",
    "  for z in z_s:\n",
    "    noises.append(model.forward_single_z(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "55lErWDyMKt1"
   },
   "outputs": [],
   "source": [
    "x_img = normalize(learn.data.train_ds[50][0].data.cuda())\n",
    "\n",
    "preds = []\n",
    "for noise in noises:\n",
    "  perturbed_img = x_img + noise\n",
    "  preds.append(torch.argmax(arch(perturbed_img[None]), 1)[0].item())\n",
    "\n",
    "from collections import Counter\n",
    "result = [(class_index_to_label(index), count) for index, count in Counter(preds).most_common(5)]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4WSg-wBFMKt5"
   },
   "outputs": [],
   "source": [
    "#experiment 3\n",
    "import itertools\n",
    "dimension_values = [[-0.9, 0.9]] * z_dim\n",
    "for i in range(z_dim):\n",
    "  if i % 100 != 0:\n",
    "    dimension_values[i] = [0.]\n",
    "# dimension_values[0] = [0.]\n",
    "# dimension_values[3] = [0.]\n",
    "# dimension_values[6] = [0.]\n",
    "# dimension_values[9] = [0.]\n",
    "pruned_z_s = [torch.tensor(t).cuda() for t in itertools.product(*dimension_values)]\n",
    "model = learn.model.eval()\n",
    "with torch.no_grad():\n",
    "  pruned_noises = [model.forward_single_z(z) for z in pruned_z_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oElDafNpuWAh"
   },
   "outputs": [],
   "source": [
    "#experiment 3: for the targeted-attack case\n",
    "pruned_z_s = []\n",
    "for i in range(z_dim):\n",
    "  new_z = torch.zeros(z_dim).cuda()\n",
    "  new_z[i] = 1.\n",
    "  pruned_z_s.append(new_z)\n",
    "  \n",
    "model = learn.model.eval()\n",
    "with torch.no_grad():\n",
    "  pruned_noises = [model.forward_single_z(z) for z in pruned_z_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Yk3VYHiuWAi"
   },
   "outputs": [],
   "source": [
    "#experiment 3-1: noises for \n",
    "pruned_z_s = []\n",
    "# for i in range(z_dim):\n",
    "#   new_z = torch.empty(z_dim).uniform_(0,1).cuda().detach()\n",
    "#   pruned_z_s.append(new_z)\n",
    "\n",
    "for i in range(z_dim):\n",
    "  new_z = torch.zeros(z_dim).cuda().detach()\n",
    "  new_z[i] = 1.\n",
    "  pruned_z_s.append(new_z)\n",
    "  \n",
    "model = learn.model.eval()\n",
    "with torch.no_grad():\n",
    "  pruned_noises = [model.forward_single_z(z) for z in pruned_z_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "knpomasruWAk"
   },
   "outputs": [],
   "source": [
    "for noise in pruned_noises[0:200]:\n",
    "  img = noise_to_image(noise)\n",
    "  img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "suMILOqauWAn"
   },
   "outputs": [],
   "source": [
    "# spider web\n",
    "z_values = [\n",
    "  [ 0.33, -0.33,  0.33,  0.33, -0.33,  0.33, -0.33, -0.33, -0.33, -0.33],\n",
    "  [ 0.33,  0.33, -0.33, -0.33, -0.33,  0.33, -0.33,  0.33, -0.33, -0.33],\n",
    "  [ 0.33,  0.33, -0.33,  0.33,  0.33, -0.33, -0.33, -0.33,  0.33, -0.33],\n",
    "  [-0.33, -0.33, -0.33, -0.33, -0.33, -0.33, -0.33, -0.33, -0.33, -0.33],\n",
    "  [-0.33, -0.33, -0.33, -0.33, -0.33,  0.33,  0.33, -0.33,  0.33,  0.33],\n",
    "  [-0.33, -0.33, -0.33,  0.33,  0.33, -0.33, -0.33, -0.33, -0.33, -0.33],\n",
    "  [-0.33, -0.33,  0.33,  0.33, -0.33, -0.33,  0.33, -0.33,  0.33, -0.33],\n",
    "  [-0.33,  0.33, -0.33,  0.33,  0.33, -0.33,  0.33,  0.33,  0.33,  0.33],\n",
    "  [-0.33,  0.33,  0.33,  0.33, -0.33, -0.33,  0.33,  0.33, -0.33, -0.33],\n",
    "  [ 0.33, -0.33, -0.33, -0.33,  0.33,  0.33, -0.33, -0.33, -0.33, -0.33],\n",
    "  [ 0.33, -0.33,  0.33,  0.33, -0.33, -0.33,  0.33,  0.33, -0.33,  0.33],\n",
    "  [ 0.33,  0.33, -0.33,  0.33, -0.33, -0.33,  0.33,  0.33, -0.33,  0.33],\n",
    "  [ 0.33,  0.33,  0.33, -0.33, -0.33, -0.33, -0.33,  0.33, -0.33, -0.33],\n",
    "  [ 0.33,  0.33,  0.33,  0.33, -0.33, -0.33, -0.33,  0.33, -0.33, -0.33],\n",
    "  [ 0.33,  0.33,  0.33,  0.33,  0.33,  0.33,  0.33,  0.33,  0.33, -0.33],\n",
    "  [ 0.33,  0.33,  0.33, -0.33, -0.33, -0.33, -0.33,  0.33,  0.33, -0.33],\n",
    "]\n",
    "\n",
    "if any(z_values.count(x) > 1 for x in z_values):\n",
    "  raise Exception(\"duplicate\")\n",
    "  \n",
    "z_s = [torch.tensor(z).cuda() for z in z_values]\n",
    "model = learn.model.eval()\n",
    "\n",
    "for z in z_s:\n",
    "  img = noise_to_image(model.forward_single_z(z))\n",
    "  img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xMATKhO5uWAo"
   },
   "outputs": [],
   "source": [
    "z_values = [\n",
    "  # window screen\n",
    "  [-0.33,  0.33,  0.33, -0.33, -0.33,  0.33, -0.33, -0.33, -0.33, -0.33],\n",
    "  [-0.33,  0.33,  0.33, -0.33, -0.33, -0.33, -0.33, -0.33,  0.33,  0.33],\n",
    "]\n",
    "\n",
    "if any(z_values.count(x) > 1 for x in z_values):\n",
    "  raise Exception(\"duplicate\")\n",
    "  \n",
    "z_s = [torch.tensor(z).cuda() for z in z_values]\n",
    "model = learn.model.eval()\n",
    "\n",
    "for z in z_s:\n",
    "  img = noise_to_image(model.forward_single_z(z))\n",
    "  img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KuAVZzmKMKt9"
   },
   "outputs": [],
   "source": [
    "#vgg-16_12 most repeated labels:\n",
    "l = [(611, 215.0),\n",
    "  (474, 194.1),\n",
    "  (398, 120.3),\n",
    "  (721, 79.6),\n",
    "  (741, 73.5),\n",
    "  (510, 62.5)]\n",
    "\n",
    "[(class_index_to_label(index), count) for index, count in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FAgk-YyWc3rG"
   },
   "outputs": [],
   "source": [
    "# learn.recorder.plot_losses()\n",
    "# learn.recorder.plot_lr()\n",
    "# learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YTHG4Bt7VDYp"
   },
   "outputs": [],
   "source": [
    "fooling_rates = []\n",
    "model = learn.model.eval()\n",
    "learn.metrics = [validation_single_perturbation]\n",
    "for i in range(10):\n",
    "  global_perturbations = model(torch.rand(1, 3, 224, 244).cuda())[0]\n",
    "  nag_util.global_perturbations = global_perturbations\n",
    "  fooling_rates.append(learn.validate()[1].cpu().item())\n",
    "  print(\"%d : %f\"%(i, fooling_rates[-1]))\n",
    "\n",
    "mean = np.mean(fooling_rates)\n",
    "stddev = np.std(fooling_rates)\n",
    "print(mean, stddev); print(fooling_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OFCjzI7UaY3C"
   },
   "outputs": [],
   "source": [
    "#the Image works good for floats in range [0..1]\n",
    "model = learn.model.eval()\n",
    "\n",
    "x_img = learn.data.train_ds[200][0]\n",
    "x = normalize(x_img.data.cuda())\n",
    "z = torch.tensor([-0.33,  0.33, -0.33, -0.33, -0.33,  0.33,  0.33, -0.33, -0.33, -0.33], dtype=torch.float32).cuda()\n",
    "# z = torch.empty(z_dim).uniform_(-1,1).cuda()\n",
    "p = model.forward_single_z(z).detach()\n",
    "\n",
    "p_x = x + p\n",
    "# print(\"img range, noise range\")\n",
    "# print_range(x); print_range(p)\n",
    "adv_label = class_index_to_label(arch(p_x[None]).argmax(1).item())\n",
    "print_big_vector(arch(p_x[None])[0])\n",
    "p_x = denormalize(p_x)\n",
    "p_x.clamp_(0,1)\n",
    "\n",
    "\n",
    "#prepare images\n",
    "p_x_img = Image(p_x)\n",
    "p = scale_to_range(p, [0., 1.])\n",
    "p_img = Image(p)\n",
    "x_img.show()\n",
    "p_img.show()\n",
    "p_x_img.show()\n",
    "\n",
    "\n",
    "# print_range(p)\n",
    "# print_range(denormalize(x))\n",
    "# print_range(p_x)\n",
    "\n",
    "benign_label = class_index_to_label(arch(x[None]).argmax(1).item())\n",
    "\n",
    "print_big_vector(arch(x[None])[0])\n",
    "print(benign_label, adv_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mzwsI2P1ZANz"
   },
   "outputs": [],
   "source": [
    "z1 = torch.tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1], dtype=torch.float32).cuda()\n",
    "p1 = model.forward_single_z(z1)\n",
    "\n",
    "z2 = torch.tensor([1, -1, -1, -1, -1, -1, -1, -1, -1, -1], dtype=torch.float32).cuda()\n",
    "p2 = model.forward_single_z(z2)\n",
    "\n",
    "z3 = torch.tensor([1, 1, -1, -1, -1, -1, -1, -1, -1, -1], dtype=torch.float32).cuda()\n",
    "p3 = model.forward_single_z(z3)\n",
    "\n",
    "l2_distance(p1, p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eroI82OKSnAL"
   },
   "outputs": [],
   "source": [
    "# the Image works good for floats in range [0..1]\n",
    "model = learn.model.eval()\n",
    "\n",
    "x_img = learn.data.train_ds[4][0]\n",
    "x = x_img.data[None].cuda()\n",
    "p = model(x)[0].squeeze().detach() \n",
    "x = x.squeeze()\n",
    "x = normalize(x)\n",
    "\n",
    "p_x = x + p\n",
    "p_x = denormalize(p_x)\n",
    "p_x.clamp_(0,1)\n",
    "\n",
    "\n",
    "#prepare images\n",
    "p_x_img = Image(p_x)\n",
    "p = scale_to_range(p, [0.,1.])\n",
    "p_img = Image(p)\n",
    "# x_img.show()\n",
    "p_img.show()\n",
    "# p_x_img.show()\n",
    "\n",
    "print_range(p)\n",
    "print_range(x)\n",
    "print_range(p_x)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NAG_denoiserTest_withRobustnessMetric.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
