{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ahmad-PH/nag-notebooks/blob/master/NAG_tripletLossExperiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cqeZpz16do4y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up-to-date.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os; import subprocess\n",
    "\n",
    "def detect_env():\n",
    "    return 'colab' if 'content' in os.listdir('/') else 'IBM'\n",
    "  \n",
    "def run_shell_command(cmd):\n",
    "  p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)\n",
    "  print(str(p.communicate()[0], 'utf-8'))\n",
    "  \n",
    "if detect_env() == 'colab': root_folder = '/content'\n",
    "elif detect_env() == 'IBM' : root_folder = '/root/Derakhshani/adversarial'\n",
    "python_files_path = root_folder + '/nag-public'\n",
    "if os.path.isdir(python_files_path):\n",
    "  initial_dir = os.getcwd()\n",
    "  os.chdir(python_files_path)\n",
    "  run_shell_command('git pull')\n",
    "  os.chdir(initial_dir)\n",
    "else:\n",
    "  os.chdir('/root/Derakhshani/adversarial')\n",
    "  run_shell_command('git clone https://github.com/ahmad-PH/nag-public.git')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.imports import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.utils.mem import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import sys; import os; import shutil\n",
    "import art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(python_files_path + '/NAG-11May-beforeDenoiser')\n",
    "\n",
    "from nag_util import *\n",
    "import nag_util\n",
    "from environment import *\n",
    "from visualization import *\n",
    "from utility import *\n",
    "\n",
    "env = create_env()\n",
    "env.setup(cuda_index = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_arch = \"targeted\"\n",
    "# gen_arch = \"non-targeted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneralRelu(nn.Module):\n",
    "  def __init__(self, leak=None, sub=None, maxv=None):\n",
    "    super().__init__()\n",
    "    self.leak,self.sub,self.maxv = leak,sub,maxv\n",
    "\n",
    "  def forward(self, x): \n",
    "    x = F.leaky_relu(x,self.leak) if self.leak is not None else F.relu(x)\n",
    "    if self.sub is not None: x.sub_(self.sub)\n",
    "    if self.maxv is not None: x.clamp_max_(self.maxv)\n",
    "    return x\n",
    "  \n",
    "class deconv_layer(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k_size = (4,4), s = (2,2), pad = (1,1), b = True, activation = True):\n",
    "        super(deconv_layer, self).__init__()\n",
    "\n",
    "        self.CT2d = nn.ConvTranspose2d(in_channels = in_ch,\n",
    "                                  out_channels = out_ch,\n",
    "                                  kernel_size = k_size,\n",
    "                                  stride = s, \n",
    "                                  padding = pad,\n",
    "                                  bias = b)\n",
    "        self.BN2d = nn.BatchNorm2d(out_ch)\n",
    "        \n",
    "        self.activation = activation\n",
    "        if self.activation:\n",
    "            self.relu = GeneralRelu(0, 0.2, 5)\n",
    "        \n",
    "        self.weight_init()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        if self.activation:\n",
    "            return self.relu(self.BN2d(self.CT2d(input)))\n",
    "        else:\n",
    "            return self.BN2d(self.CT2d(input))\n",
    "\n",
    "    def weight_init(self):\n",
    "        self.CT2d.weight.data.normal_(mean = 0, std = 0.02)\n",
    "        self.CT2d.bias.data.fill_(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class deconv_layer(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k_size = (4,4), s = (2,2), pad = (1,1), b = True, activation = True):\n",
    "        super(deconv_layer, self).__init__()\n",
    "\n",
    "        self.CT2d = nn.ConvTranspose2d(in_channels = in_ch,\n",
    "                                  out_channels = out_ch,\n",
    "                                  kernel_size = k_size,\n",
    "                                  stride = s, \n",
    "                                  padding = pad,\n",
    "                                  bias = b)\n",
    "        self.BN2d = nn.BatchNorm2d(out_ch)\n",
    "        self.activation = activation\n",
    "\n",
    "        self.weight_init()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        if self.activation:\n",
    "            return F.relu(self.BN2d(self.CT2d(input)), inplace=True)\n",
    "        else:\n",
    "            return self.BN2d(self.CT2d(input))\n",
    "\n",
    "    def weight_init(self):\n",
    "        self.CT2d.weight.data.normal_(mean = 0, std = 0.02)\n",
    "        self.CT2d.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gen_arch == \"targeted\":\n",
    "  class Gen(nn.Module):\n",
    "    def __init__(self, z_dim, active_labels = (0, 1000), gf_dim=64, y_dim = None,\n",
    "                 df_dim = 64, image_shape = [3,128,128]):\n",
    "      super(Gen, self).__init__()\n",
    "      \n",
    "      self.bs = None\n",
    "      self.z_dim = z_dim\n",
    "      self.gf_dim = gf_dim\n",
    "      self.y_dim = y_dim\n",
    "      self.df_dim = df_dim\n",
    "      self.image_shape = image_shape\n",
    "      self.active_labels = active_labels\n",
    "      \n",
    "      self.n_unit_coeffs = [10, 7, 4, 2, 1, 1, 1]\n",
    "      self.n_units = [coeff * self.gf_dim for coeff in self.n_unit_coeffs]\n",
    "      \n",
    "      self.z_ = nn.Linear(self.z_dim, self.n_units[0] * 4 * 4, bias=True)\n",
    "      self.z_.bias.data.fill_(0)\n",
    "      self.BN_ = nn.BatchNorm2d(self.n_units[0])\n",
    "\n",
    "      self.half = max(self.gf_dim // 2, 1) \n",
    "      self.quarter = max(self.gf_dim // 4, 1)\n",
    "      self.eighth = max(self.gf_dim // 8, 1)\n",
    "      # sixteenth = max(self.gf_dim // 16, 1)\n",
    "\n",
    "      self.CT2d_1 = deconv_layer(self.n_units[0], self.n_units[1], k_size = (5,5), pad = (2,2))\n",
    "      self.CT2d_2 = deconv_layer(self.n_units[1], self.n_units[2])    \n",
    "      self.CT2d_3 = deconv_layer(self.n_units[2], self.n_units[3])\n",
    "      self.CT2d_4 = deconv_layer(self.n_units[3], self.n_units[4])\n",
    "      self.CT2d_5 = deconv_layer(self.n_units[4], self.n_units[5])\n",
    "      self.CT2d_6 = deconv_layer(self.n_units[5], self.n_units[6])\n",
    "      self.CT2d_7 = deconv_layer(self.n_units[6], 3, k_size = (5,5), s = (1,1), pad = (2,2), activation = False)\n",
    "      \n",
    "      self.ksi = 10.0\n",
    "      self.output_coeff = self.ksi / (255.0 * np.mean(imagenet_stats[1])) \n",
    "\n",
    "    def randomized_deconv_layer(self, h_input, z_size_0, z_size_1, deconv_layer, expected_output_size):\n",
    "      h_input_z = self.make_z([self.bs, z_size_0, z_size_1, z_size_1])\n",
    "      h_input = torch.cat([h_input, h_input_z], dim = 1)\n",
    "      output = deconv_layer(h_input)\n",
    "      assert output.shape[2:] == (expected_output_size, expected_output_size), \\\n",
    "              \"Unexpected output shape at randomized_deconv_layer. expected\" + \\\n",
    "              \"({0},{0}), got {1}\".format(expected_output_size, output.shape[2:])\n",
    "      return output\n",
    "\n",
    "    def forward_z(self, z):\n",
    "      self.bs = z.shape[0]\n",
    "\n",
    "      h0 = F.relu(self.BN_(self.z_(z).contiguous().view(self.bs, -1, 4, 4)))\n",
    "      assert h0.shape[2:] == (4, 4), \"Unexpected shape, it shoud be (4,4)\"\n",
    "\n",
    "      h1 = self.CT2d_1(h0)\n",
    "      h2 = self.CT2d_2(h1)\n",
    "      h3 = self.CT2d_3(h2)\n",
    "      h4 = self.CT2d_4(h3)\n",
    "      h5 = self.CT2d_5(h4)\n",
    "      h6 = self.CT2d_6(h5)\n",
    "      h7 = self.CT2d_7(h6)\n",
    "      \n",
    "#       h1 = self.randomized_deconv_layer(h0, self.gf_dim, 4, self.CT2d_1, 7)\n",
    "#       h2 = self.randomized_deconv_layer(h1, self.gf_dim, 7, self.CT2d_2, 14)\n",
    "#       h3 = self.randomized_deconv_layer(h2, self.half, 14, self.CT2d_3, 28)\n",
    "#       h4 = self.randomized_deconv_layer(h3, self.quarter, 28, self.CT2d_4, 56)\n",
    "#       h5 = self.randomized_deconv_layer(h4, self.eighth, 56, self.CT2d_5, 112)\n",
    "#       h6 = self.randomized_deconv_layer(h5, self.eighth, 112, self.CT2d_6, 224)\n",
    "#       h7 = self.randomized_deconv_layer(h6, self.eighth, 224, self.CT2d_7, 224)\n",
    "\n",
    "      # this coeff scales the output to be appropriate for images that are \n",
    "      # normalized using imagenet_stats (and are hence in the approximate [-2.5, 2.5]\n",
    "      # interval)\n",
    "      return self.output_coeff * torch.tanh(h7)\n",
    "\n",
    "  #   # blind-selection\n",
    "    def forward(self, inputs):\n",
    "      self.bs = inputs.shape[0]\n",
    "\n",
    "      benign_preds_onehot = arch(inputs)\n",
    "#       benign_preds = torch.argmax(benign_preds_onehot, dim = 1)\n",
    "      worst_preds = torch.argmin(benign_preds_onehot, dim = 1)\n",
    "#       second_best_preds = torch.topk(benign_preds_onehot, 2, dim=1)[1][:, 1]\n",
    "      \n",
    "      z = torch.zeros([self.bs, 1000]).cuda()\n",
    "      for i in range(self.bs):\n",
    "        random_label = worst_preds[i].item()\n",
    "        z[i][random_label] = 1.\n",
    "\n",
    "      z_out = self.forward_z(z)\n",
    "\n",
    "      return z_out, None, None, inputs, benign_preds_onehot, z\n",
    "\n",
    "  #   #second-best selection: made validation so much worse\n",
    "  #   def forward(self, inputs):\n",
    "  #     self.bs = inputs.shape[0]\n",
    "\n",
    "  #     benign_preds_onehot = arch(inputs)\n",
    "  #     target_preds = torch.topk(benign_preds_onehot, 2, dim = 1).indices[:, 1:]\n",
    "\n",
    "  #     z = torch.zeros([self.bs, 1000]).cuda()\n",
    "  #     for i in range(self.bs):\n",
    "  #       z[i][target_preds[i]] = 1.\n",
    "\n",
    "  #     z_out = self.forward_z(z)\n",
    "\n",
    "  #     return z_out, None, None, inputs, benign_preds_onehot, z\n",
    "\n",
    "  #    def forward(self, inputs):\n",
    "  #     self.bs = inputs.shape[0]\n",
    "\n",
    "  #     benign_preds_onehot = arch(inputs)\n",
    "  #     benign_preds = torch.argmax(benign_preds_onehot, dim = 1)\n",
    "\n",
    "  #     z = torch.zeros([self.bs, 1000]).cuda()\n",
    "  #     random_label = self.randint(0,1000, exclude = benign_preds.tolist())\n",
    "  #     for i in range(self.bs):\n",
    "  #       z[i][random_label] = 1.\n",
    "\n",
    "  #     z_out = self.forward_z(z)\n",
    "\n",
    "  #     return z_out, None, None, inputs, benign_preds_onehot, z\n",
    "\n",
    "    @staticmethod\n",
    "    def randint(low, high, exclude):\n",
    "      if exclude >= low and exclude < high:\n",
    "        temp = np.random.randint(low, high - 1)\n",
    "        if temp >= exclude:\n",
    "          temp = temp + 1\n",
    "        return temp\n",
    "      else:\n",
    "        return np.random.randint(low, high)\n",
    "\n",
    "    def forward_single_z(self, z):\n",
    "      return self.forward_z(z[None]).squeeze()\n",
    "\n",
    "    def generate_single_noise(self):\n",
    "      z = torch.empty(self.z_dim).uniform_(-1,1).cuda()\n",
    "      return self.forward_single_z(z)         \n",
    "\n",
    "    def make_triplet_samples(self, z, margin, r2, r3):\n",
    "      positive_sample = z + self.random_vector_volume(z.shape, 0, margin).cuda() \n",
    "      negative_sample = z + self.random_vector_volume(z.shape, r2, r3).cuda()\n",
    "      return positive_sample, negative_sample\n",
    "\n",
    "    def random_vector_surface(self, shape, r = 1.):\n",
    "      mat = torch.randn(size=shape).cuda()\n",
    "      norm = torch.norm(mat, p=2, dim=1, keepdim = True).cuda()\n",
    "      return (mat/norm) * r\n",
    "\n",
    "\n",
    "    def random_vector_volume(self, shape, inner_r, outer_r):\n",
    "      fraction = torch.empty(shape[0]).uniform_(inner_r, outer_r).cuda()\n",
    "      fraction = ((fraction / outer_r) ** (1 / shape[1])) * outer_r # volume-normalize the fraction\n",
    "      fraction.unsqueeze_(-1)\n",
    "      return self.random_vector_surface(shape, 1) * fraction\n",
    "\n",
    "    def make_z(self, in_shape):\n",
    "      return torch.empty(in_shape).cuda().uniform_(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = Gen(z_dim = 1000).cuda()\n",
    "# t = torch.empty(1000).uniform_().cuda()\n",
    "# g.forward_single_z(t).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gen_arch == \"non-targeted\":\n",
    "  class Gen(nn.Module):\n",
    "    def __init__(self, z_dim, gf_dim=64, y_dim = None, df_dim = 64, image_shape = [3,128,128]):\n",
    "      super(Gen, self).__init__()\n",
    "\n",
    "      self.bs = None\n",
    "      self.z_dim = z_dim\n",
    "      self.gf_dim = gf_dim\n",
    "      self.y_dim = y_dim\n",
    "      self.df_dim = df_dim\n",
    "      self.image_shape = image_shape\n",
    "\n",
    "      self.z_ = nn.Linear(self.z_dim, self.gf_dim * 7 * 4 * 4, bias=True)\n",
    "      self.z_.bias.data.fill_(0)\n",
    "      self.BN_ = nn.BatchNorm2d(self.gf_dim * 7)\n",
    "\n",
    "      self.half = max(self.gf_dim // 2, 1) \n",
    "      self.quarter = max(self.gf_dim // 4, 1)\n",
    "      self.eighth = max(self.gf_dim // 8, 1)\n",
    "      # sixteenth = max(self.gf_dim // 16, 1)\n",
    "\n",
    "      self.CT2d_1 = deconv_layer(self.gf_dim * 8, self.gf_dim * 4, k_size = (5,5), pad = (2,2))\n",
    "      self.CT2d_2 = deconv_layer(self.gf_dim * 5, self.gf_dim * 2)    \n",
    "      self.CT2d_3 = deconv_layer(self.gf_dim * 2 + self.half, self.gf_dim * 1)\n",
    "      self.CT2d_4 = deconv_layer(self.gf_dim * 1 + self.quarter, self.gf_dim * 1)\n",
    "      self.CT2d_5 = deconv_layer(self.gf_dim * 1 + self.eighth, self.gf_dim * 1)\n",
    "      self.CT2d_6 = deconv_layer(self.gf_dim * 1 + self.eighth, self.gf_dim * 1)\n",
    "      self.CT2d_7 = deconv_layer(self.gf_dim * 1 + self.eighth, 3, k_size = (5,5), s = (1,1), pad = (2,2), activation = False)\n",
    "\n",
    "      self.ksi = 10.0\n",
    "      self.output_coeff = self.ksi / (255.0 * np.mean(imagenet_stats[1])) \n",
    "      \n",
    "    def randomized_deconv_layer(self, h_input, z_size_0, z_size_1, deconv_layer, expected_output_size):\n",
    "      h_input_z = self.make_z([self.bs, z_size_0, z_size_1, z_size_1])\n",
    "      h_input = torch.cat([h_input, h_input_z], dim = 1)\n",
    "      output = deconv_layer(h_input)\n",
    "      assert output.shape[2:] == (expected_output_size, expected_output_size), \\\n",
    "              \"Unexpected output shape at randomized_deconv_layer. expected\" + \\\n",
    "              \"({0},{0}), got {1}\".format(expected_output_size, output.shape[2:])\n",
    "      return output\n",
    "\n",
    "    def forward_z(self, z):\n",
    "      self.bs = z.shape[0]\n",
    "\n",
    "      h0 = F.relu(self.BN_(self.z_(z).contiguous().view(self.bs, -1, 4, 4)))\n",
    "      assert h0.shape[2:] == (4, 4), \"Non-expected shape, it shoud be (4,4)\"\n",
    "\n",
    "      h1 = self.randomized_deconv_layer(h0, self.gf_dim, 4, self.CT2d_1, 7)\n",
    "      h2 = self.randomized_deconv_layer(h1, self.gf_dim, 7, self.CT2d_2, 14)\n",
    "      h3 = self.randomized_deconv_layer(h2, self.half, 14, self.CT2d_3, 28)\n",
    "      h4 = self.randomized_deconv_layer(h3, self.quarter, 28, self.CT2d_4, 56)\n",
    "      h5 = self.randomized_deconv_layer(h4, self.eighth, 56, self.CT2d_5, 112)\n",
    "      h6 = self.randomized_deconv_layer(h5, self.eighth, 112, self.CT2d_6, 224)\n",
    "      h7 = self.randomized_deconv_layer(h6, self.eighth, 224, self.CT2d_7, 224)\n",
    "\n",
    "      # this coeff scales the output to be appropriate for images that are \n",
    "      # normalized using imagenet_stats (and are hence in the approximate [-2.5, 2.5]\n",
    "      # interval)\n",
    "      return self.output_coeff * torch.tanh(h7)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "      self.bs = inputs.shape[0]\n",
    "      z = inputs.new_empty([self.bs, self.z_dim]).uniform_(-1,1).cuda()\n",
    "      p, n = self.make_triplet_samples(z, 0.1, 0.1, 2.)\n",
    "\n",
    "      z_out = self.forward_z(z)\n",
    "#       p_out = self.forward_z(p)\n",
    "#       n_out = self.forward_z(n)\n",
    "\n",
    "#       return z_out, p_out, n_out, inputs, z\n",
    "      return z_out, None, None, inputs, z\n",
    "\n",
    "    def forward_single_z(self, z):\n",
    "      return self.forward_z(z[None]).squeeze()\n",
    "\n",
    "    def generate_single_noise(self):\n",
    "      z = torch.empty(self.z_dim).uniform_(-1,1).cuda()\n",
    "      return self.forward_single_z(z)\n",
    "\n",
    "\n",
    "    def make_triplet_samples(self, z, margin, r2, r3):\n",
    "      positive_sample = z + self.random_vector_volume(z.shape, 0, margin).cuda() \n",
    "      negative_sample = z + self.random_vector_volume(z.shape, r2, r3).cuda()\n",
    "      return positive_sample, negative_sample\n",
    "\n",
    "    def random_vector_surface(self, shape, r = 1.):\n",
    "      mat = torch.randn(size=shape).cuda()\n",
    "      norm = torch.norm(mat, p=2, dim=1, keepdim = True).cuda()\n",
    "      return (mat/norm) * r\n",
    "\n",
    "\n",
    "    def random_vector_volume(self, shape, inner_r, outer_r):\n",
    "      fraction = torch.empty(shape[0]).uniform_(inner_r, outer_r).cuda()\n",
    "      fraction = ((fraction / outer_r) ** (1 / shape[1])) * outer_r # volume-normalize the fraction\n",
    "      fraction.unsqueeze_(-1)\n",
    "      return self.random_vector_surface(shape, 1) * fraction\n",
    "\n",
    "    def make_z(self, in_shape):\n",
    "      return torch.empty(in_shape).cuda().uniform_(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def js_distance(x1, x2):\n",
    "  m = 0.5 * (x1 + x2)\n",
    "  return 0.5 * (F.kl_div(x1, m) + F.kl_div(x2, m))\n",
    "\n",
    "def kl_distance(x1, x2):\n",
    "  inp = torch.log(x1)\n",
    "  target = x2\n",
    "  return F.kl_div(inp, target, reduction='batchmean')\n",
    "\n",
    "def distrib_distance(x1, x2):\n",
    "  x1 = tensorify(x1)\n",
    "  x2 = tensorify(x2)\n",
    "  x1 = x1 / torch.sum(x1)\n",
    "  x2 = x2 / torch.sum(x2)\n",
    "  return kl_distance(x1[None], x2[None])\n",
    "\n",
    "def distrib_distance(x1, x2):\n",
    "  if not isinstance(x1, torch.Tensor): x1 = torch.tensor(x1)\n",
    "  if not isinstance(x2, torch.Tensor): x2 = torch.tensor(x2)\n",
    "  x1 = x1 * 100. / torch.sum(x1)\n",
    "  x2 = x2 * 100. / torch.sum(x2)\n",
    "  return torch.norm(x1 - x2, 2)\n",
    "\n",
    "def distance_from_uniform(x):\n",
    "  return distrib_distance(x, [1.] * len(x))\n",
    "\n",
    "def wasserstein_distance(x1, x2):\n",
    "  return torch.mean(x1 - x2)\n",
    "\n",
    "def l1_distance(x1, x2):\n",
    "  return F.l1_loss(x1, x2)\n",
    "\n",
    "def l2_distance(x1, x2):\n",
    "  return F.mse_loss(x1 * 10, x2 * 10)\n",
    "\n",
    "def mse_loss(x1, x2):\n",
    "  return F.mse_loss(x1, x2)\n",
    "\n",
    "def cos_distance(x1, x2, dim = 1):\n",
    "  return -1 * torch.mean(F.cosine_similarity(x1, x2, dim=dim))\n",
    "\n",
    "\n",
    "def triplet_loss(anchor, positive, negative, distance_func, margin):\n",
    "  # max distance when using l1_distance is 2\n",
    "  # max distacne when using l2-distance is sqrt(2)\n",
    "  ap_dist = distance_func(anchor, positive)\n",
    "  an_dist = distance_func(anchor, negative)\n",
    "\n",
    "  triplet_loss.call_count += 1\n",
    "  if triplet_loss.call_count % 200 == 0 : #and anchor.shape[1] == 1000:\n",
    "#     print(\"a: \", end=\"\"); print_big_vector(anchor[0])\n",
    "#     print(\"p: \", end=\"\"); print_big_vector(positive[0])\n",
    "#     print(\"n: \", end=\"\"); print_big_vector(negative[0])\n",
    "    print(\"func:{}, ap_dist: {}, an_dist: {}\".format(distance_func.__name__, ap_dist, an_dist))\n",
    "    \n",
    "  return torch.mean(F.relu(ap_dist - an_dist + margin))\n",
    "\n",
    "triplet_loss.call_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def diversity_loss(embeddings, z_s):\n",
    "#   size = z_s.shape[0]\n",
    "#   result = 0\n",
    "#   for i in range(size):\n",
    "#     for j in range(i+1, size):\n",
    "# #       a = F.cosine_similarity(embeddings[i], embeddings[j], dim = 0)\n",
    "# #       b = torch.norm(z_s[i] - z_s[j], 2, dim = 0)\n",
    "# #       print('embeddings: ')\n",
    "# #       print_big_vector(embeddings[i])\n",
    "# #       print_big_vector(embeddings[j])\n",
    "# #       print(f'a: {a}, b:{b}, multiple: {a*b}')\n",
    "#       result += F.cosine_similarity(embeddings[i], embeddings[j], dim = 0) * \\\n",
    "#                 torch.norm(z_s[i] - z_s[j], 2, dim = 0)\n",
    "#   n_pairs = (size * (size - 1)) / 2\n",
    "#   mean = result / n_pairs \n",
    "# #   print(f'result {result}, n_pairs {n_pairs}, mean {mean}')\n",
    "#   return mean\n",
    "  \n",
    "\n",
    "# # normalized with shuffling\n",
    "# def diversity_loss(embeddings, deranged_embeddings, z_s, deranged_z_s):\n",
    "#     cos_similarity = F.cosine_similarity(embeddings, deranged_embeddings)\n",
    "#     z_distance = torch.norm(z_s - deranged_z_s, 2, dim = 1)\n",
    "#     return torch.mean(cos_similarity * z_distance)\n",
    "  \n",
    "# # normalized with shuffling\n",
    "# def diversity_loss(embeddings, z_s):\n",
    "#     deranged_embeddings, deranged_z_s = derange(embeddings, z_s)\n",
    "#     cos_similarity = F.cosine_similarity(embeddings, deranged_embeddings)\n",
    "#     z_distance = torch.norm(z_s - deranged_z_s, dim = 1)\n",
    "#     max_possible_z_distance = 6.3246\n",
    "#     return torch.mean(cos_similarity * (z_distance/max_possible_z_distance))\n",
    "\n",
    "\n",
    "def diversity_loss(input, target):\n",
    "#   return -1 * torch.mean(torch.pow(f_x_a-f_x_s,2))\n",
    "  if input.shape[0] != batch_size:\n",
    "    print(\"input shape: \", input.shape)\n",
    "    print(\"target shape: \", target.shape, \"\\n\\n\")\n",
    "  return torch.mean(F.cosine_similarity(\n",
    "    input.view([batch_size, -1]),\n",
    "    target.view([batch_size, -1]), \n",
    "  ))\n",
    "\n",
    "\n",
    "if gen_arch == 'non-targeted':\n",
    "  def fool_loss(input, target):\n",
    "    true_class = torch.argmax(target, dim=1).view(-1,1).long().cuda()\n",
    "    target_probabilities = input.gather(1, true_class)\n",
    "    epsilon = 1e-10\n",
    "    result =  torch.mean(-1 * torch.log(1 - target_probabilities + epsilon))\n",
    "\n",
    "    fool_loss.call_count += 1\n",
    "    if fool_loss.call_count % 200 == 0:\n",
    "      print(\"target probs {}, loss: {}: \".format(target_probabilities, result))\n",
    "\n",
    "    return result\n",
    "\n",
    "  fool_loss.call_count = 0\n",
    "\n",
    "if gen_arch == 'targeted':\n",
    "  def fool_loss(model_output, target_labels):\n",
    "    target_labels = target_labels.view(-1, 1).long().cuda()\n",
    "    target_probabilities = model_output.gather(1, target_labels)\n",
    "    epsilon = 1e-10\n",
    "    # highest possible fool_loss is - log(1e-10) == 23\n",
    "    result = torch.mean(-1 * torch.log(target_probabilities + epsilon))\n",
    "\n",
    "    fool_loss.call_count += 1\n",
    "    if fool_loss.call_count % 200 == 0:\n",
    "      print(\"target probs {}, loss: {}: \".format(target_probabilities, result))\n",
    "\n",
    "    return result\n",
    "\n",
    "  fool_loss.call_count = 0\n",
    "\n",
    "\n",
    "def targeted_validation(gen_output, target):\n",
    "  perturbations, _, _, clean_images, _, z = gen_output\n",
    "  perturbed_images = clean_images + perturbations\n",
    "  target_labels = torch.argmax(z, 1)\n",
    "  adversary_preds = torch.argmax(arch(perturbed_images), 1)\n",
    "#   print('adv preds: ', adversary_preds.shape, adversary_preds)\n",
    "#   print('target_labels: ', target_labels.shape, target_labels)\n",
    "#   print('eq: ', (adversary_preds == target_labels))\n",
    "  return (adversary_preds == target_labels).float().mean()\n",
    "  \n",
    "\n",
    "# # targeted \n",
    "# def validation(gen_output, target):\n",
    "#   perturbations, _, _, clean_images, _, _ = gen_output\n",
    "#   return validation_(perturbations, clean_images)\n",
    "\n",
    "# # non-targeted\n",
    "# def validation(gen_output, target):\n",
    "#   perturbations, _, _, clean_images, _ = gen_output\n",
    "#   return validation_(perturbations, clean_images)\n",
    "\n",
    "# # general\n",
    "def validation(gen_output, target):\n",
    "  perturbations = gen_output[0]\n",
    "  clean_images = gen_output[3]\n",
    "  return validation_(perturbations, clean_images)\n",
    "\n",
    "unfooled_histogram = np.array([0.] * 1000)\n",
    "fooled_histogram = np.array([0.] * 1000)\n",
    "valid_cnt = 0\n",
    "\n",
    "def print_hist(unfooled, fooled):\n",
    "  indexed = [(i, u) for i, u in enumerate(unfooled)]\n",
    "  summarized = list(filter(lambda x: x[1] > 0.0, indexed))\n",
    "  total = fooled + unfooled\n",
    "\n",
    "  percent_total = [(i, 100. * u / (total[i] + 1e-10), total[i]) for i, u in enumerate(unfooled)]\n",
    "  sorted_percent_total = sorted(percent_total, key =lambda x: x[1], reverse = True)\n",
    "\n",
    "  print('\\npercent_total: ')\n",
    "  print(list(filter(lambda x: x[1] > 0.0, sorted_percent_total)))\n",
    "  print('\\n')\n",
    "  \n",
    "  return sorted_percent_total\n",
    "\n",
    "def validation_(perturbations, clean_images):\n",
    "  perturbed_images = clean_images + perturbations\n",
    "  benign_preds = torch.argmax(arch(clean_images), 1)\n",
    "  adversary_preds = torch.argmax(arch(perturbed_images), 1)\n",
    "\n",
    "  is_unfooled = (benign_preds == adversary_preds)\n",
    "  for i , unfooled in enumerate(is_unfooled):\n",
    "    if unfooled == 1:\n",
    "      unfooled_histogram[benign_preds[i]] += 1\n",
    "    else:\n",
    "      fooled_histogram[benign_preds[i]] += 1\n",
    "  \n",
    "#   global valid_cnt\n",
    "#   valid_cnt += 1\n",
    "#   if valid_cnt % 10 == 0:\n",
    "#     print_hist(unfooled_histogram, fooled_histogram)\n",
    "    \n",
    "  return (benign_preds != adversary_preds).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gen_arch == 'targeted':\n",
    "  class FeatureLoss(nn.Module):\n",
    "      def __name__(self):\n",
    "        return \"feature_loss\"\n",
    "\n",
    "      def __init__(self, dis, layers, layer_weights):\n",
    "          super().__init__()\n",
    "\n",
    "          # define generator here \n",
    "          self.dis = dis\n",
    "          self.diversity_layers = layers\n",
    "          self.hooks = hook_outputs(self.diversity_layers, detach=False)\n",
    "          self.weights = layer_weights\n",
    "          self.metric_names = [\"fool_loss\"] #+ [f\"div_loss_{i}\" for i in range(len(layers))] #maybe Gram\n",
    "  #         self.triplet_hooks = hook_outputs([arch.m.features[4]], detach=False)\n",
    "\n",
    "      def make_features(self, x, clone=False):\n",
    "          y = self.dis(x)\n",
    "          return y, [(o.clone() if clone else o) for o in self.hooks.stored]\n",
    "\n",
    "      def forward(self, inp, target):\n",
    "        sigma_B, _, _, X_B, B_Y, z = inp\n",
    "\n",
    "        X_A = X_B + sigma_B\n",
    "  #       X_S = self.add_perturbation_shuffled(X_B, sigma_B) # Shuffled Addversarial Examples\n",
    "\n",
    "        A_Y, A_feat = self.make_features(X_A)\n",
    "  #       _, S_feat = self.make_features(X_S)\n",
    "\n",
    "        chosen_labels = z.argmax(dim=1)\n",
    "        fooling_loss =  fool_loss(A_Y, chosen_labels)\n",
    "\n",
    "  #       raw_diversity_losses = [diversity_loss(a_f, s_f) for a_f, s_f in zip(A_feat, S_feat)]\n",
    "  #       weighted_diversity_losses = [diversity_loss(a_f, s_f) * weight for a_f, s_f, weight in zip(A_feat, S_feat, self.weights)]\n",
    "\n",
    "  #       self.losses = [fooling_loss] + weighted_diversity_losses\n",
    "  #       self.metrics = dict(zip(self.metric_names, [fooling_loss] + raw_diversity_losses))\n",
    "\n",
    "        self.losses = [fooling_loss]\n",
    "        self.metrics = dict(zip(self.metric_names, [fooling_loss]))\n",
    "\n",
    "        return sum(self.losses)\n",
    "\n",
    "      def add_perturbation_shuffled(self, inp, perturbation):\n",
    "  #       j = torch.randperm(inp.shape[0])\n",
    "          j = derangement(inp.shape[0])\n",
    "          return inp.add(perturbation[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derange(*args):\n",
    "  if len(args) == 0: raise ValueError('shuffle function needs atleast one argument')\n",
    "  deranged_indexes = derangement(args[0].shape[0])\n",
    "  if not all([args[0].shape[0] == arg.shape[0] for arg in args]): \n",
    "    raise ValueError('inputs to shuffle must all have the same 0th dimension')\n",
    "  return [arg[deranged_indexes] for arg in args]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gen_arch == 'non-targeted':\n",
    "  class FeatureLoss(nn.Module):\n",
    "      def __name__(self):\n",
    "        return \"feature_loss\"\n",
    "\n",
    "      def __init__(self, dis, layers, layer_weights):\n",
    "          super().__init__()\n",
    "\n",
    "          self.dis = dis\n",
    "          self.diversity_layers = layers\n",
    "          self.hooks = hook_outputs(self.diversity_layers, detach=False)\n",
    "          self.weights = layer_weights\n",
    "\n",
    "  #         self.metric_names = [\"fool_loss\"] + [f\"div_loss_{i}\" for i in range(len(layers))] + ['triplet_loss']# Maybe Gram\n",
    "  #         self.metric_names = [\"div_loss\"] + ['triplet_loss']# Maybe Gram\n",
    "          self.metric_names = [\"fool_loss\"] + ['div_loss']# Maybe Gram\n",
    "          self.triplet_weight = 4.\n",
    "          self.div_weight = 1.\n",
    "          self.fooling_weight = 1.\n",
    "\n",
    "      def make_features(self, x, clone=False):\n",
    "          y = self.dis(x)\n",
    "          return y, [(o.clone() if clone else o) for o in self.hooks.stored]\n",
    "\n",
    "      # contrastive loss\n",
    "      def forward(self, inp, target):\n",
    "          sigma_B, sigma_pos, sigma_neg, X_B, z_B = inp\n",
    "\n",
    "          deranged_perturbations, deranged_z_s = derange(sigma_B, z_B)\n",
    "\n",
    "          X_A = X_B + sigma_B\n",
    "          X_S = X_B + deranged_perturbations\n",
    "#           X_A_pos = X_B + sigma_pos\n",
    "#           X_A_neg = X_B + sigma_neg\n",
    "\n",
    "          B_Y, _ = self.make_features(X_B)\n",
    "          A_Y, A_feat = self.make_features(X_A)\n",
    "          _, S_feat = self.make_features(X_S)\n",
    "#           pos_softmax, _ = self.make_features(X_A_pos)\n",
    "#           neg_softmax, _ = self.make_features(X_A_neg)\n",
    "\n",
    "          raw_fooling_loss =  fool_loss(A_Y, B_Y)\n",
    "          weighted_fooling_loss = self.fooling_weight * raw_fooling_loss\n",
    "\n",
    "#           raw_diversity_loss = diversity_loss(A_feat[0], S_feat[0], z_B, deranged_z_s)\n",
    "          raw_diversity_loss = diversity_loss(A_feat[0], S_feat[0])\n",
    "          weighted_diversity_loss = raw_diversity_loss * self.div_weight\n",
    "\n",
    "#           raw_triplet_loss = triplet_loss(A_Y, pos_softmax, neg_softmax, cos_distance, 1.4)\n",
    "#           weighted_triplet_loss = raw_triplet_loss * self.triplet_weight\n",
    "\n",
    "  #         self.losses = weighted_diversity_losses + [weighted_triplet_loss]\n",
    "  #         raw_losses = raw_diversity_losses + [raw_triplet_loss]\n",
    "\n",
    "          self.losses = [weighted_fooling_loss] + [weighted_diversity_loss] #+ [weighted_triplet_loss]\n",
    "          raw_losses = [raw_fooling_loss] + [raw_diversity_loss] #+ [raw_triplet_loss]\n",
    "\n",
    "  #         self.losses = [fooling_loss] + [weighted_triplet_loss]\n",
    "  #         self.metrics = dict(zip(self.metric_names, [fooling_loss] + [raw_triplet_loss]))\n",
    "\n",
    "          if len(self.metric_names) != len(raw_losses):\n",
    "            raise Exception(\"length of metric names unequals length of losses\")\n",
    "\n",
    "          self.metrics = dict(zip(self.metric_names, raw_losses))\n",
    "          return sum(self.losses)\n",
    "\n",
    "\n",
    "\n",
    "  # #     triplet loss\n",
    "  #     def forward(self, inp, target):\n",
    "  #         sigma_B, sigma_pos, sigma_neg, X_B, _ = inp\n",
    "\n",
    "  #         X_A = self.add_perturbation(X_B, sigma_B) \n",
    "  #         X_A_pos = self.add_perturbation(X_B, sigma_pos)\n",
    "  #         X_A_neg = self.add_perturbation(X_B, sigma_neg) \n",
    "  #         X_S = self.add_perturbation_shuffled(X_B, sigma_B) # Shuffled Addversarial Examples\n",
    "\n",
    "  # #         B_Y, _ = self.make_features(X_B)\n",
    "  #         A_Y, A_feat = self.make_features(X_A)\n",
    "  # #         _, S_feat = self.make_features(X_S)\n",
    "  #         pos_softmax, _ = self.make_features(X_A_pos)\n",
    "  #         neg_softmax, _ = self.make_features(X_A_neg)\n",
    "\n",
    "  # #         raw_fooling_loss =  fool_loss(A_Y, B_Y)\n",
    "  # #         weighted_fooling_loss = self.fooling_weight * raw_fooling_loss\n",
    "\n",
    "  #         raw_diversity_losses = [diversity_loss(a_f, s_f, sigma_B, ) for a_f, s_f in zip(A_feat, S_feat)]\n",
    "  #         weighted_diversity_losses = [diversity_loss(a_f, s_f) * weight * self.div_weight for a_f, s_f, weight in zip(A_feat, S_feat, self.weights)]\n",
    "  #         raw_triplet_loss = triplet_loss(A_Y, pos_softmax, neg_softmax, cos_distance, 1.4)\n",
    "  #         weighted_triplet_loss = raw_triplet_loss * self.triplet_weight\n",
    "\n",
    "  #         self.losses = weighted_diversity_losses + [weighted_triplet_loss]\n",
    "  #         raw_losses = raw_diversity_losses + [raw_triplet_loss]\n",
    "\n",
    "  # #         self.losses = [weighted_fooling_loss] + weighted_diversity_losses + [weighted_triplet_loss]\n",
    "  # #         raw_losses = [raw_fooling_loss] + raw_diversity_losses + [raw_triplet_loss]\n",
    "\n",
    "  # #         self.losses = [fooling_loss] + [weighted_triplet_loss]\n",
    "  # #         self.metrics = dict(zip(self.metric_names, [fooling_loss] + [raw_triplet_loss]))\n",
    "\n",
    "  #         if len(self.metric_names) != len(raw_losses):\n",
    "  #           raise Exception(\"length of metric names unequals length of losses\")\n",
    "\n",
    "  #         self.metrics = dict(zip(self.metric_names, raw_losses))\n",
    "  #         return sum(self.losses)\n",
    "\n",
    "\n",
    "  #     #use two types of triplet losses\n",
    "  #     def forward(self, inp, target):\n",
    "  #       sigma_B, sigma_pos, sigma_neg, X_B = inp\n",
    "\n",
    "  #       X_A = self.add_perturbation(X_B, sigma_B) \n",
    "  #       X_A_pos = self.add_perturbation(X_B, sigma_pos)\n",
    "  #       X_A_neg = self.add_perturbation(X_B, sigma_neg) \n",
    "\n",
    "  #       X_S = self.add_perturbation_shuffled(X_B, sigma_B) # Shuffled Addversarial Examples\n",
    "\n",
    "  #       B_Y, _ = self.make_features(X_B)\n",
    "  #       A_Y, A_feat = self.make_features(X_A)\n",
    "  #       _, S_feat = self.make_features(X_S)\n",
    "  #       pos_softmax, _ = self.make_features(X_A_pos)\n",
    "  #       neg_softmax, _ = self.make_features(X_A_neg)\n",
    "\n",
    "  #       fooling_loss =  fool_loss(A_Y, B_Y)\n",
    "\n",
    "  #       raw_diversity_losses = [diversity_loss(a_f, s_f) for a_f, s_f in zip(A_feat, S_feat)]\n",
    "  #       weighted_diversity_losses = [diversity_loss(a_f, s_f) * weight * self.div_weight for a_f, s_f, weight in zip(A_feat, S_feat, self.weights)]\n",
    "\n",
    "  #       raw_triplet_loss_sm = triplet_loss(A_Y, pos_softmax, neg_softmax, cos_distance, 1.4)\n",
    "  #       weighted_triplet_loss_sm = raw_triplet_loss_sm * self.triplet_weight_sm\n",
    "\n",
    "  #       raw_triplet_loss_noise = triplet_loss(sigma_B, sigma_pos, sigma_neg, l2_distance, 5.)\n",
    "  #       weighted_triplet_loss_noise = raw_triplet_loss_noise * self.triplet_weight_noise\n",
    "\n",
    "  #       self.losses = [fooling_loss] + weighted_diversity_losses + [weighted_triplet_loss_sm, weighted_triplet_loss_noise] \n",
    "  #       self.metrics = dict(zip(self.metric_names, [fooling_loss] + raw_diversity_losses + [weighted_triplet_loss_sm, weighted_triplet_loss_noise]))\n",
    "\n",
    "  #       return sum(self.losses)\n",
    "\n",
    "  #     # just fooling and diversity\n",
    "  #     def forward(self, inp, target):\n",
    "  #       sigma_B, sigma_pos, sigma_neg, X_B = inp\n",
    "\n",
    "  #       X_A = self.add_perturbation(X_B, sigma_B) \n",
    "\n",
    "  #       X_S = self.add_perturbation_shuffled(X_B, sigma_B) # Shuffled Addversarial Examples\n",
    "\n",
    "  #       B_Y, _ = self.make_features(X_B)\n",
    "  #       A_Y, A_feat = self.make_features(X_A)\n",
    "  #       _, S_feat = self.make_features(X_S)\n",
    "\n",
    "  #       fooling_loss =  fool_loss(A_Y, B_Y)\n",
    "\n",
    "  #       raw_diversity_losses = [diversity_loss(a_f, s_f) for a_f, s_f in zip(A_feat, S_feat)]\n",
    "  #       weighted_diversity_losses = [diversity_loss(a_f, s_f) * weight * self.div_weight for a_f, s_f, weight in zip(A_feat, S_feat, self.weights)]\n",
    "\n",
    "  #       self.losses = [fooling_loss] + weighted_diversity_losses\n",
    "  #       self.metrics = dict(zip(self.metric_names, [fooling_loss] + raw_diversity_losses))\n",
    "\n",
    "  #       return sum(self.losses)\n",
    "\n",
    "\n",
    "      def add_perturbation_shuffled(self, inp, perturbation):\n",
    "        j = derangement(inp.shape[0])\n",
    "        return inp.add(perturbation[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def produce_summary(root_folder, n_files):\n",
    "  def writeline(file, values, fmt_string):\n",
    "    file.write(', '.join(fmt_string.format(v) for v in values) + '\\n')\n",
    "  \n",
    "  last_rows = []\n",
    "  for i in range(n_files):\n",
    "    prefix = '/root/Derakhshani/adversarial/textual_notes/CSVs'\n",
    "    df = pd.read_csv(\"{}/{}/{}.csv\".format(prefix, root_folder, i))\n",
    "    last_rows.append(df.iloc[-1][1:-1].values.tolist())\n",
    "  \n",
    "  last_rows = np.array(last_rows)\n",
    "  \n",
    "  labels = list(df.columns[1:-1])\n",
    "  means = np.mean(last_rows, axis=0).tolist()\n",
    "  outfile = open('{}/{}/summary.txt'.format(prefix, root_folder), 'w+')\n",
    "  outfile.write('means: \\n')\n",
    "  writeline(outfile, labels, '{: >20}')\n",
    "  writeline(outfile, means, '{: >20.3}')\n",
    "  outfile.write('\\n')\n",
    "      \n",
    "  operations = []\n",
    "  for column in df.columns[1:-1]:\n",
    "    if column in ['train_loss', 'valid_loss', 'fool_loss', 'triplet_loss'] or column[:8] == 'div_loss':\n",
    "      operations.append('min')\n",
    "    elif column in ['validation', 'targeted_validation', 'div_metric', 'entropy']:\n",
    "      operations.append('max')\n",
    "    else:\n",
    "      raise ValueError('column {} is not recognized'.format(column))\n",
    "    \n",
    "  results = []\n",
    "  indexes = []\n",
    "  \n",
    "  for i in range(len(operations)):\n",
    "    values = last_rows[:, i]\n",
    "    if operations[i] == 'max': operation = np.max\n",
    "    elif operations[i] == 'min': operation = np.min\n",
    "    result = operation(values)\n",
    "    results.append(result)\n",
    "    indexes.append(values.tolist().index(result))\n",
    "  \n",
    "  outfile.write('bests: \\n')\n",
    "  writeline(outfile, labels, '{: >20}')\n",
    "  writeline(outfile, operations, '{: >20}')\n",
    "  writeline(outfile, results, '{: >20.3}')\n",
    "  writeline(outfile, indexes, '{: >20}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils import dir_util \n",
    "\n",
    "def investigate_initial_settings(n_settings, n_epochs, lr, wd, results_dir):\n",
    "  os.mkdir(env.get_csv_dir() + results_dir)\n",
    "  os.mkdir(env.get_models_dir() + results_dir)\n",
    "  \n",
    "  for setting_ind in range(n_settings):\n",
    "    print(f\"investigation no: {setting_ind}\")\n",
    "    learn = None; gen = None; gc.collect()\n",
    "    gen = Gen(z_dim = z_dim)\n",
    "    init_cnn(gen, True)\n",
    "    \n",
    "    tmp_csv_filename =  env.temp_csv_path + '/' + results_dir + '/' + str(setting_ind)\n",
    "    csv_logger = partial(ImmediateCSVLogger, filename=tmp_csv_filename)\n",
    "\n",
    "    if gen_arch == 'non-targeted':\n",
    "      metrics = [validation]\n",
    "    elif gen_arch == 'targeted':\n",
    "      metrics = [validation, targeted_validation]\n",
    "      \n",
    "    learn = Learner(data, gen, loss_func = feat_loss, metrics=metrics, \n",
    "                    model_dir = env.get_learner_models_dir(), \n",
    "                    callback_fns=[DiversityMetric, LossMetrics, csv_logger])\n",
    "    \n",
    "    saver_best = SaveModelCallback(learn, every='improvement', monitor='validation', name=model.__name__ + \"-best\")\n",
    "    saver_every_epoch = SaveModelCallback(learn, every='epoch', name=model.__name__)\n",
    "\n",
    "    learn.fit(n_epochs, lr=lr, wd = wd, callbacks=[saver_best, saver_every_epoch])\n",
    "    \n",
    "    shutil.copyfile(tmp_csv_filename + \".csv\", env.get_csv_dir() + results_dir + '/' + str(setting_ind) + '.csv')\n",
    "    \n",
    "    model_dest = env.get_models_dir() + results_dir + '/' + str(setting_ind)\n",
    "    os.mkdir(model_dest)\n",
    "    dir_util.copy_tree(env.data_path/env.get_learner_models_dir(), model_dest)\n",
    "    shutil.rmtree(env.data_path/env.get_learner_models_dir())  \n",
    "    \n",
    "  produce_summary(results_dir, n_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_perturbations(learn, n_perturbations):\n",
    "  initial_training_mode = learn.model.training\n",
    "  gen = learn.model.eval()\n",
    "  perturbations = [gen.generate_single_noise() for _ in range(n_perturbations)]\n",
    "  learn.model.train(initial_training_mode)  \n",
    "  return perturbations\n",
    "\n",
    "def compute_prediction_histogram(learn, perturbation, verbose=False):\n",
    "  pred_hist = [0] * 1000\n",
    "  batch_no = -1\n",
    "  for batch, _ in learn.data.valid_dl:\n",
    "    batch_no += 1\n",
    "    if batch_no % 100 == 0 and verbose: print (\"at batch no {}\".format(batch_no))\n",
    "    perturbed_batch = batch + perturbation[None]\n",
    "    preds = arch(perturbed_batch).argmax(1)\n",
    "    for pred in preds:\n",
    "      pred_hist[pred] += 1\n",
    "  return pred_hist\n",
    "\n",
    "\n",
    "def compute_mean_prediction_histogram(learn, perturbations, verbose=False):\n",
    "  pred_hist = torch.tensor([0] * 1000).detach_()\n",
    "  batch_no = -1\n",
    "  for batch, _ in learn.data.valid_dl:\n",
    "    batch_no += 1\n",
    "    if batch_no % 5 == 0 and verbose: print(f\"at batch no {batch_no}\")\n",
    "    for j, perturbation in enumerate(perturbations):\n",
    "      perturbed_batch = batch + perturbation[None]\n",
    "      preds = arch(perturbed_batch).argmax(1)\n",
    "      for pred in preds:\n",
    "        pred_hist[pred] += 1\n",
    "  pred_hist = pred_hist.float() / len(perturbations)\n",
    "  return pred_hist.tolist()\n",
    "\n",
    "\n",
    "def classes_needed_to_reach(percentage, hist):\n",
    "  hist_sum = np.sum(hist)\n",
    "  indexed_hist = [(i, hist_element) for i,hist_element in  \n",
    "                          enumerate(hist)]\n",
    "  sorted_hist = sorted(indexed_hist, key=lambda x: x[1], reverse = True)\n",
    "  \n",
    "  cumulative_percent = 0\n",
    "  n_used_classes = 0\n",
    "  while cumulative_percent < percentage:\n",
    "    hist_elem = sorted_hist[n_used_classes]\n",
    "    cumulative_percent += (hist_elem[1] / hist_sum) * 100.\n",
    "    n_used_classes += 1\n",
    "\n",
    "  return n_used_classes, sorted_hist\n",
    "\n",
    "def diversity(learn, n_perturbations, percentage = 95, verbose = True):\n",
    "  pred_histogram = compute_mean_prediction_histogram(\n",
    "      learn, generate_perturbations(learn, n_perturbations), verbose\n",
    "  )\n",
    "  print(\"finished creating the prediction histogram\")\n",
    "\n",
    "  return classes_needed_to_reach(95, pred_histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiversityMetric(LearnerCallback):\n",
    "  _order = -20 # Needs to run before the recorder\n",
    "  \n",
    "  def __init__(self, learn):\n",
    "    super().__init__(learn)\n",
    "    self.average_over = 4\n",
    "    self.n_perturbations = 10\n",
    "    self.percentage = 95\n",
    "  \n",
    "  def on_train_begin(self, **kwargs):\n",
    "    self.learn.recorder.add_metric_names(['div_metric', 'entropy'])\n",
    "    \n",
    "  def on_epoch_begin(self, **kwargs):\n",
    "    global learn\n",
    "    self.perturbations_list = [generate_perturbations(self.learn, self.n_perturbations) \\\n",
    "                          for _ in range(self.average_over)]\n",
    "    self.pred_hist_list = [torch.tensor([0] * 1000).detach_() for _ in range(self.average_over)]\n",
    "    \n",
    "  def on_batch_end(self, last_output, train, **kwargs):\n",
    "    if not train:\n",
    "      images = last_output[3]; assert(images.shape[1:] == (3,224, 224))\n",
    "      for perturbations, pred_hist in zip(self.perturbations_list, self.pred_hist_list):\n",
    "        for j, perturbation in enumerate(perturbations):\n",
    "          perturbed_batch = images + perturbation[None]\n",
    "          preds = arch(perturbed_batch).argmax(1)\n",
    "          for pred in preds:\n",
    "            pred_hist[pred] += 1\n",
    "  \n",
    "  def on_epoch_end(self, last_metrics, **kwargs):\n",
    "    for i in range(len(self.pred_hist_list)):\n",
    "      self.pred_hist_list[i] = (self.pred_hist_list[i].float() / self.n_perturbations).tolist()\n",
    "    \n",
    "    div_metric_list = [classes_needed_to_reach(self.percentage, pred_hist)[0] \\\n",
    "                          for pred_hist in self.pred_hist_list]\n",
    "    entropy_list = [entropy(pred_hist) for pred_hist in self.pred_hist_list]\n",
    "    return add_metrics(last_metrics, [np.mean(div_metric_list), np.mean(entropy_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetedDiversityMetric(DiversityMetric):\n",
    "    def __init__(self, n_perturbations, percentage):\n",
    "      super().__init__(n_perturbations, percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoolingWeightScheduler(LearnerCallback):\n",
    "  def __init__(self, learn: Learner):\n",
    "    super().__init__(learn)\n",
    "    self.weights_history = []\n",
    "    self.fooling_loss_history = []\n",
    "  \n",
    "  def get_metric_value(self, metric_name):\n",
    "    for value, name in zip(self.learn.recorder.metrics[-1],self.learn.recorder.names[3:-1]):\n",
    "      if name == metric_name:\n",
    "        return value\n",
    "    raise ValueError('Could not find {} metric.'.format(metric_name))\n",
    "  \n",
    "  def on_epoch_end(self, last_metrics, **kwargs):\n",
    "    # history keeping\n",
    "    self.weights_history.append((kwargs['epoch'], self.learn.loss_func.fooling_weight))\n",
    "    \n",
    "    # the actual functionality\n",
    "    fooling_loss = self.get_metric_value('fool_loss')\n",
    "    self.fooling_loss_history.append(fooling_loss)\n",
    "    \n",
    "    if len(self.weights_history) < 2:\n",
    "      return\n",
    "    \n",
    "    if self.fooling_loss_history[-1] > self.fooling_loss_history[-2]:\n",
    "      self.learn.loss_func.fooling_weight += 0.3    \n",
    "      print('fooling weight increased to {} at the end of epoch {}'.format(\n",
    "        self.learn.loss_func.fooling_weight, kwargs['epoch']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyclicalLRScheduler(LearnerCallback):\n",
    "  def __init__(self, learn, max_lr, min_lr, cycle_len):\n",
    "    super().__init__(learn)\n",
    "    self.max_lr = max_lr\n",
    "    self.min_lr = min_lr\n",
    "    self.cycle_len = cycle_len\n",
    "    \n",
    "  def on_train_begin(self, **kwargs):\n",
    "    self.n_iter_per_epoch = len(self.learn.data.train_dl)\n",
    "    self.cycle_len_iters = self.cycle_len * self.n_iter_per_epoch\n",
    "    self.learn.opt.lr = self.min_lr\n",
    "    \n",
    "    \n",
    "  def on_batch_end(self, iteration, train, **kwargs):\n",
    "    if train:\n",
    "      cycle_index = iteration % self.cycle_len_iters\n",
    "      half_cycle_len = self.cycle_len_iters / 2\n",
    "\n",
    "      if cycle_index < half_cycle_len:\n",
    "        new_lr = float(self.max_lr - self.min_lr) / half_cycle_len * cycle_index + self.min_lr\n",
    "      else:\n",
    "        new_lr = float(self.min_lr - self.max_lr) / half_cycle_len * (cycle_index - half_cycle_len) + self.max_lr\n",
    "\n",
    "#       print('iter: {}, lr: {}'.format(iteration, new_lr))\n",
    "      self.opt.lr = new_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_data(src, path, bs, size):\n",
    "#     data = (src.label_from_func(lambda x: path/x.name)\n",
    "#            .databunch(bs=bs))\n",
    "#     data.c = 3\n",
    "#     return data\n",
    "\n",
    "def get_unet_model(arch):\n",
    "    data_path = Path(\"/content/dataset/train\")\n",
    "    src = ImageImageList.from_folder(data_path).split_none()\n",
    "    data = (src.label_from_func(lambda x: data_path/x.name)\n",
    "            .databunch(bs = batch_size))\n",
    "    data.c = 3\n",
    "    learn = unet_learner(data, arch, norm_type=NormType.Weight)\n",
    "    return learn.model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefendedClassifier(nn.Module):\n",
    "  def __init__(self, generator):\n",
    "    super().__init__()\n",
    "    self.generator = generator \n",
    "    self.denoiser = get_unet_model(models.resnet18)\n",
    "    \n",
    "  def forward(self, input_img):\n",
    "    perturbation = self.generator(input_img)[0]\n",
    "    perturbed_img = input_img + perturbation\n",
    "    predicted_noise = self.generator.output_coeff * torch.tanh(self.denoiser(perturbed_img))\n",
    "    restored_img = perturbed_img - predicted_noise\n",
    "    return restored_img, perturbation, input_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoiser_validation(defended_classifier_output, target):\n",
    "  restored_images, _, clean_images = defended_classifier_output\n",
    "  \n",
    "  original_preds = torch.argmax(arch(clean_images), 1)\n",
    "  restored_preds = torch.argmax(arch(restored_images), 1)\n",
    "  \n",
    "  return (original_preds == restored_preds).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoiserLoss(nn.Module):\n",
    "  def __name__(self):\n",
    "    return \"denoiser_loss\"\n",
    "  \n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.metric_names = [\"denoiser_loss\"]\n",
    "    \n",
    "  def forward(self, defended_classifier_output, target):\n",
    "    restored_img, perturbations, clean_images = defended_classifier_output\n",
    "    \n",
    "    restored_prediction_vector = arch(restored_img)\n",
    "    original_prediction_vector = arch(clean_images)\n",
    "    winning_class = F.softmax(original_prediction_vector, dim=1).argmax(dim=1)\n",
    "    denoiser_loss = F.cross_entropy(restored_prediction_vector, winning_class)\n",
    "\n",
    "    self.losses = [denoiser_loss]\n",
    "    self.metrics = dict(zip(self.metric_names, self.losses))\n",
    "    \n",
    "    return denoiser_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tltucTv2ep9-"
   },
   "outputs": [],
   "source": [
    "# mode = 'sanity_check'\n",
    "mode = 'normal'\n",
    "# mode = 'div_metric_calc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.resnet50\n",
    "# model = models.resnet152\n",
    "# model = models.vgg16_bn\n",
    "model = torchvision.models.googlenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "SO1h55obXzOv",
    "outputId": "54414cc5-84d5-4f45-ecab-87374a58dd33"
   },
   "outputs": [],
   "source": [
    "if mode == \"normal\":\n",
    "  env.load_dataset('dataset','data')\n",
    "  env.set_data_path('dataset')\n",
    "elif mode == \"sanity_check\":\n",
    "  env.load_dataset('dataset_sanity_check_small', 'dataset_sanity_check_small')  \n",
    "  env.set_data_path('dataset_sanity_check_small')\n",
    "elif mode == \"div_metric_calc\":\n",
    "  env.load_dataset('dataset','data')\n",
    "  env.set_data_path('dataset')\n",
    "  env.load_test_dataset(str(env.data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "koaQZmjMom7w"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "gpu_flag = True\n",
    "nag_util.batch_size = batch_size; nag_util.gpu_flag = gpu_flag;\n",
    "tfms = get_transforms(do_flip=False, max_rotate=0)\n",
    "data = (ImageList.from_folder(env.data_path)\n",
    "        .split_by_folder(valid=('test' if mode == 'div_metric_calc' else 'valid'))\n",
    "        .label_from_folder()\n",
    "        .transform(tfms, size=224)\n",
    "        .databunch(bs=batch_size, num_workers=1)\n",
    "        .normalize(imagenet_stats))\n",
    "\n",
    "# data.show_batch(rows=2, figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kDBkRV8yovwV"
   },
   "outputs": [],
   "source": [
    "if gen_arch == \"non-targeted\":\n",
    "  z_dim = 10\n",
    "elif gen_arch == \"targeted\":\n",
    "  z_dim = 1000\n",
    "  \n",
    "arch = SoftmaxWrapper(model(pretrained=True).cuda().eval())\n",
    "nag_util.arch = arch\n",
    "requires_grad(arch, False)\n",
    "\n",
    "# vgg:\n",
    "# layers = []\n",
    "# blocks = [i-1 for i,o in enumerate(children(arch.features)) if isinstance(o, nn.MaxPool2d)]\n",
    "# layers = [arch.features[i] for i in blocks]\n",
    "# layer_weights = [1] * len(layers)\n",
    "\n",
    "layers = [\n",
    "    arch.softmax\n",
    "]\n",
    "\n",
    "layer_weights = [1.] * len(layers)\n",
    "\n",
    "# inception:\n",
    "# layers = [\n",
    "#     arch.Conv2d_1a_3x3,\n",
    "#     arch.Mixed_6e,\n",
    "#     arch.Mixed_7a,\n",
    "#     arch.fc    \n",
    "# ]\n",
    "# layer_weights = [1.0/4.0] * len(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qd9gXUy_ovww"
   },
   "outputs": [],
   "source": [
    "feat_loss = FeatureLoss(arch, layers, layer_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRAnneal(LearnerCallback):\n",
    "  _order = -20 # Needs to run before the recorder\n",
    "  \n",
    "  def __init__(self, learn, final_value):\n",
    "    super().__init__(learn)\n",
    "    self.final_value = final_value\n",
    "  \n",
    "  def on_train_begin(self, **kwargs):\n",
    "    self.initial_value = self.opt.lr\n",
    "    self.learn.recorder.add_metric_names(['lr'])\n",
    "  \n",
    "  def on_epoch_end(self, epoch, n_epochs, last_metrics, **kwargs):\n",
    "    self.opt.lr = annealing_linear(self.initial_value, self.final_value, float(epoch) / n_epochs)\n",
    "    return add_metrics(last_metrics, self.opt.lr)\n",
    "  \n",
    "# class LRMonitor(LearnerCallBack):\n",
    "#   def __init__(self, learn):\n",
    "#     super().__init__(learn)\n",
    "#     self.name = 'lr'\n",
    "    \n",
    "#   def on_epoch_end(self, last_metrics, **kwargs):\n",
    "#     return add_metrics(last_metrics, self.opt.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.save_filename = 'resnet50_65' #resnet50_64\n",
    "# env.save_filename = 'resnet50_17'\n",
    "env.save_filename = 'unet_1x'\n",
    "\n",
    "if Path(env.get_csv_path() + '.csv').exists(): raise FileExistsError(\"csv_path already exists\")\n",
    "if Path(env.get_models_path()).exists(): raise FileExistsError(\"models_path already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b9J20CBLS8S9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models_directory returned is:  models/646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/mmderakhshani/lib/python3.6/site-packages/fastai/data_block.py:451: UserWarning: Your training set is empty. If this is by design, pass `ignore_empty=True` to remove this warning.\n",
      "  warn(\"Your training set is empty. If this is by design, pass `ignore_empty=True` to remove this warning.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models_directory returned is:  models/646\n"
     ]
    }
   ],
   "source": [
    "learn = None; gen = None; gc.collect()\n",
    "csv_logger = partial(ImmediateCSVLogger, filename= env.temp_csv_path + '/' + env.save_filename)\n",
    "gen = Gen(z_dim=z_dim)\n",
    "init_cnn(gen, True)\n",
    "\n",
    "if gen_arch == 'non-targeted':\n",
    "  metrics = [validation]\n",
    "elif gen_arch == 'targeted':\n",
    "  metrics = [validation, targeted_validation]\n",
    "    \n",
    "gen_learn = Learner(data, gen, loss_func = feat_loss,\n",
    "                    model_dir = env.get_learner_models_dir(),\n",
    "                    metrics=metrics, callback_fns=[DiversityMetric, LossMetrics, csv_logger])\n",
    "\n",
    "denoiser_learn = Learner(data, DefendedClassifier(gen), loss_func = DenoiserLoss(), \n",
    "                        model_dir = env.get_learner_models_dir(),\n",
    "                        metrics=denoiser_validation, callback_fns = [LossMetrics, csv_logger])\n",
    "\n",
    "# learn = Learner(data, Gen(z_dim=10), loss_func = feat_loss, metrics=[validation], callback_fns=LossMetrics, opt_func = optim.SGD)\n",
    "# learn = Learner(data, Gen(z_dim=z_dim), loss_func = feat_loss, metrics=[validation], callback_fns=[LossMetrics, DiversityWeightsScheduler])\n",
    "\n",
    "# load_starting_point(learn, model.__name__, z_dim)\n",
    "# random_seed(42, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0wOZYzOHDEdB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (9000 items)\n",
       "x: ImageList\n",
       "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
       "y: CategoryList\n",
       "n02454379,n02454379,n02454379,n02454379,n02454379\n",
       "Path: /root/Derakhshani/adversarial/datasets/dataset;\n",
       "\n",
       "Valid: LabelList (1000 items)\n",
       "x: ImageList\n",
       "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
       "y: CategoryList\n",
       "n02454379,n02397096,n02090379,n01729977,n02268853\n",
       "Path: /root/Derakhshani/adversarial/datasets/dataset;\n",
       "\n",
       "Test: None, model=Gen(\n",
       "  (z_): Linear(in_features=1000, out_features=10240, bias=True)\n",
       "  (BN_): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (CT2d_1): deconv_layer(\n",
       "    (CT2d): ConvTranspose2d(640, 448, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (BN2d): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (CT2d_2): deconv_layer(\n",
       "    (CT2d): ConvTranspose2d(448, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (BN2d): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (CT2d_3): deconv_layer(\n",
       "    (CT2d): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (BN2d): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (CT2d_4): deconv_layer(\n",
       "    (CT2d): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (BN2d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (CT2d_5): deconv_layer(\n",
       "    (CT2d): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (BN2d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (CT2d_6): deconv_layer(\n",
       "    (CT2d): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (BN2d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (CT2d_7): deconv_layer(\n",
       "    (CT2d): ConvTranspose2d(64, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (BN2d): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FeatureLoss(\n",
       "  (dis): SoftmaxWrapper(\n",
       "    (m): GoogLeNet(\n",
       "      (conv1): BasicConv2d(\n",
       "        (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "      (conv2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv3): BasicConv2d(\n",
       "        (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "      (inception3a): Inception(\n",
       "        (branch1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (branch3): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (branch4): Sequential(\n",
       "          (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (inception3b): Inception(\n",
       "        (branch1): BasicConv2d(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (branch3): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (branch4): Sequential(\n",
       "          (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "      (inception4a): Inception(\n",
       "        (branch1): BasicConv2d(\n",
       "          (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (branch3): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (branch4): Sequential(\n",
       "          (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (inception4b): Inception(\n",
       "        (branch1): BasicConv2d(\n",
       "          (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (branch3): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (branch4): Sequential(\n",
       "          (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (inception4c): Inception(\n",
       "        (branch1): BasicConv2d(\n",
       "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (branch3): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (branch4): Sequential(\n",
       "          (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (inception4d): Inception(\n",
       "        (branch1): BasicConv2d(\n",
       "          (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (branch3): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (branch4): Sequential(\n",
       "          (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (inception4e): Inception(\n",
       "        (branch1): BasicConv2d(\n",
       "          (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (branch3): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (branch4): Sequential(\n",
       "          (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "      (inception5a): Inception(\n",
       "        (branch1): BasicConv2d(\n",
       "          (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (branch3): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (branch4): Sequential(\n",
       "          (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (inception5b): Inception(\n",
       "        (branch1): BasicConv2d(\n",
       "          (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (branch3): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (branch4): Sequential(\n",
       "          (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (dropout): Dropout(p=0.2)\n",
       "      (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "    )\n",
       "    (softmax): Softmax()\n",
       "  )\n",
       "), metrics=[<function validation at 0x7f0ec25d9ea0>, <function targeted_validation at 0x7f0ec25d9bf8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/root/Derakhshani/adversarial/datasets/dataset'), model_dir='models/646', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class '__main__.DiversityMetric'>, <class 'fastai.callbacks.loss_metrics.LossMetrics'>, functools.partial(<class 'nag_util.ImmediateCSVLogger'>, filename='/root/Derakhshani/adversarial/temp/unet_1x')], callbacks=[], layer_groups=[Sequential(\n",
       "  (0): Linear(in_features=1000, out_features=10240, bias=True)\n",
       "  (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ConvTranspose2d(640, 448, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "  (3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): ConvTranspose2d(448, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (10): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (12): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (14): ConvTranspose2d(64, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (15): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")], add_time=True, silent=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !cp \"/content/gdrive/My Drive/DL/models/vgg16_12-last.pth\"  \"/content/\"\n",
    "# learn.load('/content/vgg16_12-last')\n",
    "\n",
    "# load_filename = 'resnet50-11_39'\n",
    "# load_filename = 'resnet50_startpoint_0'\n",
    "# load_filename = 'googlenet_13_attempt5/googlenet_13_attempt5_29'\n",
    "# load_filename = 'investigate_googlenet_4/1/googlenet_1'\n",
    "# load_filename = 'vgg16_30/vgg16_30_69'\n",
    "# load_filename = 'vgg16_12-last'\n",
    "# load_filename = 'googlenet_25_attempt2/googlenet_25_attempt2_399'\n",
    "# load_filename = 'googlenet_28_labelset1/googlenet_28_labelset1_59'\n",
    "load_filename = 'googlenet_32/googlenet_32_99'\n",
    "# load_filename = 'investigate_googlenet_5/1/googlenet_2'\n",
    "# load_filename = None\n",
    "\n",
    "gen_learn.load('/root/Derakhshani/adversarial/models/' + load_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/mmderakhshani/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type DenoiserLoss. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/root/anaconda3/envs/mmderakhshani/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type DefendedClassifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/root/anaconda3/envs/mmderakhshani/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Gen. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/root/anaconda3/envs/mmderakhshani/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type deconv_layer. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (9000 items)\n",
       "x: ImageList\n",
       "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
       "y: CategoryList\n",
       "n02454379,n02454379,n02454379,n02454379,n02454379\n",
       "Path: /root/Derakhshani/adversarial/datasets/dataset;\n",
       "\n",
       "Valid: LabelList (1000 items)\n",
       "x: ImageList\n",
       "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
       "y: CategoryList\n",
       "n02454379,n02397096,n02090379,n01729977,n02268853\n",
       "Path: /root/Derakhshani/adversarial/datasets/dataset;\n",
       "\n",
       "Test: None, model=DefendedClassifier(\n",
       "  (generator): Gen(\n",
       "    (z_): Linear(in_features=1000, out_features=10240, bias=True)\n",
       "    (BN_): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (CT2d_1): deconv_layer(\n",
       "      (CT2d): ConvTranspose2d(640, 448, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "      (BN2d): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (CT2d_2): deconv_layer(\n",
       "      (CT2d): ConvTranspose2d(448, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (BN2d): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (CT2d_3): deconv_layer(\n",
       "      (CT2d): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (BN2d): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (CT2d_4): deconv_layer(\n",
       "      (CT2d): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (BN2d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (CT2d_5): deconv_layer(\n",
       "      (CT2d): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (BN2d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (CT2d_6): deconv_layer(\n",
       "      (CT2d): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (BN2d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (CT2d_7): deconv_layer(\n",
       "      (CT2d): ConvTranspose2d(64, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (BN2d): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (denoiser): DynamicUnet(\n",
       "    (layers): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "        (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (4): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (4): UnetBlock(\n",
       "        (shuf): PixelShuffle_ICNR(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (shuf): PixelShuffle(upscale_factor=2)\n",
       "          (pad): ReplicationPad2d((1, 0, 1, 0))\n",
       "          (blur): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (5): UnetBlock(\n",
       "        (shuf): PixelShuffle_ICNR(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (shuf): PixelShuffle(upscale_factor=2)\n",
       "          (pad): ReplicationPad2d((1, 0, 1, 0))\n",
       "          (blur): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (6): UnetBlock(\n",
       "        (shuf): PixelShuffle_ICNR(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (shuf): PixelShuffle(upscale_factor=2)\n",
       "          (pad): ReplicationPad2d((1, 0, 1, 0))\n",
       "          (blur): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (7): UnetBlock(\n",
       "        (shuf): PixelShuffle_ICNR(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (shuf): PixelShuffle(upscale_factor=2)\n",
       "          (pad): ReplicationPad2d((1, 0, 1, 0))\n",
       "          (blur): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (8): PixelShuffle_ICNR(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (shuf): PixelShuffle(upscale_factor=2)\n",
       "        (pad): ReplicationPad2d((1, 0, 1, 0))\n",
       "        (blur): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (9): MergeLayer()\n",
       "      (10): SequentialEx(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(99, 99, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace)\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv2d(99, 99, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace)\n",
       "          )\n",
       "          (2): MergeLayer()\n",
       "        )\n",
       "      )\n",
       "      (11): Sequential(\n",
       "        (0): Conv2d(99, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=DenoiserLoss(), metrics=[<function denoiser_validation at 0x7f0ec259dd90>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/root/Derakhshani/adversarial/datasets/dataset'), model_dir='models/646', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.callbacks.loss_metrics.LossMetrics'>, functools.partial(<class 'nag_util.ImmediateCSVLogger'>, filename='/root/Derakhshani/adversarial/temp/unet_1x')], callbacks=[], layer_groups=[Sequential(\n",
       "  (0): Linear(in_features=1000, out_features=10240, bias=True)\n",
       "  (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ConvTranspose2d(640, 448, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "  (3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): ConvTranspose2d(448, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (10): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (12): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (14): ConvTranspose2d(64, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (15): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (16): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (17): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (18): ReLU(inplace)\n",
       "  (19): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (20): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (22): ReLU(inplace)\n",
       "  (23): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (24): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (25): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (26): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (27): ReLU(inplace)\n",
       "  (28): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (29): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (30): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (32): ReLU(inplace)\n",
       "  (33): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (34): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (35): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "  (36): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (37): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (38): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (39): ReLU(inplace)\n",
       "  (40): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (41): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (42): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (43): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (44): ReLU(inplace)\n",
       "  (45): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (46): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (47): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "  (48): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (49): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (50): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (51): ReLU(inplace)\n",
       "  (52): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (54): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (56): ReLU(inplace)\n",
       "  (57): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (58): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (59): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "  (60): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (61): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (62): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (63): ReLU(inplace)\n",
       "  (64): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (65): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (66): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (67): ReLU()\n",
       "  (68): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (69): ReLU(inplace)\n",
       "  (70): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (71): ReLU(inplace)\n",
       "  (72): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (73): PixelShuffle(upscale_factor=2)\n",
       "  (74): ReplicationPad2d((1, 0, 1, 0))\n",
       "  (75): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
       "  (76): ReLU(inplace)\n",
       "  (77): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (78): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (79): ReLU(inplace)\n",
       "  (80): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (81): ReLU(inplace)\n",
       "  (82): ReLU()\n",
       "  (83): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (84): PixelShuffle(upscale_factor=2)\n",
       "  (85): ReplicationPad2d((1, 0, 1, 0))\n",
       "  (86): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
       "  (87): ReLU(inplace)\n",
       "  (88): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (89): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (90): ReLU(inplace)\n",
       "  (91): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (92): ReLU(inplace)\n",
       "  (93): ReLU()\n",
       "  (94): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (95): PixelShuffle(upscale_factor=2)\n",
       "  (96): ReplicationPad2d((1, 0, 1, 0))\n",
       "  (97): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
       "  (98): ReLU(inplace)\n",
       "  (99): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (100): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (101): ReLU(inplace)\n",
       "  (102): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (103): ReLU(inplace)\n",
       "  (104): ReLU()\n",
       "  (105): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (106): PixelShuffle(upscale_factor=2)\n",
       "  (107): ReplicationPad2d((1, 0, 1, 0))\n",
       "  (108): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
       "  (109): ReLU(inplace)\n",
       "  (110): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (111): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (112): ReLU(inplace)\n",
       "  (113): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (114): ReLU(inplace)\n",
       "  (115): ReLU()\n",
       "  (116): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (117): PixelShuffle(upscale_factor=2)\n",
       "  (118): ReplicationPad2d((1, 0, 1, 0))\n",
       "  (119): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
       "  (120): ReLU(inplace)\n",
       "  (121): MergeLayer()\n",
       "  (122): Conv2d(99, 99, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (123): ReLU(inplace)\n",
       "  (124): Conv2d(99, 99, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (125): ReLU(inplace)\n",
       "  (126): MergeLayer()\n",
       "  (127): Conv2d(99, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       ")], add_time=True, silent=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_filename = 'unet_1/unet_1_4'\n",
    "denoiser_learn.load('/root/Derakhshani/adversarial/models/' + load_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchRemover(nn.Module):\n",
    "  def __init__(self, wrap_around):\n",
    "    super().__init__()\n",
    "    self.wrap_around = wrap_around\n",
    "    \n",
    "  def forward(self, inp):\n",
    "    print('passed input:', inp.shape)\n",
    "    print('converted: ', inp[None].shape)\n",
    "    return self.wrap_around(inp[None]).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed input: torch.Size([1, 224, 224])\n",
      "converted:  torch.Size([1, 1, 224, 224])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-e8edaf09c3d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                    nb_classes = 1000)\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempirical_robustness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mart_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fgsm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/mmderakhshani/lib/python3.6/site-packages/art/metrics/metrics.py\u001b[0m in \u001b[0;36mempirical_robustness\u001b[0;34m(classifier, x, attack_name, attack_params)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mcrafter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_crafter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattack_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattack_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mcrafter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'minimal'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0madv_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrafter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;31m# Predict the labels for adversarial examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mmderakhshani/lib/python3.6/site-packages/art/attacks/fast_gradient.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;31m# Use model predictions as correct outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using model predictions as correct labels for FGM.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_labels_np_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mmderakhshani/lib/python3.6/site-packages/art/classifiers/pytorch.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_preprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_preprocessed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mmderakhshani/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mmderakhshani/lib/python3.6/site-packages/art/classifiers/pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m                             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m                             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mmderakhshani/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-2b3ad4ebb8c4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'passed input:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'converted: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_around\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/mmderakhshani/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-b61738180ba7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_img)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mperturbation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mperturbed_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_img\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mperturbation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpredicted_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_coeff\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdenoiser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperturbed_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mmderakhshani/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-a50fbf836a83>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m       \u001b[0mbenign_preds_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0march\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;31m#       benign_preds = torch.argmax(benign_preds_onehot, dim = 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m       \u001b[0mworst_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbenign_preds_onehot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mmderakhshani/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Derakhshani/adversarial/nag-public/NAG-11May-beforeDenoiser/nag_util.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mmderakhshani/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mmderakhshani/lib/python3.6/site-packages/torchvision/models/googlenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mx_ch0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.229\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.485\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mx_ch1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.224\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.456\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0mx_ch2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.225\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.406\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_ch0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_ch1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_ch2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 1 with size 1"
     ]
    }
   ],
   "source": [
    "from art import metrics\n",
    "from art.classifiers import PyTorchClassifier\n",
    "\n",
    "x =  denoiser_learn.data.train_ds[0][0].data.numpy()\n",
    "\n",
    "batchless_model = BatchRemover(denoiser_learn.model)\n",
    "# WARNING: omitting clip values\n",
    "art_classifier = PyTorchClassifier(model = batchless_model, loss = feat_loss,\n",
    "                                   optimizer = denoiser_learn.opt, input_shape = x.shape,\n",
    "                                   nb_classes = 1000)\n",
    "\n",
    "metrics.empirical_robustness(art_classifier, x, 'fgsm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 224, 224)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.lr_find(1e-6, 100)\n",
    "# learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_dir = 'investigate_googlenet_4'\n",
    "# investigate_initial_settings(4, 2, lr = 1e-2, wd = 0.0, results_dir = results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutil.rmtree(env.get_models_dir() + results_dir)\n",
    "# shutil.rmtree(env.get_csv_dir() + results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class WeightTuner(LearnerCallback):\n",
    "#   def __init__(self, learn: Learner):\n",
    "#     super().__init__(learn)\n",
    "#     self.fooling_weight = learn.loss_func.fooling_weight\n",
    "    \n",
    "#   def on_epoch_begin(self, **kwargs):\n",
    "#     fooling_rate = \n",
    "#     print(\"by how much to increase the fooling_weight? (current value: {})\".format(fooling_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the selected settings are : \n",
      "\tmode: normal \n",
      "\tnetw-under-attack: googlenet \n",
      "\tload filename: googlenet_32/googlenet_32_99 \n",
      "      \tsave filename: unet_1\n",
      "\tmetric names: ['fool_loss']\n",
      "\tgen arch: targeted\n",
      "\n",
      "please MAKE SURE that the config is correct.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  load_filename\n",
    "except NameError:\n",
    "  load_filename = None\n",
    "\n",
    "print(\"the selected settings are : \")\n",
    "print('''\\tmode: {} \\n\\tnetw-under-attack: {} \\n\\tload filename: {} \n",
    "      \\tsave filename: {}\\n\\tmetric names: {}\\n\\tgen arch: {}\\n'''.format(\n",
    "      mode, model.__name__, load_filename , env.save_filename, feat_loss.metric_names,\n",
    "      gen_arch\n",
    "))\n",
    "print(\"please MAKE SURE that the config is correct.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.lr_find(1e-6, 100)\n",
    "# learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>denoiser_validation</th>\n",
       "      <th>denoiser_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.257166</td>\n",
       "      <td>6.250446</td>\n",
       "      <td>0.953000</td>\n",
       "      <td>6.250447</td>\n",
       "      <td>04:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.253636</td>\n",
       "      <td>6.251034</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>6.251033</td>\n",
       "      <td>04:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.264240</td>\n",
       "      <td>6.249228</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>6.249228</td>\n",
       "      <td>04:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.253538</td>\n",
       "      <td>6.250818</td>\n",
       "      <td>0.954000</td>\n",
       "      <td>6.250818</td>\n",
       "      <td>04:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.259487</td>\n",
       "      <td>6.249699</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>6.249699</td>\n",
       "      <td>04:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/mmderakhshani/lib/python3.6/site-packages/fastai/callbacks/tracker.py:50: UserWarning: <class 'fastai.callbacks.tracker.SaveModelCallback'> conditioned on metric `validation` which is not available. Available metrics are: train_loss, valid_loss, denoiser_validation, denoiser_loss\n",
      "  warn(f'{self.__class__} conditioned on metric `{self.monitor}` which is not available. Available metrics are: {\", \".join(map(str, self.learn.recorder.names[1:-1]))}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models_directory returned is:  models/642\n",
      "models_directory returned is:  models/642\n"
     ]
    }
   ],
   "source": [
    "# RUN SITE\n",
    "if 'x' in env.save_filename and mode != 'sanity_check':\n",
    "  raise ValueError('save_filename contains x')\n",
    "\n",
    "\n",
    "saver_best = SaveModelCallback(denoiser_learn, every='improvement', monitor='validation', name=env.save_filename + \"-best\")\n",
    "saver_every_epoch = SaveModelCallback(denoiser_learn, every='epoch', name=env.save_filename)\n",
    "# fooling_weight_scheduler = FoolingWeightScheduler(learn)\n",
    "# lr_anneal = LRAnneal(learn, 1e-4)\n",
    "# file_ctrl = FileControl(learn, '/root/Derakhshani/adversarial/ctrl', learn.model)\n",
    "# cyclical_sched = CyclicalLRScheduler(learn, 3e-2, 6e-4, 4)\n",
    "\n",
    "callbacks = [saver_best, saver_every_epoch]\n",
    "# callbacks.append(lr_anneal)\n",
    "# callbacks.append(fooling_weight_scheduler)\n",
    "# callbacks.append(file_ctrl)\n",
    "# callbacks.append(cyclical_sched)\n",
    "\n",
    "denoiser_learn.fit(5, lr=1e-2, callbacks=callbacks)\n",
    "\n",
    "# with Hooks(gen, append_stats_normal) as hooks:\n",
    "#   learn.fit(1, lr=5e-03, wd = 0., callbacks=[saver_best, saver_every_epoch])\n",
    "\n",
    "# for i in range(10):\n",
    "#   learn.fit_one_cycle(7, wd = 0.,max_lr=1., div_factor = 1000.) \n",
    "\n",
    "shutil.copyfile(env.temp_csv_path + '/' + env.save_filename + \".csv\", env.get_csv_path() + '.csv')\n",
    "shutil.copytree(env.data_path/env.get_learner_models_dir(), env.get_models_path())\n",
    "shutil.rmtree(env.data_path/env.get_learner_models_dir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "denoiser_learn.recorder.plot_losses()\n",
    "denoiser_learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up folder:  googlenet_32\n",
      "files that will be kept are: ['googlenet_32_99.pth', 'googlenet_32-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  unet_1\n",
      "files that will be kept are: ['unet_1_4.pth', 'unet_1-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "new file in keep_file: 'unet_1-best.pth' doesnt exist. fix it and then press enter to continue.\n",
      "\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/16\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/19\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/15\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/3\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/2\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/5\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/1\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/13\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/0\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/4\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/10\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/18\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/9\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/12\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/14\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/8\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/6\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/11\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/7\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_resnet50_8/17\n",
      "files that will be kept are: ['resnet50_2.pth', 'resnet50-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_vgg16_2/3\n",
      "no file found with the pattern \"model_name_index.pth\", ignoring the directory.\n",
      "cleaning up folder:  investigate_vgg16_2/2\n",
      "no file found with the pattern \"model_name_index.pth\", ignoring the directory.\n",
      "cleaning up folder:  investigate_vgg16_2/5\n",
      "no file found with the pattern \"model_name_index.pth\", ignoring the directory.\n",
      "cleaning up folder:  investigate_vgg16_2/1\n",
      "no file found with the pattern \"model_name_index.pth\", ignoring the directory.\n",
      "cleaning up folder:  investigate_vgg16_2/0\n",
      "no file found with the pattern \"model_name_index.pth\", ignoring the directory.\n",
      "cleaning up folder:  investigate_vgg16_2/4\n",
      "no file found with the pattern \"model_name_index.pth\", ignoring the directory.\n",
      "cleaning up folder:  investigate_vgg16_2/9\n",
      "no file found with the pattern \"model_name_index.pth\", ignoring the directory.\n",
      "cleaning up folder:  investigate_vgg16_2/8\n",
      "no file found with the pattern \"model_name_index.pth\", ignoring the directory.\n",
      "cleaning up folder:  investigate_vgg16_2/6\n",
      "no file found with the pattern \"model_name_index.pth\", ignoring the directory.\n",
      "cleaning up folder:  investigate_vgg16_2/7\n",
      "no file found with the pattern \"model_name_index.pth\", ignoring the directory.\n",
      "cleaning up folder:  googlenet_33\n",
      "files that will be kept are: ['googlenet_33_29.pth', 'googlenet_33-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_googlenet_5/3\n",
      "files that will be kept are: ['googlenet_2.pth', 'googlenet-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_googlenet_5/2\n",
      "files that will be kept are: ['googlenet_2.pth', 'googlenet-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_googlenet_5/5\n",
      "files that will be kept are: ['googlenet_2.pth', 'googlenet-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_googlenet_5/1\n",
      "files that will be kept are: ['googlenet_2.pth', 'googlenet-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_googlenet_5/0\n",
      "files that will be kept are: ['googlenet_2.pth', 'googlenet-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_googlenet_5/4\n",
      "files that will be kept are: ['googlenet_2.pth', 'googlenet-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_googlenet_5/9\n",
      "files that will be kept are: ['googlenet_2.pth', 'googlenet-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_googlenet_5/8\n",
      "files that will be kept are: ['googlenet_2.pth', 'googlenet-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_googlenet_5/6\n",
      "files that will be kept are: ['googlenet_2.pth', 'googlenet-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  investigate_googlenet_5/7\n",
      "files that will be kept are: ['googlenet_2.pth', 'googlenet-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  unet_2\n",
      "files that will be kept are: ['unet_2_4.pth', 'unet_2-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "new file in keep_file: 'unet_2-best.pth' doesnt exist. fix it and then press enter to continue.\n",
      "\n",
      "done.\n",
      "cleaning up folder:  resnet50_72\n",
      "files that will be kept are: ['resnet50_72_99.pth', 'resnet50_72-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      "done.\n",
      "cleaning up folder:  googlenet_34\n",
      "files that will be kept are: ['googlenet_34_29.pth', 'googlenet_34-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n",
      "cleaning up folder:  vgg16_38\n",
      "files that will be kept are: ['vgg16_38_99.pth', 'vgg16_38-best.pth']\n",
      "change the keep.txt if they are wrong, then enter 'y' to delete the rest.\n",
      "y\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "from cleanup import cleanup_models_folder\n",
    "cleanup_models_folder('/root/Derakhshani/adversarial/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot histogram\n",
    "fig, axes = plt.subplots(len(hooks),1, figsize=(30,12))\n",
    "for ax,h in zip(axes.flatten(), hooks):\n",
    "  ax.imshow(get_hist(h), origin='lower')\n",
    "  ax.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mean and std\n",
    "fig,(ax0,ax1) = plt.subplots(1,2, figsize=(10,4))\n",
    "for h in hooks:\n",
    "  ms, ss, _ = h.stats\n",
    "  ax0.plot(ms[:100])\n",
    "  ax1.plot(ss[:100])\n",
    "plt.legend(range(len(hooks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax0,ax1) = plt.subplots(1,2, figsize=(10,4))\n",
    "for h in hooks:\n",
    "  ms, ss, _ = h.stats\n",
    "  ax0.plot(ms)\n",
    "  ax1.plot(ss)\n",
    "plt.legend(range(len(hooks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero precentage:\n",
    "fig,axes = plt.subplots(len(hooks),1, figsize=(30,30))\n",
    "for ax,h in zip(axes.flatten(), hooks):\n",
    "    ax.plot(get_min(h))\n",
    "    ax.set_ylim(0,1)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MO2fZ-hSSUzJ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# z1 = torch.empty(10).uniform_(-1,1).cuda()\n",
    "# z2 = torch.empty(10).uniform_(-1,1).cuda()\n",
    "z1 = torch.tensor([0.8, -0.5] * 5).cuda()\n",
    "z2 = torch.tensor([-1.] * 10).cuda()\n",
    "print(\"z1: \", z1)\n",
    "print(\"z2: \", z2)\n",
    "print(\"distance: \", torch.norm(z1-z2,p=2))\n",
    "model = learn.model.eval()\n",
    "\n",
    "z_s = interpolate(z1, z2, 0.1)\n",
    "print(len(z_s))\n",
    "\n",
    "for i,z in enumerate(z_s):\n",
    "  img = noise_to_image(model.forward_single_z(z))\n",
    "  img.show()\n",
    "  #img.save('./pics/' + str(i) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea : have 200 noises (1 for each class), then start iterating the dataset, and for each image, randomly apply one noise and record the result\n",
    "def targeted_diversity(learn, n_perturbations = 200, percentage = 95):\n",
    "  model = learn.model.eval()\n",
    "\n",
    "  one_hot_conditions = [torch.empty(z_dim).uniform_(0,1).cuda().detach() for _ in range(n_perturbations)]\n",
    "#   for i in range(z_dim):\n",
    "#     one_hot_conditions[i][i] = 1.\n",
    "\n",
    "  perturbations = [model.forward_single_z(z) for z in one_hot_conditions]\n",
    "\n",
    "  hist = [0.] * 1000\n",
    "  batch_no = -1\n",
    "  for batch, _ in learn.data.valid_dl:\n",
    "    batch_no += 1\n",
    "    if batch_no % 100 == 0 : print(\"at batch_no {}\".format(batch_no))\n",
    "    perturbed_batch = batch + perturbations[np.random.randint(0,len(perturbations))][None]\n",
    "    preds = arch(perturbed_batch).argmax(1)\n",
    "    for pred in preds:\n",
    "      hist[pred] += 1\n",
    "\n",
    "  pred_histogram_sum = np.sum(hist)\n",
    "  indexed_pred_histogram = [(i, hist_element) for i,hist_element in  \n",
    "                            enumerate(hist)]\n",
    "\n",
    "  indexed_pred_histogram.sort(key=lambda x: x[1], reverse = True)\n",
    "\n",
    "  cumulative_percent = 0\n",
    "  n_used_classes = 0\n",
    "  while cumulative_percent < percentage:\n",
    "    hist_elem = indexed_pred_histogram[n_used_classes]\n",
    "    cumulative_percent += (hist_elem[1] / pred_histogram_sum) * 100.\n",
    "    n_used_classes += 1\n",
    "\n",
    "  return n_used_classes, indexed_pred_histogram\n",
    "\n",
    "def targeted_diversity_average(learn, n_perturbations = 200, percentage = 95, average_over = 4):\n",
    "  results = []\n",
    "  for i in range(average_over):\n",
    "    n, _ = targeted_diversity(learn, n_perturbations, percentage)\n",
    "    print(f'done with the {i}th calculation: {n}')\n",
    "    results.append(n)\n",
    "  return np.mean(results)\n",
    "\n",
    "def diversity_average(learn, n_perturbations = 10, percentage = 95, average_over = 4):\n",
    "  results = []\n",
    "  for i in range(average_over):\n",
    "    n, _ = diversity(learn, n_perturbations, percentage, verbose = False)\n",
    "    print(f'done with the {i}th calculation: {n}')\n",
    "    results.append(n)\n",
    "  return np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at batch no 0\n",
      "at batch no 5\n",
      "at batch no 10\n",
      "at batch no 15\n",
      "at batch no 20\n",
      "at batch no 25\n",
      "at batch no 30\n",
      "at batch no 35\n",
      "at batch no 40\n",
      "at batch no 45\n",
      "at batch no 50\n",
      "at batch no 55\n",
      "at batch no 60\n",
      "finished creating the prediction histogram\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(566,\n",
       " [(794, 50.099998474121094),\n",
       "  (599, 21.100000381469727),\n",
       "  (668, 20.200000762939453),\n",
       "  (904, 15.0),\n",
       "  (973, 13.600000381469727),\n",
       "  (490, 12.899999618530273),\n",
       "  (39, 12.699999809265137),\n",
       "  (770, 12.600000381469727),\n",
       "  (741, 11.300000190734863),\n",
       "  (828, 11.100000381469727),\n",
       "  (109, 9.199999809265137),\n",
       "  (556, 8.600000381469727),\n",
       "  (489, 8.399999618530273),\n",
       "  (955, 8.399999618530273),\n",
       "  (887, 8.300000190734863),\n",
       "  (669, 8.100000381469727),\n",
       "  (84, 7.400000095367432),\n",
       "  (855, 7.0),\n",
       "  (538, 6.800000190734863),\n",
       "  (108, 6.599999904632568),\n",
       "  (124, 6.0),\n",
       "  (397, 5.900000095367432),\n",
       "  (48, 5.800000190734863),\n",
       "  (61, 5.5),\n",
       "  (777, 4.900000095367432),\n",
       "  (721, 4.800000190734863),\n",
       "  (401, 4.5),\n",
       "  (971, 4.400000095367432),\n",
       "  (893, 4.300000190734863),\n",
       "  (857, 4.099999904632568),\n",
       "  (591, 4.0),\n",
       "  (711, 3.9000000953674316),\n",
       "  (709, 3.799999952316284),\n",
       "  (455, 3.700000047683716),\n",
       "  (55, 3.5999999046325684),\n",
       "  (414, 3.5),\n",
       "  (906, 3.5),\n",
       "  (151, 3.4000000953674316),\n",
       "  (389, 3.4000000953674316),\n",
       "  (406, 3.4000000953674316),\n",
       "  (865, 3.299999952316284),\n",
       "  (750, 3.200000047683716),\n",
       "  (581, 3.0),\n",
       "  (0, 2.9000000953674316),\n",
       "  (1, 2.9000000953674316),\n",
       "  (476, 2.9000000953674316),\n",
       "  (915, 2.9000000953674316),\n",
       "  (363, 2.799999952316284),\n",
       "  (837, 2.799999952316284),\n",
       "  (982, 2.799999952316284),\n",
       "  (110, 2.700000047683716),\n",
       "  (46, 2.5999999046325684),\n",
       "  (62, 2.5999999046325684),\n",
       "  (593, 2.5999999046325684),\n",
       "  (640, 2.5999999046325684),\n",
       "  (735, 2.5999999046325684),\n",
       "  (819, 2.5999999046325684),\n",
       "  (94, 2.5),\n",
       "  (126, 2.5),\n",
       "  (431, 2.5),\n",
       "  (611, 2.4000000953674316),\n",
       "  (864, 2.4000000953674316),\n",
       "  (868, 2.4000000953674316),\n",
       "  (222, 2.299999952316284),\n",
       "  (558, 2.299999952316284),\n",
       "  (572, 2.299999952316284),\n",
       "  (850, 2.299999952316284),\n",
       "  (115, 2.200000047683716),\n",
       "  (410, 2.200000047683716),\n",
       "  (698, 2.200000047683716),\n",
       "  (763, 2.200000047683716),\n",
       "  (772, 2.200000047683716),\n",
       "  (779, 2.200000047683716),\n",
       "  (97, 2.0999999046325684),\n",
       "  (238, 2.0999999046325684),\n",
       "  (440, 2.0999999046325684),\n",
       "  (447, 2.0999999046325684),\n",
       "  (464, 2.0999999046325684),\n",
       "  (872, 2.0999999046325684),\n",
       "  (898, 2.0999999046325684),\n",
       "  (68, 2.0),\n",
       "  (118, 2.0),\n",
       "  (182, 2.0),\n",
       "  (242, 2.0),\n",
       "  (292, 2.0),\n",
       "  (393, 2.0),\n",
       "  (520, 2.0),\n",
       "  (621, 2.0),\n",
       "  (60, 1.899999976158142),\n",
       "  (188, 1.899999976158142),\n",
       "  (189, 1.899999976158142),\n",
       "  (192, 1.899999976158142),\n",
       "  (342, 1.899999976158142),\n",
       "  (411, 1.899999976158142),\n",
       "  (472, 1.899999976158142),\n",
       "  (570, 1.899999976158142),\n",
       "  (619, 1.899999976158142),\n",
       "  (620, 1.899999976158142),\n",
       "  (724, 1.899999976158142),\n",
       "  (791, 1.899999976158142),\n",
       "  (800, 1.899999976158142),\n",
       "  (199, 1.7999999523162842),\n",
       "  (290, 1.7999999523162842),\n",
       "  (348, 1.7999999523162842),\n",
       "  (423, 1.7999999523162842),\n",
       "  (761, 1.7999999523162842),\n",
       "  (762, 1.7999999523162842),\n",
       "  (870, 1.7999999523162842),\n",
       "  (920, 1.7999999523162842),\n",
       "  (72, 1.7000000476837158),\n",
       "  (128, 1.7000000476837158),\n",
       "  (155, 1.7000000476837158),\n",
       "  (195, 1.7000000476837158),\n",
       "  (334, 1.7000000476837158),\n",
       "  (526, 1.7000000476837158),\n",
       "  (547, 1.7000000476837158),\n",
       "  (671, 1.7000000476837158),\n",
       "  (725, 1.7000000476837158),\n",
       "  (775, 1.7000000476837158),\n",
       "  (783, 1.7000000476837158),\n",
       "  (824, 1.7000000476837158),\n",
       "  (871, 1.7000000476837158),\n",
       "  (123, 1.600000023841858),\n",
       "  (375, 1.600000023841858),\n",
       "  (457, 1.600000023841858),\n",
       "  (468, 1.600000023841858),\n",
       "  (492, 1.600000023841858),\n",
       "  (508, 1.600000023841858),\n",
       "  (550, 1.600000023841858),\n",
       "  (562, 1.600000023841858),\n",
       "  (803, 1.600000023841858),\n",
       "  (817, 1.600000023841858),\n",
       "  (953, 1.600000023841858),\n",
       "  (963, 1.600000023841858),\n",
       "  (107, 1.5),\n",
       "  (119, 1.5),\n",
       "  (202, 1.5),\n",
       "  (230, 1.5),\n",
       "  (420, 1.5),\n",
       "  (477, 1.5),\n",
       "  (564, 1.5),\n",
       "  (748, 1.5),\n",
       "  (815, 1.5),\n",
       "  (907, 1.5),\n",
       "  (76, 1.399999976158142),\n",
       "  (83, 1.399999976158142),\n",
       "  (193, 1.399999976158142),\n",
       "  (231, 1.399999976158142),\n",
       "  (274, 1.399999976158142),\n",
       "  (293, 1.399999976158142),\n",
       "  (305, 1.399999976158142),\n",
       "  (314, 1.399999976158142),\n",
       "  (336, 1.399999976158142),\n",
       "  (552, 1.399999976158142),\n",
       "  (565, 1.399999976158142),\n",
       "  (579, 1.399999976158142),\n",
       "  (597, 1.399999976158142),\n",
       "  (624, 1.399999976158142),\n",
       "  (679, 1.399999976158142),\n",
       "  (784, 1.399999976158142),\n",
       "  (786, 1.399999976158142),\n",
       "  (801, 1.399999976158142),\n",
       "  (891, 1.399999976158142),\n",
       "  (902, 1.399999976158142),\n",
       "  (33, 1.2999999523162842),\n",
       "  (57, 1.2999999523162842),\n",
       "  (96, 1.2999999523162842),\n",
       "  (120, 1.2999999523162842),\n",
       "  (247, 1.2999999523162842),\n",
       "  (275, 1.2999999523162842),\n",
       "  (328, 1.2999999523162842),\n",
       "  (355, 1.2999999523162842),\n",
       "  (409, 1.2999999523162842),\n",
       "  (441, 1.2999999523162842),\n",
       "  (505, 1.2999999523162842),\n",
       "  (586, 1.2999999523162842),\n",
       "  (588, 1.2999999523162842),\n",
       "  (633, 1.2999999523162842),\n",
       "  (638, 1.2999999523162842),\n",
       "  (821, 1.2999999523162842),\n",
       "  (842, 1.2999999523162842),\n",
       "  (892, 1.2999999523162842),\n",
       "  (58, 1.2000000476837158),\n",
       "  (65, 1.2000000476837158),\n",
       "  (171, 1.2000000476837158),\n",
       "  (204, 1.2000000476837158),\n",
       "  (205, 1.2000000476837158),\n",
       "  (219, 1.2000000476837158),\n",
       "  (307, 1.2000000476837158),\n",
       "  (308, 1.2000000476837158),\n",
       "  (327, 1.2000000476837158),\n",
       "  (331, 1.2000000476837158),\n",
       "  (353, 1.2000000476837158),\n",
       "  (366, 1.2000000476837158),\n",
       "  (443, 1.2000000476837158),\n",
       "  (454, 1.2000000476837158),\n",
       "  (474, 1.2000000476837158),\n",
       "  (495, 1.2000000476837158),\n",
       "  (563, 1.2000000476837158),\n",
       "  (574, 1.2000000476837158),\n",
       "  (602, 1.2000000476837158),\n",
       "  (641, 1.2000000476837158),\n",
       "  (654, 1.2000000476837158),\n",
       "  (658, 1.2000000476837158),\n",
       "  (781, 1.2000000476837158),\n",
       "  (823, 1.2000000476837158),\n",
       "  (848, 1.2000000476837158),\n",
       "  (854, 1.2000000476837158),\n",
       "  (858, 1.2000000476837158),\n",
       "  (883, 1.2000000476837158),\n",
       "  (24, 1.100000023841858),\n",
       "  (41, 1.100000023841858),\n",
       "  (51, 1.100000023841858),\n",
       "  (113, 1.100000023841858),\n",
       "  (116, 1.100000023841858),\n",
       "  (236, 1.100000023841858),\n",
       "  (249, 1.100000023841858),\n",
       "  (253, 1.100000023841858),\n",
       "  (271, 1.100000023841858),\n",
       "  (281, 1.100000023841858),\n",
       "  (300, 1.100000023841858),\n",
       "  (310, 1.100000023841858),\n",
       "  (317, 1.100000023841858),\n",
       "  (318, 1.100000023841858),\n",
       "  (319, 1.100000023841858),\n",
       "  (350, 1.100000023841858),\n",
       "  (381, 1.100000023841858),\n",
       "  (395, 1.100000023841858),\n",
       "  (396, 1.100000023841858),\n",
       "  (491, 1.100000023841858),\n",
       "  (496, 1.100000023841858),\n",
       "  (497, 1.100000023841858),\n",
       "  (506, 1.100000023841858),\n",
       "  (507, 1.100000023841858),\n",
       "  (527, 1.100000023841858),\n",
       "  (544, 1.100000023841858),\n",
       "  (575, 1.100000023841858),\n",
       "  (609, 1.100000023841858),\n",
       "  (626, 1.100000023841858),\n",
       "  (759, 1.100000023841858),\n",
       "  (787, 1.100000023841858),\n",
       "  (796, 1.100000023841858),\n",
       "  (806, 1.100000023841858),\n",
       "  (820, 1.100000023841858),\n",
       "  (834, 1.100000023841858),\n",
       "  (863, 1.100000023841858),\n",
       "  (882, 1.100000023841858),\n",
       "  (894, 1.100000023841858),\n",
       "  (918, 1.100000023841858),\n",
       "  (981, 1.100000023841858),\n",
       "  (996, 1.100000023841858),\n",
       "  (7, 1.0),\n",
       "  (8, 1.0),\n",
       "  (10, 1.0),\n",
       "  (15, 1.0),\n",
       "  (17, 1.0),\n",
       "  (19, 1.0),\n",
       "  (25, 1.0),\n",
       "  (28, 1.0),\n",
       "  (37, 1.0),\n",
       "  (42, 1.0),\n",
       "  (45, 1.0),\n",
       "  (49, 1.0),\n",
       "  (52, 1.0),\n",
       "  (53, 1.0),\n",
       "  (63, 1.0),\n",
       "  (70, 1.0),\n",
       "  (75, 1.0),\n",
       "  (79, 1.0),\n",
       "  (86, 1.0),\n",
       "  (87, 1.0),\n",
       "  (90, 1.0),\n",
       "  (91, 1.0),\n",
       "  (92, 1.0),\n",
       "  (98, 1.0),\n",
       "  (102, 1.0),\n",
       "  (105, 1.0),\n",
       "  (117, 1.0),\n",
       "  (134, 1.0),\n",
       "  (139, 1.0),\n",
       "  (140, 1.0),\n",
       "  (141, 1.0),\n",
       "  (144, 1.0),\n",
       "  (158, 1.0),\n",
       "  (161, 1.0),\n",
       "  (162, 1.0),\n",
       "  (163, 1.0),\n",
       "  (164, 1.0),\n",
       "  (173, 1.0),\n",
       "  (183, 1.0),\n",
       "  (186, 1.0),\n",
       "  (196, 1.0),\n",
       "  (197, 1.0),\n",
       "  (198, 1.0),\n",
       "  (206, 1.0),\n",
       "  (213, 1.0),\n",
       "  (218, 1.0),\n",
       "  (228, 1.0),\n",
       "  (235, 1.0),\n",
       "  (260, 1.0),\n",
       "  (273, 1.0),\n",
       "  (284, 1.0),\n",
       "  (289, 1.0),\n",
       "  (291, 1.0),\n",
       "  (301, 1.0),\n",
       "  (304, 1.0),\n",
       "  (306, 1.0),\n",
       "  (312, 1.0),\n",
       "  (313, 1.0),\n",
       "  (316, 1.0),\n",
       "  (321, 1.0),\n",
       "  (323, 1.0),\n",
       "  (337, 1.0),\n",
       "  (347, 1.0),\n",
       "  (360, 1.0),\n",
       "  (376, 1.0),\n",
       "  (378, 1.0),\n",
       "  (387, 1.0),\n",
       "  (392, 1.0),\n",
       "  (398, 1.0),\n",
       "  (417, 1.0),\n",
       "  (425, 1.0),\n",
       "  (428, 1.0),\n",
       "  (429, 1.0),\n",
       "  (433, 1.0),\n",
       "  (445, 1.0),\n",
       "  (451, 1.0),\n",
       "  (483, 1.0),\n",
       "  (488, 1.0),\n",
       "  (498, 1.0),\n",
       "  (518, 1.0),\n",
       "  (528, 1.0),\n",
       "  (530, 1.0),\n",
       "  (531, 1.0),\n",
       "  (533, 1.0),\n",
       "  (566, 1.0),\n",
       "  (580, 1.0),\n",
       "  (608, 1.0),\n",
       "  (612, 1.0),\n",
       "  (616, 1.0),\n",
       "  (625, 1.0),\n",
       "  (629, 1.0),\n",
       "  (637, 1.0),\n",
       "  (645, 1.0),\n",
       "  (646, 1.0),\n",
       "  (651, 1.0),\n",
       "  (655, 1.0),\n",
       "  (661, 1.0),\n",
       "  (684, 1.0),\n",
       "  (687, 1.0),\n",
       "  (691, 1.0),\n",
       "  (692, 1.0),\n",
       "  (694, 1.0),\n",
       "  (716, 1.0),\n",
       "  (719, 1.0),\n",
       "  (734, 1.0),\n",
       "  (738, 1.0),\n",
       "  (746, 1.0),\n",
       "  (753, 1.0),\n",
       "  (768, 1.0),\n",
       "  (793, 1.0),\n",
       "  (802, 1.0),\n",
       "  (816, 1.0),\n",
       "  (826, 1.0),\n",
       "  (830, 1.0),\n",
       "  (831, 1.0),\n",
       "  (847, 1.0),\n",
       "  (873, 1.0),\n",
       "  (884, 1.0),\n",
       "  (905, 1.0),\n",
       "  (923, 1.0),\n",
       "  (932, 1.0),\n",
       "  (934, 1.0),\n",
       "  (937, 1.0),\n",
       "  (939, 1.0),\n",
       "  (944, 1.0),\n",
       "  (946, 1.0),\n",
       "  (957, 1.0),\n",
       "  (959, 1.0),\n",
       "  (984, 1.0),\n",
       "  (985, 1.0),\n",
       "  (987, 1.0),\n",
       "  (989, 1.0),\n",
       "  (992, 1.0),\n",
       "  (9, 0.8999999761581421),\n",
       "  (18, 0.8999999761581421),\n",
       "  (21, 0.8999999761581421),\n",
       "  (36, 0.8999999761581421),\n",
       "  (47, 0.8999999761581421),\n",
       "  (85, 0.8999999761581421),\n",
       "  (135, 0.8999999761581421),\n",
       "  (142, 0.8999999761581421),\n",
       "  (145, 0.8999999761581421),\n",
       "  (176, 0.8999999761581421),\n",
       "  (187, 0.8999999761581421),\n",
       "  (263, 0.8999999761581421),\n",
       "  (266, 0.8999999761581421),\n",
       "  (303, 0.8999999761581421),\n",
       "  (315, 0.8999999761581421),\n",
       "  (326, 0.8999999761581421),\n",
       "  (365, 0.8999999761581421),\n",
       "  (384, 0.8999999761581421),\n",
       "  (390, 0.8999999761581421),\n",
       "  (391, 0.8999999761581421),\n",
       "  (408, 0.8999999761581421),\n",
       "  (459, 0.8999999761581421),\n",
       "  (463, 0.8999999761581421),\n",
       "  (482, 0.8999999761581421),\n",
       "  (503, 0.8999999761581421),\n",
       "  (534, 0.8999999761581421),\n",
       "  (535, 0.8999999761581421),\n",
       "  (555, 0.8999999761581421),\n",
       "  (577, 0.8999999761581421),\n",
       "  (635, 0.8999999761581421),\n",
       "  (663, 0.8999999761581421),\n",
       "  (674, 0.8999999761581421),\n",
       "  (702, 0.8999999761581421),\n",
       "  (703, 0.8999999761581421),\n",
       "  (712, 0.8999999761581421),\n",
       "  (743, 0.8999999761581421),\n",
       "  (757, 0.8999999761581421),\n",
       "  (764, 0.8999999761581421),\n",
       "  (776, 0.8999999761581421),\n",
       "  (788, 0.8999999761581421),\n",
       "  (808, 0.8999999761581421),\n",
       "  (832, 0.8999999761581421),\n",
       "  (833, 0.8999999761581421),\n",
       "  (900, 0.8999999761581421),\n",
       "  (968, 0.8999999761581421),\n",
       "  (988, 0.8999999761581421),\n",
       "  (997, 0.8999999761581421),\n",
       "  (38, 0.800000011920929),\n",
       "  (77, 0.800000011920929),\n",
       "  (93, 0.800000011920929),\n",
       "  (100, 0.800000011920929),\n",
       "  (160, 0.800000011920929),\n",
       "  (246, 0.800000011920929),\n",
       "  (254, 0.800000011920929),\n",
       "  (280, 0.800000011920929),\n",
       "  (294, 0.800000011920929),\n",
       "  (344, 0.800000011920929),\n",
       "  (372, 0.800000011920929),\n",
       "  (377, 0.800000011920929),\n",
       "  (399, 0.800000011920929),\n",
       "  (407, 0.800000011920929),\n",
       "  (415, 0.800000011920929),\n",
       "  (430, 0.800000011920929),\n",
       "  (432, 0.800000011920929),\n",
       "  (439, 0.800000011920929),\n",
       "  (458, 0.800000011920929),\n",
       "  (514, 0.800000011920929),\n",
       "  (545, 0.800000011920929),\n",
       "  (546, 0.800000011920929),\n",
       "  (595, 0.800000011920929),\n",
       "  (603, 0.800000011920929),\n",
       "  (643, 0.800000011920929),\n",
       "  (644, 0.800000011920929),\n",
       "  (672, 0.800000011920929),\n",
       "  (696, 0.800000011920929),\n",
       "  (729, 0.800000011920929),\n",
       "  (732, 0.800000011920929),\n",
       "  (809, 0.800000011920929),\n",
       "  (822, 0.800000011920929),\n",
       "  (829, 0.800000011920929),\n",
       "  (838, 0.800000011920929),\n",
       "  (843, 0.800000011920929),\n",
       "  (852, 0.800000011920929),\n",
       "  (885, 0.800000011920929),\n",
       "  (889, 0.800000011920929),\n",
       "  (901, 0.800000011920929),\n",
       "  (956, 0.800000011920929),\n",
       "  (34, 0.699999988079071),\n",
       "  (50, 0.699999988079071),\n",
       "  (99, 0.699999988079071),\n",
       "  (112, 0.699999988079071),\n",
       "  (168, 0.699999988079071),\n",
       "  (184, 0.699999988079071),\n",
       "  (214, 0.699999988079071),\n",
       "  (216, 0.699999988079071),\n",
       "  (217, 0.699999988079071),\n",
       "  (232, 0.699999988079071),\n",
       "  (270, 0.699999988079071),\n",
       "  (320, 0.699999988079071),\n",
       "  (330, 0.699999988079071),\n",
       "  (335, 0.699999988079071),\n",
       "  (345, 0.699999988079071),\n",
       "  (361, 0.699999988079071),\n",
       "  (388, 0.699999988079071),\n",
       "  (412, 0.699999988079071),\n",
       "  (512, 0.699999988079071),\n",
       "  (561, 0.699999988079071),\n",
       "  (576, 0.699999988079071),\n",
       "  (632, 0.699999988079071),\n",
       "  (695, 0.699999988079071),\n",
       "  (805, 0.699999988079071),\n",
       "  (879, 0.699999988079071),\n",
       "  (886, 0.699999988079071),\n",
       "  (952, 0.699999988079071),\n",
       "  (32, 0.6000000238418579),\n",
       "  (88, 0.6000000238418579),\n",
       "  (146, 0.6000000238418579),\n",
       "  (148, 0.6000000238418579),\n",
       "  (209, 0.6000000238418579),\n",
       "  (211, 0.6000000238418579),\n",
       "  (322, 0.6000000238418579),\n",
       "  (340, 0.6000000238418579),\n",
       "  (343, 0.6000000238418579),\n",
       "  (442, 0.6000000238418579),\n",
       "  (450, 0.6000000238418579),\n",
       "  (470, 0.6000000238418579),\n",
       "  (532, 0.6000000238418579),\n",
       "  (539, 0.6000000238418579),\n",
       "  (554, 0.6000000238418579),\n",
       "  (560, 0.6000000238418579),\n",
       "  (571, 0.6000000238418579),\n",
       "  (584, 0.6000000238418579),\n",
       "  (589, 0.6000000238418579),\n",
       "  (656, 0.6000000238418579),\n",
       "  (699, 0.6000000238418579),\n",
       "  (736, 0.6000000238418579),\n",
       "  (754, 0.6000000238418579),\n",
       "  (758, 0.6000000238418579),\n",
       "  (765, 0.6000000238418579),\n",
       "  (790, 0.6000000238418579),\n",
       "  (888, 0.6000000238418579),\n",
       "  (890, 0.6000000238418579),\n",
       "  (972, 0.6000000238418579),\n",
       "  (979, 0.6000000238418579),\n",
       "  (12, 0.5),\n",
       "  (16, 0.5),\n",
       "  (22, 0.5),\n",
       "  (143, 0.5),\n",
       "  (157, 0.5),\n",
       "  (166, 0.5),\n",
       "  (203, 0.5),\n",
       "  (212, 0.5),\n",
       "  (221, 0.5),\n",
       "  (224, 0.5),\n",
       "  (229, 0.5),\n",
       "  (234, 0.5),\n",
       "  (237, 0.5),\n",
       "  (252, 0.5),\n",
       "  (276, 0.5),\n",
       "  (282, 0.5),\n",
       "  (288, 0.5),\n",
       "  (295, 0.5),\n",
       "  (296, 0.5),\n",
       "  (309, 0.5),\n",
       "  (329, 0.5),\n",
       "  (402, 0.5),\n",
       "  (413, 0.5),\n",
       "  (436, 0.5),\n",
       "  (444, 0.5),\n",
       "  (448, 0.5),\n",
       "  (471, 0.5),\n",
       "  (540, 0.5),\n",
       "  (604, 0.5),\n",
       "  (639, 0.5),\n",
       "  (647, 0.5),\n",
       "  (683, 0.5),\n",
       "  (697, 0.5),\n",
       "  (715, 0.5),\n",
       "  (752, 0.5),\n",
       "  (755, 0.5),\n",
       "  (795, 0.5),\n",
       "  (811, 0.5),\n",
       "  (839, 0.5),\n",
       "  (853, 0.5),\n",
       "  (862, 0.5),\n",
       "  (877, 0.5),\n",
       "  (897, 0.5),\n",
       "  (910, 0.5),\n",
       "  (911, 0.5),\n",
       "  (927, 0.5),\n",
       "  (977, 0.5),\n",
       "  (20, 0.4000000059604645),\n",
       "  (29, 0.4000000059604645),\n",
       "  (69, 0.4000000059604645),\n",
       "  (122, 0.4000000059604645),\n",
       "  (125, 0.4000000059604645),\n",
       "  (130, 0.4000000059604645),\n",
       "  (132, 0.4000000059604645),\n",
       "  (178, 0.4000000059604645),\n",
       "  (180, 0.4000000059604645),\n",
       "  (256, 0.4000000059604645),\n",
       "  (264, 0.4000000059604645),\n",
       "  (298, 0.4000000059604645),\n",
       "  (370, 0.4000000059604645),\n",
       "  (419, 0.4000000059604645),\n",
       "  (424, 0.4000000059604645),\n",
       "  (480, 0.4000000059604645),\n",
       "  (484, 0.4000000059604645),\n",
       "  (509, 0.4000000059604645),\n",
       "  (511, 0.4000000059604645),\n",
       "  (537, 0.4000000059604645),\n",
       "  (582, 0.4000000059604645),\n",
       "  (587, 0.4000000059604645),\n",
       "  (590, 0.4000000059604645),\n",
       "  (606, 0.4000000059604645),\n",
       "  (615, 0.4000000059604645),\n",
       "  (652, 0.4000000059604645),\n",
       "  (670, 0.4000000059604645),\n",
       "  (689, 0.4000000059604645),\n",
       "  (700, 0.4000000059604645),\n",
       "  (707, 0.4000000059604645),\n",
       "  (720, 0.4000000059604645),\n",
       "  (727, 0.4000000059604645),\n",
       "  (745, 0.4000000059604645),\n",
       "  (804, 0.4000000059604645),\n",
       "  (844, 0.4000000059604645),\n",
       "  (866, 0.4000000059604645),\n",
       "  (878, 0.4000000059604645),\n",
       "  (881, 0.4000000059604645),\n",
       "  (896, 0.4000000059604645),\n",
       "  (925, 0.4000000059604645),\n",
       "  (2, 0.30000001192092896),\n",
       "  (5, 0.30000001192092896),\n",
       "  (74, 0.30000001192092896),\n",
       "  (78, 0.30000001192092896),\n",
       "  (81, 0.30000001192092896),\n",
       "  (89, 0.30000001192092896),\n",
       "  (101, 0.30000001192092896),\n",
       "  (136, 0.30000001192092896),\n",
       "  (138, 0.30000001192092896),\n",
       "  (169, 0.30000001192092896),\n",
       "  (190, 0.30000001192092896),\n",
       "  (207, 0.30000001192092896),\n",
       "  (208, 0.30000001192092896),\n",
       "  (215, 0.30000001192092896),\n",
       "  (243, 0.30000001192092896),\n",
       "  (250, 0.30000001192092896),\n",
       "  (285, 0.30000001192092896),\n",
       "  (286, 0.30000001192092896),\n",
       "  (302, 0.30000001192092896),\n",
       "  (332, 0.30000001192092896),\n",
       "  (341, 0.30000001192092896),\n",
       "  (357, 0.30000001192092896),\n",
       "  (364, 0.30000001192092896),\n",
       "  (369, 0.30000001192092896),\n",
       "  (386, 0.30000001192092896),\n",
       "  (403, 0.30000001192092896),\n",
       "  (438, 0.30000001192092896),\n",
       "  (456, 0.30000001192092896),\n",
       "  (461, 0.30000001192092896),\n",
       "  (487, 0.30000001192092896),\n",
       "  (523, 0.30000001192092896),\n",
       "  (541, 0.30000001192092896),\n",
       "  (542, 0.30000001192092896),\n",
       "  (607, 0.30000001192092896),\n",
       "  (613, 0.30000001192092896),\n",
       "  (636, 0.30000001192092896),\n",
       "  (650, 0.30000001192092896),\n",
       "  (704, 0.30000001192092896),\n",
       "  (740, 0.30000001192092896),\n",
       "  (818, 0.30000001192092896),\n",
       "  (867, 0.30000001192092896),\n",
       "  (6, 0.20000000298023224),\n",
       "  (11, 0.20000000298023224),\n",
       "  (14, 0.20000000298023224),\n",
       "  (23, 0.20000000298023224),\n",
       "  (35, 0.20000000298023224),\n",
       "  (40, 0.20000000298023224),\n",
       "  (44, 0.20000000298023224),\n",
       "  (56, 0.20000000298023224),\n",
       "  (71, 0.20000000298023224),\n",
       "  (114, 0.20000000298023224),\n",
       "  (159, 0.20000000298023224),\n",
       "  (201, 0.20000000298023224),\n",
       "  (223, 0.20000000298023224),\n",
       "  (241, 0.20000000298023224),\n",
       "  (248, 0.20000000298023224),\n",
       "  (261, 0.20000000298023224),\n",
       "  (265, 0.20000000298023224),\n",
       "  (269, 0.20000000298023224),\n",
       "  (272, 0.20000000298023224),\n",
       "  (352, 0.20000000298023224),\n",
       "  (394, 0.20000000298023224),\n",
       "  (453, 0.20000000298023224),\n",
       "  (486, 0.20000000298023224),\n",
       "  (502, 0.20000000298023224),\n",
       "  (513, 0.20000000298023224),\n",
       "  (516, 0.20000000298023224),\n",
       "  (524, 0.20000000298023224),\n",
       "  (529, 0.20000000298023224),\n",
       "  (567, 0.20000000298023224),\n",
       "  (592, 0.20000000298023224),\n",
       "  (601, 0.20000000298023224),\n",
       "  (614, 0.20000000298023224),\n",
       "  (634, 0.20000000298023224),\n",
       "  (642, 0.20000000298023224),\n",
       "  (649, 0.20000000298023224),\n",
       "  (662, 0.20000000298023224),\n",
       "  (664, 0.20000000298023224),\n",
       "  (667, 0.20000000298023224),\n",
       "  (678, 0.20000000298023224),\n",
       "  (680, 0.20000000298023224),\n",
       "  (688, 0.20000000298023224),\n",
       "  (706, 0.20000000298023224),\n",
       "  (751, 0.20000000298023224),\n",
       "  (766, 0.20000000298023224),\n",
       "  (773, 0.20000000298023224),\n",
       "  (799, 0.20000000298023224),\n",
       "  (827, 0.20000000298023224),\n",
       "  (859, 0.20000000298023224),\n",
       "  (962, 0.20000000298023224),\n",
       "  (976, 0.20000000298023224),\n",
       "  (978, 0.20000000298023224),\n",
       "  (994, 0.20000000298023224),\n",
       "  (4, 0.10000000149011612),\n",
       "  (31, 0.10000000149011612),\n",
       "  (67, 0.10000000149011612),\n",
       "  (95, 0.10000000149011612),\n",
       "  (121, 0.10000000149011612),\n",
       "  (150, 0.10000000149011612),\n",
       "  (170, 0.10000000149011612),\n",
       "  (181, 0.10000000149011612),\n",
       "  (226, 0.10000000149011612),\n",
       "  (227, 0.10000000149011612),\n",
       "  (245, 0.10000000149011612),\n",
       "  (257, 0.10000000149011612),\n",
       "  (259, 0.10000000149011612),\n",
       "  (267, 0.10000000149011612),\n",
       "  (279, 0.10000000149011612),\n",
       "  (297, 0.10000000149011612),\n",
       "  (311, 0.10000000149011612),\n",
       "  (324, 0.10000000149011612),\n",
       "  (354, 0.10000000149011612),\n",
       "  (358, 0.10000000149011612),\n",
       "  (359, 0.10000000149011612),\n",
       "  (362, 0.10000000149011612),\n",
       "  (379, 0.10000000149011612),\n",
       "  (380, 0.10000000149011612),\n",
       "  (382, 0.10000000149011612),\n",
       "  (383, 0.10000000149011612),\n",
       "  (385, 0.10000000149011612),\n",
       "  (400, 0.10000000149011612),\n",
       "  (422, 0.10000000149011612),\n",
       "  (434, 0.10000000149011612),\n",
       "  (452, 0.10000000149011612),\n",
       "  (501, 0.10000000149011612),\n",
       "  (517, 0.10000000149011612),\n",
       "  (568, 0.10000000149011612),\n",
       "  (578, 0.10000000149011612),\n",
       "  (585, 0.10000000149011612),\n",
       "  (605, 0.10000000149011612),\n",
       "  (618, 0.10000000149011612),\n",
       "  (628, 0.10000000149011612),\n",
       "  (657, 0.10000000149011612),\n",
       "  (665, 0.10000000149011612),\n",
       "  (676, 0.10000000149011612),\n",
       "  (685, 0.10000000149011612),\n",
       "  (690, 0.10000000149011612),\n",
       "  (701, 0.10000000149011612),\n",
       "  (710, 0.10000000149011612),\n",
       "  (749, 0.10000000149011612),\n",
       "  (771, 0.10000000149011612),\n",
       "  (774, 0.10000000149011612),\n",
       "  (778, 0.10000000149011612),\n",
       "  (782, 0.10000000149011612),\n",
       "  (797, 0.10000000149011612),\n",
       "  (814, 0.10000000149011612),\n",
       "  (825, 0.10000000149011612),\n",
       "  (849, 0.10000000149011612),\n",
       "  (869, 0.10000000149011612),\n",
       "  (874, 0.10000000149011612),\n",
       "  (875, 0.10000000149011612),\n",
       "  (903, 0.10000000149011612),\n",
       "  (919, 0.10000000149011612),\n",
       "  (921, 0.10000000149011612),\n",
       "  (933, 0.10000000149011612),\n",
       "  (938, 0.10000000149011612),\n",
       "  (943, 0.10000000149011612),\n",
       "  (949, 0.10000000149011612),\n",
       "  (983, 0.10000000149011612),\n",
       "  (990, 0.10000000149011612),\n",
       "  (3, 0.0),\n",
       "  (13, 0.0),\n",
       "  (26, 0.0),\n",
       "  (27, 0.0),\n",
       "  (30, 0.0),\n",
       "  (43, 0.0),\n",
       "  (54, 0.0),\n",
       "  (59, 0.0),\n",
       "  (64, 0.0),\n",
       "  (66, 0.0),\n",
       "  (73, 0.0),\n",
       "  (80, 0.0),\n",
       "  (82, 0.0),\n",
       "  (103, 0.0),\n",
       "  (104, 0.0),\n",
       "  (106, 0.0),\n",
       "  (111, 0.0),\n",
       "  (127, 0.0),\n",
       "  (129, 0.0),\n",
       "  (131, 0.0),\n",
       "  (133, 0.0),\n",
       "  (137, 0.0),\n",
       "  (147, 0.0),\n",
       "  (149, 0.0),\n",
       "  (152, 0.0),\n",
       "  (153, 0.0),\n",
       "  (154, 0.0),\n",
       "  (156, 0.0),\n",
       "  (165, 0.0),\n",
       "  (167, 0.0),\n",
       "  (172, 0.0),\n",
       "  (174, 0.0),\n",
       "  (175, 0.0),\n",
       "  (177, 0.0),\n",
       "  (179, 0.0),\n",
       "  (185, 0.0),\n",
       "  (191, 0.0),\n",
       "  (194, 0.0),\n",
       "  (200, 0.0),\n",
       "  (210, 0.0),\n",
       "  (220, 0.0),\n",
       "  (225, 0.0),\n",
       "  (233, 0.0),\n",
       "  (239, 0.0),\n",
       "  (240, 0.0),\n",
       "  (244, 0.0),\n",
       "  (251, 0.0),\n",
       "  (255, 0.0),\n",
       "  (258, 0.0),\n",
       "  (262, 0.0),\n",
       "  (268, 0.0),\n",
       "  (277, 0.0),\n",
       "  (278, 0.0),\n",
       "  (283, 0.0),\n",
       "  (287, 0.0),\n",
       "  (299, 0.0),\n",
       "  (325, 0.0),\n",
       "  (333, 0.0),\n",
       "  (338, 0.0),\n",
       "  (339, 0.0),\n",
       "  (346, 0.0),\n",
       "  (349, 0.0),\n",
       "  (351, 0.0),\n",
       "  (356, 0.0),\n",
       "  (367, 0.0),\n",
       "  (368, 0.0),\n",
       "  (371, 0.0),\n",
       "  (373, 0.0),\n",
       "  (374, 0.0),\n",
       "  (404, 0.0),\n",
       "  (405, 0.0),\n",
       "  (416, 0.0),\n",
       "  (418, 0.0),\n",
       "  (421, 0.0),\n",
       "  (426, 0.0),\n",
       "  (427, 0.0),\n",
       "  (435, 0.0),\n",
       "  (437, 0.0),\n",
       "  (446, 0.0),\n",
       "  (449, 0.0),\n",
       "  (460, 0.0),\n",
       "  (462, 0.0),\n",
       "  (465, 0.0),\n",
       "  (466, 0.0),\n",
       "  (467, 0.0),\n",
       "  (469, 0.0),\n",
       "  (473, 0.0),\n",
       "  (475, 0.0),\n",
       "  (478, 0.0),\n",
       "  (479, 0.0),\n",
       "  (481, 0.0),\n",
       "  (485, 0.0),\n",
       "  (493, 0.0),\n",
       "  (494, 0.0),\n",
       "  (499, 0.0),\n",
       "  (500, 0.0),\n",
       "  (504, 0.0),\n",
       "  (510, 0.0),\n",
       "  (515, 0.0),\n",
       "  (519, 0.0),\n",
       "  (521, 0.0),\n",
       "  (522, 0.0),\n",
       "  (525, 0.0),\n",
       "  (536, 0.0),\n",
       "  (543, 0.0),\n",
       "  (548, 0.0),\n",
       "  (549, 0.0),\n",
       "  (551, 0.0),\n",
       "  (553, 0.0),\n",
       "  (557, 0.0),\n",
       "  (559, 0.0),\n",
       "  (569, 0.0),\n",
       "  (573, 0.0),\n",
       "  (583, 0.0),\n",
       "  (594, 0.0),\n",
       "  (596, 0.0),\n",
       "  (598, 0.0),\n",
       "  (600, 0.0),\n",
       "  (610, 0.0),\n",
       "  (617, 0.0),\n",
       "  (622, 0.0),\n",
       "  (623, 0.0),\n",
       "  (627, 0.0),\n",
       "  (630, 0.0),\n",
       "  (631, 0.0),\n",
       "  (648, 0.0),\n",
       "  (653, 0.0),\n",
       "  (659, 0.0),\n",
       "  (660, 0.0),\n",
       "  (666, 0.0),\n",
       "  (673, 0.0),\n",
       "  (675, 0.0),\n",
       "  (677, 0.0),\n",
       "  (681, 0.0),\n",
       "  (682, 0.0),\n",
       "  (686, 0.0),\n",
       "  (693, 0.0),\n",
       "  (705, 0.0),\n",
       "  (708, 0.0),\n",
       "  (713, 0.0),\n",
       "  (714, 0.0),\n",
       "  (717, 0.0),\n",
       "  (718, 0.0),\n",
       "  (722, 0.0),\n",
       "  (723, 0.0),\n",
       "  (726, 0.0),\n",
       "  (728, 0.0),\n",
       "  (730, 0.0),\n",
       "  (731, 0.0),\n",
       "  (733, 0.0),\n",
       "  (737, 0.0),\n",
       "  (739, 0.0),\n",
       "  (742, 0.0),\n",
       "  (744, 0.0),\n",
       "  (747, 0.0),\n",
       "  (756, 0.0),\n",
       "  (760, 0.0),\n",
       "  (767, 0.0),\n",
       "  (769, 0.0),\n",
       "  (780, 0.0),\n",
       "  (785, 0.0),\n",
       "  (789, 0.0),\n",
       "  (792, 0.0),\n",
       "  (798, 0.0),\n",
       "  (807, 0.0),\n",
       "  (810, 0.0),\n",
       "  (812, 0.0),\n",
       "  (813, 0.0),\n",
       "  (835, 0.0),\n",
       "  (836, 0.0),\n",
       "  (840, 0.0),\n",
       "  (841, 0.0),\n",
       "  (845, 0.0),\n",
       "  (846, 0.0),\n",
       "  (851, 0.0),\n",
       "  (856, 0.0),\n",
       "  (860, 0.0),\n",
       "  (861, 0.0),\n",
       "  (876, 0.0),\n",
       "  (880, 0.0),\n",
       "  (895, 0.0),\n",
       "  (899, 0.0),\n",
       "  (908, 0.0),\n",
       "  (909, 0.0),\n",
       "  (912, 0.0),\n",
       "  (913, 0.0),\n",
       "  (914, 0.0),\n",
       "  (916, 0.0),\n",
       "  (917, 0.0),\n",
       "  (922, 0.0),\n",
       "  (924, 0.0),\n",
       "  (926, 0.0),\n",
       "  (928, 0.0),\n",
       "  (929, 0.0),\n",
       "  (930, 0.0),\n",
       "  (931, 0.0),\n",
       "  (935, 0.0),\n",
       "  (936, 0.0),\n",
       "  (940, 0.0),\n",
       "  (941, 0.0),\n",
       "  (942, 0.0),\n",
       "  (945, 0.0),\n",
       "  (947, 0.0),\n",
       "  (948, 0.0),\n",
       "  (950, 0.0),\n",
       "  (951, 0.0),\n",
       "  (954, 0.0),\n",
       "  (958, 0.0),\n",
       "  (960, 0.0),\n",
       "  (961, 0.0),\n",
       "  (964, 0.0),\n",
       "  (965, 0.0),\n",
       "  (966, 0.0),\n",
       "  (967, 0.0),\n",
       "  (969, 0.0),\n",
       "  (970, 0.0),\n",
       "  (974, 0.0),\n",
       "  (975, 0.0),\n",
       "  (980, 0.0),\n",
       "  (986, 0.0),\n",
       "  (991, 0.0),\n",
       "  (993, 0.0),\n",
       "  (995, 0.0),\n",
       "  (998, 0.0),\n",
       "  (999, 0.0)])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, hist = diversity(learn, 10, 95)\n",
    "n, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at batch_no 0\n",
      "done with the 0th calculation: 717\n",
      "at batch_no 0\n",
      "done with the 1th calculation: 718\n",
      "at batch_no 0\n",
      "done with the 2th calculation: 720\n",
      "at batch_no 0\n",
      "done with the 3th calculation: 718\n",
      "result for n_pert: 10 is 718.25\n",
      "at batch_no 0\n",
      "done with the 0th calculation: 713\n",
      "at batch_no 0\n",
      "done with the 1th calculation: 724\n",
      "at batch_no 0\n",
      "done with the 2th calculation: 715\n",
      "at batch_no 0\n",
      "done with the 3th calculation: 719\n",
      "result for n_pert: 20 is 717.75\n",
      "at batch_no 0\n",
      "done with the 0th calculation: 712\n",
      "at batch_no 0\n",
      "done with the 1th calculation: 722\n",
      "at batch_no 0\n",
      "done with the 2th calculation: 720\n",
      "at batch_no 0\n",
      "done with the 3th calculation: 717\n",
      "result for n_pert: 30 is 717.75\n",
      "at batch_no 0\n",
      "done with the 0th calculation: 716\n",
      "at batch_no 0\n",
      "done with the 1th calculation: 717\n",
      "at batch_no 0\n",
      "done with the 2th calculation: 713\n",
      "at batch_no 0\n",
      "done with the 3th calculation: 714\n",
      "result for n_pert: 40 is 715.0\n",
      "at batch_no 0\n",
      "done with the 0th calculation: 717\n",
      "at batch_no 0\n",
      "done with the 1th calculation: 723\n",
      "at batch_no 0\n",
      "done with the 2th calculation: 722\n",
      "at batch_no 0\n",
      "done with the 3th calculation: 720\n",
      "result for n_pert: 50 is 720.5\n",
      "at batch_no 0\n",
      "done with the 0th calculation: 719\n",
      "at batch_no 0\n",
      "done with the 1th calculation: 712\n",
      "at batch_no 0\n",
      "done with the 2th calculation: 712\n",
      "at batch_no 0\n",
      "done with the 3th calculation: 720\n",
      "result for n_pert: 60 is 715.75\n",
      "at batch_no 0\n",
      "done with the 0th calculation: 723\n",
      "at batch_no 0\n",
      "done with the 1th calculation: 721\n",
      "at batch_no 0\n",
      "done with the 2th calculation: 722\n",
      "at batch_no 0\n",
      "done with the 3th calculation: 711\n",
      "result for n_pert: 70 is 719.25\n",
      "at batch_no 0\n",
      "done with the 0th calculation: 715\n",
      "at batch_no 0\n",
      "done with the 1th calculation: 715\n",
      "at batch_no 0\n",
      "done with the 2th calculation: 717\n",
      "at batch_no 0\n",
      "done with the 3th calculation: 715\n",
      "result for n_pert: 80 is 715.5\n",
      "at batch_no 0\n",
      "done with the 0th calculation: 721\n",
      "at batch_no 0\n",
      "done with the 1th calculation: 716\n",
      "at batch_no 0\n",
      "done with the 2th calculation: 716\n",
      "at batch_no 0\n",
      "done with the 3th calculation: 714\n",
      "result for n_pert: 90 is 716.75\n",
      "at batch_no 0\n",
      "done with the 0th calculation: 718\n",
      "at batch_no 0\n",
      "done with the 1th calculation: 719\n",
      "at batch_no 0\n",
      "done with the 2th calculation: 724\n",
      "at batch_no 0\n",
      "done with the 3th calculation: 723\n",
      "result for n_pert: 100 is 721.0\n"
     ]
    }
   ],
   "source": [
    "results_1 = []\n",
    "for n_pert in range(10, 110, 10):\n",
    "  n = targeted_diversity_average(learn, n_pert, 95, 4)\n",
    "  print(f'result for n_pert: {n_pert} is {n}')\n",
    "  results_1.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7feac1262b70>]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = list(range(10, 110, 10))\n",
    "plt.ylim(0, 800)\n",
    "plt.plot(x, results_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished creating the prediction histogram\n",
      "done with the 0th calculation: 548\n",
      "finished creating the prediction histogram\n",
      "done with the 1th calculation: 524\n",
      "finished creating the prediction histogram\n",
      "done with the 2th calculation: 519\n",
      "result for n_pert: 10 is 530.3333333333334\n",
      "finished creating the prediction histogram\n",
      "done with the 0th calculation: 524\n",
      "finished creating the prediction histogram\n",
      "done with the 1th calculation: 546\n",
      "finished creating the prediction histogram\n",
      "done with the 2th calculation: 518\n",
      "result for n_pert: 20 is 529.3333333333334\n",
      "finished creating the prediction histogram\n",
      "done with the 0th calculation: 561\n",
      "finished creating the prediction histogram\n",
      "done with the 1th calculation: 543\n",
      "finished creating the prediction histogram\n",
      "done with the 2th calculation: 523\n",
      "result for n_pert: 30 is 542.3333333333334\n",
      "finished creating the prediction histogram\n",
      "done with the 0th calculation: 571\n",
      "finished creating the prediction histogram\n",
      "done with the 1th calculation: 548\n",
      "finished creating the prediction histogram\n",
      "done with the 2th calculation: 548\n",
      "result for n_pert: 40 is 555.6666666666666\n",
      "finished creating the prediction histogram\n",
      "done with the 0th calculation: 552\n",
      "finished creating the prediction histogram\n",
      "done with the 1th calculation: 535\n",
      "finished creating the prediction histogram\n",
      "done with the 2th calculation: 538\n",
      "result for n_pert: 50 is 541.6666666666666\n",
      "finished creating the prediction histogram\n",
      "done with the 0th calculation: 558\n",
      "finished creating the prediction histogram\n",
      "done with the 1th calculation: 540\n",
      "finished creating the prediction histogram\n",
      "done with the 0th calculation: 540\n",
      "finished creating the prediction histogram\n",
      "done with the 1th calculation: 534\n",
      "finished creating the prediction histogram\n",
      "done with the 2th calculation: 534\n",
      "result for n_pert: 70 is 536.0\n",
      "finished creating the prediction histogram\n",
      "done with the 0th calculation: 547\n",
      "finished creating the prediction histogram\n",
      "done with the 1th calculation: 521\n",
      "finished creating the prediction histogram\n",
      "done with the 2th calculation: 542\n",
      "result for n_pert: 80 is 536.6666666666666\n",
      "finished creating the prediction histogram\n",
      "done with the 0th calculation: 539\n",
      "finished creating the prediction histogram\n",
      "done with the 1th calculation: 564\n",
      "finished creating the prediction histogram\n",
      "done with the 2th calculation: 530\n",
      "result for n_pert: 90 is 544.3333333333334\n",
      "finished creating the prediction histogram\n",
      "done with the 0th calculation: 550\n",
      "finished creating the prediction histogram\n",
      "done with the 1th calculation: 540\n",
      "finished creating the prediction histogram\n",
      "done with the 2th calculation: 540\n",
      "result for n_pert: 100 is 543.3333333333334\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for n_pert in range(10, 110, 10):\n",
    "  n = diversity_average(learn, n_pert, 95, 3)\n",
    "  print(f'result for n_pert: {n_pert} is {n}')\n",
    "  results.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fea6868afd0>]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = list(range(10, 110, 10))\n",
    "plt.ylim(0, 600)\n",
    "plt.plot(x, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#targeted:\n",
    "targeted_div_metrics = results_1\n",
    "div_metrics = results\n",
    "\n",
    "#non-targeted:\n",
    "n_targeted_div_metrics = [244.0, 247.0, 265.3333333333333, 246.66666666666666, 241.0, 231.33333333333334, \n",
    "                          247.66666666666666, 229.0, 222.33333333333334, 236.0]\n",
    "n_div_metrics = [132, 118, 122, 135, 133, 129, 136, 132, 124, 143]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, targeted_div_metrics)\n",
    "plt.plot(x, n_targeted_div_metrics)\n",
    "plt.title('targeted_div_metric')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, div_metrics)\n",
    "plt.plot(x, n_div_metrics)\n",
    "plt.title('div_metric')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on validation\n",
    "%precision 2\n",
    "# n, hist = targeted_diversity(learn, 150, 95)\n",
    "# n, hist\n",
    "n, hist = diversity(learn, 10, 95)\n",
    "n, hist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on validation\n",
    "%precision 2\n",
    "# n, hist = targeted_diversity(learn, 150, 95)\n",
    "# n, hist\n",
    "n, hist = diversity(learn, 10, 95)\n",
    "n, hist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at batch no 0\n",
      "at batch no 5\n",
      "at batch no 10\n",
      "at batch no 15\n",
      "at batch no 20\n",
      "at batch no 25\n",
      "at batch no 30\n",
      "at batch no 35\n",
      "at batch no 40\n",
      "at batch no 45\n",
      "at batch no 50\n",
      "at batch no 55\n",
      "at batch no 60\n",
      "finished creating the prediction histogram\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(364,\n",
       " [(721, 143.20),\n",
       "  (750, 49.40),\n",
       "  (971, 48.40),\n",
       "  (794, 47.10),\n",
       "  (431, 35.10),\n",
       "  (669, 35.10),\n",
       "  (414, 30.60),\n",
       "  (588, 28.40),\n",
       "  (520, 24.90),\n",
       "  (61, 24.20),\n",
       "  (904, 18.30),\n",
       "  (411, 14.30),\n",
       "  (828, 13.50),\n",
       "  (39, 11.70),\n",
       "  (556, 11.40),\n",
       "  (581, 9.20),\n",
       "  (651, 8.30),\n",
       "  (489, 7.80),\n",
       "  (599, 6.60),\n",
       "  (84, 5.50),\n",
       "  (572, 4.80),\n",
       "  (907, 4.70),\n",
       "  (987, 4.40),\n",
       "  (401, 4.30),\n",
       "  (490, 4.30),\n",
       "  (614, 4.30),\n",
       "  (60, 4.00),\n",
       "  (955, 3.50),\n",
       "  (711, 3.30),\n",
       "  (48, 3.20),\n",
       "  (691, 3.10),\n",
       "  (709, 3.00),\n",
       "  (419, 2.90),\n",
       "  (770, 2.90),\n",
       "  (815, 2.90),\n",
       "  (864, 2.80),\n",
       "  (879, 2.80),\n",
       "  (108, 2.70),\n",
       "  (441, 2.70),\n",
       "  (632, 2.70),\n",
       "  (56, 2.50),\n",
       "  (604, 2.50),\n",
       "  (55, 2.40),\n",
       "  (464, 2.30),\n",
       "  (549, 2.30),\n",
       "  (575, 2.20),\n",
       "  (893, 2.20),\n",
       "  (973, 2.20),\n",
       "  (96, 2.10),\n",
       "  (496, 2.10),\n",
       "  (518, 2.10),\n",
       "  (412, 2.00),\n",
       "  (641, 2.00),\n",
       "  (762, 2.00),\n",
       "  (801, 2.00),\n",
       "  (872, 2.00),\n",
       "  (858, 1.90),\n",
       "  (871, 1.90),\n",
       "  (580, 1.80),\n",
       "  (621, 1.80),\n",
       "  (746, 1.80),\n",
       "  (806, 1.80),\n",
       "  (46, 1.70),\n",
       "  (151, 1.70),\n",
       "  (171, 1.70),\n",
       "  (633, 1.70),\n",
       "  (781, 1.70),\n",
       "  (790, 1.70),\n",
       "  (850, 1.70),\n",
       "  (424, 1.60),\n",
       "  (443, 1.60),\n",
       "  (453, 1.60),\n",
       "  (646, 1.60),\n",
       "  (981, 1.60),\n",
       "  (128, 1.50),\n",
       "  (360, 1.50),\n",
       "  (457, 1.50),\n",
       "  (545, 1.50),\n",
       "  (680, 1.50),\n",
       "  (722, 1.50),\n",
       "  (743, 1.50),\n",
       "  (1, 1.40),\n",
       "  (94, 1.40),\n",
       "  (230, 1.40),\n",
       "  (292, 1.40),\n",
       "  (406, 1.40),\n",
       "  (410, 1.40),\n",
       "  (440, 1.40),\n",
       "  (506, 1.40),\n",
       "  (847, 1.40),\n",
       "  (897, 1.40),\n",
       "  (67, 1.30),\n",
       "  (68, 1.30),\n",
       "  (124, 1.30),\n",
       "  (417, 1.30),\n",
       "  (538, 1.30),\n",
       "  (706, 1.30),\n",
       "  (779, 1.30),\n",
       "  (791, 1.30),\n",
       "  (826, 1.30),\n",
       "  (865, 1.30),\n",
       "  (898, 1.30),\n",
       "  (937, 1.30),\n",
       "  (953, 1.30),\n",
       "  (242, 1.20),\n",
       "  (310, 1.20),\n",
       "  (408, 1.20),\n",
       "  (582, 1.20),\n",
       "  (591, 1.20),\n",
       "  (698, 1.20),\n",
       "  (857, 1.20),\n",
       "  (896, 1.20),\n",
       "  (963, 1.20),\n",
       "  (83, 1.10),\n",
       "  (90, 1.10),\n",
       "  (92, 1.10),\n",
       "  (123, 1.10),\n",
       "  (293, 1.10),\n",
       "  (300, 1.10),\n",
       "  (316, 1.10),\n",
       "  (393, 1.10),\n",
       "  (407, 1.10),\n",
       "  (468, 1.10),\n",
       "  (612, 1.10),\n",
       "  (619, 1.10),\n",
       "  (645, 1.10),\n",
       "  (656, 1.10),\n",
       "  (738, 1.10),\n",
       "  (783, 1.10),\n",
       "  (805, 1.10),\n",
       "  (817, 1.10),\n",
       "  (906, 1.10),\n",
       "  (7, 1.00),\n",
       "  (25, 1.00),\n",
       "  (31, 1.00),\n",
       "  (33, 1.00),\n",
       "  (37, 1.00),\n",
       "  (57, 1.00),\n",
       "  (75, 1.00),\n",
       "  (88, 1.00),\n",
       "  (91, 1.00),\n",
       "  (102, 1.00),\n",
       "  (115, 1.00),\n",
       "  (120, 1.00),\n",
       "  (163, 1.00),\n",
       "  (176, 1.00),\n",
       "  (186, 1.00),\n",
       "  (195, 1.00),\n",
       "  (218, 1.00),\n",
       "  (231, 1.00),\n",
       "  (247, 1.00),\n",
       "  (260, 1.00),\n",
       "  (274, 1.00),\n",
       "  (281, 1.00),\n",
       "  (290, 1.00),\n",
       "  (306, 1.00),\n",
       "  (307, 1.00),\n",
       "  (314, 1.00),\n",
       "  (318, 1.00),\n",
       "  (334, 1.00),\n",
       "  (376, 1.00),\n",
       "  (392, 1.00),\n",
       "  (429, 1.00),\n",
       "  (474, 1.00),\n",
       "  (483, 1.00),\n",
       "  (488, 1.00),\n",
       "  (492, 1.00),\n",
       "  (498, 1.00),\n",
       "  (507, 1.00),\n",
       "  (516, 1.00),\n",
       "  (528, 1.00),\n",
       "  (530, 1.00),\n",
       "  (533, 1.00),\n",
       "  (562, 1.00),\n",
       "  (566, 1.00),\n",
       "  (602, 1.00),\n",
       "  (625, 1.00),\n",
       "  (637, 1.00),\n",
       "  (661, 1.00),\n",
       "  (684, 1.00),\n",
       "  (694, 1.00),\n",
       "  (716, 1.00),\n",
       "  (725, 1.00),\n",
       "  (734, 1.00),\n",
       "  (787, 1.00),\n",
       "  (816, 1.00),\n",
       "  (822, 1.00),\n",
       "  (824, 1.00),\n",
       "  (837, 1.00),\n",
       "  (873, 1.00),\n",
       "  (923, 1.00),\n",
       "  (934, 1.00),\n",
       "  (944, 1.00),\n",
       "  (992, 1.00),\n",
       "  (997, 1.00),\n",
       "  (40, 0.90),\n",
       "  (62, 0.90),\n",
       "  (105, 0.90),\n",
       "  (164, 0.90),\n",
       "  (301, 0.90),\n",
       "  (347, 0.90),\n",
       "  (369, 0.90),\n",
       "  (397, 0.90),\n",
       "  (425, 0.90),\n",
       "  (444, 0.90),\n",
       "  (753, 0.90),\n",
       "  (819, 0.90),\n",
       "  (868, 0.90),\n",
       "  (889, 0.90),\n",
       "  (982, 0.90),\n",
       "  (47, 0.80),\n",
       "  (72, 0.80),\n",
       "  (86, 0.80),\n",
       "  (97, 0.80),\n",
       "  (118, 0.80),\n",
       "  (254, 0.80),\n",
       "  (275, 0.80),\n",
       "  (304, 0.80),\n",
       "  (331, 0.80),\n",
       "  (463, 0.80),\n",
       "  (509, 0.80),\n",
       "  (532, 0.80),\n",
       "  (576, 0.80),\n",
       "  (586, 0.80),\n",
       "  (606, 0.80),\n",
       "  (638, 0.80),\n",
       "  (703, 0.80),\n",
       "  (732, 0.80),\n",
       "  (772, 0.80),\n",
       "  (786, 0.80),\n",
       "  (803, 0.80),\n",
       "  (829, 0.80),\n",
       "  (878, 0.80),\n",
       "  (899, 0.80),\n",
       "  (905, 0.80),\n",
       "  (915, 0.80),\n",
       "  (984, 0.80),\n",
       "  (8, 0.70),\n",
       "  (15, 0.70),\n",
       "  (38, 0.70),\n",
       "  (42, 0.70),\n",
       "  (109, 0.70),\n",
       "  (116, 0.70),\n",
       "  (144, 0.70),\n",
       "  (155, 0.70),\n",
       "  (189, 0.70),\n",
       "  (235, 0.70),\n",
       "  (313, 0.70),\n",
       "  (341, 0.70),\n",
       "  (353, 0.70),\n",
       "  (355, 0.70),\n",
       "  (387, 0.70),\n",
       "  (438, 0.70),\n",
       "  (476, 0.70),\n",
       "  (497, 0.70),\n",
       "  (508, 0.70),\n",
       "  (517, 0.70),\n",
       "  (526, 0.70),\n",
       "  (547, 0.70),\n",
       "  (552, 0.70),\n",
       "  (564, 0.70),\n",
       "  (570, 0.70),\n",
       "  (579, 0.70),\n",
       "  (620, 0.70),\n",
       "  (629, 0.70),\n",
       "  (727, 0.70),\n",
       "  (741, 0.70),\n",
       "  (752, 0.70),\n",
       "  (778, 0.70),\n",
       "  (788, 0.70),\n",
       "  (814, 0.70),\n",
       "  (925, 0.70),\n",
       "  (17, 0.60),\n",
       "  (19, 0.60),\n",
       "  (87, 0.60),\n",
       "  (289, 0.60),\n",
       "  (291, 0.60),\n",
       "  (294, 0.60),\n",
       "  (327, 0.60),\n",
       "  (375, 0.60),\n",
       "  (398, 0.60),\n",
       "  (409, 0.60),\n",
       "  (433, 0.60),\n",
       "  (445, 0.60),\n",
       "  (472, 0.60),\n",
       "  (482, 0.60),\n",
       "  (535, 0.60),\n",
       "  (544, 0.60),\n",
       "  (565, 0.60),\n",
       "  (671, 0.60),\n",
       "  (679, 0.60),\n",
       "  (696, 0.60),\n",
       "  (701, 0.60),\n",
       "  (751, 0.60),\n",
       "  (760, 0.60),\n",
       "  (796, 0.60),\n",
       "  (797, 0.60),\n",
       "  (820, 0.60),\n",
       "  (867, 0.60),\n",
       "  (892, 0.60),\n",
       "  (902, 0.60),\n",
       "  (920, 0.60),\n",
       "  (998, 0.60),\n",
       "  (0, 0.50),\n",
       "  (45, 0.50),\n",
       "  (50, 0.50),\n",
       "  (52, 0.50),\n",
       "  (107, 0.50),\n",
       "  (149, 0.50),\n",
       "  (159, 0.50),\n",
       "  (336, 0.50),\n",
       "  (342, 0.50),\n",
       "  (348, 0.50),\n",
       "  (391, 0.50),\n",
       "  (495, 0.50),\n",
       "  (515, 0.50),\n",
       "  (523, 0.50),\n",
       "  (527, 0.50),\n",
       "  (539, 0.50),\n",
       "  (555, 0.50),\n",
       "  (605, 0.50),\n",
       "  (607, 0.50),\n",
       "  (609, 0.50),\n",
       "  (626, 0.50),\n",
       "  (654, 0.50),\n",
       "  (655, 0.50),\n",
       "  (664, 0.50),\n",
       "  (674, 0.50),\n",
       "  (705, 0.50),\n",
       "  (719, 0.50),\n",
       "  (745, 0.50),\n",
       "  (754, 0.50),\n",
       "  (759, 0.50),\n",
       "  (768, 0.50),\n",
       "  (823, 0.50),\n",
       "  (853, 0.50),\n",
       "  (900, 0.50),\n",
       "  (917, 0.50),\n",
       "  (985, 0.50),\n",
       "  (9, 0.40),\n",
       "  (23, 0.40),\n",
       "  (24, 0.40),\n",
       "  (28, 0.40),\n",
       "  (63, 0.40),\n",
       "  (77, 0.40),\n",
       "  (126, 0.40),\n",
       "  (134, 0.40),\n",
       "  (140, 0.40),\n",
       "  (168, 0.40),\n",
       "  (192, 0.40),\n",
       "  (197, 0.40),\n",
       "  (205, 0.40),\n",
       "  (219, 0.40),\n",
       "  (224, 0.40),\n",
       "  (236, 0.40),\n",
       "  (249, 0.40),\n",
       "  (305, 0.40),\n",
       "  (319, 0.40),\n",
       "  (321, 0.40),\n",
       "  (332, 0.40),\n",
       "  (363, 0.40),\n",
       "  (381, 0.40),\n",
       "  (383, 0.40),\n",
       "  (388, 0.40),\n",
       "  (389, 0.40),\n",
       "  (396, 0.40),\n",
       "  (473, 0.40),\n",
       "  (481, 0.40),\n",
       "  (491, 0.40),\n",
       "  (522, 0.40),\n",
       "  (546, 0.40),\n",
       "  (574, 0.40),\n",
       "  (584, 0.40),\n",
       "  (672, 0.40),\n",
       "  (692, 0.40),\n",
       "  (697, 0.40),\n",
       "  (712, 0.40),\n",
       "  (802, 0.40),\n",
       "  (843, 0.40),\n",
       "  (854, 0.40),\n",
       "  (870, 0.40),\n",
       "  (880, 0.40),\n",
       "  (882, 0.40),\n",
       "  (890, 0.40),\n",
       "  (918, 0.40),\n",
       "  (938, 0.40),\n",
       "  (991, 0.40),\n",
       "  (41, 0.30),\n",
       "  (65, 0.30),\n",
       "  (71, 0.30),\n",
       "  (74, 0.30),\n",
       "  (113, 0.30),\n",
       "  (183, 0.30),\n",
       "  (191, 0.30),\n",
       "  (196, 0.30),\n",
       "  (202, 0.30),\n",
       "  (228, 0.30),\n",
       "  (232, 0.30),\n",
       "  (253, 0.30),\n",
       "  (303, 0.30),\n",
       "  (320, 0.30),\n",
       "  (337, 0.30),\n",
       "  (350, 0.30),\n",
       "  (358, 0.30),\n",
       "  (364, 0.30),\n",
       "  (399, 0.30),\n",
       "  (452, 0.30),\n",
       "  (454, 0.30),\n",
       "  (477, 0.30),\n",
       "  (480, 0.30),\n",
       "  (512, 0.30),\n",
       "  (537, 0.30),\n",
       "  (550, 0.30),\n",
       "  (554, 0.30),\n",
       "  (560, 0.30),\n",
       "  (593, 0.30),\n",
       "  (640, 0.30),\n",
       "  (644, 0.30),\n",
       "  (683, 0.30),\n",
       "  (707, 0.30),\n",
       "  (720, 0.30),\n",
       "  (729, 0.30),\n",
       "  (748, 0.30),\n",
       "  (757, 0.30),\n",
       "  (758, 0.30),\n",
       "  (777, 0.30),\n",
       "  (811, 0.30),\n",
       "  (831, 0.30),\n",
       "  (840, 0.30),\n",
       "  (846, 0.30),\n",
       "  (875, 0.30),\n",
       "  (883, 0.30),\n",
       "  (932, 0.30),\n",
       "  (939, 0.30),\n",
       "  (951, 0.30),\n",
       "  (957, 0.30),\n",
       "  (968, 0.30),\n",
       "  (995, 0.30),\n",
       "  (58, 0.20),\n",
       "  (82, 0.20),\n",
       "  (93, 0.20),\n",
       "  (98, 0.20),\n",
       "  (99, 0.20),\n",
       "  (100, 0.20),\n",
       "  (117, 0.20),\n",
       "  (122, 0.20),\n",
       "  (131, 0.20),\n",
       "  (138, 0.20),\n",
       "  (153, 0.20),\n",
       "  (161, 0.20),\n",
       "  (178, 0.20),\n",
       "  (188, 0.20),\n",
       "  (198, 0.20),\n",
       "  (206, 0.20),\n",
       "  (238, 0.20),\n",
       "  (283, 0.20),\n",
       "  (284, 0.20),\n",
       "  (317, 0.20),\n",
       "  (323, 0.20),\n",
       "  (326, 0.20),\n",
       "  (340, 0.20),\n",
       "  (344, 0.20),\n",
       "  (379, 0.20),\n",
       "  (395, 0.20),\n",
       "  (420, 0.20),\n",
       "  (432, 0.20),\n",
       "  (435, 0.20),\n",
       "  (436, 0.20),\n",
       "  (455, 0.20),\n",
       "  (484, 0.20),\n",
       "  (485, 0.20),\n",
       "  (487, 0.20),\n",
       "  (502, 0.20),\n",
       "  (505, 0.20),\n",
       "  (514, 0.20),\n",
       "  (534, 0.20),\n",
       "  (557, 0.20),\n",
       "  (585, 0.20),\n",
       "  (595, 0.20),\n",
       "  (618, 0.20),\n",
       "  (635, 0.20),\n",
       "  (643, 0.20),\n",
       "  (681, 0.20),\n",
       "  (700, 0.20),\n",
       "  (717, 0.20),\n",
       "  (723, 0.20),\n",
       "  (728, 0.20),\n",
       "  (736, 0.20),\n",
       "  (747, 0.20),\n",
       "  (785, 0.20),\n",
       "  (800, 0.20),\n",
       "  (808, 0.20),\n",
       "  (809, 0.20),\n",
       "  (818, 0.20),\n",
       "  (821, 0.20),\n",
       "  (825, 0.20),\n",
       "  (832, 0.20),\n",
       "  (844, 0.20),\n",
       "  (852, 0.20),\n",
       "  (876, 0.20),\n",
       "  (881, 0.20),\n",
       "  (926, 0.20),\n",
       "  (962, 0.20),\n",
       "  (966, 0.20),\n",
       "  (996, 0.20),\n",
       "  (11, 0.10),\n",
       "  (18, 0.10),\n",
       "  (21, 0.10),\n",
       "  (22, 0.10),\n",
       "  (26, 0.10),\n",
       "  (66, 0.10),\n",
       "  (70, 0.10),\n",
       "  (76, 0.10),\n",
       "  (79, 0.10),\n",
       "  (95, 0.10),\n",
       "  (111, 0.10),\n",
       "  (114, 0.10),\n",
       "  (121, 0.10),\n",
       "  (125, 0.10),\n",
       "  (129, 0.10),\n",
       "  (132, 0.10),\n",
       "  (139, 0.10),\n",
       "  (141, 0.10),\n",
       "  (142, 0.10),\n",
       "  (146, 0.10),\n",
       "  (158, 0.10),\n",
       "  (173, 0.10),\n",
       "  (179, 0.10),\n",
       "  (193, 0.10),\n",
       "  (214, 0.10),\n",
       "  (222, 0.10),\n",
       "  (229, 0.10),\n",
       "  (237, 0.10),\n",
       "  (252, 0.10),\n",
       "  (256, 0.10),\n",
       "  (268, 0.10),\n",
       "  (273, 0.10),\n",
       "  (276, 0.10),\n",
       "  (278, 0.10),\n",
       "  (282, 0.10),\n",
       "  (295, 0.10),\n",
       "  (298, 0.10),\n",
       "  (308, 0.10),\n",
       "  (309, 0.10),\n",
       "  (311, 0.10),\n",
       "  (315, 0.10),\n",
       "  (330, 0.10),\n",
       "  (343, 0.10),\n",
       "  (346, 0.10),\n",
       "  (351, 0.10),\n",
       "  (352, 0.10),\n",
       "  (356, 0.10),\n",
       "  (361, 0.10),\n",
       "  (365, 0.10),\n",
       "  (366, 0.10),\n",
       "  (377, 0.10),\n",
       "  (413, 0.10),\n",
       "  (423, 0.10),\n",
       "  (427, 0.10),\n",
       "  (428, 0.10),\n",
       "  (439, 0.10),\n",
       "  (442, 0.10),\n",
       "  (447, 0.10),\n",
       "  (448, 0.10),\n",
       "  (450, 0.10),\n",
       "  (451, 0.10),\n",
       "  (459, 0.10),\n",
       "  (475, 0.10),\n",
       "  (486, 0.10),\n",
       "  (493, 0.10),\n",
       "  (504, 0.10),\n",
       "  (521, 0.10),\n",
       "  (540, 0.10),\n",
       "  (551, 0.10),\n",
       "  (563, 0.10),\n",
       "  (569, 0.10),\n",
       "  (577, 0.10),\n",
       "  (603, 0.10),\n",
       "  (611, 0.10),\n",
       "  (613, 0.10),\n",
       "  (615, 0.10),\n",
       "  (616, 0.10),\n",
       "  (636, 0.10),\n",
       "  (639, 0.10),\n",
       "  (650, 0.10),\n",
       "  (665, 0.10),\n",
       "  (668, 0.10),\n",
       "  (673, 0.10),\n",
       "  (730, 0.10),\n",
       "  (735, 0.10),\n",
       "  (755, 0.10),\n",
       "  (756, 0.10),\n",
       "  (761, 0.10),\n",
       "  (763, 0.10),\n",
       "  (764, 0.10),\n",
       "  (765, 0.10),\n",
       "  (775, 0.10),\n",
       "  (792, 0.10),\n",
       "  (804, 0.10),\n",
       "  (813, 0.10),\n",
       "  (830, 0.10),\n",
       "  (833, 0.10),\n",
       "  (834, 0.10),\n",
       "  (836, 0.10),\n",
       "  (839, 0.10),\n",
       "  (842, 0.10),\n",
       "  (855, 0.10),\n",
       "  (856, 0.10),\n",
       "  (863, 0.10),\n",
       "  (866, 0.10),\n",
       "  (884, 0.10),\n",
       "  (885, 0.10),\n",
       "  (901, 0.10),\n",
       "  (927, 0.10),\n",
       "  (946, 0.10),\n",
       "  (950, 0.10),\n",
       "  (952, 0.10),\n",
       "  (954, 0.10),\n",
       "  (978, 0.10),\n",
       "  (983, 0.10),\n",
       "  (988, 0.10),\n",
       "  (999, 0.10),\n",
       "  (2, 0.00),\n",
       "  (3, 0.00),\n",
       "  (4, 0.00),\n",
       "  (5, 0.00),\n",
       "  (6, 0.00),\n",
       "  (10, 0.00),\n",
       "  (12, 0.00),\n",
       "  (13, 0.00),\n",
       "  (14, 0.00),\n",
       "  (16, 0.00),\n",
       "  (20, 0.00),\n",
       "  (27, 0.00),\n",
       "  (29, 0.00),\n",
       "  (30, 0.00),\n",
       "  (32, 0.00),\n",
       "  (34, 0.00),\n",
       "  (35, 0.00),\n",
       "  (36, 0.00),\n",
       "  (43, 0.00),\n",
       "  (44, 0.00),\n",
       "  (49, 0.00),\n",
       "  (51, 0.00),\n",
       "  (53, 0.00),\n",
       "  (54, 0.00),\n",
       "  (59, 0.00),\n",
       "  (64, 0.00),\n",
       "  (69, 0.00),\n",
       "  (73, 0.00),\n",
       "  (78, 0.00),\n",
       "  (80, 0.00),\n",
       "  (81, 0.00),\n",
       "  (85, 0.00),\n",
       "  (89, 0.00),\n",
       "  (101, 0.00),\n",
       "  (103, 0.00),\n",
       "  (104, 0.00),\n",
       "  (106, 0.00),\n",
       "  (110, 0.00),\n",
       "  (112, 0.00),\n",
       "  (119, 0.00),\n",
       "  (127, 0.00),\n",
       "  (130, 0.00),\n",
       "  (133, 0.00),\n",
       "  (135, 0.00),\n",
       "  (136, 0.00),\n",
       "  (137, 0.00),\n",
       "  (143, 0.00),\n",
       "  (145, 0.00),\n",
       "  (147, 0.00),\n",
       "  (148, 0.00),\n",
       "  (150, 0.00),\n",
       "  (152, 0.00),\n",
       "  (154, 0.00),\n",
       "  (156, 0.00),\n",
       "  (157, 0.00),\n",
       "  (160, 0.00),\n",
       "  (162, 0.00),\n",
       "  (165, 0.00),\n",
       "  (166, 0.00),\n",
       "  (167, 0.00),\n",
       "  (169, 0.00),\n",
       "  (170, 0.00),\n",
       "  (172, 0.00),\n",
       "  (174, 0.00),\n",
       "  (175, 0.00),\n",
       "  (177, 0.00),\n",
       "  (180, 0.00),\n",
       "  (181, 0.00),\n",
       "  (182, 0.00),\n",
       "  (184, 0.00),\n",
       "  (185, 0.00),\n",
       "  (187, 0.00),\n",
       "  (190, 0.00),\n",
       "  (194, 0.00),\n",
       "  (199, 0.00),\n",
       "  (200, 0.00),\n",
       "  (201, 0.00),\n",
       "  (203, 0.00),\n",
       "  (204, 0.00),\n",
       "  (207, 0.00),\n",
       "  (208, 0.00),\n",
       "  (209, 0.00),\n",
       "  (210, 0.00),\n",
       "  (211, 0.00),\n",
       "  (212, 0.00),\n",
       "  (213, 0.00),\n",
       "  (215, 0.00),\n",
       "  (216, 0.00),\n",
       "  (217, 0.00),\n",
       "  (220, 0.00),\n",
       "  (221, 0.00),\n",
       "  (223, 0.00),\n",
       "  (225, 0.00),\n",
       "  (226, 0.00),\n",
       "  (227, 0.00),\n",
       "  (233, 0.00),\n",
       "  (234, 0.00),\n",
       "  (239, 0.00),\n",
       "  (240, 0.00),\n",
       "  (241, 0.00),\n",
       "  (243, 0.00),\n",
       "  (244, 0.00),\n",
       "  (245, 0.00),\n",
       "  (246, 0.00),\n",
       "  (248, 0.00),\n",
       "  (250, 0.00),\n",
       "  (251, 0.00),\n",
       "  (255, 0.00),\n",
       "  (257, 0.00),\n",
       "  (258, 0.00),\n",
       "  (259, 0.00),\n",
       "  (261, 0.00),\n",
       "  (262, 0.00),\n",
       "  (263, 0.00),\n",
       "  (264, 0.00),\n",
       "  (265, 0.00),\n",
       "  (266, 0.00),\n",
       "  (267, 0.00),\n",
       "  (269, 0.00),\n",
       "  (270, 0.00),\n",
       "  (271, 0.00),\n",
       "  (272, 0.00),\n",
       "  (277, 0.00),\n",
       "  (279, 0.00),\n",
       "  (280, 0.00),\n",
       "  (285, 0.00),\n",
       "  (286, 0.00),\n",
       "  (287, 0.00),\n",
       "  (288, 0.00),\n",
       "  (296, 0.00),\n",
       "  (297, 0.00),\n",
       "  (299, 0.00),\n",
       "  (302, 0.00),\n",
       "  (312, 0.00),\n",
       "  (322, 0.00),\n",
       "  (324, 0.00),\n",
       "  (325, 0.00),\n",
       "  (328, 0.00),\n",
       "  (329, 0.00),\n",
       "  (333, 0.00),\n",
       "  (335, 0.00),\n",
       "  (338, 0.00),\n",
       "  (339, 0.00),\n",
       "  (345, 0.00),\n",
       "  (349, 0.00),\n",
       "  (354, 0.00),\n",
       "  (357, 0.00),\n",
       "  (359, 0.00),\n",
       "  (362, 0.00),\n",
       "  (367, 0.00),\n",
       "  (368, 0.00),\n",
       "  (370, 0.00),\n",
       "  (371, 0.00),\n",
       "  (372, 0.00),\n",
       "  (373, 0.00),\n",
       "  (374, 0.00),\n",
       "  (378, 0.00),\n",
       "  (380, 0.00),\n",
       "  (382, 0.00),\n",
       "  (384, 0.00),\n",
       "  (385, 0.00),\n",
       "  (386, 0.00),\n",
       "  (390, 0.00),\n",
       "  (394, 0.00),\n",
       "  (400, 0.00),\n",
       "  (402, 0.00),\n",
       "  (403, 0.00),\n",
       "  (404, 0.00),\n",
       "  (405, 0.00),\n",
       "  (415, 0.00),\n",
       "  (416, 0.00),\n",
       "  (418, 0.00),\n",
       "  (421, 0.00),\n",
       "  (422, 0.00),\n",
       "  (426, 0.00),\n",
       "  (430, 0.00),\n",
       "  (434, 0.00),\n",
       "  (437, 0.00),\n",
       "  (446, 0.00),\n",
       "  (449, 0.00),\n",
       "  (456, 0.00),\n",
       "  (458, 0.00),\n",
       "  (460, 0.00),\n",
       "  (461, 0.00),\n",
       "  (462, 0.00),\n",
       "  (465, 0.00),\n",
       "  (466, 0.00),\n",
       "  (467, 0.00),\n",
       "  (469, 0.00),\n",
       "  (470, 0.00),\n",
       "  (471, 0.00),\n",
       "  (478, 0.00),\n",
       "  (479, 0.00),\n",
       "  (494, 0.00),\n",
       "  (499, 0.00),\n",
       "  (500, 0.00),\n",
       "  (501, 0.00),\n",
       "  (503, 0.00),\n",
       "  (510, 0.00),\n",
       "  (511, 0.00),\n",
       "  (513, 0.00),\n",
       "  (519, 0.00),\n",
       "  (524, 0.00),\n",
       "  (525, 0.00),\n",
       "  (529, 0.00),\n",
       "  (531, 0.00),\n",
       "  (536, 0.00),\n",
       "  (541, 0.00),\n",
       "  (542, 0.00),\n",
       "  (543, 0.00),\n",
       "  (548, 0.00),\n",
       "  (553, 0.00),\n",
       "  (558, 0.00),\n",
       "  (559, 0.00),\n",
       "  (561, 0.00),\n",
       "  (567, 0.00),\n",
       "  (568, 0.00),\n",
       "  (571, 0.00),\n",
       "  (573, 0.00),\n",
       "  (578, 0.00),\n",
       "  (583, 0.00),\n",
       "  (587, 0.00),\n",
       "  (589, 0.00),\n",
       "  (590, 0.00),\n",
       "  (592, 0.00),\n",
       "  (594, 0.00),\n",
       "  (596, 0.00),\n",
       "  (597, 0.00),\n",
       "  (598, 0.00),\n",
       "  (600, 0.00),\n",
       "  (601, 0.00),\n",
       "  (608, 0.00),\n",
       "  (610, 0.00),\n",
       "  (617, 0.00),\n",
       "  (622, 0.00),\n",
       "  (623, 0.00),\n",
       "  (624, 0.00),\n",
       "  (627, 0.00),\n",
       "  (628, 0.00),\n",
       "  (630, 0.00),\n",
       "  (631, 0.00),\n",
       "  (634, 0.00),\n",
       "  (642, 0.00),\n",
       "  (647, 0.00),\n",
       "  (648, 0.00),\n",
       "  (649, 0.00),\n",
       "  (652, 0.00),\n",
       "  (653, 0.00),\n",
       "  (657, 0.00),\n",
       "  (658, 0.00),\n",
       "  (659, 0.00),\n",
       "  (660, 0.00),\n",
       "  (662, 0.00),\n",
       "  (663, 0.00),\n",
       "  (666, 0.00),\n",
       "  (667, 0.00),\n",
       "  (670, 0.00),\n",
       "  (675, 0.00),\n",
       "  (676, 0.00),\n",
       "  (677, 0.00),\n",
       "  (678, 0.00),\n",
       "  (682, 0.00),\n",
       "  (685, 0.00),\n",
       "  (686, 0.00),\n",
       "  (687, 0.00),\n",
       "  (688, 0.00),\n",
       "  (689, 0.00),\n",
       "  (690, 0.00),\n",
       "  (693, 0.00),\n",
       "  (695, 0.00),\n",
       "  (699, 0.00),\n",
       "  (702, 0.00),\n",
       "  (704, 0.00),\n",
       "  (708, 0.00),\n",
       "  (710, 0.00),\n",
       "  (713, 0.00),\n",
       "  (714, 0.00),\n",
       "  (715, 0.00),\n",
       "  (718, 0.00),\n",
       "  (724, 0.00),\n",
       "  (726, 0.00),\n",
       "  (731, 0.00),\n",
       "  (733, 0.00),\n",
       "  (737, 0.00),\n",
       "  (739, 0.00),\n",
       "  (740, 0.00),\n",
       "  (742, 0.00),\n",
       "  (744, 0.00),\n",
       "  (749, 0.00),\n",
       "  (766, 0.00),\n",
       "  (767, 0.00),\n",
       "  (769, 0.00),\n",
       "  (771, 0.00),\n",
       "  (773, 0.00),\n",
       "  (774, 0.00),\n",
       "  (776, 0.00),\n",
       "  (780, 0.00),\n",
       "  (782, 0.00),\n",
       "  (784, 0.00),\n",
       "  (789, 0.00),\n",
       "  (793, 0.00),\n",
       "  (795, 0.00),\n",
       "  (798, 0.00),\n",
       "  (799, 0.00),\n",
       "  (807, 0.00),\n",
       "  (810, 0.00),\n",
       "  (812, 0.00),\n",
       "  (827, 0.00),\n",
       "  (835, 0.00),\n",
       "  (838, 0.00),\n",
       "  (841, 0.00),\n",
       "  (845, 0.00),\n",
       "  (848, 0.00),\n",
       "  (849, 0.00),\n",
       "  (851, 0.00),\n",
       "  (859, 0.00),\n",
       "  (860, 0.00),\n",
       "  (861, 0.00),\n",
       "  (862, 0.00),\n",
       "  (869, 0.00),\n",
       "  (874, 0.00),\n",
       "  (877, 0.00),\n",
       "  (886, 0.00),\n",
       "  (887, 0.00),\n",
       "  (888, 0.00),\n",
       "  (891, 0.00),\n",
       "  (894, 0.00),\n",
       "  (895, 0.00),\n",
       "  (903, 0.00),\n",
       "  (908, 0.00),\n",
       "  (909, 0.00),\n",
       "  (910, 0.00),\n",
       "  (911, 0.00),\n",
       "  (912, 0.00),\n",
       "  (913, 0.00),\n",
       "  (914, 0.00),\n",
       "  (916, 0.00),\n",
       "  (919, 0.00),\n",
       "  (921, 0.00),\n",
       "  (922, 0.00),\n",
       "  (924, 0.00),\n",
       "  (928, 0.00),\n",
       "  (929, 0.00),\n",
       "  (930, 0.00),\n",
       "  (931, 0.00),\n",
       "  (933, 0.00),\n",
       "  (935, 0.00),\n",
       "  (936, 0.00),\n",
       "  (940, 0.00),\n",
       "  (941, 0.00),\n",
       "  (942, 0.00),\n",
       "  (943, 0.00),\n",
       "  (945, 0.00),\n",
       "  (947, 0.00),\n",
       "  (948, 0.00),\n",
       "  (949, 0.00),\n",
       "  (956, 0.00),\n",
       "  (958, 0.00),\n",
       "  (959, 0.00),\n",
       "  (960, 0.00),\n",
       "  (961, 0.00),\n",
       "  (964, 0.00),\n",
       "  (965, 0.00),\n",
       "  (967, 0.00),\n",
       "  (969, 0.00),\n",
       "  (970, 0.00),\n",
       "  (972, 0.00),\n",
       "  (974, 0.00),\n",
       "  (975, 0.00),\n",
       "  (976, 0.00),\n",
       "  (977, 0.00),\n",
       "  (979, 0.00),\n",
       "  (980, 0.00),\n",
       "  (986, 0.00),\n",
       "  (989, 0.00),\n",
       "  (990, 0.00),\n",
       "  (993, 0.00),\n",
       "  (994, 0.00)])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#on validation\n",
    "%precision 2\n",
    "# n, hist = targeted_diversity(learn, 150, 95)\n",
    "# n, hist\n",
    "n, hist = diversity(learn, 10, 95)\n",
    "n, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f59cf2afe48>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_hist = sorted(hist, key=lambda x: x[0], reverse = False)\n",
    "values = [elem[1] for elem in sorted_hist]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.6468)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at batch_no 0\n",
      "at batch_no 100\n",
      "at batch_no 200\n",
      "at batch_no 300\n",
      "at batch_no 400\n",
      "at batch_no 500\n",
      "at batch_no 600\n",
      "at batch_no 700\n",
      "at batch_no 800\n",
      "at batch_no 900\n",
      "at batch_no 1000\n",
      "at batch_no 1100\n",
      "at batch_no 1200\n",
      "at batch_no 1300\n",
      "at batch_no 1400\n",
      "at batch_no 1500\n",
      "at batch_no 1600\n",
      "at batch_no 1700\n",
      "at batch_no 1800\n",
      "at batch_no 1900\n",
      "at batch_no 2000\n",
      "at batch_no 2100\n",
      "at batch_no 2200\n",
      "at batch_no 2300\n",
      "at batch_no 2400\n",
      "at batch_no 2500\n",
      "at batch_no 2600\n",
      "at batch_no 2700\n",
      "at batch_no 2800\n",
      "at batch_no 2900\n",
      "at batch_no 3000\n",
      "at batch_no 3100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(885,\n",
       " [(815, 234.00),\n",
       "  (652, 177.00),\n",
       "  (646, 163.00),\n",
       "  (580, 160.00),\n",
       "  (611, 156.00),\n",
       "  (489, 145.00),\n",
       "  (591, 144.00),\n",
       "  (621, 141.00),\n",
       "  (737, 139.00),\n",
       "  (904, 130.00),\n",
       "  (94, 129.00),\n",
       "  (868, 127.00),\n",
       "  (582, 125.00),\n",
       "  (497, 123.00),\n",
       "  (893, 120.00),\n",
       "  (794, 118.00),\n",
       "  (116, 115.00),\n",
       "  (955, 115.00),\n",
       "  (979, 114.00),\n",
       "  (679, 112.00),\n",
       "  (721, 109.00),\n",
       "  (39, 108.00),\n",
       "  (565, 108.00),\n",
       "  (741, 106.00),\n",
       "  (491, 105.00),\n",
       "  (562, 103.00),\n",
       "  (839, 102.00),\n",
       "  (109, 101.00),\n",
       "  (162, 101.00),\n",
       "  (549, 99.00),\n",
       "  (46, 97.00),\n",
       "  (48, 96.00),\n",
       "  (84, 95.00),\n",
       "  (750, 95.00),\n",
       "  (82, 94.00),\n",
       "  (973, 94.00),\n",
       "  (151, 93.00),\n",
       "  (492, 93.00),\n",
       "  (695, 93.00),\n",
       "  (199, 91.00),\n",
       "  (843, 89.00),\n",
       "  (51, 88.00),\n",
       "  (971, 88.00),\n",
       "  (640, 87.00),\n",
       "  (424, 86.00),\n",
       "  (669, 86.00),\n",
       "  (692, 86.00),\n",
       "  (879, 86.00),\n",
       "  (281, 85.00),\n",
       "  (47, 84.00),\n",
       "  (783, 84.00),\n",
       "  (203, 83.00),\n",
       "  (310, 83.00),\n",
       "  (382, 83.00),\n",
       "  (411, 83.00),\n",
       "  (866, 83.00),\n",
       "  (743, 82.00),\n",
       "  (364, 81.00),\n",
       "  (577, 81.00),\n",
       "  (197, 80.00),\n",
       "  (318, 80.00),\n",
       "  (319, 80.00),\n",
       "  (406, 80.00),\n",
       "  (725, 80.00),\n",
       "  (828, 80.00),\n",
       "  (180, 79.00),\n",
       "  (189, 79.00),\n",
       "  (208, 79.00),\n",
       "  (298, 79.00),\n",
       "  (703, 79.00),\n",
       "  (754, 79.00),\n",
       "  (905, 79.00),\n",
       "  (956, 79.00),\n",
       "  (847, 78.00),\n",
       "  (76, 77.00),\n",
       "  (182, 77.00),\n",
       "  (342, 77.00),\n",
       "  (455, 77.00),\n",
       "  (572, 77.00),\n",
       "  (711, 77.00),\n",
       "  (762, 77.00),\n",
       "  (896, 77.00),\n",
       "  (963, 77.00),\n",
       "  (217, 76.00),\n",
       "  (440, 76.00),\n",
       "  (824, 76.00),\n",
       "  (830, 76.00),\n",
       "  (55, 75.00),\n",
       "  (219, 75.00),\n",
       "  (270, 75.00),\n",
       "  (700, 75.00),\n",
       "  (730, 75.00),\n",
       "  (791, 75.00),\n",
       "  (128, 74.00),\n",
       "  (849, 74.00),\n",
       "  (938, 74.00),\n",
       "  (982, 74.00),\n",
       "  (237, 73.00),\n",
       "  (343, 73.00),\n",
       "  (363, 73.00),\n",
       "  (454, 73.00),\n",
       "  (570, 73.00),\n",
       "  (645, 73.00),\n",
       "  (735, 73.00),\n",
       "  (778, 73.00),\n",
       "  (825, 73.00),\n",
       "  (222, 72.00),\n",
       "  (304, 72.00),\n",
       "  (436, 72.00),\n",
       "  (483, 72.00),\n",
       "  (800, 72.00),\n",
       "  (826, 72.00),\n",
       "  (61, 71.00),\n",
       "  (74, 71.00),\n",
       "  (471, 71.00),\n",
       "  (472, 71.00),\n",
       "  (805, 71.00),\n",
       "  (806, 71.00),\n",
       "  (916, 71.00),\n",
       "  (30, 70.00),\n",
       "  (496, 70.00),\n",
       "  (716, 70.00),\n",
       "  (23, 69.00),\n",
       "  (341, 69.00),\n",
       "  (425, 69.00),\n",
       "  (775, 69.00),\n",
       "  (808, 69.00),\n",
       "  (878, 69.00),\n",
       "  (556, 68.00),\n",
       "  (620, 68.00),\n",
       "  (845, 68.00),\n",
       "  (184, 67.00),\n",
       "  (192, 67.00),\n",
       "  (195, 67.00),\n",
       "  (300, 67.00),\n",
       "  (361, 67.00),\n",
       "  (671, 67.00),\n",
       "  (887, 67.00),\n",
       "  (912, 67.00),\n",
       "  (37, 66.00),\n",
       "  (178, 66.00),\n",
       "  (313, 66.00),\n",
       "  (458, 66.00),\n",
       "  (654, 66.00),\n",
       "  (772, 66.00),\n",
       "  (820, 66.00),\n",
       "  (863, 66.00),\n",
       "  (870, 66.00),\n",
       "  (77, 65.00),\n",
       "  (124, 65.00),\n",
       "  (423, 65.00),\n",
       "  (655, 65.00),\n",
       "  (949, 65.00),\n",
       "  (988, 65.00),\n",
       "  (6, 64.00),\n",
       "  (211, 64.00),\n",
       "  (506, 64.00),\n",
       "  (688, 64.00),\n",
       "  (926, 64.00),\n",
       "  (972, 64.00),\n",
       "  (234, 63.00),\n",
       "  (272, 63.00),\n",
       "  (293, 63.00),\n",
       "  (481, 63.00),\n",
       "  (595, 63.00),\n",
       "  (852, 63.00),\n",
       "  (871, 63.00),\n",
       "  (895, 63.00),\n",
       "  (953, 63.00),\n",
       "  (975, 63.00),\n",
       "  (992, 63.00),\n",
       "  (90, 62.00),\n",
       "  (463, 62.00),\n",
       "  (505, 62.00),\n",
       "  (561, 62.00),\n",
       "  (697, 62.00),\n",
       "  (809, 62.00),\n",
       "  (864, 62.00),\n",
       "  (944, 62.00),\n",
       "  (987, 62.00),\n",
       "  (97, 61.00),\n",
       "  (99, 61.00),\n",
       "  (118, 61.00),\n",
       "  (125, 61.00),\n",
       "  (135, 61.00),\n",
       "  (155, 61.00),\n",
       "  (238, 61.00),\n",
       "  (292, 61.00),\n",
       "  (331, 61.00),\n",
       "  (468, 61.00),\n",
       "  (474, 61.00),\n",
       "  (597, 61.00),\n",
       "  (788, 61.00),\n",
       "  (834, 61.00),\n",
       "  (913, 61.00),\n",
       "  (50, 60.00),\n",
       "  (311, 60.00),\n",
       "  (401, 60.00),\n",
       "  (404, 60.00),\n",
       "  (420, 60.00),\n",
       "  (457, 60.00),\n",
       "  (476, 60.00),\n",
       "  (515, 60.00),\n",
       "  (532, 60.00),\n",
       "  (586, 60.00),\n",
       "  (594, 60.00),\n",
       "  (635, 60.00),\n",
       "  (649, 60.00),\n",
       "  (781, 60.00),\n",
       "  (850, 60.00),\n",
       "  (880, 60.00),\n",
       "  (892, 60.00),\n",
       "  (937, 60.00),\n",
       "  (946, 60.00),\n",
       "  (33, 59.00),\n",
       "  (129, 59.00),\n",
       "  (263, 59.00),\n",
       "  (372, 59.00),\n",
       "  (519, 59.00),\n",
       "  (564, 59.00),\n",
       "  (607, 59.00),\n",
       "  (724, 59.00),\n",
       "  (766, 59.00),\n",
       "  (770, 59.00),\n",
       "  (875, 59.00),\n",
       "  (957, 59.00),\n",
       "  (85, 58.00),\n",
       "  (119, 58.00),\n",
       "  (161, 58.00),\n",
       "  (181, 58.00),\n",
       "  (249, 58.00),\n",
       "  (259, 58.00),\n",
       "  (280, 58.00),\n",
       "  (348, 58.00),\n",
       "  (383, 58.00),\n",
       "  (441, 58.00),\n",
       "  (522, 58.00),\n",
       "  (539, 58.00),\n",
       "  (552, 58.00),\n",
       "  (563, 58.00),\n",
       "  (601, 58.00),\n",
       "  (619, 58.00),\n",
       "  (696, 58.00),\n",
       "  (748, 58.00),\n",
       "  (816, 58.00),\n",
       "  (21, 57.00),\n",
       "  (69, 57.00),\n",
       "  (89, 57.00),\n",
       "  (113, 57.00),\n",
       "  (115, 57.00),\n",
       "  (218, 57.00),\n",
       "  (232, 57.00),\n",
       "  (250, 57.00),\n",
       "  (284, 57.00),\n",
       "  (316, 57.00),\n",
       "  (407, 57.00),\n",
       "  (428, 57.00),\n",
       "  (488, 57.00),\n",
       "  (581, 57.00),\n",
       "  (603, 57.00),\n",
       "  (614, 57.00),\n",
       "  (626, 57.00),\n",
       "  (698, 57.00),\n",
       "  (774, 57.00),\n",
       "  (777, 57.00),\n",
       "  (784, 57.00),\n",
       "  (790, 57.00),\n",
       "  (842, 57.00),\n",
       "  (962, 57.00),\n",
       "  (8, 56.00),\n",
       "  (31, 56.00),\n",
       "  (57, 56.00),\n",
       "  (60, 56.00),\n",
       "  (171, 56.00),\n",
       "  (225, 56.00),\n",
       "  (275, 56.00),\n",
       "  (317, 56.00),\n",
       "  (334, 56.00),\n",
       "  (391, 56.00),\n",
       "  (443, 56.00),\n",
       "  (490, 56.00),\n",
       "  (527, 56.00),\n",
       "  (569, 56.00),\n",
       "  (593, 56.00),\n",
       "  (609, 56.00),\n",
       "  (642, 56.00),\n",
       "  (792, 56.00),\n",
       "  (819, 56.00),\n",
       "  (857, 56.00),\n",
       "  (924, 56.00),\n",
       "  (952, 56.00),\n",
       "  (24, 55.00),\n",
       "  (25, 55.00),\n",
       "  (67, 55.00),\n",
       "  (229, 55.00),\n",
       "  (231, 55.00),\n",
       "  (283, 55.00),\n",
       "  (291, 55.00),\n",
       "  (308, 55.00),\n",
       "  (328, 55.00),\n",
       "  (386, 55.00),\n",
       "  (396, 55.00),\n",
       "  (410, 55.00),\n",
       "  (509, 55.00),\n",
       "  (512, 55.00),\n",
       "  (612, 55.00),\n",
       "  (661, 55.00),\n",
       "  (822, 55.00),\n",
       "  (858, 55.00),\n",
       "  (884, 55.00),\n",
       "  (950, 55.00),\n",
       "  (985, 55.00),\n",
       "  (986, 55.00),\n",
       "  (991, 55.00),\n",
       "  (88, 54.00),\n",
       "  (159, 54.00),\n",
       "  (170, 54.00),\n",
       "  (206, 54.00),\n",
       "  (228, 54.00),\n",
       "  (241, 54.00),\n",
       "  (269, 54.00),\n",
       "  (276, 54.00),\n",
       "  (285, 54.00),\n",
       "  (327, 54.00),\n",
       "  (487, 54.00),\n",
       "  (547, 54.00),\n",
       "  (657, 54.00),\n",
       "  (709, 54.00),\n",
       "  (768, 54.00),\n",
       "  (780, 54.00),\n",
       "  (801, 54.00),\n",
       "  (832, 54.00),\n",
       "  (855, 54.00),\n",
       "  (936, 54.00),\n",
       "  (990, 54.00),\n",
       "  (995, 54.00),\n",
       "  (3, 53.00),\n",
       "  (35, 53.00),\n",
       "  (58, 53.00),\n",
       "  (70, 53.00),\n",
       "  (104, 53.00),\n",
       "  (138, 53.00),\n",
       "  (177, 53.00),\n",
       "  (251, 53.00),\n",
       "  (254, 53.00),\n",
       "  (274, 53.00),\n",
       "  (307, 53.00),\n",
       "  (367, 53.00),\n",
       "  (444, 53.00),\n",
       "  (452, 53.00),\n",
       "  (477, 53.00),\n",
       "  (508, 53.00),\n",
       "  (524, 53.00),\n",
       "  (526, 53.00),\n",
       "  (528, 53.00),\n",
       "  (533, 53.00),\n",
       "  (641, 53.00),\n",
       "  (653, 53.00),\n",
       "  (665, 53.00),\n",
       "  (668, 53.00),\n",
       "  (739, 53.00),\n",
       "  (818, 53.00),\n",
       "  (835, 53.00),\n",
       "  (888, 53.00),\n",
       "  (903, 53.00),\n",
       "  (922, 53.00),\n",
       "  (1, 52.00),\n",
       "  (92, 52.00),\n",
       "  (164, 52.00),\n",
       "  (176, 52.00),\n",
       "  (216, 52.00),\n",
       "  (239, 52.00),\n",
       "  (431, 52.00),\n",
       "  (448, 52.00),\n",
       "  (478, 52.00),\n",
       "  (701, 52.00),\n",
       "  (738, 52.00),\n",
       "  (752, 52.00),\n",
       "  (779, 52.00),\n",
       "  (787, 52.00),\n",
       "  (829, 52.00),\n",
       "  (833, 52.00),\n",
       "  (840, 52.00),\n",
       "  (877, 52.00),\n",
       "  (917, 52.00),\n",
       "  (939, 52.00),\n",
       "  (943, 52.00),\n",
       "  (133, 51.00),\n",
       "  (160, 51.00),\n",
       "  (188, 51.00),\n",
       "  (196, 51.00),\n",
       "  (212, 51.00),\n",
       "  (221, 51.00),\n",
       "  (286, 51.00),\n",
       "  (362, 51.00),\n",
       "  (377, 51.00),\n",
       "  (416, 51.00),\n",
       "  (419, 51.00),\n",
       "  (514, 51.00),\n",
       "  (545, 51.00),\n",
       "  (592, 51.00),\n",
       "  (636, 51.00),\n",
       "  (637, 51.00),\n",
       "  (746, 51.00),\n",
       "  (757, 51.00),\n",
       "  (764, 51.00),\n",
       "  (776, 51.00),\n",
       "  (902, 51.00),\n",
       "  (927, 51.00),\n",
       "  (13, 50.00),\n",
       "  (36, 50.00),\n",
       "  (102, 50.00),\n",
       "  (114, 50.00),\n",
       "  (126, 50.00),\n",
       "  (261, 50.00),\n",
       "  (277, 50.00),\n",
       "  (289, 50.00),\n",
       "  (294, 50.00),\n",
       "  (295, 50.00),\n",
       "  (301, 50.00),\n",
       "  (352, 50.00),\n",
       "  (358, 50.00),\n",
       "  (373, 50.00),\n",
       "  (449, 50.00),\n",
       "  (467, 50.00),\n",
       "  (604, 50.00),\n",
       "  (608, 50.00),\n",
       "  (618, 50.00),\n",
       "  (639, 50.00),\n",
       "  (659, 50.00),\n",
       "  (685, 50.00),\n",
       "  (765, 50.00),\n",
       "  (997, 50.00),\n",
       "  (0, 49.00),\n",
       "  (9, 49.00),\n",
       "  (123, 49.00),\n",
       "  (172, 49.00),\n",
       "  (267, 49.00),\n",
       "  (325, 49.00),\n",
       "  (375, 49.00),\n",
       "  (376, 49.00),\n",
       "  (378, 49.00),\n",
       "  (387, 49.00),\n",
       "  (388, 49.00),\n",
       "  (398, 49.00),\n",
       "  (523, 49.00),\n",
       "  (535, 49.00),\n",
       "  (541, 49.00),\n",
       "  (566, 49.00),\n",
       "  (583, 49.00),\n",
       "  (602, 49.00),\n",
       "  (667, 49.00),\n",
       "  (704, 49.00),\n",
       "  (763, 49.00),\n",
       "  (771, 49.00),\n",
       "  (874, 49.00),\n",
       "  (11, 48.00),\n",
       "  (12, 48.00),\n",
       "  (14, 48.00),\n",
       "  (15, 48.00),\n",
       "  (16, 48.00),\n",
       "  (18, 48.00),\n",
       "  (41, 48.00),\n",
       "  (71, 48.00),\n",
       "  (78, 48.00),\n",
       "  (134, 48.00),\n",
       "  (137, 48.00),\n",
       "  (141, 48.00),\n",
       "  (156, 48.00),\n",
       "  (194, 48.00),\n",
       "  (209, 48.00),\n",
       "  (214, 48.00),\n",
       "  (255, 48.00),\n",
       "  (264, 48.00),\n",
       "  (279, 48.00),\n",
       "  (288, 48.00),\n",
       "  (290, 48.00),\n",
       "  (312, 48.00),\n",
       "  (336, 48.00),\n",
       "  (340, 48.00),\n",
       "  (349, 48.00),\n",
       "  (354, 48.00),\n",
       "  (413, 48.00),\n",
       "  (451, 48.00),\n",
       "  (517, 48.00),\n",
       "  (628, 48.00),\n",
       "  (683, 48.00),\n",
       "  (684, 48.00),\n",
       "  (758, 48.00),\n",
       "  (797, 48.00),\n",
       "  (865, 48.00),\n",
       "  (872, 48.00),\n",
       "  (881, 48.00),\n",
       "  (890, 48.00),\n",
       "  (891, 48.00),\n",
       "  (915, 48.00),\n",
       "  (951, 48.00),\n",
       "  (994, 48.00),\n",
       "  (40, 47.00),\n",
       "  (53, 47.00),\n",
       "  (100, 47.00),\n",
       "  (101, 47.00),\n",
       "  (110, 47.00),\n",
       "  (130, 47.00),\n",
       "  (136, 47.00),\n",
       "  (227, 47.00),\n",
       "  (243, 47.00),\n",
       "  (253, 47.00),\n",
       "  (256, 47.00),\n",
       "  (265, 47.00),\n",
       "  (321, 47.00),\n",
       "  (333, 47.00),\n",
       "  (335, 47.00),\n",
       "  (337, 47.00),\n",
       "  (350, 47.00),\n",
       "  (351, 47.00),\n",
       "  (395, 47.00),\n",
       "  (426, 47.00),\n",
       "  (503, 47.00),\n",
       "  (518, 47.00),\n",
       "  (560, 47.00),\n",
       "  (576, 47.00),\n",
       "  (606, 47.00),\n",
       "  (707, 47.00),\n",
       "  (732, 47.00),\n",
       "  (759, 47.00),\n",
       "  (769, 47.00),\n",
       "  (807, 47.00),\n",
       "  (886, 47.00),\n",
       "  (5, 46.00),\n",
       "  (22, 46.00),\n",
       "  (56, 46.00),\n",
       "  (63, 46.00),\n",
       "  (65, 46.00),\n",
       "  (72, 46.00),\n",
       "  (79, 46.00),\n",
       "  (87, 46.00),\n",
       "  (95, 46.00),\n",
       "  (108, 46.00),\n",
       "  (149, 46.00),\n",
       "  (157, 46.00),\n",
       "  (201, 46.00),\n",
       "  (215, 46.00),\n",
       "  (266, 46.00),\n",
       "  (320, 46.00),\n",
       "  (323, 46.00),\n",
       "  (324, 46.00),\n",
       "  (366, 46.00),\n",
       "  (370, 46.00),\n",
       "  (397, 46.00),\n",
       "  (422, 46.00),\n",
       "  (432, 46.00),\n",
       "  (433, 46.00),\n",
       "  (434, 46.00),\n",
       "  (530, 46.00),\n",
       "  (616, 46.00),\n",
       "  (658, 46.00),\n",
       "  (664, 46.00),\n",
       "  (751, 46.00),\n",
       "  (753, 46.00),\n",
       "  (796, 46.00),\n",
       "  (823, 46.00),\n",
       "  (848, 46.00),\n",
       "  (867, 46.00),\n",
       "  (882, 46.00),\n",
       "  (918, 46.00),\n",
       "  (983, 46.00),\n",
       "  (989, 46.00),\n",
       "  (993, 46.00),\n",
       "  (2, 45.00),\n",
       "  (28, 45.00),\n",
       "  (66, 45.00),\n",
       "  (96, 45.00),\n",
       "  (105, 45.00),\n",
       "  (121, 45.00),\n",
       "  (139, 45.00),\n",
       "  (144, 45.00),\n",
       "  (169, 45.00),\n",
       "  (191, 45.00),\n",
       "  (247, 45.00),\n",
       "  (273, 45.00),\n",
       "  (299, 45.00),\n",
       "  (326, 45.00),\n",
       "  (332, 45.00),\n",
       "  (339, 45.00),\n",
       "  (344, 45.00),\n",
       "  (355, 45.00),\n",
       "  (365, 45.00),\n",
       "  (389, 45.00),\n",
       "  (392, 45.00),\n",
       "  (445, 45.00),\n",
       "  (571, 45.00),\n",
       "  (599, 45.00),\n",
       "  (625, 45.00),\n",
       "  (674, 45.00),\n",
       "  (734, 45.00),\n",
       "  (755, 45.00),\n",
       "  (817, 45.00),\n",
       "  (853, 45.00),\n",
       "  (900, 45.00),\n",
       "  (910, 45.00),\n",
       "  (75, 44.00),\n",
       "  (131, 44.00),\n",
       "  (186, 44.00),\n",
       "  (223, 44.00),\n",
       "  (244, 44.00),\n",
       "  (252, 44.00),\n",
       "  (405, 44.00),\n",
       "  (412, 44.00),\n",
       "  (417, 44.00),\n",
       "  (473, 44.00),\n",
       "  (475, 44.00),\n",
       "  (486, 44.00),\n",
       "  (579, 44.00),\n",
       "  (613, 44.00),\n",
       "  (682, 44.00),\n",
       "  (702, 44.00),\n",
       "  (706, 44.00),\n",
       "  (727, 44.00),\n",
       "  (821, 44.00),\n",
       "  (941, 44.00),\n",
       "  (968, 44.00),\n",
       "  (984, 44.00),\n",
       "  (44, 43.00),\n",
       "  (83, 43.00),\n",
       "  (107, 43.00),\n",
       "  (142, 43.00),\n",
       "  (198, 43.00),\n",
       "  (268, 43.00),\n",
       "  (330, 43.00),\n",
       "  (353, 43.00),\n",
       "  (357, 43.00),\n",
       "  (360, 43.00),\n",
       "  (381, 43.00),\n",
       "  (384, 43.00),\n",
       "  (414, 43.00),\n",
       "  (495, 43.00),\n",
       "  (537, 43.00),\n",
       "  (542, 43.00),\n",
       "  (717, 43.00),\n",
       "  (782, 43.00),\n",
       "  (844, 43.00),\n",
       "  (873, 43.00),\n",
       "  (907, 43.00),\n",
       "  (920, 43.00),\n",
       "  (959, 43.00),\n",
       "  (998, 43.00),\n",
       "  (7, 42.00),\n",
       "  (17, 42.00),\n",
       "  (19, 42.00),\n",
       "  (42, 42.00),\n",
       "  (80, 42.00),\n",
       "  (93, 42.00),\n",
       "  (112, 42.00),\n",
       "  (132, 42.00),\n",
       "  (154, 42.00),\n",
       "  (174, 42.00),\n",
       "  (193, 42.00),\n",
       "  (245, 42.00),\n",
       "  (260, 42.00),\n",
       "  (306, 42.00),\n",
       "  (309, 42.00),\n",
       "  (421, 42.00),\n",
       "  (429, 42.00),\n",
       "  (437, 42.00),\n",
       "  (447, 42.00),\n",
       "  (464, 42.00),\n",
       "  (485, 42.00),\n",
       "  (507, 42.00),\n",
       "  (510, 42.00),\n",
       "  (538, 42.00),\n",
       "  (575, 42.00),\n",
       "  (633, 42.00),\n",
       "  (656, 42.00),\n",
       "  (666, 42.00),\n",
       "  (690, 42.00),\n",
       "  (710, 42.00),\n",
       "  (799, 42.00),\n",
       "  (889, 42.00),\n",
       "  (894, 42.00),\n",
       "  (919, 42.00),\n",
       "  (932, 42.00),\n",
       "  (933, 42.00),\n",
       "  (981, 42.00),\n",
       "  (999, 42.00),\n",
       "  (117, 41.00),\n",
       "  (127, 41.00),\n",
       "  (153, 41.00),\n",
       "  (190, 41.00),\n",
       "  (224, 41.00),\n",
       "  (258, 41.00),\n",
       "  (278, 41.00),\n",
       "  (322, 41.00),\n",
       "  (390, 41.00),\n",
       "  (393, 41.00),\n",
       "  (430, 41.00),\n",
       "  (574, 41.00),\n",
       "  (712, 41.00),\n",
       "  (723, 41.00),\n",
       "  (795, 41.00),\n",
       "  (854, 41.00),\n",
       "  (898, 41.00),\n",
       "  (929, 41.00),\n",
       "  (27, 40.00),\n",
       "  (230, 40.00),\n",
       "  (242, 40.00),\n",
       "  (257, 40.00),\n",
       "  (287, 40.00),\n",
       "  (418, 40.00),\n",
       "  (500, 40.00),\n",
       "  (546, 40.00),\n",
       "  (548, 40.00),\n",
       "  (558, 40.00),\n",
       "  (573, 40.00),\n",
       "  (584, 40.00),\n",
       "  (600, 40.00),\n",
       "  (610, 40.00),\n",
       "  (713, 40.00),\n",
       "  (736, 40.00),\n",
       "  (749, 40.00),\n",
       "  (837, 40.00),\n",
       "  (862, 40.00),\n",
       "  (921, 40.00),\n",
       "  (925, 40.00),\n",
       "  (996, 40.00),\n",
       "  (173, 39.00),\n",
       "  (183, 39.00),\n",
       "  (262, 39.00),\n",
       "  (296, 39.00),\n",
       "  (297, 39.00),\n",
       "  (302, 39.00),\n",
       "  (329, 39.00),\n",
       "  (368, 39.00),\n",
       "  (435, 39.00),\n",
       "  (470, 39.00),\n",
       "  (480, 39.00),\n",
       "  (513, 39.00),\n",
       "  (520, 39.00),\n",
       "  (529, 39.00),\n",
       "  (553, 39.00),\n",
       "  (670, 39.00),\n",
       "  (672, 39.00),\n",
       "  (677, 39.00),\n",
       "  (694, 39.00),\n",
       "  (722, 39.00),\n",
       "  (726, 39.00),\n",
       "  (756, 39.00),\n",
       "  (812, 39.00),\n",
       "  (945, 39.00),\n",
       "  (43, 38.00),\n",
       "  (91, 38.00),\n",
       "  (210, 38.00),\n",
       "  (235, 38.00),\n",
       "  (236, 38.00),\n",
       "  (305, 38.00),\n",
       "  (314, 38.00),\n",
       "  (439, 38.00),\n",
       "  (442, 38.00),\n",
       "  (456, 38.00),\n",
       "  (462, 38.00),\n",
       "  (466, 38.00),\n",
       "  (501, 38.00),\n",
       "  (540, 38.00),\n",
       "  (555, 38.00),\n",
       "  (559, 38.00),\n",
       "  (643, 38.00),\n",
       "  (687, 38.00),\n",
       "  (699, 38.00),\n",
       "  (708, 38.00),\n",
       "  (719, 38.00),\n",
       "  (38, 37.00),\n",
       "  (52, 37.00),\n",
       "  (111, 37.00),\n",
       "  (140, 37.00),\n",
       "  (175, 37.00),\n",
       "  (204, 37.00),\n",
       "  (248, 37.00),\n",
       "  (338, 37.00),\n",
       "  (346, 37.00),\n",
       "  (379, 37.00),\n",
       "  (450, 37.00),\n",
       "  (494, 37.00),\n",
       "  (554, 37.00),\n",
       "  (615, 37.00),\n",
       "  (630, 37.00),\n",
       "  (650, 37.00),\n",
       "  (678, 37.00),\n",
       "  (693, 37.00),\n",
       "  (714, 37.00),\n",
       "  (761, 37.00),\n",
       "  (814, 37.00),\n",
       "  (831, 37.00),\n",
       "  (934, 37.00),\n",
       "  (10, 36.00),\n",
       "  (26, 36.00),\n",
       "  (45, 36.00),\n",
       "  (62, 36.00),\n",
       "  (98, 36.00),\n",
       "  (120, 36.00),\n",
       "  (145, 36.00),\n",
       "  (200, 36.00),\n",
       "  (207, 36.00),\n",
       "  (408, 36.00),\n",
       "  (427, 36.00),\n",
       "  (453, 36.00),\n",
       "  (511, 36.00),\n",
       "  (588, 36.00),\n",
       "  (827, 36.00),\n",
       "  (851, 36.00),\n",
       "  (20, 35.00),\n",
       "  (143, 35.00),\n",
       "  (148, 35.00),\n",
       "  (220, 35.00),\n",
       "  (347, 35.00),\n",
       "  (374, 35.00),\n",
       "  (380, 35.00),\n",
       "  (409, 35.00),\n",
       "  (415, 35.00),\n",
       "  (543, 35.00),\n",
       "  (605, 35.00),\n",
       "  (627, 35.00),\n",
       "  (745, 35.00),\n",
       "  (760, 35.00),\n",
       "  (793, 35.00),\n",
       "  (798, 35.00),\n",
       "  (846, 35.00),\n",
       "  (958, 35.00),\n",
       "  (73, 34.00),\n",
       "  (226, 34.00),\n",
       "  (399, 34.00),\n",
       "  (465, 34.00),\n",
       "  (720, 34.00),\n",
       "  (786, 34.00),\n",
       "  (802, 34.00),\n",
       "  (861, 34.00),\n",
       "  (897, 34.00),\n",
       "  (928, 34.00),\n",
       "  (81, 33.00),\n",
       "  (152, 33.00),\n",
       "  (158, 33.00),\n",
       "  (205, 33.00),\n",
       "  (213, 33.00),\n",
       "  (385, 33.00),\n",
       "  (647, 33.00),\n",
       "  (803, 33.00),\n",
       "  (859, 33.00),\n",
       "  (964, 33.00),\n",
       "  (59, 32.00),\n",
       "  (86, 32.00),\n",
       "  (146, 32.00),\n",
       "  (356, 32.00),\n",
       "  (359, 32.00),\n",
       "  (371, 32.00),\n",
       "  (402, 32.00),\n",
       "  (629, 32.00),\n",
       "  (883, 32.00),\n",
       "  (947, 32.00),\n",
       "  (980, 32.00),\n",
       "  (106, 31.00),\n",
       "  (179, 31.00),\n",
       "  (233, 31.00),\n",
       "  (403, 31.00),\n",
       "  (459, 31.00),\n",
       "  (502, 31.00),\n",
       "  (521, 31.00),\n",
       "  (744, 31.00),\n",
       "  (914, 31.00),\n",
       "  (923, 31.00),\n",
       "  (954, 31.00),\n",
       "  (64, 30.00),\n",
       "  (166, 30.00),\n",
       "  (202, 30.00),\n",
       "  (345, 30.00),\n",
       "  (469, 30.00),\n",
       "  (484, 30.00),\n",
       "  (531, 30.00),\n",
       "  (551, 30.00),\n",
       "  (568, 30.00),\n",
       "  (578, 30.00),\n",
       "  (589, 30.00),\n",
       "  (634, 30.00),\n",
       "  (663, 30.00),\n",
       "  (705, 30.00),\n",
       "  (948, 30.00),\n",
       "  (187, 29.00),\n",
       "  (461, 29.00),\n",
       "  (498, 29.00),\n",
       "  (557, 29.00),\n",
       "  (585, 29.00),\n",
       "  (617, 29.00),\n",
       "  (860, 29.00),\n",
       "  (966, 29.00),\n",
       "  (4, 28.00),\n",
       "  (29, 28.00),\n",
       "  (122, 28.00),\n",
       "  (596, 28.00),\n",
       "  (632, 28.00),\n",
       "  (676, 28.00),\n",
       "  (691, 28.00),\n",
       "  (733, 28.00),\n",
       "  (747, 28.00),\n",
       "  (49, 27.00),\n",
       "  (54, 27.00),\n",
       "  (147, 27.00),\n",
       "  (150, 27.00),\n",
       "  (271, 27.00),\n",
       "  (303, 27.00),\n",
       "  (369, 27.00),\n",
       "  (567, 27.00),\n",
       "  (587, 27.00),\n",
       "  (624, 27.00),\n",
       "  (644, 27.00),\n",
       "  (660, 27.00),\n",
       "  (718, 27.00),\n",
       "  (767, 27.00),\n",
       "  (789, 27.00),\n",
       "  (32, 26.00),\n",
       "  (516, 26.00),\n",
       "  (544, 26.00),\n",
       "  (631, 26.00),\n",
       "  (731, 26.00),\n",
       "  (804, 26.00),\n",
       "  (869, 26.00),\n",
       "  (965, 26.00),\n",
       "  (163, 25.00),\n",
       "  (168, 25.00),\n",
       "  (394, 25.00),\n",
       "  (479, 25.00),\n",
       "  (482, 25.00),\n",
       "  (536, 25.00),\n",
       "  (590, 25.00),\n",
       "  (623, 25.00),\n",
       "  (686, 25.00),\n",
       "  (838, 25.00),\n",
       "  (908, 25.00),\n",
       "  (165, 24.00),\n",
       "  (785, 24.00),\n",
       "  (901, 24.00),\n",
       "  (931, 24.00),\n",
       "  (942, 24.00),\n",
       "  (185, 23.00),\n",
       "  (240, 23.00),\n",
       "  (499, 23.00),\n",
       "  (638, 23.00),\n",
       "  (680, 23.00),\n",
       "  (876, 23.00),\n",
       "  (974, 23.00),\n",
       "  (68, 22.00),\n",
       "  (525, 22.00),\n",
       "  (740, 22.00),\n",
       "  (773, 22.00),\n",
       "  (811, 22.00),\n",
       "  (856, 22.00),\n",
       "  (909, 22.00),\n",
       "  (911, 22.00),\n",
       "  (246, 21.00),\n",
       "  (438, 21.00),\n",
       "  (675, 21.00),\n",
       "  (885, 21.00),\n",
       "  (315, 20.00),\n",
       "  (400, 20.00),\n",
       "  (662, 20.00),\n",
       "  (715, 20.00),\n",
       "  (977, 20.00),\n",
       "  (598, 19.00),\n",
       "  (729, 19.00),\n",
       "  (622, 18.00),\n",
       "  (651, 18.00),\n",
       "  (103, 17.00),\n",
       "  (550, 17.00),\n",
       "  (648, 17.00),\n",
       "  (728, 17.00),\n",
       "  (841, 17.00),\n",
       "  (976, 17.00),\n",
       "  (460, 16.00),\n",
       "  (504, 16.00),\n",
       "  (836, 16.00),\n",
       "  (930, 16.00),\n",
       "  (970, 16.00),\n",
       "  (282, 15.00),\n",
       "  (446, 15.00),\n",
       "  (493, 15.00),\n",
       "  (534, 15.00),\n",
       "  (906, 15.00),\n",
       "  (813, 14.00),\n",
       "  (969, 13.00),\n",
       "  (742, 12.00),\n",
       "  (940, 12.00),\n",
       "  (34, 11.00),\n",
       "  (167, 11.00),\n",
       "  (689, 11.00),\n",
       "  (967, 11.00),\n",
       "  (978, 11.00),\n",
       "  (681, 9.00),\n",
       "  (899, 9.00),\n",
       "  (960, 9.00),\n",
       "  (673, 8.00),\n",
       "  (810, 7.00),\n",
       "  (935, 6.00),\n",
       "  (961, 2.00)])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#on test\n",
    "%precision 2\n",
    "# n, hist = targeted_diversity(learn, 150, 95)\n",
    "# n, hist\n",
    "n, hist = targeted_diversity(learn, 10, 95)\n",
    "n, hist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at batch_no 0\n",
      "at batch_no 100\n",
      "at batch_no 200\n",
      "at batch_no 300\n",
      "at batch_no 400\n",
      "at batch_no 500\n",
      "at batch_no 600\n",
      "at batch_no 700\n",
      "at batch_no 800\n",
      "at batch_no 900\n",
      "at batch_no 1000\n",
      "at batch_no 1100\n",
      "at batch_no 1200\n",
      "at batch_no 1300\n",
      "at batch_no 1400\n",
      "at batch_no 1500\n",
      "at batch_no 1600\n",
      "at batch_no 1700\n",
      "at batch_no 1800\n",
      "at batch_no 1900\n",
      "at batch_no 2000\n",
      "at batch_no 2100\n",
      "at batch_no 2200\n",
      "at batch_no 2300\n",
      "at batch_no 2400\n",
      "at batch_no 2500\n",
      "at batch_no 2600\n",
      "at batch_no 2700\n",
      "at batch_no 2800\n",
      "at batch_no 2900\n",
      "at batch_no 3000\n",
      "at batch_no 3100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(885,\n",
       " [(815, 239.00),\n",
       "  (652, 181.00),\n",
       "  (646, 168.00),\n",
       "  (580, 163.00),\n",
       "  (611, 155.00),\n",
       "  (591, 148.00),\n",
       "  (737, 143.00),\n",
       "  (489, 142.00),\n",
       "  (621, 139.00),\n",
       "  (904, 134.00),\n",
       "  (794, 130.00),\n",
       "  (497, 127.00),\n",
       "  (893, 127.00),\n",
       "  (582, 125.00),\n",
       "  (94, 123.00),\n",
       "  (955, 120.00),\n",
       "  (116, 115.00),\n",
       "  (868, 115.00),\n",
       "  (39, 112.00),\n",
       "  (679, 112.00),\n",
       "  (565, 110.00),\n",
       "  (162, 109.00),\n",
       "  (491, 108.00),\n",
       "  (721, 108.00),\n",
       "  (979, 108.00),\n",
       "  (741, 105.00),\n",
       "  (839, 105.00),\n",
       "  (109, 104.00),\n",
       "  (562, 104.00),\n",
       "  (84, 103.00),\n",
       "  (549, 102.00),\n",
       "  (48, 99.00),\n",
       "  (82, 99.00),\n",
       "  (492, 99.00),\n",
       "  (51, 98.00),\n",
       "  (973, 96.00),\n",
       "  (199, 95.00),\n",
       "  (750, 95.00),\n",
       "  (46, 93.00),\n",
       "  (640, 92.00),\n",
       "  (695, 92.00),\n",
       "  (151, 88.00),\n",
       "  (971, 88.00),\n",
       "  (783, 87.00),\n",
       "  (843, 87.00),\n",
       "  (203, 86.00),\n",
       "  (669, 86.00),\n",
       "  (692, 86.00),\n",
       "  (424, 84.00),\n",
       "  (956, 84.00),\n",
       "  (281, 83.00),\n",
       "  (577, 83.00),\n",
       "  (828, 82.00),\n",
       "  (866, 82.00),\n",
       "  (47, 81.00),\n",
       "  (310, 81.00),\n",
       "  (743, 81.00),\n",
       "  (847, 81.00),\n",
       "  (61, 80.00),\n",
       "  (208, 80.00),\n",
       "  (703, 80.00),\n",
       "  (180, 79.00),\n",
       "  (182, 79.00),\n",
       "  (382, 79.00),\n",
       "  (830, 79.00),\n",
       "  (189, 78.00),\n",
       "  (219, 78.00),\n",
       "  (319, 78.00),\n",
       "  (343, 78.00),\n",
       "  (411, 78.00),\n",
       "  (725, 78.00),\n",
       "  (879, 78.00),\n",
       "  (342, 77.00),\n",
       "  (406, 77.00),\n",
       "  (440, 77.00),\n",
       "  (454, 77.00),\n",
       "  (778, 77.00),\n",
       "  (128, 76.00),\n",
       "  (197, 76.00),\n",
       "  (270, 76.00),\n",
       "  (298, 76.00),\n",
       "  (570, 76.00),\n",
       "  (824, 76.00),\n",
       "  (982, 76.00),\n",
       "  (711, 75.00),\n",
       "  (754, 75.00),\n",
       "  (762, 75.00),\n",
       "  (791, 75.00),\n",
       "  (963, 75.00),\n",
       "  (55, 74.00),\n",
       "  (217, 74.00),\n",
       "  (237, 74.00),\n",
       "  (364, 74.00),\n",
       "  (455, 74.00),\n",
       "  (572, 74.00),\n",
       "  (671, 74.00),\n",
       "  (805, 74.00),\n",
       "  (905, 74.00),\n",
       "  (318, 73.00),\n",
       "  (436, 73.00),\n",
       "  (735, 73.00),\n",
       "  (30, 72.00),\n",
       "  (304, 72.00),\n",
       "  (363, 72.00),\n",
       "  (472, 72.00),\n",
       "  (645, 72.00),\n",
       "  (730, 72.00),\n",
       "  (800, 72.00),\n",
       "  (845, 72.00),\n",
       "  (76, 71.00),\n",
       "  (483, 71.00),\n",
       "  (496, 71.00),\n",
       "  (716, 71.00),\n",
       "  (878, 71.00),\n",
       "  (938, 71.00),\n",
       "  (23, 70.00),\n",
       "  (50, 70.00),\n",
       "  (313, 70.00),\n",
       "  (471, 70.00),\n",
       "  (654, 70.00),\n",
       "  (700, 70.00),\n",
       "  (806, 70.00),\n",
       "  (826, 70.00),\n",
       "  (192, 69.00),\n",
       "  (820, 69.00),\n",
       "  (825, 69.00),\n",
       "  (896, 69.00),\n",
       "  (195, 68.00),\n",
       "  (425, 68.00),\n",
       "  (849, 68.00),\n",
       "  (916, 68.00),\n",
       "  (74, 67.00),\n",
       "  (222, 67.00),\n",
       "  (341, 67.00),\n",
       "  (468, 67.00),\n",
       "  (808, 67.00),\n",
       "  (949, 67.00),\n",
       "  (37, 66.00),\n",
       "  (77, 66.00),\n",
       "  (556, 66.00),\n",
       "  (688, 66.00),\n",
       "  (850, 66.00),\n",
       "  (912, 66.00),\n",
       "  (944, 66.00),\n",
       "  (972, 66.00),\n",
       "  (655, 65.00),\n",
       "  (775, 65.00),\n",
       "  (926, 65.00),\n",
       "  (97, 64.00),\n",
       "  (124, 64.00),\n",
       "  (178, 64.00),\n",
       "  (293, 64.00),\n",
       "  (772, 64.00),\n",
       "  (863, 64.00),\n",
       "  (870, 64.00),\n",
       "  (880, 64.00),\n",
       "  (992, 64.00),\n",
       "  (125, 63.00),\n",
       "  (181, 63.00),\n",
       "  (184, 63.00),\n",
       "  (211, 63.00),\n",
       "  (238, 63.00),\n",
       "  (272, 63.00),\n",
       "  (300, 63.00),\n",
       "  (311, 63.00),\n",
       "  (331, 63.00),\n",
       "  (420, 63.00),\n",
       "  (458, 63.00),\n",
       "  (506, 63.00),\n",
       "  (515, 63.00),\n",
       "  (620, 63.00),\n",
       "  (864, 63.00),\n",
       "  (892, 63.00),\n",
       "  (953, 63.00),\n",
       "  (90, 62.00),\n",
       "  (135, 62.00),\n",
       "  (155, 62.00),\n",
       "  (161, 62.00),\n",
       "  (234, 62.00),\n",
       "  (505, 62.00),\n",
       "  (561, 62.00),\n",
       "  (619, 62.00),\n",
       "  (784, 62.00),\n",
       "  (819, 62.00),\n",
       "  (871, 62.00),\n",
       "  (975, 62.00),\n",
       "  (988, 62.00),\n",
       "  (6, 61.00),\n",
       "  (249, 61.00),\n",
       "  (292, 61.00),\n",
       "  (476, 61.00),\n",
       "  (527, 61.00),\n",
       "  (635, 61.00),\n",
       "  (724, 61.00),\n",
       "  (788, 61.00),\n",
       "  (895, 61.00),\n",
       "  (937, 61.00),\n",
       "  (946, 61.00),\n",
       "  (99, 60.00),\n",
       "  (225, 60.00),\n",
       "  (423, 60.00),\n",
       "  (463, 60.00),\n",
       "  (481, 60.00),\n",
       "  (586, 60.00),\n",
       "  (595, 60.00),\n",
       "  (626, 60.00),\n",
       "  (748, 60.00),\n",
       "  (781, 60.00),\n",
       "  (792, 60.00),\n",
       "  (875, 60.00),\n",
       "  (884, 60.00),\n",
       "  (887, 60.00),\n",
       "  (231, 59.00),\n",
       "  (316, 59.00),\n",
       "  (327, 59.00),\n",
       "  (361, 59.00),\n",
       "  (391, 59.00),\n",
       "  (401, 59.00),\n",
       "  (474, 59.00),\n",
       "  (509, 59.00),\n",
       "  (593, 59.00),\n",
       "  (597, 59.00),\n",
       "  (641, 59.00),\n",
       "  (697, 59.00),\n",
       "  (790, 59.00),\n",
       "  (952, 59.00),\n",
       "  (8, 58.00),\n",
       "  (115, 58.00),\n",
       "  (118, 58.00),\n",
       "  (348, 58.00),\n",
       "  (404, 58.00),\n",
       "  (410, 58.00),\n",
       "  (478, 58.00),\n",
       "  (532, 58.00),\n",
       "  (594, 58.00),\n",
       "  (609, 58.00),\n",
       "  (614, 58.00),\n",
       "  (770, 58.00),\n",
       "  (809, 58.00),\n",
       "  (957, 58.00),\n",
       "  (962, 58.00),\n",
       "  (991, 58.00),\n",
       "  (24, 57.00),\n",
       "  (33, 57.00),\n",
       "  (113, 57.00),\n",
       "  (129, 57.00),\n",
       "  (275, 57.00),\n",
       "  (308, 57.00),\n",
       "  (407, 57.00),\n",
       "  (441, 57.00),\n",
       "  (457, 57.00),\n",
       "  (477, 57.00),\n",
       "  (522, 57.00),\n",
       "  (539, 57.00),\n",
       "  (564, 57.00),\n",
       "  (581, 57.00),\n",
       "  (607, 57.00),\n",
       "  (698, 57.00),\n",
       "  (774, 57.00),\n",
       "  (816, 57.00),\n",
       "  (834, 57.00),\n",
       "  (842, 57.00),\n",
       "  (877, 57.00),\n",
       "  (913, 57.00),\n",
       "  (25, 56.00),\n",
       "  (57, 56.00),\n",
       "  (119, 56.00),\n",
       "  (171, 56.00),\n",
       "  (280, 56.00),\n",
       "  (284, 56.00),\n",
       "  (317, 56.00),\n",
       "  (334, 56.00),\n",
       "  (396, 56.00),\n",
       "  (428, 56.00),\n",
       "  (443, 56.00),\n",
       "  (488, 56.00),\n",
       "  (601, 56.00),\n",
       "  (642, 56.00),\n",
       "  (649, 56.00),\n",
       "  (661, 56.00),\n",
       "  (696, 56.00),\n",
       "  (852, 56.00),\n",
       "  (950, 56.00),\n",
       "  (987, 56.00),\n",
       "  (21, 55.00),\n",
       "  (60, 55.00),\n",
       "  (69, 55.00),\n",
       "  (85, 55.00),\n",
       "  (88, 55.00),\n",
       "  (104, 55.00),\n",
       "  (170, 55.00),\n",
       "  (232, 55.00),\n",
       "  (250, 55.00),\n",
       "  (254, 55.00),\n",
       "  (259, 55.00),\n",
       "  (274, 55.00),\n",
       "  (283, 55.00),\n",
       "  (291, 55.00),\n",
       "  (328, 55.00),\n",
       "  (367, 55.00),\n",
       "  (372, 55.00),\n",
       "  (375, 55.00),\n",
       "  (452, 55.00),\n",
       "  (512, 55.00),\n",
       "  (547, 55.00),\n",
       "  (563, 55.00),\n",
       "  (569, 55.00),\n",
       "  (603, 55.00),\n",
       "  (608, 55.00),\n",
       "  (618, 55.00),\n",
       "  (653, 55.00),\n",
       "  (766, 55.00),\n",
       "  (780, 55.00),\n",
       "  (797, 55.00),\n",
       "  (801, 55.00),\n",
       "  (822, 55.00),\n",
       "  (829, 55.00),\n",
       "  (840, 55.00),\n",
       "  (857, 55.00),\n",
       "  (903, 55.00),\n",
       "  (936, 55.00),\n",
       "  (206, 54.00),\n",
       "  (228, 54.00),\n",
       "  (251, 54.00),\n",
       "  (263, 54.00),\n",
       "  (285, 54.00),\n",
       "  (307, 54.00),\n",
       "  (386, 54.00),\n",
       "  (419, 54.00),\n",
       "  (448, 54.00),\n",
       "  (524, 54.00),\n",
       "  (701, 54.00),\n",
       "  (768, 54.00),\n",
       "  (777, 54.00),\n",
       "  (832, 54.00),\n",
       "  (835, 54.00),\n",
       "  (888, 54.00),\n",
       "  (902, 54.00),\n",
       "  (924, 54.00),\n",
       "  (939, 54.00),\n",
       "  (943, 54.00),\n",
       "  (985, 54.00),\n",
       "  (986, 54.00),\n",
       "  (31, 53.00),\n",
       "  (58, 53.00),\n",
       "  (159, 53.00),\n",
       "  (256, 53.00),\n",
       "  (294, 53.00),\n",
       "  (383, 53.00),\n",
       "  (487, 53.00),\n",
       "  (533, 53.00),\n",
       "  (541, 53.00),\n",
       "  (612, 53.00),\n",
       "  (657, 53.00),\n",
       "  (664, 53.00),\n",
       "  (667, 53.00),\n",
       "  (709, 53.00),\n",
       "  (858, 53.00),\n",
       "  (917, 53.00),\n",
       "  (922, 53.00),\n",
       "  (990, 53.00),\n",
       "  (995, 53.00),\n",
       "  (997, 53.00),\n",
       "  (0, 52.00),\n",
       "  (89, 52.00),\n",
       "  (164, 52.00),\n",
       "  (218, 52.00),\n",
       "  (229, 52.00),\n",
       "  (269, 52.00),\n",
       "  (276, 52.00),\n",
       "  (289, 52.00),\n",
       "  (352, 52.00),\n",
       "  (451, 52.00),\n",
       "  (490, 52.00),\n",
       "  (528, 52.00),\n",
       "  (545, 52.00),\n",
       "  (665, 52.00),\n",
       "  (752, 52.00),\n",
       "  (771, 52.00),\n",
       "  (927, 52.00),\n",
       "  (13, 51.00),\n",
       "  (36, 51.00),\n",
       "  (67, 51.00),\n",
       "  (70, 51.00),\n",
       "  (78, 51.00),\n",
       "  (126, 51.00),\n",
       "  (133, 51.00),\n",
       "  (177, 51.00),\n",
       "  (194, 51.00),\n",
       "  (196, 51.00),\n",
       "  (209, 51.00),\n",
       "  (239, 51.00),\n",
       "  (241, 51.00),\n",
       "  (261, 51.00),\n",
       "  (264, 51.00),\n",
       "  (286, 51.00),\n",
       "  (295, 51.00),\n",
       "  (362, 51.00),\n",
       "  (388, 51.00),\n",
       "  (431, 51.00),\n",
       "  (508, 51.00),\n",
       "  (526, 51.00),\n",
       "  (602, 51.00),\n",
       "  (616, 51.00),\n",
       "  (685, 51.00),\n",
       "  (738, 51.00),\n",
       "  (739, 51.00),\n",
       "  (1, 50.00),\n",
       "  (3, 50.00),\n",
       "  (92, 50.00),\n",
       "  (100, 50.00),\n",
       "  (138, 50.00),\n",
       "  (172, 50.00),\n",
       "  (216, 50.00),\n",
       "  (277, 50.00),\n",
       "  (325, 50.00),\n",
       "  (340, 50.00),\n",
       "  (358, 50.00),\n",
       "  (373, 50.00),\n",
       "  (378, 50.00),\n",
       "  (433, 50.00),\n",
       "  (519, 50.00),\n",
       "  (552, 50.00),\n",
       "  (639, 50.00),\n",
       "  (668, 50.00),\n",
       "  (683, 50.00),\n",
       "  (684, 50.00),\n",
       "  (746, 50.00),\n",
       "  (757, 50.00),\n",
       "  (779, 50.00),\n",
       "  (833, 50.00),\n",
       "  (865, 50.00),\n",
       "  (9, 49.00),\n",
       "  (14, 49.00),\n",
       "  (15, 49.00),\n",
       "  (35, 49.00),\n",
       "  (63, 49.00),\n",
       "  (66, 49.00),\n",
       "  (96, 49.00),\n",
       "  (123, 49.00),\n",
       "  (160, 49.00),\n",
       "  (176, 49.00),\n",
       "  (212, 49.00),\n",
       "  (214, 49.00),\n",
       "  (267, 49.00),\n",
       "  (326, 49.00),\n",
       "  (333, 49.00),\n",
       "  (336, 49.00),\n",
       "  (349, 49.00),\n",
       "  (376, 49.00),\n",
       "  (377, 49.00),\n",
       "  (387, 49.00),\n",
       "  (416, 49.00),\n",
       "  (444, 49.00),\n",
       "  (467, 49.00),\n",
       "  (583, 49.00),\n",
       "  (604, 49.00),\n",
       "  (606, 49.00),\n",
       "  (628, 49.00),\n",
       "  (659, 49.00),\n",
       "  (704, 49.00),\n",
       "  (732, 49.00),\n",
       "  (765, 49.00),\n",
       "  (776, 49.00),\n",
       "  (787, 49.00),\n",
       "  (855, 49.00),\n",
       "  (11, 48.00),\n",
       "  (16, 48.00),\n",
       "  (18, 48.00),\n",
       "  (22, 48.00),\n",
       "  (41, 48.00),\n",
       "  (95, 48.00),\n",
       "  (102, 48.00),\n",
       "  (114, 48.00),\n",
       "  (188, 48.00),\n",
       "  (191, 48.00),\n",
       "  (243, 48.00),\n",
       "  (253, 48.00),\n",
       "  (265, 48.00),\n",
       "  (290, 48.00),\n",
       "  (337, 48.00),\n",
       "  (344, 48.00),\n",
       "  (365, 48.00),\n",
       "  (397, 48.00),\n",
       "  (432, 48.00),\n",
       "  (449, 48.00),\n",
       "  (514, 48.00),\n",
       "  (535, 48.00),\n",
       "  (566, 48.00),\n",
       "  (576, 48.00),\n",
       "  (592, 48.00),\n",
       "  (633, 48.00),\n",
       "  (674, 48.00),\n",
       "  (706, 48.00),\n",
       "  (707, 48.00),\n",
       "  (764, 48.00),\n",
       "  (853, 48.00),\n",
       "  (874, 48.00),\n",
       "  (890, 48.00),\n",
       "  (891, 48.00),\n",
       "  (915, 48.00),\n",
       "  (5, 47.00),\n",
       "  (12, 47.00),\n",
       "  (53, 47.00),\n",
       "  (72, 47.00),\n",
       "  (79, 47.00),\n",
       "  (121, 47.00),\n",
       "  (134, 47.00),\n",
       "  (144, 47.00),\n",
       "  (156, 47.00),\n",
       "  (169, 47.00),\n",
       "  (193, 47.00),\n",
       "  (201, 47.00),\n",
       "  (255, 47.00),\n",
       "  (279, 47.00),\n",
       "  (288, 47.00),\n",
       "  (301, 47.00),\n",
       "  (321, 47.00),\n",
       "  (350, 47.00),\n",
       "  (351, 47.00),\n",
       "  (366, 47.00),\n",
       "  (413, 47.00),\n",
       "  (503, 47.00),\n",
       "  (560, 47.00),\n",
       "  (571, 47.00),\n",
       "  (753, 47.00),\n",
       "  (769, 47.00),\n",
       "  (796, 47.00),\n",
       "  (823, 47.00),\n",
       "  (867, 47.00),\n",
       "  (886, 47.00),\n",
       "  (889, 47.00),\n",
       "  (951, 47.00),\n",
       "  (989, 47.00),\n",
       "  (28, 46.00),\n",
       "  (65, 46.00),\n",
       "  (87, 46.00),\n",
       "  (101, 46.00),\n",
       "  (110, 46.00),\n",
       "  (130, 46.00),\n",
       "  (136, 46.00),\n",
       "  (139, 46.00),\n",
       "  (149, 46.00),\n",
       "  (221, 46.00),\n",
       "  (227, 46.00),\n",
       "  (273, 46.00),\n",
       "  (312, 46.00),\n",
       "  (323, 46.00),\n",
       "  (392, 46.00),\n",
       "  (395, 46.00),\n",
       "  (398, 46.00),\n",
       "  (414, 46.00),\n",
       "  (486, 46.00),\n",
       "  (523, 46.00),\n",
       "  (530, 46.00),\n",
       "  (625, 46.00),\n",
       "  (727, 46.00),\n",
       "  (751, 46.00),\n",
       "  (758, 46.00),\n",
       "  (795, 46.00),\n",
       "  (872, 46.00),\n",
       "  (881, 46.00),\n",
       "  (882, 46.00),\n",
       "  (907, 46.00),\n",
       "  (959, 46.00),\n",
       "  (983, 46.00),\n",
       "  (994, 46.00),\n",
       "  (2, 45.00),\n",
       "  (56, 45.00),\n",
       "  (71, 45.00),\n",
       "  (131, 45.00),\n",
       "  (137, 45.00),\n",
       "  (141, 45.00),\n",
       "  (157, 45.00),\n",
       "  (247, 45.00),\n",
       "  (320, 45.00),\n",
       "  (324, 45.00),\n",
       "  (335, 45.00),\n",
       "  (339, 45.00),\n",
       "  (354, 45.00),\n",
       "  (384, 45.00),\n",
       "  (417, 45.00),\n",
       "  (422, 45.00),\n",
       "  (426, 45.00),\n",
       "  (475, 45.00),\n",
       "  (517, 45.00),\n",
       "  (599, 45.00),\n",
       "  (613, 45.00),\n",
       "  (666, 45.00),\n",
       "  (702, 45.00),\n",
       "  (759, 45.00),\n",
       "  (763, 45.00),\n",
       "  (818, 45.00),\n",
       "  (821, 45.00),\n",
       "  (848, 45.00),\n",
       "  (873, 45.00),\n",
       "  (900, 45.00),\n",
       "  (918, 45.00),\n",
       "  (44, 44.00),\n",
       "  (75, 44.00),\n",
       "  (105, 44.00),\n",
       "  (107, 44.00),\n",
       "  (112, 44.00),\n",
       "  (215, 44.00),\n",
       "  (244, 44.00),\n",
       "  (252, 44.00),\n",
       "  (258, 44.00),\n",
       "  (332, 44.00),\n",
       "  (390, 44.00),\n",
       "  (445, 44.00),\n",
       "  (456, 44.00),\n",
       "  (518, 44.00),\n",
       "  (579, 44.00),\n",
       "  (658, 44.00),\n",
       "  (690, 44.00),\n",
       "  (717, 44.00),\n",
       "  (755, 44.00),\n",
       "  (807, 44.00),\n",
       "  (920, 44.00),\n",
       "  (941, 44.00),\n",
       "  (984, 44.00),\n",
       "  (993, 44.00),\n",
       "  (80, 43.00),\n",
       "  (108, 43.00),\n",
       "  (142, 43.00),\n",
       "  (174, 43.00),\n",
       "  (198, 43.00),\n",
       "  (242, 43.00),\n",
       "  (268, 43.00),\n",
       "  (287, 43.00),\n",
       "  (306, 43.00),\n",
       "  (330, 43.00),\n",
       "  (355, 43.00),\n",
       "  (357, 43.00),\n",
       "  (381, 43.00),\n",
       "  (421, 43.00),\n",
       "  (434, 43.00),\n",
       "  (473, 43.00),\n",
       "  (495, 43.00),\n",
       "  (510, 43.00),\n",
       "  (637, 43.00),\n",
       "  (672, 43.00),\n",
       "  (812, 43.00),\n",
       "  (817, 43.00),\n",
       "  (894, 43.00),\n",
       "  (929, 43.00),\n",
       "  (933, 43.00),\n",
       "  (981, 43.00),\n",
       "  (998, 43.00),\n",
       "  (7, 42.00),\n",
       "  (42, 42.00),\n",
       "  (153, 42.00),\n",
       "  (173, 42.00),\n",
       "  (257, 42.00),\n",
       "  (266, 42.00),\n",
       "  (299, 42.00),\n",
       "  (360, 42.00),\n",
       "  (370, 42.00),\n",
       "  (389, 42.00),\n",
       "  (418, 42.00),\n",
       "  (442, 42.00),\n",
       "  (520, 42.00),\n",
       "  (538, 42.00),\n",
       "  (573, 42.00),\n",
       "  (723, 42.00),\n",
       "  (734, 42.00),\n",
       "  (756, 42.00),\n",
       "  (837, 42.00),\n",
       "  (898, 42.00),\n",
       "  (910, 42.00),\n",
       "  (968, 42.00),\n",
       "  (19, 41.00),\n",
       "  (38, 41.00),\n",
       "  (40, 41.00),\n",
       "  (83, 41.00),\n",
       "  (132, 41.00),\n",
       "  (223, 41.00),\n",
       "  (260, 41.00),\n",
       "  (302, 41.00),\n",
       "  (305, 41.00),\n",
       "  (353, 41.00),\n",
       "  (405, 41.00),\n",
       "  (429, 41.00),\n",
       "  (430, 41.00),\n",
       "  (437, 41.00),\n",
       "  (537, 41.00),\n",
       "  (558, 41.00),\n",
       "  (574, 41.00),\n",
       "  (575, 41.00),\n",
       "  (636, 41.00),\n",
       "  (694, 41.00),\n",
       "  (710, 41.00),\n",
       "  (712, 41.00),\n",
       "  (851, 41.00),\n",
       "  (919, 41.00),\n",
       "  (932, 41.00),\n",
       "  (996, 41.00),\n",
       "  (93, 40.00),\n",
       "  (117, 40.00),\n",
       "  (190, 40.00),\n",
       "  (224, 40.00),\n",
       "  (236, 40.00),\n",
       "  (245, 40.00),\n",
       "  (278, 40.00),\n",
       "  (322, 40.00),\n",
       "  (380, 40.00),\n",
       "  (447, 40.00),\n",
       "  (485, 40.00),\n",
       "  (500, 40.00),\n",
       "  (507, 40.00),\n",
       "  (542, 40.00),\n",
       "  (555, 40.00),\n",
       "  (559, 40.00),\n",
       "  (584, 40.00),\n",
       "  (643, 40.00),\n",
       "  (682, 40.00),\n",
       "  (699, 40.00),\n",
       "  (713, 40.00),\n",
       "  (726, 40.00),\n",
       "  (799, 40.00),\n",
       "  (862, 40.00),\n",
       "  (925, 40.00),\n",
       "  (945, 40.00),\n",
       "  (999, 40.00),\n",
       "  (10, 39.00),\n",
       "  (17, 39.00),\n",
       "  (27, 39.00),\n",
       "  (91, 39.00),\n",
       "  (111, 39.00),\n",
       "  (127, 39.00),\n",
       "  (140, 39.00),\n",
       "  (145, 39.00),\n",
       "  (148, 39.00),\n",
       "  (186, 39.00),\n",
       "  (329, 39.00),\n",
       "  (338, 39.00),\n",
       "  (379, 39.00),\n",
       "  (393, 39.00),\n",
       "  (439, 39.00),\n",
       "  (480, 39.00),\n",
       "  (501, 39.00),\n",
       "  (546, 39.00),\n",
       "  (670, 39.00),\n",
       "  (722, 39.00),\n",
       "  (749, 39.00),\n",
       "  (761, 39.00),\n",
       "  (883, 39.00),\n",
       "  (204, 38.00),\n",
       "  (230, 38.00),\n",
       "  (297, 38.00),\n",
       "  (309, 38.00),\n",
       "  (314, 38.00),\n",
       "  (368, 38.00),\n",
       "  (412, 38.00),\n",
       "  (470, 38.00),\n",
       "  (529, 38.00),\n",
       "  (540, 38.00),\n",
       "  (548, 38.00),\n",
       "  (553, 38.00),\n",
       "  (656, 38.00),\n",
       "  (687, 38.00),\n",
       "  (708, 38.00),\n",
       "  (714, 38.00),\n",
       "  (736, 38.00),\n",
       "  (782, 38.00),\n",
       "  (831, 38.00),\n",
       "  (844, 38.00),\n",
       "  (854, 38.00),\n",
       "  (20, 37.00),\n",
       "  (52, 37.00),\n",
       "  (152, 37.00),\n",
       "  (154, 37.00),\n",
       "  (175, 37.00),\n",
       "  (183, 37.00),\n",
       "  (210, 37.00),\n",
       "  (235, 37.00),\n",
       "  (262, 37.00),\n",
       "  (296, 37.00),\n",
       "  (347, 37.00),\n",
       "  (435, 37.00),\n",
       "  (462, 37.00),\n",
       "  (466, 37.00),\n",
       "  (494, 37.00),\n",
       "  (554, 37.00),\n",
       "  (600, 37.00),\n",
       "  (610, 37.00),\n",
       "  (630, 37.00),\n",
       "  (678, 37.00),\n",
       "  (814, 37.00),\n",
       "  (921, 37.00),\n",
       "  (98, 36.00),\n",
       "  (200, 36.00),\n",
       "  (205, 36.00),\n",
       "  (207, 36.00),\n",
       "  (399, 36.00),\n",
       "  (408, 36.00),\n",
       "  (453, 36.00),\n",
       "  (511, 36.00),\n",
       "  (513, 36.00),\n",
       "  (650, 36.00),\n",
       "  (693, 36.00),\n",
       "  (719, 36.00),\n",
       "  (720, 36.00),\n",
       "  (861, 36.00),\n",
       "  (928, 36.00),\n",
       "  (934, 36.00),\n",
       "  (120, 35.00),\n",
       "  (143, 35.00),\n",
       "  (248, 35.00),\n",
       "  (346, 35.00),\n",
       "  (356, 35.00),\n",
       "  (605, 35.00),\n",
       "  (802, 35.00),\n",
       "  (43, 34.00),\n",
       "  (45, 34.00),\n",
       "  (62, 34.00),\n",
       "  (86, 34.00),\n",
       "  (220, 34.00),\n",
       "  (359, 34.00),\n",
       "  (374, 34.00),\n",
       "  (450, 34.00),\n",
       "  (464, 34.00),\n",
       "  (615, 34.00),\n",
       "  (677, 34.00),\n",
       "  (745, 34.00),\n",
       "  (793, 34.00),\n",
       "  (798, 34.00),\n",
       "  (827, 34.00),\n",
       "  (947, 34.00),\n",
       "  (958, 34.00),\n",
       "  (964, 34.00),\n",
       "  (59, 33.00),\n",
       "  (158, 33.00),\n",
       "  (213, 33.00),\n",
       "  (226, 33.00),\n",
       "  (233, 33.00),\n",
       "  (402, 33.00),\n",
       "  (403, 33.00),\n",
       "  (409, 33.00),\n",
       "  (415, 33.00),\n",
       "  (588, 33.00),\n",
       "  (691, 33.00),\n",
       "  (954, 33.00),\n",
       "  (26, 32.00),\n",
       "  (64, 32.00),\n",
       "  (73, 32.00),\n",
       "  (106, 32.00),\n",
       "  (385, 32.00),\n",
       "  (427, 32.00),\n",
       "  (465, 32.00),\n",
       "  (543, 32.00),\n",
       "  (627, 32.00),\n",
       "  (760, 32.00),\n",
       "  (786, 32.00),\n",
       "  (859, 32.00),\n",
       "  (897, 32.00),\n",
       "  (948, 32.00),\n",
       "  (980, 32.00),\n",
       "  (122, 31.00),\n",
       "  (371, 31.00),\n",
       "  (461, 31.00),\n",
       "  (469, 31.00),\n",
       "  (484, 31.00),\n",
       "  (502, 31.00),\n",
       "  (521, 31.00),\n",
       "  (531, 31.00),\n",
       "  (551, 31.00),\n",
       "  (568, 31.00),\n",
       "  (578, 31.00),\n",
       "  (644, 31.00),\n",
       "  (647, 31.00),\n",
       "  (705, 31.00),\n",
       "  (744, 31.00),\n",
       "  (789, 31.00),\n",
       "  (846, 31.00),\n",
       "  (914, 31.00),\n",
       "  (81, 30.00),\n",
       "  (146, 30.00),\n",
       "  (166, 30.00),\n",
       "  (179, 30.00),\n",
       "  (345, 30.00),\n",
       "  (459, 30.00),\n",
       "  (557, 30.00),\n",
       "  (589, 30.00),\n",
       "  (617, 30.00),\n",
       "  (629, 30.00),\n",
       "  (632, 30.00),\n",
       "  (803, 30.00),\n",
       "  (966, 30.00),\n",
       "  (303, 29.00),\n",
       "  (498, 29.00),\n",
       "  (585, 29.00),\n",
       "  (634, 29.00),\n",
       "  (4, 28.00),\n",
       "  (29, 28.00),\n",
       "  (54, 28.00),\n",
       "  (567, 28.00),\n",
       "  (587, 28.00),\n",
       "  (631, 28.00),\n",
       "  (663, 28.00),\n",
       "  (718, 28.00),\n",
       "  (731, 28.00),\n",
       "  (767, 28.00),\n",
       "  (860, 28.00),\n",
       "  (876, 28.00),\n",
       "  (909, 28.00),\n",
       "  (923, 28.00),\n",
       "  (147, 27.00),\n",
       "  (187, 27.00),\n",
       "  (202, 27.00),\n",
       "  (479, 27.00),\n",
       "  (482, 27.00),\n",
       "  (660, 27.00),\n",
       "  (733, 27.00),\n",
       "  (965, 27.00),\n",
       "  (49, 26.00),\n",
       "  (150, 26.00),\n",
       "  (271, 26.00),\n",
       "  (624, 26.00),\n",
       "  (676, 26.00),\n",
       "  (686, 26.00),\n",
       "  (785, 26.00),\n",
       "  (869, 26.00),\n",
       "  (931, 26.00),\n",
       "  (32, 25.00),\n",
       "  (163, 25.00),\n",
       "  (240, 25.00),\n",
       "  (369, 25.00),\n",
       "  (544, 25.00),\n",
       "  (804, 25.00),\n",
       "  (885, 25.00),\n",
       "  (516, 24.00),\n",
       "  (536, 24.00),\n",
       "  (590, 24.00),\n",
       "  (596, 24.00),\n",
       "  (747, 24.00),\n",
       "  (856, 24.00),\n",
       "  (901, 24.00),\n",
       "  (168, 23.00),\n",
       "  (185, 23.00),\n",
       "  (315, 23.00),\n",
       "  (394, 23.00),\n",
       "  (438, 23.00),\n",
       "  (623, 23.00),\n",
       "  (680, 23.00),\n",
       "  (811, 23.00),\n",
       "  (838, 23.00),\n",
       "  (908, 23.00),\n",
       "  (911, 23.00),\n",
       "  (974, 23.00),\n",
       "  (165, 22.00),\n",
       "  (550, 22.00),\n",
       "  (638, 22.00),\n",
       "  (675, 22.00),\n",
       "  (942, 22.00),\n",
       "  (499, 21.00),\n",
       "  (525, 21.00),\n",
       "  (773, 21.00),\n",
       "  (68, 20.00),\n",
       "  (662, 20.00),\n",
       "  (715, 20.00),\n",
       "  (729, 20.00),\n",
       "  (740, 20.00),\n",
       "  (246, 19.00),\n",
       "  (400, 19.00),\n",
       "  (598, 19.00),\n",
       "  (622, 19.00),\n",
       "  (648, 18.00),\n",
       "  (651, 18.00),\n",
       "  (728, 18.00),\n",
       "  (836, 18.00),\n",
       "  (977, 18.00),\n",
       "  (504, 17.00),\n",
       "  (813, 17.00),\n",
       "  (906, 17.00),\n",
       "  (976, 17.00),\n",
       "  (460, 16.00),\n",
       "  (534, 16.00),\n",
       "  (841, 16.00),\n",
       "  (930, 16.00),\n",
       "  (970, 15.00),\n",
       "  (103, 14.00),\n",
       "  (282, 14.00),\n",
       "  (742, 14.00),\n",
       "  (969, 14.00),\n",
       "  (34, 13.00),\n",
       "  (446, 13.00),\n",
       "  (493, 13.00),\n",
       "  (967, 12.00),\n",
       "  (167, 11.00),\n",
       "  (940, 11.00),\n",
       "  (978, 11.00),\n",
       "  (689, 10.00),\n",
       "  (899, 9.00),\n",
       "  (960, 9.00),\n",
       "  (673, 8.00),\n",
       "  (681, 8.00),\n",
       "  (810, 8.00),\n",
       "  (935, 8.00),\n",
       "  (961, 2.00)])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#on test\n",
    "%precision 2\n",
    "# n, hist = targeted_diversity(learn, 150, 95)\n",
    "# n, hist\n",
    "n, hist = targeted_diversity(learn, 10, 95)\n",
    "n, hist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at batch_no 0\n",
      "at batch_no 100\n",
      "at batch_no 200\n",
      "at batch_no 300\n",
      "at batch_no 400\n",
      "at batch_no 500\n",
      "at batch_no 600\n",
      "at batch_no 700\n",
      "at batch_no 800\n",
      "at batch_no 900\n",
      "at batch_no 1000\n",
      "at batch_no 1100\n",
      "at batch_no 1200\n",
      "at batch_no 1300\n",
      "at batch_no 1400\n",
      "at batch_no 1500\n",
      "at batch_no 1600\n",
      "at batch_no 1700\n",
      "at batch_no 1800\n",
      "at batch_no 1900\n",
      "at batch_no 2000\n",
      "at batch_no 2100\n",
      "at batch_no 2200\n",
      "at batch_no 2300\n",
      "at batch_no 2400\n",
      "at batch_no 2500\n",
      "at batch_no 2600\n",
      "at batch_no 2700\n",
      "at batch_no 2800\n",
      "at batch_no 2900\n",
      "at batch_no 3000\n",
      "at batch_no 3100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(885,\n",
       " [(815, 227.00),\n",
       "  (652, 183.00),\n",
       "  (646, 172.00),\n",
       "  (580, 155.00),\n",
       "  (591, 149.00),\n",
       "  (621, 148.00),\n",
       "  (737, 148.00),\n",
       "  (611, 147.00),\n",
       "  (489, 136.00),\n",
       "  (904, 129.00),\n",
       "  (497, 125.00),\n",
       "  (868, 125.00),\n",
       "  (979, 124.00),\n",
       "  (582, 122.00),\n",
       "  (794, 122.00),\n",
       "  (94, 118.00),\n",
       "  (955, 118.00),\n",
       "  (893, 117.00),\n",
       "  (721, 116.00),\n",
       "  (116, 114.00),\n",
       "  (491, 108.00),\n",
       "  (565, 108.00),\n",
       "  (741, 107.00),\n",
       "  (562, 106.00),\n",
       "  (679, 106.00),\n",
       "  (39, 105.00),\n",
       "  (839, 104.00),\n",
       "  (109, 102.00),\n",
       "  (162, 101.00),\n",
       "  (750, 100.00),\n",
       "  (46, 98.00),\n",
       "  (695, 98.00),\n",
       "  (549, 97.00),\n",
       "  (82, 95.00),\n",
       "  (199, 95.00),\n",
       "  (492, 95.00),\n",
       "  (84, 94.00),\n",
       "  (973, 94.00),\n",
       "  (51, 93.00),\n",
       "  (151, 91.00),\n",
       "  (48, 90.00),\n",
       "  (424, 89.00),\n",
       "  (843, 89.00),\n",
       "  (203, 87.00),\n",
       "  (692, 87.00),\n",
       "  (971, 87.00),\n",
       "  (640, 86.00),\n",
       "  (669, 86.00),\n",
       "  (197, 84.00),\n",
       "  (440, 84.00),\n",
       "  (879, 84.00),\n",
       "  (47, 83.00),\n",
       "  (180, 83.00),\n",
       "  (577, 83.00),\n",
       "  (208, 81.00),\n",
       "  (743, 81.00),\n",
       "  (783, 81.00),\n",
       "  (847, 81.00),\n",
       "  (189, 80.00),\n",
       "  (281, 80.00),\n",
       "  (382, 80.00),\n",
       "  (406, 80.00),\n",
       "  (703, 80.00),\n",
       "  (824, 80.00),\n",
       "  (905, 80.00),\n",
       "  (61, 79.00),\n",
       "  (318, 79.00),\n",
       "  (319, 79.00),\n",
       "  (411, 79.00),\n",
       "  (762, 79.00),\n",
       "  (866, 79.00),\n",
       "  (219, 78.00),\n",
       "  (310, 78.00),\n",
       "  (938, 78.00),\n",
       "  (76, 77.00),\n",
       "  (270, 77.00),\n",
       "  (364, 77.00),\n",
       "  (849, 77.00),\n",
       "  (182, 76.00),\n",
       "  (298, 76.00),\n",
       "  (791, 76.00),\n",
       "  (828, 76.00),\n",
       "  (896, 76.00),\n",
       "  (956, 76.00),\n",
       "  (963, 76.00),\n",
       "  (55, 75.00),\n",
       "  (217, 75.00),\n",
       "  (342, 75.00),\n",
       "  (343, 75.00),\n",
       "  (730, 75.00),\n",
       "  (778, 75.00),\n",
       "  (830, 75.00),\n",
       "  (455, 74.00),\n",
       "  (483, 74.00),\n",
       "  (800, 74.00),\n",
       "  (982, 74.00),\n",
       "  (304, 73.00),\n",
       "  (363, 73.00),\n",
       "  (436, 73.00),\n",
       "  (471, 73.00),\n",
       "  (472, 73.00),\n",
       "  (645, 73.00),\n",
       "  (805, 73.00),\n",
       "  (128, 72.00),\n",
       "  (725, 72.00),\n",
       "  (754, 72.00),\n",
       "  (878, 71.00),\n",
       "  (192, 70.00),\n",
       "  (341, 70.00),\n",
       "  (454, 70.00),\n",
       "  (556, 70.00),\n",
       "  (572, 70.00),\n",
       "  (735, 70.00),\n",
       "  (806, 70.00),\n",
       "  (825, 70.00),\n",
       "  (826, 70.00),\n",
       "  (178, 69.00),\n",
       "  (195, 69.00),\n",
       "  (570, 69.00),\n",
       "  (671, 69.00),\n",
       "  (716, 69.00),\n",
       "  (23, 68.00),\n",
       "  (50, 68.00),\n",
       "  (654, 68.00),\n",
       "  (700, 68.00),\n",
       "  (775, 68.00),\n",
       "  (30, 67.00),\n",
       "  (77, 67.00),\n",
       "  (425, 67.00),\n",
       "  (496, 67.00),\n",
       "  (845, 67.00),\n",
       "  (916, 67.00),\n",
       "  (949, 67.00),\n",
       "  (37, 66.00),\n",
       "  (124, 66.00),\n",
       "  (420, 66.00),\n",
       "  (586, 66.00),\n",
       "  (620, 66.00),\n",
       "  (784, 66.00),\n",
       "  (895, 66.00),\n",
       "  (926, 66.00),\n",
       "  (155, 65.00),\n",
       "  (234, 65.00),\n",
       "  (238, 65.00),\n",
       "  (293, 65.00),\n",
       "  (313, 65.00),\n",
       "  (649, 65.00),\n",
       "  (688, 65.00),\n",
       "  (820, 65.00),\n",
       "  (863, 65.00),\n",
       "  (864, 65.00),\n",
       "  (870, 65.00),\n",
       "  (871, 65.00),\n",
       "  (892, 65.00),\n",
       "  (988, 65.00),\n",
       "  (6, 64.00),\n",
       "  (74, 64.00),\n",
       "  (222, 64.00),\n",
       "  (237, 64.00),\n",
       "  (361, 64.00),\n",
       "  (463, 64.00),\n",
       "  (468, 64.00),\n",
       "  (711, 64.00),\n",
       "  (772, 64.00),\n",
       "  (887, 64.00),\n",
       "  (944, 64.00),\n",
       "  (97, 63.00),\n",
       "  (119, 63.00),\n",
       "  (331, 63.00),\n",
       "  (474, 63.00),\n",
       "  (819, 63.00),\n",
       "  (913, 63.00),\n",
       "  (972, 63.00),\n",
       "  (8, 62.00),\n",
       "  (90, 62.00),\n",
       "  (99, 62.00),\n",
       "  (125, 62.00),\n",
       "  (161, 62.00),\n",
       "  (184, 62.00),\n",
       "  (272, 62.00),\n",
       "  (300, 62.00),\n",
       "  (348, 62.00),\n",
       "  (506, 62.00),\n",
       "  (515, 62.00),\n",
       "  (593, 62.00),\n",
       "  (788, 62.00),\n",
       "  (808, 62.00),\n",
       "  (842, 62.00),\n",
       "  (875, 62.00),\n",
       "  (880, 62.00),\n",
       "  (992, 62.00),\n",
       "  (135, 61.00),\n",
       "  (225, 61.00),\n",
       "  (280, 61.00),\n",
       "  (292, 61.00),\n",
       "  (311, 61.00),\n",
       "  (316, 61.00),\n",
       "  (476, 61.00),\n",
       "  (505, 61.00),\n",
       "  (561, 61.00),\n",
       "  (609, 61.00),\n",
       "  (698, 61.00),\n",
       "  (809, 61.00),\n",
       "  (850, 61.00),\n",
       "  (937, 61.00),\n",
       "  (946, 61.00),\n",
       "  (953, 61.00),\n",
       "  (181, 60.00),\n",
       "  (372, 60.00),\n",
       "  (401, 60.00),\n",
       "  (532, 60.00),\n",
       "  (539, 60.00),\n",
       "  (619, 60.00),\n",
       "  (697, 60.00),\n",
       "  (781, 60.00),\n",
       "  (884, 60.00),\n",
       "  (113, 59.00),\n",
       "  (327, 59.00),\n",
       "  (391, 59.00),\n",
       "  (404, 59.00),\n",
       "  (481, 59.00),\n",
       "  (490, 59.00),\n",
       "  (522, 59.00),\n",
       "  (581, 59.00),\n",
       "  (607, 59.00),\n",
       "  (655, 59.00),\n",
       "  (724, 59.00),\n",
       "  (774, 59.00),\n",
       "  (912, 59.00),\n",
       "  (952, 59.00),\n",
       "  (987, 59.00),\n",
       "  (60, 58.00),\n",
       "  (211, 58.00),\n",
       "  (249, 58.00),\n",
       "  (284, 58.00),\n",
       "  (317, 58.00),\n",
       "  (407, 58.00),\n",
       "  (410, 58.00),\n",
       "  (423, 58.00),\n",
       "  (458, 58.00),\n",
       "  (563, 58.00),\n",
       "  (594, 58.00),\n",
       "  (595, 58.00),\n",
       "  (597, 58.00),\n",
       "  (603, 58.00),\n",
       "  (641, 58.00),\n",
       "  (696, 58.00),\n",
       "  (709, 58.00),\n",
       "  (790, 58.00),\n",
       "  (857, 58.00),\n",
       "  (21, 57.00),\n",
       "  (307, 57.00),\n",
       "  (419, 57.00),\n",
       "  (441, 57.00),\n",
       "  (457, 57.00),\n",
       "  (612, 57.00),\n",
       "  (618, 57.00),\n",
       "  (636, 57.00),\n",
       "  (801, 57.00),\n",
       "  (69, 56.00),\n",
       "  (118, 56.00),\n",
       "  (231, 56.00),\n",
       "  (232, 56.00),\n",
       "  (263, 56.00),\n",
       "  (275, 56.00),\n",
       "  (308, 56.00),\n",
       "  (334, 56.00),\n",
       "  (367, 56.00),\n",
       "  (452, 56.00),\n",
       "  (477, 56.00),\n",
       "  (527, 56.00),\n",
       "  (547, 56.00),\n",
       "  (564, 56.00),\n",
       "  (635, 56.00),\n",
       "  (642, 56.00),\n",
       "  (653, 56.00),\n",
       "  (657, 56.00),\n",
       "  (661, 56.00),\n",
       "  (780, 56.00),\n",
       "  (816, 56.00),\n",
       "  (822, 56.00),\n",
       "  (957, 56.00),\n",
       "  (962, 56.00),\n",
       "  (975, 56.00),\n",
       "  (25, 55.00),\n",
       "  (31, 55.00),\n",
       "  (33, 55.00),\n",
       "  (57, 55.00),\n",
       "  (88, 55.00),\n",
       "  (104, 55.00),\n",
       "  (115, 55.00),\n",
       "  (129, 55.00),\n",
       "  (228, 55.00),\n",
       "  (328, 55.00),\n",
       "  (383, 55.00),\n",
       "  (396, 55.00),\n",
       "  (428, 55.00),\n",
       "  (509, 55.00),\n",
       "  (614, 55.00),\n",
       "  (738, 55.00),\n",
       "  (748, 55.00),\n",
       "  (777, 55.00),\n",
       "  (834, 55.00),\n",
       "  (852, 55.00),\n",
       "  (877, 55.00),\n",
       "  (985, 55.00),\n",
       "  (24, 54.00),\n",
       "  (58, 54.00),\n",
       "  (67, 54.00),\n",
       "  (70, 54.00),\n",
       "  (85, 54.00),\n",
       "  (170, 54.00),\n",
       "  (250, 54.00),\n",
       "  (259, 54.00),\n",
       "  (274, 54.00),\n",
       "  (444, 54.00),\n",
       "  (448, 54.00),\n",
       "  (451, 54.00),\n",
       "  (519, 54.00),\n",
       "  (524, 54.00),\n",
       "  (552, 54.00),\n",
       "  (569, 54.00),\n",
       "  (601, 54.00),\n",
       "  (766, 54.00),\n",
       "  (770, 54.00),\n",
       "  (818, 54.00),\n",
       "  (829, 54.00),\n",
       "  (855, 54.00),\n",
       "  (858, 54.00),\n",
       "  (950, 54.00),\n",
       "  (991, 54.00),\n",
       "  (995, 54.00),\n",
       "  (89, 53.00),\n",
       "  (171, 53.00),\n",
       "  (196, 53.00),\n",
       "  (216, 53.00),\n",
       "  (218, 53.00),\n",
       "  (256, 53.00),\n",
       "  (269, 53.00),\n",
       "  (276, 53.00),\n",
       "  (283, 53.00),\n",
       "  (289, 53.00),\n",
       "  (352, 53.00),\n",
       "  (375, 53.00),\n",
       "  (608, 53.00),\n",
       "  (626, 53.00),\n",
       "  (701, 53.00),\n",
       "  (768, 53.00),\n",
       "  (832, 53.00),\n",
       "  (903, 53.00),\n",
       "  (924, 53.00),\n",
       "  (936, 53.00),\n",
       "  (986, 53.00),\n",
       "  (0, 52.00),\n",
       "  (3, 52.00),\n",
       "  (36, 52.00),\n",
       "  (92, 52.00),\n",
       "  (96, 52.00),\n",
       "  (164, 52.00),\n",
       "  (172, 52.00),\n",
       "  (209, 52.00),\n",
       "  (241, 52.00),\n",
       "  (251, 52.00),\n",
       "  (254, 52.00),\n",
       "  (277, 52.00),\n",
       "  (291, 52.00),\n",
       "  (467, 52.00),\n",
       "  (528, 52.00),\n",
       "  (685, 52.00),\n",
       "  (757, 52.00),\n",
       "  (765, 52.00),\n",
       "  (792, 52.00),\n",
       "  (840, 52.00),\n",
       "  (865, 52.00),\n",
       "  (888, 52.00),\n",
       "  (922, 52.00),\n",
       "  (939, 52.00),\n",
       "  (990, 52.00),\n",
       "  (997, 52.00),\n",
       "  (15, 51.00),\n",
       "  (78, 51.00),\n",
       "  (114, 51.00),\n",
       "  (206, 51.00),\n",
       "  (229, 51.00),\n",
       "  (239, 51.00),\n",
       "  (285, 51.00),\n",
       "  (286, 51.00),\n",
       "  (336, 51.00),\n",
       "  (358, 51.00),\n",
       "  (378, 51.00),\n",
       "  (386, 51.00),\n",
       "  (395, 51.00),\n",
       "  (413, 51.00),\n",
       "  (431, 51.00),\n",
       "  (487, 51.00),\n",
       "  (488, 51.00),\n",
       "  (512, 51.00),\n",
       "  (526, 51.00),\n",
       "  (533, 51.00),\n",
       "  (535, 51.00),\n",
       "  (592, 51.00),\n",
       "  (667, 51.00),\n",
       "  (752, 51.00),\n",
       "  (753, 51.00),\n",
       "  (835, 51.00),\n",
       "  (886, 51.00),\n",
       "  (902, 51.00),\n",
       "  (1, 50.00),\n",
       "  (41, 50.00),\n",
       "  (126, 50.00),\n",
       "  (138, 50.00),\n",
       "  (176, 50.00),\n",
       "  (177, 50.00),\n",
       "  (194, 50.00),\n",
       "  (253, 50.00),\n",
       "  (261, 50.00),\n",
       "  (267, 50.00),\n",
       "  (294, 50.00),\n",
       "  (362, 50.00),\n",
       "  (373, 50.00),\n",
       "  (443, 50.00),\n",
       "  (449, 50.00),\n",
       "  (508, 50.00),\n",
       "  (514, 50.00),\n",
       "  (523, 50.00),\n",
       "  (545, 50.00),\n",
       "  (602, 50.00),\n",
       "  (606, 50.00),\n",
       "  (616, 50.00),\n",
       "  (665, 50.00),\n",
       "  (746, 50.00),\n",
       "  (771, 50.00),\n",
       "  (779, 50.00),\n",
       "  (797, 50.00),\n",
       "  (874, 50.00),\n",
       "  (917, 50.00),\n",
       "  (9, 49.00),\n",
       "  (12, 49.00),\n",
       "  (13, 49.00),\n",
       "  (35, 49.00),\n",
       "  (71, 49.00),\n",
       "  (102, 49.00),\n",
       "  (121, 49.00),\n",
       "  (159, 49.00),\n",
       "  (160, 49.00),\n",
       "  (214, 49.00),\n",
       "  (266, 49.00),\n",
       "  (301, 49.00),\n",
       "  (340, 49.00),\n",
       "  (387, 49.00),\n",
       "  (388, 49.00),\n",
       "  (541, 49.00),\n",
       "  (604, 49.00),\n",
       "  (639, 49.00),\n",
       "  (664, 49.00),\n",
       "  (739, 49.00),\n",
       "  (764, 49.00),\n",
       "  (776, 49.00),\n",
       "  (833, 49.00),\n",
       "  (890, 49.00),\n",
       "  (915, 49.00),\n",
       "  (927, 49.00),\n",
       "  (11, 48.00),\n",
       "  (14, 48.00),\n",
       "  (18, 48.00),\n",
       "  (72, 48.00),\n",
       "  (95, 48.00),\n",
       "  (100, 48.00),\n",
       "  (133, 48.00),\n",
       "  (134, 48.00),\n",
       "  (149, 48.00),\n",
       "  (156, 48.00),\n",
       "  (169, 48.00),\n",
       "  (221, 48.00),\n",
       "  (247, 48.00),\n",
       "  (255, 48.00),\n",
       "  (295, 48.00),\n",
       "  (320, 48.00),\n",
       "  (321, 48.00),\n",
       "  (325, 48.00),\n",
       "  (337, 48.00),\n",
       "  (376, 48.00),\n",
       "  (398, 48.00),\n",
       "  (432, 48.00),\n",
       "  (433, 48.00),\n",
       "  (478, 48.00),\n",
       "  (503, 48.00),\n",
       "  (517, 48.00),\n",
       "  (583, 48.00),\n",
       "  (628, 48.00),\n",
       "  (668, 48.00),\n",
       "  (683, 48.00),\n",
       "  (704, 48.00),\n",
       "  (727, 48.00),\n",
       "  (787, 48.00),\n",
       "  (848, 48.00),\n",
       "  (881, 48.00),\n",
       "  (943, 48.00),\n",
       "  (951, 48.00),\n",
       "  (989, 48.00),\n",
       "  (994, 48.00),\n",
       "  (22, 47.00),\n",
       "  (56, 47.00),\n",
       "  (79, 47.00),\n",
       "  (87, 47.00),\n",
       "  (123, 47.00),\n",
       "  (137, 47.00),\n",
       "  (139, 47.00),\n",
       "  (141, 47.00),\n",
       "  (193, 47.00),\n",
       "  (273, 47.00),\n",
       "  (288, 47.00),\n",
       "  (290, 47.00),\n",
       "  (326, 47.00),\n",
       "  (333, 47.00),\n",
       "  (335, 47.00),\n",
       "  (344, 47.00),\n",
       "  (351, 47.00),\n",
       "  (354, 47.00),\n",
       "  (366, 47.00),\n",
       "  (416, 47.00),\n",
       "  (422, 47.00),\n",
       "  (445, 47.00),\n",
       "  (518, 47.00),\n",
       "  (571, 47.00),\n",
       "  (576, 47.00),\n",
       "  (625, 47.00),\n",
       "  (637, 47.00),\n",
       "  (666, 47.00),\n",
       "  (684, 47.00),\n",
       "  (707, 47.00),\n",
       "  (751, 47.00),\n",
       "  (763, 47.00),\n",
       "  (769, 47.00),\n",
       "  (807, 47.00),\n",
       "  (889, 47.00),\n",
       "  (891, 47.00),\n",
       "  (918, 47.00),\n",
       "  (983, 47.00),\n",
       "  (5, 46.00),\n",
       "  (28, 46.00),\n",
       "  (53, 46.00),\n",
       "  (66, 46.00),\n",
       "  (130, 46.00),\n",
       "  (136, 46.00),\n",
       "  (144, 46.00),\n",
       "  (157, 46.00),\n",
       "  (191, 46.00),\n",
       "  (201, 46.00),\n",
       "  (212, 46.00),\n",
       "  (243, 46.00),\n",
       "  (257, 46.00),\n",
       "  (264, 46.00),\n",
       "  (279, 46.00),\n",
       "  (312, 46.00),\n",
       "  (323, 46.00),\n",
       "  (350, 46.00),\n",
       "  (377, 46.00),\n",
       "  (384, 46.00),\n",
       "  (392, 46.00),\n",
       "  (560, 46.00),\n",
       "  (566, 46.00),\n",
       "  (579, 46.00),\n",
       "  (659, 46.00),\n",
       "  (702, 46.00),\n",
       "  (706, 46.00),\n",
       "  (732, 46.00),\n",
       "  (823, 46.00),\n",
       "  (872, 46.00),\n",
       "  (993, 46.00),\n",
       "  (16, 45.00),\n",
       "  (40, 45.00),\n",
       "  (75, 45.00),\n",
       "  (105, 45.00),\n",
       "  (110, 45.00),\n",
       "  (131, 45.00),\n",
       "  (188, 45.00),\n",
       "  (215, 45.00),\n",
       "  (252, 45.00),\n",
       "  (324, 45.00),\n",
       "  (339, 45.00),\n",
       "  (355, 45.00),\n",
       "  (365, 45.00),\n",
       "  (381, 45.00),\n",
       "  (389, 45.00),\n",
       "  (397, 45.00),\n",
       "  (426, 45.00),\n",
       "  (475, 45.00),\n",
       "  (537, 45.00),\n",
       "  (613, 45.00),\n",
       "  (674, 45.00),\n",
       "  (758, 45.00),\n",
       "  (759, 45.00),\n",
       "  (796, 45.00),\n",
       "  (853, 45.00),\n",
       "  (867, 45.00),\n",
       "  (882, 45.00),\n",
       "  (900, 45.00),\n",
       "  (968, 45.00),\n",
       "  (981, 45.00),\n",
       "  (2, 44.00),\n",
       "  (17, 44.00),\n",
       "  (42, 44.00),\n",
       "  (44, 44.00),\n",
       "  (101, 44.00),\n",
       "  (107, 44.00),\n",
       "  (132, 44.00),\n",
       "  (227, 44.00),\n",
       "  (245, 44.00),\n",
       "  (287, 44.00),\n",
       "  (370, 44.00),\n",
       "  (412, 44.00),\n",
       "  (414, 44.00),\n",
       "  (447, 44.00),\n",
       "  (817, 44.00),\n",
       "  (821, 44.00),\n",
       "  (929, 44.00),\n",
       "  (941, 44.00),\n",
       "  (959, 44.00),\n",
       "  (63, 43.00),\n",
       "  (65, 43.00),\n",
       "  (83, 43.00),\n",
       "  (93, 43.00),\n",
       "  (174, 43.00),\n",
       "  (244, 43.00),\n",
       "  (299, 43.00),\n",
       "  (330, 43.00),\n",
       "  (332, 43.00),\n",
       "  (349, 43.00),\n",
       "  (437, 43.00),\n",
       "  (456, 43.00),\n",
       "  (485, 43.00),\n",
       "  (520, 43.00),\n",
       "  (574, 43.00),\n",
       "  (575, 43.00),\n",
       "  (599, 43.00),\n",
       "  (658, 43.00),\n",
       "  (682, 43.00),\n",
       "  (710, 43.00),\n",
       "  (717, 43.00),\n",
       "  (723, 43.00),\n",
       "  (755, 43.00),\n",
       "  (756, 43.00),\n",
       "  (761, 43.00),\n",
       "  (782, 43.00),\n",
       "  (795, 43.00),\n",
       "  (873, 43.00),\n",
       "  (898, 43.00),\n",
       "  (907, 43.00),\n",
       "  (910, 43.00),\n",
       "  (919, 43.00),\n",
       "  (984, 43.00),\n",
       "  (999, 43.00),\n",
       "  (108, 42.00),\n",
       "  (112, 42.00),\n",
       "  (153, 42.00),\n",
       "  (223, 42.00),\n",
       "  (260, 42.00),\n",
       "  (265, 42.00),\n",
       "  (268, 42.00),\n",
       "  (305, 42.00),\n",
       "  (329, 42.00),\n",
       "  (353, 42.00),\n",
       "  (429, 42.00),\n",
       "  (430, 42.00),\n",
       "  (434, 42.00),\n",
       "  (473, 42.00),\n",
       "  (495, 42.00),\n",
       "  (510, 42.00),\n",
       "  (558, 42.00),\n",
       "  (633, 42.00),\n",
       "  (643, 42.00),\n",
       "  (672, 42.00),\n",
       "  (690, 42.00),\n",
       "  (996, 42.00),\n",
       "  (7, 41.00),\n",
       "  (19, 41.00),\n",
       "  (80, 41.00),\n",
       "  (142, 41.00),\n",
       "  (154, 41.00),\n",
       "  (173, 41.00),\n",
       "  (190, 41.00),\n",
       "  (258, 41.00),\n",
       "  (302, 41.00),\n",
       "  (306, 41.00),\n",
       "  (322, 41.00),\n",
       "  (360, 41.00),\n",
       "  (390, 41.00),\n",
       "  (393, 41.00),\n",
       "  (421, 41.00),\n",
       "  (462, 41.00),\n",
       "  (486, 41.00),\n",
       "  (501, 41.00),\n",
       "  (507, 41.00),\n",
       "  (530, 41.00),\n",
       "  (573, 41.00),\n",
       "  (712, 41.00),\n",
       "  (714, 41.00),\n",
       "  (734, 41.00),\n",
       "  (837, 41.00),\n",
       "  (844, 41.00),\n",
       "  (862, 41.00),\n",
       "  (933, 41.00),\n",
       "  (998, 41.00),\n",
       "  (27, 40.00),\n",
       "  (117, 40.00),\n",
       "  (127, 40.00),\n",
       "  (186, 40.00),\n",
       "  (210, 40.00),\n",
       "  (297, 40.00),\n",
       "  (368, 40.00),\n",
       "  (380, 40.00),\n",
       "  (417, 40.00),\n",
       "  (442, 40.00),\n",
       "  (466, 40.00),\n",
       "  (538, 40.00),\n",
       "  (630, 40.00),\n",
       "  (670, 40.00),\n",
       "  (713, 40.00),\n",
       "  (722, 40.00),\n",
       "  (749, 40.00),\n",
       "  (799, 40.00),\n",
       "  (812, 40.00),\n",
       "  (851, 40.00),\n",
       "  (920, 40.00),\n",
       "  (925, 40.00),\n",
       "  (52, 39.00),\n",
       "  (91, 39.00),\n",
       "  (140, 39.00),\n",
       "  (183, 39.00),\n",
       "  (224, 39.00),\n",
       "  (236, 39.00),\n",
       "  (242, 39.00),\n",
       "  (248, 39.00),\n",
       "  (309, 39.00),\n",
       "  (346, 39.00),\n",
       "  (357, 39.00),\n",
       "  (405, 39.00),\n",
       "  (500, 39.00),\n",
       "  (548, 39.00),\n",
       "  (559, 39.00),\n",
       "  (694, 39.00),\n",
       "  (699, 39.00),\n",
       "  (708, 39.00),\n",
       "  (726, 39.00),\n",
       "  (894, 39.00),\n",
       "  (932, 39.00),\n",
       "  (10, 38.00),\n",
       "  (43, 38.00),\n",
       "  (262, 38.00),\n",
       "  (347, 38.00),\n",
       "  (427, 38.00),\n",
       "  (464, 38.00),\n",
       "  (480, 38.00),\n",
       "  (540, 38.00),\n",
       "  (542, 38.00),\n",
       "  (555, 38.00),\n",
       "  (584, 38.00),\n",
       "  (656, 38.00),\n",
       "  (719, 38.00),\n",
       "  (736, 38.00),\n",
       "  (814, 38.00),\n",
       "  (859, 38.00),\n",
       "  (921, 38.00),\n",
       "  (928, 38.00),\n",
       "  (38, 37.00),\n",
       "  (98, 37.00),\n",
       "  (111, 37.00),\n",
       "  (198, 37.00),\n",
       "  (200, 37.00),\n",
       "  (207, 37.00),\n",
       "  (230, 37.00),\n",
       "  (235, 37.00),\n",
       "  (278, 37.00),\n",
       "  (296, 37.00),\n",
       "  (338, 37.00),\n",
       "  (374, 37.00),\n",
       "  (379, 37.00),\n",
       "  (418, 37.00),\n",
       "  (439, 37.00),\n",
       "  (513, 37.00),\n",
       "  (529, 37.00),\n",
       "  (553, 37.00),\n",
       "  (554, 37.00),\n",
       "  (786, 37.00),\n",
       "  (854, 37.00),\n",
       "  (945, 37.00),\n",
       "  (45, 36.00),\n",
       "  (62, 36.00),\n",
       "  (143, 36.00),\n",
       "  (145, 36.00),\n",
       "  (148, 36.00),\n",
       "  (152, 36.00),\n",
       "  (175, 36.00),\n",
       "  (204, 36.00),\n",
       "  (205, 36.00),\n",
       "  (314, 36.00),\n",
       "  (385, 36.00),\n",
       "  (399, 36.00),\n",
       "  (408, 36.00),\n",
       "  (435, 36.00),\n",
       "  (453, 36.00),\n",
       "  (470, 36.00),\n",
       "  (546, 36.00),\n",
       "  (588, 36.00),\n",
       "  (605, 36.00),\n",
       "  (610, 36.00),\n",
       "  (615, 36.00),\n",
       "  (678, 36.00),\n",
       "  (687, 36.00),\n",
       "  (720, 36.00),\n",
       "  (793, 36.00),\n",
       "  (802, 36.00),\n",
       "  (934, 36.00),\n",
       "  (20, 35.00),\n",
       "  (120, 35.00),\n",
       "  (213, 35.00),\n",
       "  (226, 35.00),\n",
       "  (359, 35.00),\n",
       "  (600, 35.00),\n",
       "  (632, 35.00),\n",
       "  (827, 35.00),\n",
       "  (831, 35.00),\n",
       "  (846, 35.00),\n",
       "  (883, 35.00),\n",
       "  (958, 35.00),\n",
       "  (26, 34.00),\n",
       "  (73, 34.00),\n",
       "  (220, 34.00),\n",
       "  (356, 34.00),\n",
       "  (409, 34.00),\n",
       "  (415, 34.00),\n",
       "  (450, 34.00),\n",
       "  (494, 34.00),\n",
       "  (511, 34.00),\n",
       "  (543, 34.00),\n",
       "  (585, 34.00),\n",
       "  (627, 34.00),\n",
       "  (677, 34.00),\n",
       "  (693, 34.00),\n",
       "  (861, 34.00),\n",
       "  (897, 34.00),\n",
       "  (923, 34.00),\n",
       "  (947, 34.00),\n",
       "  (86, 33.00),\n",
       "  (403, 33.00),\n",
       "  (465, 33.00),\n",
       "  (650, 33.00),\n",
       "  (798, 33.00),\n",
       "  (964, 33.00),\n",
       "  (980, 33.00),\n",
       "  (158, 32.00),\n",
       "  (371, 32.00),\n",
       "  (402, 32.00),\n",
       "  (461, 32.00),\n",
       "  (629, 32.00),\n",
       "  (634, 32.00),\n",
       "  (644, 32.00),\n",
       "  (647, 32.00),\n",
       "  (760, 32.00),\n",
       "  (948, 32.00),\n",
       "  (954, 32.00),\n",
       "  (59, 31.00),\n",
       "  (64, 31.00),\n",
       "  (81, 31.00),\n",
       "  (459, 31.00),\n",
       "  (498, 31.00),\n",
       "  (521, 31.00),\n",
       "  (531, 31.00),\n",
       "  (578, 31.00),\n",
       "  (589, 31.00),\n",
       "  (745, 31.00),\n",
       "  (803, 31.00),\n",
       "  (860, 31.00),\n",
       "  (966, 31.00),\n",
       "  (146, 30.00),\n",
       "  (179, 30.00),\n",
       "  (303, 30.00),\n",
       "  (567, 30.00),\n",
       "  (676, 30.00),\n",
       "  (744, 30.00),\n",
       "  (789, 30.00),\n",
       "  (4, 29.00),\n",
       "  (122, 29.00),\n",
       "  (166, 29.00),\n",
       "  (187, 29.00),\n",
       "  (233, 29.00),\n",
       "  (345, 29.00),\n",
       "  (484, 29.00),\n",
       "  (551, 29.00),\n",
       "  (557, 29.00),\n",
       "  (568, 29.00),\n",
       "  (617, 29.00),\n",
       "  (733, 29.00),\n",
       "  (914, 29.00),\n",
       "  (29, 28.00),\n",
       "  (32, 28.00),\n",
       "  (106, 28.00),\n",
       "  (147, 28.00),\n",
       "  (469, 28.00),\n",
       "  (482, 28.00),\n",
       "  (502, 28.00),\n",
       "  (544, 28.00),\n",
       "  (663, 28.00),\n",
       "  (686, 28.00),\n",
       "  (691, 28.00),\n",
       "  (747, 28.00),\n",
       "  (804, 28.00),\n",
       "  (931, 28.00),\n",
       "  (54, 27.00),\n",
       "  (150, 27.00),\n",
       "  (271, 27.00),\n",
       "  (587, 27.00),\n",
       "  (596, 27.00),\n",
       "  (624, 27.00),\n",
       "  (660, 27.00),\n",
       "  (705, 27.00),\n",
       "  (869, 27.00),\n",
       "  (369, 26.00),\n",
       "  (718, 26.00),\n",
       "  (731, 26.00),\n",
       "  (942, 26.00),\n",
       "  (965, 26.00),\n",
       "  (202, 25.00),\n",
       "  (240, 25.00),\n",
       "  (536, 25.00),\n",
       "  (767, 25.00),\n",
       "  (911, 25.00),\n",
       "  (974, 25.00),\n",
       "  (163, 24.00),\n",
       "  (168, 24.00),\n",
       "  (479, 24.00),\n",
       "  (516, 24.00),\n",
       "  (590, 24.00),\n",
       "  (631, 24.00),\n",
       "  (680, 24.00),\n",
       "  (876, 24.00),\n",
       "  (901, 24.00),\n",
       "  (909, 24.00),\n",
       "  (49, 23.00),\n",
       "  (165, 23.00),\n",
       "  (185, 23.00),\n",
       "  (623, 23.00),\n",
       "  (785, 23.00),\n",
       "  (811, 23.00),\n",
       "  (838, 23.00),\n",
       "  (856, 23.00),\n",
       "  (68, 22.00),\n",
       "  (315, 22.00),\n",
       "  (438, 22.00),\n",
       "  (499, 22.00),\n",
       "  (773, 22.00),\n",
       "  (394, 21.00),\n",
       "  (622, 21.00),\n",
       "  (638, 21.00),\n",
       "  (675, 21.00),\n",
       "  (729, 21.00),\n",
       "  (976, 21.00),\n",
       "  (525, 20.00),\n",
       "  (598, 20.00),\n",
       "  (662, 20.00),\n",
       "  (728, 20.00),\n",
       "  (908, 20.00),\n",
       "  (103, 19.00),\n",
       "  (246, 19.00),\n",
       "  (400, 19.00),\n",
       "  (550, 19.00),\n",
       "  (715, 19.00),\n",
       "  (740, 19.00),\n",
       "  (885, 19.00),\n",
       "  (282, 18.00),\n",
       "  (648, 18.00),\n",
       "  (836, 18.00),\n",
       "  (970, 18.00),\n",
       "  (651, 17.00),\n",
       "  (906, 17.00),\n",
       "  (930, 17.00),\n",
       "  (977, 17.00),\n",
       "  (446, 16.00),\n",
       "  (841, 16.00),\n",
       "  (460, 15.00),\n",
       "  (534, 15.00),\n",
       "  (969, 15.00),\n",
       "  (493, 14.00),\n",
       "  (504, 14.00),\n",
       "  (742, 14.00),\n",
       "  (813, 14.00),\n",
       "  (689, 13.00),\n",
       "  (34, 12.00),\n",
       "  (940, 12.00),\n",
       "  (967, 12.00),\n",
       "  (167, 11.00),\n",
       "  (899, 11.00),\n",
       "  (673, 10.00),\n",
       "  (960, 10.00),\n",
       "  (978, 9.00),\n",
       "  (681, 8.00),\n",
       "  (935, 8.00),\n",
       "  (810, 7.00),\n",
       "  (961, 2.00)])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#on test\n",
    "%precision 2\n",
    "# n, hist = targeted_diversity(learn, 150, 95)\n",
    "# n, hist\n",
    "n, hist = targeted_diversity(learn, 10, 95)\n",
    "n, hist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f59b994b4e0>]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# on test\n",
    "sorted_hist = sorted(hist, key=lambda x: x[0], reverse = False)\n",
    "values = [elem[1] for elem in sorted_hist]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.8493)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#on test\n",
    "entropy(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1fCvFG0VMKts"
   },
   "outputs": [],
   "source": [
    "def make_triplet_samples(z, margin, r2, r3):\n",
    "  positive_sample = z + random_vector_volume(z.shape, 0, margin).cuda() \n",
    "  negative_sample = z + random_vector_volume(z.shape, r2, r3).cuda()\n",
    "  return positive_sample, negative_sample\n",
    "\n",
    "def random_vector_surface(shape, r = 1.):\n",
    "  mat = torch.randn(size=shape).cuda()\n",
    "  norm = torch.norm(mat, p=2, dim=1, keepdim = True).cuda()\n",
    "  return (mat/norm) * r\n",
    "\n",
    "def random_vector_volume(shape, inner_r, outer_r):\n",
    "  fraction = torch.empty(shape[0]).uniform_(inner_r, outer_r).cuda()\n",
    "  fraction = ((fraction / outer_r) ** (1 / shape[1])) * outer_r # volume-normalize the fraction\n",
    "  fraction.unsqueeze_(-1)\n",
    "  return random_vector_surface(shape, 1) * fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PizmBkGqMKtu"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def most_frequent(x):\n",
    "  return Counter(x).most_common(1)[0]\n",
    "\n",
    "def preds_around(center, radius, n_preds, model, dummy_img):\n",
    "  z_s = random_vector_volume([n_preds, 10], radius, radius + 0.01) + center[None]\n",
    "  noises = model.forward_z(z_s)\n",
    "  perturbed_imgs = noises + dummy_img \n",
    "  return torch.argmax(arch(perturbed_imgs), 1)\n",
    "  \n",
    "def most_freq_pred_around(center, radius, n_preds, model, dummy_img):\n",
    "  preds = preds_around(center, radius, n_preds, model, dummy_img)\n",
    "  most_freq = most_frequent(preds.tolist())\n",
    "  return (class_index_to_label(most_freq[0]), most_freq[1]/n_preds)\n",
    "\n",
    "def investigate_neighborhood(z, step, model, dummy_img):\n",
    "  with torch.no_grad():\n",
    "    result = []\n",
    "    for radius in np.arange(0.1, 6., step):\n",
    "#       print(\"creating {} more preds\".format(int(10 + 5 * (radius ** 2))))\n",
    "      most_freq_pred = most_freq_pred_around(z, radius, int(10 + 5 * (radius ** 2)), model, dummy_img)\n",
    "      result.append((radius, most_freq_pred))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d-btRW4qMKtw",
    "outputId": "90e81f6a-1b9e-45a4-ae82-bda370319bd9"
   },
   "outputs": [],
   "source": [
    "#experiment 1\n",
    "\n",
    "z = torch.tensor([0.5] * 10).cuda()\n",
    "# z = torch.empty(10).uniform_(-1, 1).cuda()\n",
    "# z_s = z[None]\n",
    "\n",
    "model = learn.model.eval()\n",
    "x_img = normalize(learn.data.train_ds[50][0].data.cuda())\n",
    "  \n",
    "for i in range(6):\n",
    "  z = torch.empty(10).uniform_(-1, 1).cuda()\n",
    "  print(\"investigation for: \", z)\n",
    "  for elem in investigate_neighborhood(z, 0.5, model, x_img):\n",
    "    print(elem)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment 1-1: modified investigate_z\n",
    "z_investigate_path = '/root/Derakhshani/adversarial/textual_notes/investigate_z_{}.txt'.format(env.save_filename)\n",
    "if Path(z_investigate_path).exists(): raise FileExistsError(\"file already exists\")\n",
    "file = open(str(z_investigate_path), 'w')\n",
    "        \n",
    "for i, (z, noise) in enumerate(zip(pruned_z_s, pruned_noises)):\n",
    "  hist = compute_prediction_histogram(learn, noise)\n",
    "  indexed_hist = [(i, val) for i, val in enumerate(hist)]\n",
    "  sorted_hist = sorted(indexed_hist, key=lambda x: x[1], reverse=True)\n",
    "  labeled_hist = [(class_index_to_label(i), count) for i, count in sorted_hist]\n",
    "  print(\"result {}:\".format(i))\n",
    "  print(big_vector_to_str(z))\n",
    "  print(labeled_hist[:6])\n",
    "  print(\"\\n\\n\")\n",
    "  \n",
    "  file.write(\"result {}:\\n\".format(i))\n",
    "  file.write(big_vector_to_str(z) + \"\\n\")\n",
    "  file.write(str(labeled_hist[:6]))\n",
    "  file.write(\"\\n\\n\\n\")\n",
    "  file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bp6YOnipMKtz"
   },
   "outputs": [],
   "source": [
    "#experiment 2\n",
    "import itertools\n",
    "z_s = [torch.tensor(t).cuda() for t in itertools.product( *([[-0.33, 0.33]] * 10) )]\n",
    "model = learn.model.eval()\n",
    "noises = []\n",
    "with torch.no_grad():\n",
    "  for z in z_s:\n",
    "    noises.append(model.forward_single_z(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "55lErWDyMKt1",
    "outputId": "93d8fb71-3fd5-44a5-d3ec-8013e13f17ba"
   },
   "outputs": [],
   "source": [
    "x_img = normalize(learn.data.train_ds[50][0].data.cuda())\n",
    "\n",
    "preds = []\n",
    "for noise in noises:\n",
    "  perturbed_img = x_img + noise\n",
    "  preds.append(torch.argmax(arch(perturbed_img[None]), 1)[0].item())\n",
    "\n",
    "from collections import Counter\n",
    "result = [(class_index_to_label(index), count) for index, count in Counter(preds).most_common(5)]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4WSg-wBFMKt5"
   },
   "outputs": [],
   "source": [
    "#experiment 3\n",
    "import itertools\n",
    "dimension_values = [[-0.9, 0.9]] * z_dim\n",
    "for i in range(z_dim):\n",
    "  if i % 100 != 0:\n",
    "    dimension_values[i] = [0.]\n",
    "# dimension_values[0] = [0.]\n",
    "# dimension_values[3] = [0.]\n",
    "# dimension_values[6] = [0.]\n",
    "# dimension_values[9] = [0.]\n",
    "pruned_z_s = [torch.tensor(t).cuda() for t in itertools.product(*dimension_values)]\n",
    "model = learn.model.eval()\n",
    "with torch.no_grad():\n",
    "  pruned_noises = [model.forward_single_z(z) for z in pruned_z_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment 3: for the targeted-attack case\n",
    "pruned_z_s = []\n",
    "for i in range(z_dim):\n",
    "  new_z = torch.zeros(z_dim).cuda()\n",
    "  new_z[i] = 1.\n",
    "  pruned_z_s.append(new_z)\n",
    "  \n",
    "model = learn.model.eval()\n",
    "with torch.no_grad():\n",
    "  pruned_noises = [model.forward_single_z(z) for z in pruned_z_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment 3-1: noises for \n",
    "pruned_z_s = []\n",
    "# for i in range(z_dim):\n",
    "#   new_z = torch.empty(z_dim).uniform_(0,1).cuda().detach()\n",
    "#   pruned_z_s.append(new_z)\n",
    "\n",
    "for i in range(z_dim):\n",
    "  new_z = torch.zeros(z_dim).cuda().detach()\n",
    "  new_z[i] = 1.\n",
    "  pruned_z_s.append(new_z)\n",
    "  \n",
    "model = learn.model.eval()\n",
    "with torch.no_grad():\n",
    "  pruned_noises = [model.forward_single_z(z) for z in pruned_z_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for noise in pruned_noises[0:200]:\n",
    "  img = noise_to_image(noise)\n",
    "  img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spider web\n",
    "z_values = [\n",
    "  [ 0.33, -0.33,  0.33,  0.33, -0.33,  0.33, -0.33, -0.33, -0.33, -0.33],\n",
    "  [ 0.33,  0.33, -0.33, -0.33, -0.33,  0.33, -0.33,  0.33, -0.33, -0.33],\n",
    "  [ 0.33,  0.33, -0.33,  0.33,  0.33, -0.33, -0.33, -0.33,  0.33, -0.33],\n",
    "  [-0.33, -0.33, -0.33, -0.33, -0.33, -0.33, -0.33, -0.33, -0.33, -0.33],\n",
    "  [-0.33, -0.33, -0.33, -0.33, -0.33,  0.33,  0.33, -0.33,  0.33,  0.33],\n",
    "  [-0.33, -0.33, -0.33,  0.33,  0.33, -0.33, -0.33, -0.33, -0.33, -0.33],\n",
    "  [-0.33, -0.33,  0.33,  0.33, -0.33, -0.33,  0.33, -0.33,  0.33, -0.33],\n",
    "  [-0.33,  0.33, -0.33,  0.33,  0.33, -0.33,  0.33,  0.33,  0.33,  0.33],\n",
    "  [-0.33,  0.33,  0.33,  0.33, -0.33, -0.33,  0.33,  0.33, -0.33, -0.33],\n",
    "  [ 0.33, -0.33, -0.33, -0.33,  0.33,  0.33, -0.33, -0.33, -0.33, -0.33],\n",
    "  [ 0.33, -0.33,  0.33,  0.33, -0.33, -0.33,  0.33,  0.33, -0.33,  0.33],\n",
    "  [ 0.33,  0.33, -0.33,  0.33, -0.33, -0.33,  0.33,  0.33, -0.33,  0.33],\n",
    "  [ 0.33,  0.33,  0.33, -0.33, -0.33, -0.33, -0.33,  0.33, -0.33, -0.33],\n",
    "  [ 0.33,  0.33,  0.33,  0.33, -0.33, -0.33, -0.33,  0.33, -0.33, -0.33],\n",
    "  [ 0.33,  0.33,  0.33,  0.33,  0.33,  0.33,  0.33,  0.33,  0.33, -0.33],\n",
    "  [ 0.33,  0.33,  0.33, -0.33, -0.33, -0.33, -0.33,  0.33,  0.33, -0.33],\n",
    "]\n",
    "\n",
    "if any(z_values.count(x) > 1 for x in z_values):\n",
    "  raise Exception(\"duplicate\")\n",
    "  \n",
    "z_s = [torch.tensor(z).cuda() for z in z_values]\n",
    "model = learn.model.eval()\n",
    "\n",
    "for z in z_s:\n",
    "  img = noise_to_image(model.forward_single_z(z))\n",
    "  img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_values = [\n",
    "  # window screen\n",
    "  [-0.33,  0.33,  0.33, -0.33, -0.33,  0.33, -0.33, -0.33, -0.33, -0.33],\n",
    "  [-0.33,  0.33,  0.33, -0.33, -0.33, -0.33, -0.33, -0.33,  0.33,  0.33],\n",
    "]\n",
    "\n",
    "if any(z_values.count(x) > 1 for x in z_values):\n",
    "  raise Exception(\"duplicate\")\n",
    "  \n",
    "z_s = [torch.tensor(z).cuda() for z in z_values]\n",
    "model = learn.model.eval()\n",
    "\n",
    "for z in z_s:\n",
    "  img = noise_to_image(model.forward_single_z(z))\n",
    "  img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KuAVZzmKMKt9",
    "outputId": "7e6643e0-ce55-438b-e0ae-79bde3ee4cef"
   },
   "outputs": [],
   "source": [
    "#vgg-16_12 most repeated labels:\n",
    "l = [(611, 215.0),\n",
    "  (474, 194.1),\n",
    "  (398, 120.3),\n",
    "  (721, 79.6),\n",
    "  (741, 73.5),\n",
    "  (510, 62.5)]\n",
    "\n",
    "[(class_index_to_label(index), count) for index, count in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FAgk-YyWc3rG"
   },
   "outputs": [],
   "source": [
    "# learn.recorder.plot_losses()\n",
    "# learn.recorder.plot_lr()\n",
    "# learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YTHG4Bt7VDYp"
   },
   "outputs": [],
   "source": [
    "fooling_rates = []\n",
    "model = learn.model.eval()\n",
    "learn.metrics = [validation_single_perturbation]\n",
    "for i in range(10):\n",
    "  global_perturbations = model(torch.rand(1, 3, 224, 244).cuda())[0]\n",
    "  nag_util.global_perturbations = global_perturbations\n",
    "  fooling_rates.append(learn.validate()[1].cpu().item())\n",
    "  print(\"%d : %f\"%(i, fooling_rates[-1]))\n",
    "\n",
    "mean = np.mean(fooling_rates)\n",
    "stddev = np.std(fooling_rates)\n",
    "print(mean, stddev); print(fooling_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "colab_type": "code",
    "id": "OFCjzI7UaY3C",
    "outputId": "740185b4-dd54-46f4-b0af-79ee452568e1"
   },
   "outputs": [],
   "source": [
    "#the Image works good for floats in range [0..1]\n",
    "model = learn.model.eval()\n",
    "\n",
    "x_img = learn.data.train_ds[200][0]\n",
    "x = normalize(x_img.data.cuda())\n",
    "z = torch.tensor([-0.33,  0.33, -0.33, -0.33, -0.33,  0.33,  0.33, -0.33, -0.33, -0.33], dtype=torch.float32).cuda()\n",
    "# z = torch.empty(z_dim).uniform_(-1,1).cuda()\n",
    "p = model.forward_single_z(z).detach()\n",
    "\n",
    "p_x = x + p\n",
    "# print(\"img range, noise range\")\n",
    "# print_range(x); print_range(p)\n",
    "adv_label = class_index_to_label(arch(p_x[None]).argmax(1).item())\n",
    "print_big_vector(arch(p_x[None])[0])\n",
    "p_x = denormalize(p_x)\n",
    "p_x.clamp_(0,1)\n",
    "\n",
    "\n",
    "#prepare images\n",
    "p_x_img = Image(p_x)\n",
    "p = scale_to_range(p, [0., 1.])\n",
    "p_img = Image(p)\n",
    "x_img.show()\n",
    "p_img.show()\n",
    "p_x_img.show()\n",
    "\n",
    "\n",
    "# print_range(p)\n",
    "# print_range(denormalize(x))\n",
    "# print_range(p_x)\n",
    "\n",
    "benign_label = class_index_to_label(arch(x[None]).argmax(1).item())\n",
    "\n",
    "print_big_vector(arch(x[None])[0])\n",
    "print(benign_label, adv_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mzwsI2P1ZANz"
   },
   "outputs": [],
   "source": [
    "z1 = torch.tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1], dtype=torch.float32).cuda()\n",
    "p1 = model.forward_single_z(z1)\n",
    "\n",
    "z2 = torch.tensor([1, -1, -1, -1, -1, -1, -1, -1, -1, -1], dtype=torch.float32).cuda()\n",
    "p2 = model.forward_single_z(z2)\n",
    "\n",
    "z3 = torch.tensor([1, 1, -1, -1, -1, -1, -1, -1, -1, -1], dtype=torch.float32).cuda()\n",
    "p3 = model.forward_single_z(z3)\n",
    "\n",
    "l2_distance(p1, p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eroI82OKSnAL"
   },
   "outputs": [],
   "source": [
    "#the Image works good for floats in range [0..1]\n",
    "model = learn.model.eval()\n",
    "\n",
    "x_img = learn.data.train_ds[4][0]\n",
    "x = x_img.data[None].cuda()\n",
    "p = model(x)[0].squeeze().detach() \n",
    "x = x.squeeze()\n",
    "x = normalize(x)\n",
    "\n",
    "p_x = x + p\n",
    "p_x = denormalize(p_x)\n",
    "p_x.clamp_(0,1)\n",
    "\n",
    "\n",
    "#prepare images\n",
    "p_x_img = Image(p_x)\n",
    "p = scale_to_range(p, [0.,1.])\n",
    "p_img = Image(p)\n",
    "# x_img.show()\n",
    "p_img.show()\n",
    "# p_x_img.show()\n",
    "\n",
    "print_range(p)\n",
    "print_range(x)\n",
    "print_range(p_x)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "NAG-tripletLossExperiment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
